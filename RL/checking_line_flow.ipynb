{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55eb063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/swagger_spec_validator/validator12.py:18: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/swagger_spec_validator/validator12.py:18: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/swagger_spec_validator/ref_validators.py:14: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema.validators import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/swagger_spec_validator/validator20.py:18: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema.validators import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/bravado_core/swagger20_validator.py:6: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/bravado_core/swagger20_validator.py:6: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/bravado_core/spec.py:14: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema.validators import RefResolver\n",
      "[neptune] [warning] NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs-legacy.neptune.ai/setup/upgrading/\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# Suppress PyPSA INFO messages (keep warnings and errors)\n",
    "logging.getLogger('pypsa').setLevel(logging.WARNING)\n",
    "\n",
    "import pypsa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "import gc\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import neptune\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "#import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05420ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_artificial_lines_reasonable(network):\n",
    "    \"\"\"\n",
    "    Fix artificial lines with reasonable capacity values:\n",
    "    - s_nom = based on connected bus demand (with safety factor)\n",
    "    - s_nom_extendable = False (non-extendable)\n",
    "    - Keep capacity high enough to meet demand\n",
    "    \"\"\"\n",
    "    print(\"=== FIXING ARTIFICIAL LINES WITH REASONABLE CAPACITY ===\")\n",
    "\n",
    "    # Find artificial lines\n",
    "    artificial_lines = [line for line in network.lines.index\n",
    "                       if any(keyword in str(line).lower() for keyword in ['new', '<->', 'artificial'])]\n",
    "\n",
    "    if not artificial_lines:\n",
    "        # If no artificial lines found by name, look for lines with s_nom=0\n",
    "        # which is often a sign of artificial lines\n",
    "        zero_capacity_lines = network.lines[network.lines.s_nom == 0].index.tolist()\n",
    "        if zero_capacity_lines:\n",
    "            artificial_lines = zero_capacity_lines\n",
    "\n",
    "    print(f\"Found {len(artificial_lines)} artificial lines to fix:\")\n",
    "\n",
    "    # Get maximum demand per bus across all snapshots\n",
    "    bus_max_demand = {}\n",
    "    for bus in network.buses.index:\n",
    "        bus_demand = 0\n",
    "        for load_name, load in network.loads.iterrows():\n",
    "            if load.bus == bus and load_name in network.loads_t.p_set.columns:\n",
    "                bus_demand = max(bus_demand, network.loads_t.p_set[load_name].max())\n",
    "        bus_max_demand[bus] = bus_demand\n",
    "\n",
    "    # Fix each artificial line with reasonable capacity\n",
    "    for line_name in artificial_lines:\n",
    "        # Get connected buses\n",
    "        bus0 = network.lines.loc[line_name, 'bus0']\n",
    "        bus1 = network.lines.loc[line_name, 'bus1']\n",
    "\n",
    "        # Get maximum demand at these buses\n",
    "        bus0_demand = bus_max_demand.get(bus0, 0)\n",
    "        bus1_demand = bus_max_demand.get(bus1, 0)\n",
    "\n",
    "        # Calculate required capacity with safety factor\n",
    "        # Use 3x the higher demand to ensure adequate capacity\n",
    "        safety_factor = 3.0\n",
    "        required_capacity = max(bus0_demand, bus1_demand) * safety_factor\n",
    "\n",
    "        # Ensure minimum reasonable capacity (1000 MW)\n",
    "        required_capacity = max(required_capacity, 1000)\n",
    "\n",
    "        print(f\"\\n Fixing: {line_name}\")\n",
    "        print(f\"    Connected buses: {bus0} ↔ {bus1}\")\n",
    "        print(f\"    Bus demands: {bus0}: {bus0_demand:.1f} MW, {bus1}: {bus1_demand:.1f} MW\")\n",
    "\n",
    "        # Set s_nom to required capacity\n",
    "        old_s_nom = network.lines.loc[line_name, 's_nom']\n",
    "        network.lines.loc[line_name, 's_nom'] = required_capacity\n",
    "        print(f\"    s_nom: {old_s_nom} → {required_capacity:.1f} MW\")\n",
    "\n",
    "        # Make sure line is not extendable\n",
    "        if 's_nom_extendable' not in network.lines.columns:\n",
    "            network.lines['s_nom_extendable'] = False\n",
    "        network.lines.loc[line_name, 's_nom_extendable'] = False\n",
    "        print(f\"    s_nom_extendable: → False\")\n",
    "\n",
    "    return network\n",
    "\n",
    "def remove_offshore_wind(network):\n",
    "    \"\"\"\n",
    "    Remove offshore wind generators. \n",
    "    All of these have zero nominal capacity (likely missing data). \n",
    "    Need to remove them to avoid division by zero error in constraint check for slack gens.\n",
    "    Problem is still feasible without offwind slack since pypsa optimize still feasible.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, identify offshore wind generators\n",
    "    offwind_gens = network.generators[\n",
    "        network.generators.index.str.contains('offwind', case=False, na=False)\n",
    "    ].index\n",
    "    \n",
    "    print(f\"Found {len(offwind_gens)} offshore wind generators:\")\n",
    "    print(offwind_gens.tolist())\n",
    "    \n",
    "    # Check their properties\n",
    "    offwind_data = network.generators.loc[offwind_gens, ['p_nom', 'control', 'carrier']]\n",
    "    print(\"\\nOffshore wind generator details:\")\n",
    "    print(offwind_data)\n",
    "    \n",
    "    # Remove offshore wind generators one by one\n",
    "    print(f\"\\nRemoving {len(offwind_gens)} offshore wind generators...\")\n",
    "    for gen in offwind_gens:\n",
    "        network.remove(\"Generator\", gen)\n",
    "\n",
    "def create_pypsa_network(network_file):\n",
    "    \"\"\"Create a PyPSA network from the .nc file.\"\"\"\n",
    "    # Initialize network\n",
    "    network = pypsa.Network(network_file)\n",
    "    for storage_name in network.storage_units.index:\n",
    "        # Use .loc for direct assignment to avoid SettingWithCopyWarning\n",
    "        network.storage_units.loc[storage_name, 'cyclic_state_of_charge'] = False\n",
    "\n",
    "        # Set marginal_cost to 0.01\n",
    "        network.storage_units.loc[storage_name, 'marginal_cost'] = 0.01\n",
    "\n",
    "        # Set marginal_cost_storage to 0.01\n",
    "        network.storage_units.loc[storage_name, 'marginal_cost_storage'] = 0.01\n",
    "\n",
    "        # Set spill_cost to 0.1\n",
    "        network.storage_units.loc[storage_name, 'spill_cost'] = 0.1\n",
    "\n",
    "        network.storage_units.loc[storage_name, 'efficiency_store'] = 0.866025 #use phs efficiency (hydro didnt have an efficiency, but i want to model them all as the same)\n",
    "\n",
    "        # Fix unrealistic max_hours values\n",
    "        current_max_hours = network.storage_units.loc[storage_name, 'max_hours']\n",
    "\n",
    "        if 'PHS' in storage_name:\n",
    "            # PHS with missing data - set to typical range\n",
    "            network.storage_units.loc[storage_name, 'max_hours'] = 8.0\n",
    "            print(f\"Fixed {storage_name}: set max_hours to 8.0\")\n",
    "\n",
    "        elif 'hydro' in storage_name:\n",
    "            # Hydro with unrealistic data - set to validated range\n",
    "            network.storage_units.loc[storage_name, 'max_hours'] = 6.0\n",
    "            print(f\"Fixed {storage_name}: corrected max_hours from {current_max_hours} to 6.0\")\n",
    "\n",
    "\n",
    "    fix_artificial_lines_reasonable(network)\n",
    "    remove_offshore_wind(network)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8913a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed ZA0 0 PHS: set max_hours to 8.0\n",
      "Fixed ZA0 5 PHS: set max_hours to 8.0\n",
      "Fixed ZA0 6 hydro: corrected max_hours from 3831.6270020496813 to 6.0\n",
      "=== FIXING ARTIFICIAL LINES WITH REASONABLE CAPACITY ===\n",
      "Found 3 artificial lines to fix:\n",
      "\n",
      " Fixing: lines new ZA0 4 <-> ZA2 0 AC\n",
      "    Connected buses: ZA0 4 ↔ ZA2 0\n",
      "    Bus demands: ZA0 4: 15945.8 MW, ZA2 0: 452.6 MW\n",
      "    s_nom: 0.0 → 47837.3 MW\n",
      "    s_nom_extendable: → False\n",
      "\n",
      " Fixing: lines new ZA0 0 <-> ZA1 0 AC\n",
      "    Connected buses: ZA0 0 ↔ ZA1 0\n",
      "    Bus demands: ZA0 0: 3513.0 MW, ZA1 0: 1386.9 MW\n",
      "    s_nom: 0.0 → 10538.9 MW\n",
      "    s_nom_extendable: → False\n",
      "\n",
      " Fixing: lines new ZA0 0 <-> ZA3 0 AC\n",
      "    Connected buses: ZA0 0 ↔ ZA3 0\n",
      "    Bus demands: ZA0 0: 3513.0 MW, ZA3 0: 721.1 MW\n",
      "    s_nom: 0.0 → 10538.9 MW\n",
      "    s_nom_extendable: → False\n",
      "Found 12 offshore wind generators:\n",
      "['ZA0 1 offwind-ac', 'ZA0 1 offwind-dc', 'ZA0 5 offwind-ac', 'ZA0 5 offwind-dc', 'ZA0 7 offwind-ac', 'ZA0 7 offwind-dc', 'ZA0 8 offwind-ac', 'ZA0 8 offwind-dc', 'ZA1 0 offwind-ac', 'ZA1 0 offwind-dc', 'ZA3 0 offwind-ac', 'ZA3 0 offwind-dc']\n",
      "\n",
      "Offshore wind generator details:\n",
      "                  p_nom control     carrier\n",
      "Generator                                  \n",
      "ZA0 1 offwind-ac    0.0          offwind-ac\n",
      "ZA0 1 offwind-dc    0.0          offwind-dc\n",
      "ZA0 5 offwind-ac    0.0          offwind-ac\n",
      "ZA0 5 offwind-dc    0.0          offwind-dc\n",
      "ZA0 7 offwind-ac    0.0          offwind-ac\n",
      "ZA0 7 offwind-dc    0.0          offwind-dc\n",
      "ZA0 8 offwind-ac    0.0          offwind-ac\n",
      "ZA0 8 offwind-dc    0.0          offwind-dc\n",
      "ZA1 0 offwind-ac    0.0   Slack  offwind-ac\n",
      "ZA1 0 offwind-dc    0.0          offwind-dc\n",
      "ZA3 0 offwind-ac    0.0   Slack  offwind-ac\n",
      "ZA3 0 offwind-dc    0.0          offwind-dc\n",
      "\n",
      "Removing 12 offshore wind generators...\n"
     ]
    }
   ],
   "source": [
    "network = create_pypsa_network(\"elec_s_10_ec_lc1.0_1h.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f6b5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_line_constraints(network, current_snapshot):\n",
    "    constraint_results = np.zeros(len(network.lines.index))\n",
    "    for idx, line_name in enumerate(network.lines.index):\n",
    "            # Get line parameters\n",
    "            s_nom = network.lines.loc[line_name, 's_nom']\n",
    "            \n",
    "            # Get s_max_pu if it exists in time series, otherwise use 1.0\n",
    "            if hasattr(network.lines_t, 's_max_pu') and line_name in network.lines_t.s_max_pu.columns:\n",
    "                s_max_pu = network.lines_t.s_max_pu.loc[current_snapshot, line_name]\n",
    "            else:\n",
    "                s_max_pu = network.lines.loc[line_name, 's_max_pu'] if 's_max_pu' in network.lines.columns else 1.0\n",
    "\n",
    "            # Calculate the actual flow limit\n",
    "            s_max = s_max_pu * s_nom\n",
    "\n",
    "            # Get power flows\n",
    "            p0 = network.lines_t.p0.loc[current_snapshot, line_name]\n",
    "            \n",
    "            # In PyPSA's linear power flow, the constraint is typically |P| ≤ S_nom\n",
    "            # since reactive power is not modeled in LPF\n",
    "            flow_magnitude = abs(p0)\n",
    "\n",
    "            # Check if flow exceeds limit\n",
    "            if flow_magnitude > s_max:\n",
    "                violation = min(float((flow_magnitude - s_max)/s_max), 1.0)\n",
    "                constraint_results[idx] = violation  # Use idx instead of constraint_results_idx\n",
    "\n",
    "    return constraint_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f871460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.determine_network_topology()\n",
    "        \n",
    "# Step 2: Pre-compute power flow matrices for each sub-network\n",
    "for sub in network.sub_networks.obj:\n",
    "    sub.calculate_B_H()\n",
    "\n",
    "# Initialize p_set for generators if it doesn't exist\n",
    "if 'p_set' not in network.generators_t:\n",
    "    print(\"Creating generators_t.p_set since it doesn't exist\")\n",
    "    network.generators_t['p_set'] = pd.DataFrame(index=network.snapshots, \n",
    "                                               columns=network.generators.index,\n",
    "                                               data=0.0)\n",
    "            \n",
    "renewable_gens = network.generators_t.p_max_pu.columns\n",
    "\n",
    "slack_generators = network.generators[network.generators.control == \"Slack\"].index\n",
    "# in the 10-node SA network there are 4 slack gens so this should return a list of indexes\n",
    "dispatchable_gens = network.generators[\n",
    "    (~network.generators.index.isin(slack_generators)) &\n",
    "    (~network.generators.index.isin(renewable_gens))\n",
    "].index\n",
    "\n",
    "# Renewable generators: have time-varying p_max_pu, not slack\n",
    "renewable_gens = network.generators[\n",
    "    (network.generators.index.isin(renewable_gens)) &\n",
    "    (~network.generators.index.isin(slack_generators))\n",
    "].index\n",
    "\n",
    "# Storage units (if any exist in the network)\n",
    "storage_units = network.storage_units.index\n",
    "\n",
    "# Store names as lists for easier indexing\n",
    "dispatchable_names = list(dispatchable_gens)\n",
    "renewable_names = list(renewable_gens)\n",
    "storage_names = list(storage_units)\n",
    "\n",
    "# Get static limits for dispatchable generators\n",
    "dispatchable_df = network.generators.loc[dispatchable_gens]\n",
    "disp_p_min = (dispatchable_df.p_min_pu * dispatchable_df.p_nom).values #returns numpy arrays\n",
    "disp_p_max = (dispatchable_df.p_max_pu * dispatchable_df.p_nom).values\n",
    "\n",
    "# Get nominal capacities and minimum limits for renewable generators\n",
    "renewable_df = network.generators.loc[renewable_gens]\n",
    "renewable_p_nom = renewable_df.p_nom.values\n",
    "renewable_p_min_pu = renewable_df.p_min_pu.values\n",
    "\n",
    "storage_df = network.storage_units.loc[storage_units]\n",
    "#this is a bit redundant since self.storage_units is the array of all indices of self.network.storage_units but leave it in so could replace which indices you want\n",
    "storage_p_nom = storage_df.p_nom.values\n",
    "\n",
    "def take_worst_action(network, current_snapshot, dispatchable_names, renewable_names, storage_names, disp_p_min, disp_p_max, renewable_p_nom, renewable_p_min_pu, storage_p_nom):\n",
    "    \"\"\"Set all generators to minimum power to create worst-case scenario\"\"\"\n",
    "    # Set all dispatchable generators to minimum power\n",
    "    for i, gen_name in enumerate(dispatchable_names):\n",
    "        min_power = disp_p_min[i]\n",
    "        network.generators_t.p_set.loc[current_snapshot, gen_name] = min_power\n",
    "    \n",
    "    # Set all renewable generators to minimum (usually zero)\n",
    "    for i, gen_name in enumerate(renewable_names):\n",
    "        min_power = renewable_p_min_pu[i] * renewable_p_nom[i]\n",
    "        network.generators_t.p_set.loc[current_snapshot, gen_name] = min_power\n",
    "    \n",
    "    # Set all storage units to zero dispatch and zero set\n",
    "    for storage_name in storage_names:\n",
    "        # Initialize time-dependent storage parameters if they don't exist\n",
    "        for attr in ['p_dispatch', 'p_set', 'p_store']:\n",
    "            if attr not in network.storage_units_t:\n",
    "                network.storage_units_t[attr] = pd.DataFrame(index=network.snapshots,\n",
    "                                                           columns=network.storage_units.index,\n",
    "                                                           data=0.0)\n",
    "        \n",
    "        network.storage_units_t.p_dispatch.loc[current_snapshot, storage_name] = 0.0\n",
    "        network.storage_units_t.p_set.loc[current_snapshot, storage_name] = 0.0\n",
    "        network.storage_units_t.p_store.loc[current_snapshot, storage_name] = 0.0\n",
    "    \n",
    "    # Run power flow\n",
    "    try:\n",
    "        network.lpf(current_snapshot, skip_pre=True)\n",
    "        converged = True\n",
    "    except Exception as e:\n",
    "        print(f\"Power flow failed for snapshot {current_snapshot}: {e}\")\n",
    "        converged = False\n",
    "    \n",
    "    return converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7db0bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispatchable generators: ['ZA0 1 CCGT', 'ZA0 3 biomass', 'ZA0 3 coal', 'ZA0 4 CCGT', 'ZA0 4 coal', 'ZA0 5 CCGT', 'ZA0 5 nuclear', 'ZA0 7 CCGT', 'ZA0 7 coal', 'ZA0 8 CCGT', 'ZA0 8 biomass', 'ZA0 9 coal']\n",
      "Renewable generators: ['ZA0 0 onwind', 'ZA0 0 ror', 'ZA0 0 solar', 'ZA0 1 onwind', 'ZA0 1 solar', 'ZA0 2 onwind', 'ZA0 2 ror', 'ZA0 2 solar', 'ZA0 3 onwind', 'ZA0 3 ror', 'ZA0 3 solar', 'ZA0 4 onwind', 'ZA0 4 solar', 'ZA0 5 onwind', 'ZA0 5 solar', 'ZA0 6 onwind', 'ZA0 6 solar', 'ZA0 7 onwind', 'ZA0 7 solar', 'ZA0 8 onwind', 'ZA0 8 ror', 'ZA0 8 solar', 'ZA0 9 onwind', 'ZA0 9 solar', 'ZA1 0 onwind', 'ZA1 0 solar', 'ZA2 0 onwind', 'ZA2 0 solar', 'ZA3 0 onwind', 'ZA3 0 solar']\n",
      "Storage units: ['ZA0 0 PHS', 'ZA0 5 PHS', 'ZA0 6 hydro']\n",
      "Total line constraint violations: 330.872225422805\n"
     ]
    }
   ],
   "source": [
    "# Reset network and initialize variables\n",
    "violation_sum = 0\n",
    "\n",
    "# Print information about the generators for debugging\n",
    "print(f\"Dispatchable generators: {dispatchable_names}\")\n",
    "print(f\"Renewable generators: {renewable_names}\")\n",
    "print(f\"Storage units: {storage_names}\")\n",
    "\n",
    "# # Check if we need to limit the number of snapshots to process\n",
    "# max_snapshots = 24  # Process only one day (24 hours) to avoid excessive warnings\n",
    "# snapshots_to_process = network.snapshots[:max_snapshots]\n",
    "# print(f\"Processing {len(snapshots_to_process)} snapshots out of {len(network.snapshots)} total\")\n",
    "\n",
    "# Create p_set if it doesn't exist\n",
    "if 'p_set' not in network.generators_t:\n",
    "    print(\"Creating generators_t.p_set since it doesn't exist\")\n",
    "    network.generators_t['p_set'] = pd.DataFrame(index=network.snapshots, \n",
    "                                               columns=network.generators.index,\n",
    "                                               data=0.0)\n",
    "\n",
    "# Loop through snapshots\n",
    "for snapshot_idx, current_snapshot in enumerate(network.snapshots):\n",
    "    # Take worst action for this snapshot\n",
    "    converged = take_worst_action(network, current_snapshot, dispatchable_names, renewable_names, \n",
    "                     storage_names, disp_p_min, disp_p_max, renewable_p_nom, \n",
    "                     renewable_p_min_pu, storage_p_nom)\n",
    "    \n",
    "    if converged:\n",
    "        # Check for constraint violations\n",
    "        constraint_results = check_line_constraints(network, current_snapshot)\n",
    "        violation_sum += np.sum(constraint_results)\n",
    "    else:\n",
    "        print(f\"Skipping constraint check for snapshot {snapshot_idx} due to power flow failure\")\n",
    "\n",
    "print(f\"Total line constraint violations: {violation_sum}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypsa-earth-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

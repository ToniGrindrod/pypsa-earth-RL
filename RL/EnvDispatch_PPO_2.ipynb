{"cells":[{"cell_type":"code","execution_count":1,"id":"PJfT8e2MPYnj","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJfT8e2MPYnj","outputId":"7d2a91d2-c1b7-4086-ccdb-41416c9bf460","executionInfo":{"status":"ok","timestamp":1757610521368,"user_tz":-120,"elapsed":36477,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypsa\n","  Downloading pypsa-0.35.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pypsa) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pypsa) (1.16.1)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from pypsa) (2.2.2)\n","Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (from pypsa) (2025.9.0)\n","Collecting netcdf4 (from pypsa)\n","  Downloading netCDF4-1.7.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting linopy>=0.4 (from pypsa)\n","  Downloading linopy-0.5.7-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pypsa) (3.10.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from pypsa) (5.24.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from pypsa) (0.13.2)\n","Requirement already satisfied: geopandas>=0.9 in /usr/local/lib/python3.12/dist-packages (from pypsa) (1.1.1)\n","Collecting shapely<2.1 (from pypsa)\n","  Downloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: networkx>=2 in /usr/local/lib/python3.12/dist-packages (from pypsa) (3.5)\n","Collecting deprecation (from pypsa)\n","  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n","Collecting validators (from pypsa)\n","  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: highspy in /usr/local/lib/python3.12/dist-packages (from pypsa) (1.11.0)\n","Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas>=0.9->pypsa) (0.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas>=0.9->pypsa) (25.0)\n","Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas>=0.9->pypsa) (3.7.2)\n","Requirement already satisfied: bottleneck in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (1.4.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (0.12.1)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (2.11.0)\n","Requirement already satisfied: dask>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (2025.5.0)\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (1.25.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (4.67.1)\n","Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (2.19.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (2.32.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->pypsa) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->pypsa) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->pypsa) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (4.59.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (3.2.3)\n","Collecting cftime (from netcdf4->pypsa)\n","  Downloading cftime-1.6.4.post1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netcdf4->pypsa) (2025.8.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->pypsa) (8.5.0)\n","Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (8.2.1)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (3.1.1)\n","Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (2025.3.0)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (6.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24->pypsa) (1.17.0)\n","Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->linopy>=0.4->pypsa) (2.38.0)\n","Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->linopy>=0.4->pypsa) (2.25.1)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->linopy>=0.4->pypsa) (2.4.3)\n","Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->linopy>=0.4->pypsa) (2.7.2)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->linopy>=0.4->pypsa) (1.7.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->linopy>=0.4->pypsa) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->linopy>=0.4->pypsa) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->linopy>=0.4->pypsa) (2.5.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->linopy>=0.4->pypsa) (1.70.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->linopy>=0.4->pypsa) (5.29.5)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->linopy>=0.4->pypsa) (1.26.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->linopy>=0.4->pypsa) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->linopy>=0.4->pypsa) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->linopy>=0.4->pypsa) (4.9.1)\n","Requirement already satisfied: locket in /usr/local/lib/python3.12/dist-packages (from partd>=1.4.0->dask>=0.18.0->linopy>=0.4->pypsa) (1.0.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage->linopy>=0.4->pypsa) (0.6.1)\n","Downloading pypsa-0.35.2-py3-none-any.whl (267 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.3/267.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading linopy-0.5.7-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n","Downloading netCDF4-1.7.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cftime-1.6.4.post1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: validators, shapely, deprecation, cftime, netcdf4, linopy, pypsa\n","  Attempting uninstall: shapely\n","    Found existing installation: shapely 2.1.1\n","    Uninstalling shapely-2.1.1:\n","      Successfully uninstalled shapely-2.1.1\n","Successfully installed cftime-1.6.4.post1 deprecation-2.1.0 linopy-0.5.7 netcdf4-1.7.2 pypsa-0.35.2 shapely-2.0.7 validators-0.35.0\n","Collecting neptune-client\n","  Downloading neptune_client-1.14.0-py3-none-any.whl.metadata (5.0 kB)\n","Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (3.1.45)\n","Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (11.3.0)\n","Requirement already satisfied: PyJWT in /usr/local/lib/python3.12/dist-packages (from neptune-client) (2.10.1)\n","Collecting boto3>=1.28.0 (from neptune-client)\n","  Downloading boto3-1.40.28-py3-none-any.whl.metadata (6.7 kB)\n","Collecting bravado<12.0.0,>=11.0.0 (from neptune-client)\n","  Downloading bravado-11.1.0-py2.py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (8.2.1)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (1.0.0)\n","Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (3.3.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from neptune-client) (25.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from neptune-client) (2.2.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from neptune-client) (5.9.5)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (2.32.4)\n","Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (2.0.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (1.17.0)\n","Collecting swagger-spec-validator>=2.7.4 (from neptune-client)\n","  Downloading swagger_spec_validator-3.0.4-py2.py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (4.15.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (2.5.0)\n","Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.12/dist-packages (from neptune-client) (1.8.0)\n","Collecting botocore<1.41.0,>=1.40.28 (from boto3>=1.28.0->neptune-client)\n","  Downloading botocore-1.40.28-py3-none-any.whl.metadata (5.7 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.0->neptune-client)\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.15.0,>=0.14.0 (from boto3>=1.28.0->neptune-client)\n","  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n","Collecting bravado-core>=5.16.1 (from bravado<12.0.0,>=11.0.0->neptune-client)\n","  Downloading bravado-core-6.1.1.tar.gz (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting monotonic (from bravado<12.0.0,>=11.0.0->neptune-client)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.1.1)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.9.0.post0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0.2)\n","Requirement already satisfied: simplejson in /usr/local/lib/python3.12/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (3.20.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from GitPython>=2.0.8->neptune-client) (4.0.12)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20.0->neptune-client) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20.0->neptune-client) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20.0->neptune-client) (2025.8.3)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.25.1)\n","Requirement already satisfied: importlib-resources>=1.3 in /usr/local/lib/python3.12/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (6.5.2)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->neptune-client) (2.0.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->neptune-client) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->neptune-client) (2025.2)\n","Collecting jsonref (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n","  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (5.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.27.1)\n","Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.5.1)\n","Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (20.11.0)\n","Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (3.0.0)\n","Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (0.1.4)\n","Requirement already satisfied: rfc3986-validator>0.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (0.1.1)\n","Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.1.0)\n","Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.3.0)\n","Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (24.11.1)\n","Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.2.2)\n","Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.3.0)\n","Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (2.9.0.20250822)\n","Downloading neptune_client-1.14.0-py3-none-any.whl (487 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boto3-1.40.28-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bravado-11.1.0-py2.py3-none-any.whl (37 kB)\n","Downloading swagger_spec_validator-3.0.4-py2.py3-none-any.whl (28 kB)\n","Downloading botocore-1.40.28-py3-none-any.whl (14.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n","Building wheels for collected packages: bravado-core\n","  Building wheel for bravado-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bravado-core: filename=bravado_core-6.1.1-py2.py3-none-any.whl size=67675 sha256=229641904f22f62f4f1798e42ea6c236bffe7bef1e5ec7bc33626da8411fec52\n","  Stored in directory: /root/.cache/pip/wheels/b8/56/c6/3695a1daf18ee45607f1d352fca288d173bc3b1722228c6fb1\n","Successfully built bravado-core\n","Installing collected packages: monotonic, jsonref, jmespath, botocore, s3transfer, swagger-spec-validator, boto3, bravado-core, bravado, neptune-client\n","Successfully installed boto3-1.40.28 botocore-1.40.28 bravado-11.1.0 bravado-core-6.1.1 jmespath-1.0.1 jsonref-1.1.0 monotonic-1.6 neptune-client-1.14.0 s3transfer-0.14.0 swagger-spec-validator-3.0.4\n","Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n"]}],"source":["!pip install pypsa\n","!pip install neptune-client\n","!pip install gymnasium\n","#!pip install ipdb"]},{"cell_type":"code","execution_count":2,"id":"ce4a5972","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ce4a5972","outputId":"36b89ee7-26bc-4380-9f09-b2e025240888","executionInfo":{"status":"ok","timestamp":1757610540182,"user_tz":-120,"elapsed":18811,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[neptune] [warning] NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs-legacy.neptune.ai/setup/upgrading/\n"]}],"source":["import logging\n","# Suppress PyPSA INFO messages (keep warnings and errors)\n","logging.getLogger('pypsa').setLevel(logging.WARNING)\n","\n","import pypsa\n","import pandas as pd\n","import numpy as np\n","import gymnasium as gym\n","from gymnasium import spaces\n","\n","import gc\n","import psutil\n","import matplotlib.pyplot as plt\n","\n","import neptune\n","\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import random\n","\n","import os\n","#import ipdb"]},{"cell_type":"code","execution_count":3,"id":"25f8eec5-ab49-4607-bc23-7034927360e9","metadata":{"id":"25f8eec5-ab49-4607-bc23-7034927360e9","executionInfo":{"status":"ok","timestamp":1757610540186,"user_tz":-120,"elapsed":2,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["def set_all_seeds(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)"]},{"cell_type":"code","execution_count":4,"id":"a3ee85e6","metadata":{"id":"a3ee85e6","executionInfo":{"status":"ok","timestamp":1757610540247,"user_tz":-120,"elapsed":32,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def calculate_offset_k_initialization(network_file, reward_scale_factor, k_samples=1000, seed=42, **env_kwargs):\n","    \"\"\"\n","    Calculate the offset k for replacement reward method.\n","    Creates a temporary environment to perform the calculation.\n","\n","    We also use this value to scale the reward of the\n","\n","    Parameters:\n","    -----------\n","    network_file : str\n","      Path to the PyPSA network file\n","    input_dir : str\n","      Directory containing constraint mappings\n","    k_samples : int\n","      Number of random samples to use for estimation\n","    **env_kwargs : dict\n","      Additional keyword arguments for environment creation\n","\n","    Returns:\n","    --------\n","    k_mean: Offset value k found by mean method. This is needed for the replacement reward function\n","    k_worst: the highest objective value sampled. we want to scale our rewards by this number/100 so that\n","    constraint_df: pandas DataFrame with constraint violations for each sample\n","    \"\"\"\n","    print(f\"Sampling {k_samples} random states to calculate offset k...\")\n","\n","    # Set up reproducible random number generator for action sampling\n","    import numpy as np\n","    local_rng = np.random.RandomState(seed)\n","    # Set up a separate RNG for snapshot selection\n","    snapshot_rng = np.random.RandomState(seed + 10000)  # Different seed space\n","\n","\n","    # Create temporary environment WITH SEED\n","    temp_env = EnvDispatchConstr(\n","        network_file=network_file, no_convergence_lpf_penalty=0,reward_scale_factor=reward_scale_factor,#these params aren't used, just pass\n","        seed=seed,\n","        **env_kwargs\n","    )\n","    #I'm just making this env to access certain attributes/ methods; which should be fine since none of these attributes/methods reference these two parameters.\n","\n","    # Extract constraint names in the correct order\n","    slack_generators = temp_env.network.generators[temp_env.network.generators.control == \"Slack\"].index\n","\n","    #remove this because don't check line constraints during training\n","    #line_names = temp_env.network.lines.index\n","    storage_names = temp_env.storage_names\n","\n","    # Build constraint names in the order they appear in info['constraint_results']\n","    constraint_names = []\n","\n","    # p_min for each slack generator\n","    for gen_name in slack_generators:\n","        constraint_names.append(f\"p_min_{gen_name}\")\n","\n","    # p_max for each slack generator\n","    for gen_name in slack_generators:\n","        constraint_names.append(f\"p_max_{gen_name}\")\n","\n","    # # s_max for each line\n","    # for line_name in line_names:\n","    #     constraint_names.append(f\"s_max_{line_name}\")\n","\n","    # soc_min for each storage\n","    for storage_name in storage_names:\n","        constraint_names.append(f\"soc_min_{storage_name}\")\n","\n","    # soc_max for each storage\n","    for storage_name in storage_names:\n","        constraint_names.append(f\"soc_max_{storage_name}\")\n","\n","    print(f\"Identified {len(constraint_names)} constraints:\")\n","    for i, name in enumerate(constraint_names):\n","        print(f\"  {i}: {name}\")\n","\n","    action_dim = temp_env.action_space.shape[0]\n","\n","    objective_values = []\n","    constraint_data = []  # List to store dictionaries for DataFrame creation\n","    successful_samples = 0\n","\n","    try:\n","        for i in range(k_samples):\n","            try:\n","                # Reset environment with deterministic seed\n","                env_seed = seed + i  # Different seed for each sample\n","                temp_env.reset(seed=env_seed)\n","                #go to random snapshot (env reset doesnt actually do that)\n","                temp_env.snapshot_idx = snapshot_rng.randint(0, temp_env.total_snapshots)\n","                # Sample random action using local RNG (not global random state)\n","                random_action = local_rng.uniform(0, 1, size=action_dim)  # [0,1] range# This ensures [0,1] range\n","                # Take step - this handles all action scaling and application\n","                # make sure to get snapshot before the step to use when call evaluate_objective_direc() again\n","                #i increase the current snapshot_idx by executing step() if do this line after step, when evaluate_objective_direct() is run it evaluates the objective for the next step!\n","                current_snapshot = temp_env.network.snapshots[temp_env.snapshot_idx]\n","                obs, reward, terminated, truncated, info = temp_env.step(random_action)\n","                # Get the base objective value (the -J(s) part, before any penalties or offsets)\n","                obj_value = reward_scale_factor*temp_env.evaluate_objective_direct(current_snapshot)\n","                objective_values.append(obj_value)\n","\n","                # Create row data for this sample\n","                constraint_results = info['constraint_results']\n","                row_data = {\n","                    'sample_idx': successful_samples,\n","                    'snapshot_idx': temp_env.snapshot_idx,\n","                    'objective_value': obj_value\n","                }\n","\n","                # Add constraint violations using proper names\n","                for j, violation in enumerate(constraint_results):\n","                    if j < len(constraint_names):\n","                        row_data[constraint_names[j]] = violation\n","                    else:\n","                        # Fallback if there's a mismatch\n","                        row_data[f'constraint_{j}'] = violation\n","                        print(f\"Warning: More constraints than expected at index {j}\")\n","\n","                constraint_data.append(row_data)\n","                successful_samples += 1\n","\n","                # Progress indicator every 200 samples\n","                if (i + 1) % 200 == 0:\n","                    print(f\"  Completed {i + 1}/{k_samples} samples...\")\n","\n","            except Exception as e:\n","                # Skip failed samples but continue\n","                if i < 5:  # Only print first few errors to avoid spam\n","                    print(f\"  Sample {i} failed: {e}\")\n","                continue\n","\n","        # Create DataFrame from collected data\n","        constraint_df = pd.DataFrame(constraint_data)\n","\n","        # Calculate offset based on method\n","        if objective_values:\n","            k_worst = abs(max(objective_values))\n","            print(f\"k_worst = |{max(objective_values):.2f}| = {k_worst:.2f}\")\n","            mean_val = np.mean(objective_values)\n","            k_mean = abs(mean_val)\n","            print(f\"k_mean = |{mean_val:.2f}| = {k_mean:.2f}\")\n","\n","            print(f\"  Successfully sampled {successful_samples}/{k_samples} states\")\n","            print(f\"  Objective value range: [{min(objective_values):.2f}, {max(objective_values):.2f}]\")\n","            print(f\"  Constraint DataFrame shape: {constraint_df.shape}\")\n","        else:\n","            print(\"  Warning: No successful samples\")\n","            constraint_df = pd.DataFrame()  # Empty DataFrame\n","\n","    except Exception as e:\n","          print(f\"Error in offset calculation: {e}\")\n","          import traceback\n","          traceback.print_exc()\n","          constraint_df = pd.DataFrame()  # Empty DataFrame on error\n","\n","    return k_mean, k_worst, constraint_df"]},{"cell_type":"code","execution_count":5,"id":"e6492b6d-ad1d-4889-bfc6-c205241d224b","metadata":{"id":"e6492b6d-ad1d-4889-bfc6-c205241d224b","executionInfo":{"status":"ok","timestamp":1757600323140,"user_tz":-120,"elapsed":9,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["# seed = 42  # Define seed variable first\n","# set_all_seeds(seed)\n","# gdrive_base = './'  # or '/workspace/'\n","# network_file_path = os.path.join(gdrive_base, \"networks_1_year_connected\", \"elec_s_10_ec_lc1.0_1h.nc\")\n","\n","# k_mean, k_worst, constraint_df = calculate_offset_k_initialization(network_file=network_file_path, seed=seed)\n","\n","# # Save to text file\n","# kmean_file_path = os.path.join(gdrive_base, \"offset\", f\"k_mean_seed{seed}.txt\")\n","# with open(kmean_file_path, 'w') as f:\n","#     f.write(str(k_mean))\n","\n","# kworst_file_path = os.path.join(gdrive_base, \"offset\", f\"k_worst_seed{seed}.txt\")\n","# with open(kworst_file_path, 'w') as f:\n","#     f.write(str(k_worst))"]},{"cell_type":"code","execution_count":6,"id":"35484e19-a59f-4538-97a2-c3e978e4eae6","metadata":{"id":"35484e19-a59f-4538-97a2-c3e978e4eae6","executionInfo":{"status":"ok","timestamp":1757600323156,"user_tz":-120,"elapsed":17,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["# def plot_constraint_violations(constraint_df, figsize=(10, 8), save_dir=None):\n","#     \"\"\"\n","#     Plot constraint violations vs objective values as separate scatter plots for each constraint.\n","\n","#     Parameters:\n","#     -----------\n","#     constraint_df : pandas.DataFrame\n","#         DataFrame returned by calculate_offset_k_initialization containing constraint data\n","#     figsize : tuple\n","#         Figure size (width, height) for each individual plot\n","#     save_dir : str, optional\n","#         If provided, save plots to this directory with names based on constraint names\n","#     \"\"\"\n","#     if constraint_df.empty:\n","#         print(\"No data to plot - DataFrame is empty\")\n","#         return\n","\n","#     # Get constraint columns (excluding metadata columns)\n","#     constraint_cols = [col for col in constraint_df.columns\n","#                       if col not in ['sample_idx', 'snapshot_idx', 'objective_value']]\n","\n","#     if not constraint_cols:\n","#         print(\"No constraint columns found in DataFrame\")\n","#         return\n","\n","#     num_constraints = len(constraint_cols)\n","#     print(f\"Creating {num_constraints} separate plots for objective vs violations across {len(constraint_df)} samples\")\n","\n","#     # Get objective values for x-axis\n","#     objective_values = constraint_df['objective_value']\n","\n","#     for i, constraint_col in enumerate(constraint_cols):\n","#         # Create a new figure for each constraint\n","#         fig, ax = plt.subplots(1, 1, figsize=figsize)\n","\n","#         violations = constraint_df[constraint_col]\n","\n","#         # Create scatter plot: objective value vs constraint violation\n","#         # Plot ALL data points, including NaN/inf values\n","#         scatter = ax.scatter(objective_values, violations, alpha=0.6, s=30, c=constraint_df['sample_idx'],\n","#                            cmap='viridis', edgecolors='black', linewidth=0.5)\n","\n","#         # Use the actual constraint name as title\n","#         ax.set_title(f'{constraint_col}: Objective vs Violation', fontsize=14, fontweight='bold')\n","#         ax.set_xlabel('Objective Value', fontsize=12)\n","#         ax.set_ylabel('Constraint Violation', fontsize=12)\n","#         ax.grid(True, alpha=0.3)\n","\n","#         # Add colorbar for sample index\n","#         cbar = plt.colorbar(scatter, ax=ax)\n","#         cbar.set_label('Sample Index', fontsize=11)\n","\n","#         # Calculate statistics on ALL data (including NaN/inf)\n","#         mean_viol = violations.mean()\n","#         max_viol = violations.max()\n","#         min_viol = violations.min()\n","#         std_viol = violations.std()\n","\n","#         # Count finite vs non-finite values\n","#         finite_count = np.isfinite(violations).sum()\n","#         total_count = len(violations)\n","\n","#         # Calculate correlation ONLY on finite values\n","#         try:\n","#             # Filter for correlation calculation only\n","#             valid_mask = np.isfinite(objective_values) & np.isfinite(violations)\n","#             if valid_mask.sum() > 1:  # Need at least 2 valid points\n","#                 valid_obj = objective_values[valid_mask]\n","#                 valid_viol = violations[valid_mask]\n","\n","#                 # Check if there's variance in both variables\n","#                 if np.std(valid_obj) > 1e-10 and np.std(valid_viol) > 1e-10:\n","#                     correlation = np.corrcoef(valid_obj, valid_viol)[0, 1]\n","#                     corr_text = f'{correlation:.3f}'\n","#                 else:\n","#                     corr_text = 'N/A (no variance)'\n","#             else:\n","#                 corr_text = 'N/A (insufficient data)'\n","#         except:\n","#             corr_text = 'N/A (calc error)'\n","\n","#         stats_text = (f'Violation Statistics:\\n'\n","#                      f'Mean: {mean_viol:.3f}\\n'\n","#                      f'Max: {max_viol:.3f}\\n'\n","#                      f'Min: {min_viol:.3f}\\n'\n","#                      f'Std: {std_viol:.3f}\\n'\n","#                      f'Finite values: {finite_count}/{total_count}\\n'\n","#                      f'Correlation w/ Objective: {corr_text}')\n","\n","#         ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,\n","#                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.9),\n","#                 fontsize=10)\n","\n","#         plt.tight_layout()\n","\n","#         # Save individual plot if directory provided\n","#         if save_dir:\n","#             import os\n","#             os.makedirs(save_dir, exist_ok=True)\n","#             # Use constraint name for filename, replacing invalid characters\n","#             safe_filename = constraint_col.replace('/', '_').replace('\\\\', '_').replace(':', '_')\n","#             save_path = os.path.join(save_dir, f'{safe_filename}.png')\n","#             plt.savefig(save_path, dpi=300, bbox_inches='tight')\n","#             print(f\"Saved {constraint_col} plot to {save_path}\")\n","\n","#         plt.show()\n","\n","#     print(f\"Completed plotting {num_constraints} constraint plots\")\n","\n","# def plot_constraint_violations_summary(constraint_df, figsize=(12, 8), save_path=None):\n","#     \"\"\"\n","#     Create summary plots for constraint violations: histograms and box plots.\n","\n","#     Parameters:\n","#     -----------\n","#     constraint_df : pandas.DataFrame\n","#         DataFrame returned by calculate_offset_k_initialization containing constraint data\n","#     figsize : tuple\n","#         Figure size (width, height)\n","#     save_path : str, optional\n","#         If provided, save the plot to this path\n","#     \"\"\"\n","#     if constraint_df.empty:\n","#         print(\"No data to plot - DataFrame is empty\")\n","#         return\n","\n","#     # Get constraint columns (excluding metadata columns)\n","#     constraint_cols = [col for col in constraint_df.columns\n","#                       if col not in ['sample_idx', 'snapshot_idx', 'objective_value']]\n","\n","#     if not constraint_cols:\n","#         print(\"No constraint columns found in DataFrame\")\n","#         return\n","\n","#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n","\n","#     # Box plot of all constraints - plot ALL data\n","#     violation_data = constraint_df[constraint_cols].values\n","\n","#     # For box plots, we need to handle NaN/inf differently since matplotlib can't plot them\n","#     # Create a list of arrays, removing only NaN/inf for the box plot visualization\n","#     clean_data_for_boxplot = []\n","#     constraint_labels = []\n","#     for col in constraint_cols:\n","#         col_data = constraint_df[col].values\n","#         finite_vals = col_data[np.isfinite(col_data)]\n","#         clean_data_for_boxplot.append(finite_vals)\n","#         # Shorten label names for readability\n","#         short_label = col.replace('p_min_', 'Pmin_').replace('p_max_', 'Pmax_').replace('s_max_', 'Smax_').replace('soc_min_', 'SOCmin_').replace('soc_max_', 'SOCmax_')\n","#         constraint_labels.append(short_label)\n","\n","#     ax1.boxplot(clean_data_for_boxplot, labels=constraint_labels)\n","#     ax1.set_title('Constraint Violation Distributions\\n(NaN/inf excluded from display)')\n","#     ax1.set_xlabel('Constraint')\n","#     ax1.set_ylabel('Violation Value')\n","#     ax1.grid(True, alpha=0.3)\n","#     # Rotate x labels for better readability\n","#     ax1.tick_params(axis='x', rotation=45)\n","\n","#     # Histogram of violation magnitudes - plot ALL finite data\n","#     all_violations = violation_data.flatten()\n","#     finite_violations = all_violations[np.isfinite(all_violations)]\n","\n","#     if len(finite_violations) > 0:\n","#         ax2.hist(finite_violations, bins=50, alpha=0.7, edgecolor='black')\n","#         ax2.set_title('Distribution of All Violation Values\\n(NaN/inf excluded from display)')\n","#         ax2.set_xlabel('Violation Value')\n","#         ax2.set_ylabel('Frequency')\n","#         ax2.grid(True, alpha=0.3)\n","\n","#         # Calculate statistics on finite data only\n","#         mean_val = np.mean(finite_violations)\n","#         median_val = np.median(finite_violations)\n","#         ax2.axvline(mean_val, color='red', linestyle='--',\n","#                     label=f'Mean: {mean_val:.3f}')\n","#         ax2.axvline(median_val, color='green', linestyle='--',\n","#                     label=f'Median: {median_val:.3f}')\n","#         ax2.legend()\n","\n","#         # Add info about excluded data\n","#         total_points = len(all_violations)\n","#         finite_points = len(finite_violations)\n","#         excluded_points = total_points - finite_points\n","#         if excluded_points > 0:\n","#             ax2.text(0.02, 0.98, f'Excluded {excluded_points}/{total_points} NaN/inf values',\n","#                     transform=ax2.transAxes, verticalalignment='top',\n","#                     bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n","#     else:\n","#         ax2.text(0.5, 0.5, 'All data contains NaN/inf values', transform=ax2.transAxes,\n","#                 ha='center', va='center')\n","#         ax2.set_title('Distribution of All Violation Values')\n","\n","#     plt.tight_layout()\n","\n","#     if save_path:\n","#         plt.savefig(save_path, dpi=300, bbox_inches='tight')\n","#         print(f\"Summary plot saved to {save_path}\")\n","\n","#     plt.show()\n","\n","# def plot_total_violations(constraint_df, figsize=(10, 8), save_path=None):\n","#     \"\"\"\n","#     Plot objective values vs total constraint violations (sum of all individual constraint violations).\n","\n","#     Parameters:\n","#     -----------\n","#     constraint_df : pandas.DataFrame\n","#         DataFrame returned by calculate_offset_k_initialization containing constraint data\n","#     figsize : tuple\n","#         Figure size (width, height)\n","#     save_path : str, optional\n","#         If provided, save the plot to this path\n","#     \"\"\"\n","#     if constraint_df.empty:\n","#         print(\"No data to plot - DataFrame is empty\")\n","#         return\n","\n","#     # Get constraint columns (excluding metadata columns)\n","#     constraint_cols = [col for col in constraint_df.columns\n","#                       if col not in ['sample_idx', 'snapshot_idx', 'objective_value']]\n","\n","#     if not constraint_cols:\n","#         print(\"No constraint columns found in DataFrame\")\n","#         return\n","\n","#     print(f\"Calculating total violations from {len(constraint_cols)} constraints across {len(constraint_df)} samples\")\n","\n","#     # Calculate total violation for each sample (sum across all constraints)\n","#     total_violations = constraint_df[constraint_cols].sum(axis=1)\n","#     objective_values = constraint_df['objective_value']\n","\n","#     # Find maximum total violation\n","#     max_total_violation = total_violations.max()\n","#     max_violation_idx = total_violations.idxmax()\n","#     max_sample = constraint_df.loc[max_violation_idx]\n","\n","#     print(f\"\\nMaximum total violation: {max_total_violation:.4f}\")\n","#     print(f\"Occurred at sample {max_sample['sample_idx']} (snapshot {max_sample['snapshot_idx']})\")\n","#     print(f\"Objective value at max violation: {max_sample['objective_value']:.2f}\")\n","\n","#     # Create the plot\n","#     fig, ax = plt.subplots(1, 1, figsize=figsize)\n","\n","#     # Create scatter plot: objective value vs total violation\n","#     scatter = ax.scatter(objective_values, total_violations, alpha=0.6, s=30,\n","#                         c=constraint_df['sample_idx'], cmap='viridis',\n","#                         edgecolors='black', linewidth=0.5)\n","\n","#     # Highlight the maximum violation point\n","#     ax.scatter(max_sample['objective_value'], max_total_violation,\n","#               color='red', s=100, marker='*', edgecolors='black', linewidth=1,\n","#               label=f'Max Total Violation: {max_total_violation:.4f}')\n","\n","#     ax.set_title('Objective vs Total Constraint Violations', fontsize=14, fontweight='bold')\n","#     ax.set_xlabel('Objective Value', fontsize=12)\n","#     ax.set_ylabel('Total Constraint Violation (Sum)', fontsize=12)\n","#     ax.grid(True, alpha=0.3)\n","#     ax.legend()\n","\n","#     # Add colorbar for sample index\n","#     cbar = plt.colorbar(scatter, ax=ax)\n","#     cbar.set_label('Sample Index', fontsize=11)\n","\n","#     # Calculate statistics on total violations\n","#     mean_total = total_violations.mean()\n","#     max_total = total_violations.max()\n","#     min_total = total_violations.min()\n","#     std_total = total_violations.std()\n","\n","#     # Count finite vs non-finite values\n","#     finite_count = np.isfinite(total_violations).sum()\n","#     total_count = len(total_violations)\n","\n","#     # Calculate correlation between objective and total violations\n","#     try:\n","#         valid_mask = np.isfinite(objective_values) & np.isfinite(total_violations)\n","#         if valid_mask.sum() > 1:\n","#             valid_obj = objective_values[valid_mask]\n","#             valid_total = total_violations[valid_mask]\n","\n","#             if np.std(valid_obj) > 1e-10 and np.std(valid_total) > 1e-10:\n","#                 correlation = np.corrcoef(valid_obj, valid_total)[0, 1]\n","#                 corr_text = f'{correlation:.3f}'\n","#             else:\n","#                 corr_text = 'N/A (no variance)'\n","#         else:\n","#             corr_text = 'N/A (insufficient data)'\n","#     except:\n","#         corr_text = 'N/A (calc error)'\n","\n","#     stats_text = (f'Total Violation Statistics:\\n'\n","#                  f'Mean: {mean_total:.4f}\\n'\n","#                  f'Max: {max_total:.4f}\\n'\n","#                  f'Min: {min_total:.4f}\\n'\n","#                  f'Std: {std_total:.4f}\\n'\n","#                  f'Finite values: {finite_count}/{total_count}\\n'\n","#                  f'Correlation w/ Objective: {corr_text}')\n","\n","#     ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,\n","#             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.9),\n","#             fontsize=10)\n","\n","#     plt.tight_layout()\n","\n","#     if save_path:\n","#         plt.savefig(save_path, dpi=300, bbox_inches='tight')\n","#         print(f\"Total violations plot saved to {save_path}\")\n","\n","#     plt.show()\n","\n","#     # Print breakdown of violations for the worst case\n","#     print(f\"\\nBreakdown of violations for sample with maximum total violation:\")\n","#     print(f\"Sample {max_sample['sample_idx']} (snapshot {max_sample['snapshot_idx']}):\")\n","#     for constraint_col in constraint_cols:\n","#         violation_val = max_sample[constraint_col]\n","#         if pd.notna(violation_val) and violation_val != 0:\n","#             print(f\"  {constraint_col}: {violation_val:.4f}\")\n","\n","#     return max_total_violation, max_violation_idx"]},{"cell_type":"code","execution_count":7,"id":"153fc32b-81fb-4ead-9844-b481c9b79d7a","metadata":{"id":"153fc32b-81fb-4ead-9844-b481c9b79d7a","executionInfo":{"status":"ok","timestamp":1757600323159,"user_tz":-120,"elapsed":2,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["# # Plot individual constraint violations as separate plots\n","# plot_constraint_violations(constraint_df, figsize=(10, 8), save_dir=\"workspace/constraints\")\n","\n","# # Plot objective vs total violations\n","# max_total_violation, worst_sample_idx = plot_total_violations(\n","#     constraint_df,\n","#     save_path=\"workspace/total_violations.png\"\n","# )\n","# print(f\"The worst case total violation was: {max_total_violation}\")\n","# plot_constraint_violations_summary(constraint_df, save_path=\"workspace/constraint_summary.png\")"]},{"cell_type":"code","execution_count":8,"id":"7b56db97-8102-404e-b0e5-e8d14e2d19f0","metadata":{"id":"7b56db97-8102-404e-b0e5-e8d14e2d19f0","executionInfo":{"status":"ok","timestamp":1757600323173,"user_tz":-120,"elapsed":11,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["# def plot_violation_count_distribution(constraint_df, violation_threshold=0.0, figsize=(12, 8), save_path=None):\n","#     \"\"\"\n","#     Plot the distribution of number of violations per sample.\n","\n","#     Parameters:\n","#     -----------\n","#     constraint_df : pandas.DataFrame\n","#         DataFrame returned by calculate_offset_k_initialization containing constraint data\n","#     violation_threshold : float\n","#         Threshold above which a constraint is considered violated (default: 0.0)\n","#     figsize : tuple\n","#         Figure size (width, height)\n","#     save_path : str, optional\n","#         If provided, save the plot to this path\n","#     \"\"\"\n","#     if constraint_df.empty:\n","#         print(\"No data to plot - DataFrame is empty\")\n","#         return\n","\n","#     # Get constraint columns (excluding metadata columns)\n","#     constraint_cols = [col for col in constraint_df.columns\n","#                       if col not in ['sample_idx', 'snapshot_idx', 'objective_value']]\n","\n","#     if not constraint_cols:\n","#         print(\"No constraint columns found in DataFrame\")\n","#         return\n","\n","#     print(f\"Analyzing violation counts from {len(constraint_cols)} constraints across {len(constraint_df)} samples\")\n","#     print(f\"Using violation threshold: {violation_threshold}\")\n","\n","#     # Count violations per sample (number of constraints violated)\n","#     # A constraint is violated if its value > violation_threshold\n","#     violation_counts = []\n","#     for _, row in constraint_df.iterrows():\n","#         count = 0\n","#         valid_constraints = 0\n","#         for constraint_col in constraint_cols:\n","#             violation_val = row[constraint_col]\n","#             if pd.notna(violation_val) and np.isfinite(violation_val):\n","#                 valid_constraints += 1\n","#                 if violation_val > violation_threshold:\n","#                     count += 1\n","#         violation_counts.append(count)\n","\n","#     violation_counts = np.array(violation_counts)\n","\n","#     # Create subplots\n","#     fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=figsize)\n","\n","#     # 1. Histogram of violation counts\n","#     unique_counts, count_frequencies = np.unique(violation_counts, return_counts=True)\n","\n","#     ax1.bar(unique_counts, count_frequencies, alpha=0.7, edgecolor='black', width=0.8)\n","#     ax1.set_title('Distribution of Number of Violations per Sample')\n","#     ax1.set_xlabel('Number of Constraints Violated')\n","#     ax1.set_ylabel('Number of Samples')\n","#     ax1.grid(True, alpha=0.3, axis='y')\n","\n","#     # Add percentage labels on bars\n","#     total_samples = len(violation_counts)\n","#     for i, (count, freq) in enumerate(zip(unique_counts, count_frequencies)):\n","#         percentage = (freq / total_samples) * 100\n","#         ax1.text(count, freq + 0.01 * max(count_frequencies), f'{percentage:.1f}%',\n","#                 ha='center', va='bottom', fontsize=9)\n","\n","#     # 2. Pie chart of violation categories\n","#     no_violations = np.sum(violation_counts == 0)\n","#     some_violations = np.sum((violation_counts > 0) & (violation_counts < len(constraint_cols)))\n","#     all_violations = np.sum(violation_counts == len(constraint_cols))\n","\n","#     categories = []\n","#     sizes = []\n","#     colors = ['green', 'orange', 'red']\n","#     labels = []\n","\n","#     if no_violations > 0:\n","#         categories.append('No Violations')\n","#         sizes.append(no_violations)\n","#         labels.append(f'No Violations\\n({no_violations} samples)')\n","\n","#     if some_violations > 0:\n","#         categories.append('Some Violations')\n","#         sizes.append(some_violations)\n","#         labels.append(f'Some Violations\\n({some_violations} samples)')\n","\n","#     if all_violations > 0:\n","#         categories.append('All Violated')\n","#         sizes.append(all_violations)\n","#         labels.append(f'All Violated\\n({all_violations} samples)')\n","\n","#     if sizes:\n","#         wedges, texts, autotexts = ax2.pie(sizes, labels=labels, colors=colors[:len(sizes)],\n","#                                           autopct='%1.1f%%', startangle=90)\n","#         ax2.set_title('Violation Categories')\n","#     else:\n","#         ax2.text(0.5, 0.5, 'No valid data', ha='center', va='center', transform=ax2.transAxes)\n","\n","#     # 3. Objective value vs number of violations\n","#     objective_values = constraint_df['objective_value']\n","#     scatter = ax3.scatter(objective_values, violation_counts, alpha=0.6, s=30,\n","#                          c=constraint_df['sample_idx'], cmap='viridis',\n","#                          edgecolors='black', linewidth=0.5)\n","\n","#     ax3.set_title('Objective Value vs Number of Violations')\n","#     ax3.set_xlabel('Objective Value')\n","#     ax3.set_ylabel('Number of Constraints Violated')\n","#     ax3.grid(True, alpha=0.3)\n","#     ax3.set_yticks(range(max(violation_counts) + 1))\n","\n","#     # Add colorbar\n","#     cbar = plt.colorbar(scatter, ax=ax3)\n","#     cbar.set_label('Sample Index', fontsize=10)\n","\n","#     # 4. Box plot of objective values by violation count\n","#     violation_count_groups = {}\n","#     for i, count in enumerate(violation_counts):\n","#         if count not in violation_count_groups:\n","#             violation_count_groups[count] = []\n","#         obj_val = objective_values.iloc[i]\n","#         if pd.notna(obj_val) and np.isfinite(obj_val):\n","#             violation_count_groups[count].append(obj_val)\n","\n","#     # Only include groups with at least one valid objective value\n","#     valid_groups = {k: v for k, v in violation_count_groups.items() if len(v) > 0}\n","\n","#     if valid_groups:\n","#         box_data = [valid_groups[count] for count in sorted(valid_groups.keys())]\n","#         box_labels = [f'{count}\\n(n={len(valid_groups[count])})' for count in sorted(valid_groups.keys())]\n","\n","#         ax4.boxplot(box_data, labels=box_labels)\n","#         ax4.set_title('Objective Value Distribution by Violation Count')\n","#         ax4.set_xlabel('Number of Violations')\n","#         ax4.set_ylabel('Objective Value')\n","#         ax4.grid(True, alpha=0.3)\n","#     else:\n","#         ax4.text(0.5, 0.5, 'No valid objective values', ha='center', va='center', transform=ax4.transAxes)\n","\n","#     # Calculate and display summary statistics\n","#     mean_violations = np.mean(violation_counts)\n","#     median_violations = np.median(violation_counts)\n","#     max_violations = np.max(violation_counts)\n","#     std_violations = np.std(violation_counts)\n","\n","#     # Find samples with maximum violations\n","#     max_violation_samples = constraint_df[violation_counts == max_violations]\n","\n","#     # Calculate correlation between objective and violation count\n","#     try:\n","#         valid_mask = np.isfinite(objective_values) & np.isfinite(violation_counts)\n","#         if valid_mask.sum() > 1:\n","#             valid_obj = objective_values[valid_mask]\n","#             valid_counts = violation_counts[valid_mask]\n","\n","#             if np.std(valid_obj) > 1e-10 and np.std(valid_counts) > 1e-10:\n","#                 correlation = np.corrcoef(valid_obj, valid_counts)[0, 1]\n","#                 corr_text = f'{correlation:.3f}'\n","#             else:\n","#                 corr_text = 'N/A (no variance)'\n","#         else:\n","#             corr_text = 'N/A (insufficient data)'\n","#     except:\n","#         corr_text = 'N/A (calc error)'\n","\n","#     # Add summary text box\n","#     summary_text = (f'Violation Count Statistics:\\n'\n","#                    f'Mean: {mean_violations:.2f}\\n'\n","#                    f'Median: {median_violations:.1f}\\n'\n","#                    f'Max: {max_violations}\\n'\n","#                    f'Std: {std_violations:.2f}\\n'\n","#                    f'Total constraints: {len(constraint_cols)}\\n'\n","#                    f'Samples with 0 violations: {no_violations}/{total_samples}\\n'\n","#                    f'Correlation w/ Objective: {corr_text}')\n","\n","#     fig.text(0.02, 0.02, summary_text, fontsize=10,\n","#              bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n","\n","#     plt.tight_layout()\n","#     plt.subplots_adjust(bottom=0.2)  # Make room for summary text\n","\n","#     if save_path:\n","#         plt.savefig(save_path, dpi=300, bbox_inches='tight')\n","#         print(f\"Violation count distribution plot saved to {save_path}\")\n","\n","#     plt.show()\n","\n","#     # Print detailed summary\n","#     print(f\"\\n=== VIOLATION COUNT ANALYSIS ===\")\n","#     print(f\"Total samples: {total_samples}\")\n","#     print(f\"Total constraints: {len(constraint_cols)}\")\n","#     print(f\"Violation threshold: {violation_threshold}\")\n","#     print(f\"\\nViolation count distribution:\")\n","#     for count, freq in zip(unique_counts, count_frequencies):\n","#         percentage = (freq / total_samples) * 100\n","#         print(f\"  {count} violations: {freq} samples ({percentage:.1f}%)\")\n","\n","#     print(f\"\\nSamples with maximum violations ({max_violations}):\")\n","#     for _, sample in max_violation_samples.iterrows():\n","#         print(f\"  Sample {sample['sample_idx']} (snapshot {sample['snapshot_idx']}) - Objective: {sample['objective_value']:.2f}\")\n","\n","#         # Show which constraints are violated for this sample\n","#         violated_constraints = []\n","#         for constraint_col in constraint_cols:\n","#             violation_val = sample[constraint_col]\n","#             if pd.notna(violation_val) and np.isfinite(violation_val) and violation_val > violation_threshold:\n","#                 violated_constraints.append(f\"{constraint_col}: {violation_val:.4f}\")\n","\n","#         if violated_constraints:\n","#             print(f\"    Violated constraints: {', '.join(violated_constraints[:3])}\" +\n","#                   (f\" (and {len(violated_constraints)-3} more)\" if len(violated_constraints) > 3 else \"\"))\n","\n","#     return violation_counts, unique_counts, count_frequencies"]},{"cell_type":"code","execution_count":9,"id":"229c631f-9ce0-4d6d-b38d-1a982be93048","metadata":{"id":"229c631f-9ce0-4d6d-b38d-1a982be93048","executionInfo":{"status":"ok","timestamp":1757600323176,"user_tz":-120,"elapsed":2,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":[" # violation_counts, unique_counts, frequencies = plot_violation_count_distribution(constraint_df)\n"]},{"cell_type":"code","execution_count":5,"id":"9db9ca87","metadata":{"id":"9db9ca87","executionInfo":{"status":"ok","timestamp":1757610540288,"user_tz":-120,"elapsed":39,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["def fix_artificial_lines_reasonable(network):\n","    \"\"\"\n","    Fix artificial lines with reasonable capacity values:\n","    - s_nom = based on connected bus demand (with safety factor)\n","    - s_nom_extendable = False (non-extendable)\n","    - Keep capacity high enough to meet demand\n","    \"\"\"\n","    print(\"=== FIXING ARTIFICIAL LINES WITH REASONABLE CAPACITY ===\")\n","\n","    # Find artificial lines\n","    artificial_lines = [line for line in network.lines.index\n","                       if any(keyword in str(line).lower() for keyword in ['new', '<->', 'artificial'])]\n","\n","    if not artificial_lines:\n","        # If no artificial lines found by name, look for lines with s_nom=0\n","        # which is often a sign of artificial lines\n","        zero_capacity_lines = network.lines[network.lines.s_nom == 0].index.tolist()\n","        if zero_capacity_lines:\n","            artificial_lines = zero_capacity_lines\n","\n","    print(f\"Found {len(artificial_lines)} artificial lines to fix:\")\n","\n","    # Get maximum demand per bus across all snapshots\n","    bus_max_demand = {}\n","    for bus in network.buses.index:\n","        bus_demand = 0\n","        for load_name, load in network.loads.iterrows():\n","            if load.bus == bus and load_name in network.loads_t.p_set.columns:\n","                bus_demand = max(bus_demand, network.loads_t.p_set[load_name].max())\n","        bus_max_demand[bus] = bus_demand\n","\n","    # Fix each artificial line with reasonable capacity\n","    for line_name in artificial_lines:\n","        # Get connected buses\n","        bus0 = network.lines.loc[line_name, 'bus0']\n","        bus1 = network.lines.loc[line_name, 'bus1']\n","\n","        # Get maximum demand at these buses\n","        bus0_demand = bus_max_demand.get(bus0, 0)\n","        bus1_demand = bus_max_demand.get(bus1, 0)\n","\n","        # Calculate required capacity with safety factor\n","        # Use 3x the higher demand to ensure adequate capacity\n","        safety_factor = 3.0\n","        required_capacity = max(bus0_demand, bus1_demand) * safety_factor\n","\n","        # Ensure minimum reasonable capacity (1000 MW)\n","        required_capacity = max(required_capacity, 1000)\n","\n","        print(f\"\\n Fixing: {line_name}\")\n","        print(f\"    Connected buses: {bus0} ↔ {bus1}\")\n","        print(f\"    Bus demands: {bus0}: {bus0_demand:.1f} MW, {bus1}: {bus1_demand:.1f} MW\")\n","\n","        # Set s_nom to required capacity\n","        old_s_nom = network.lines.loc[line_name, 's_nom']\n","        network.lines.loc[line_name, 's_nom'] = required_capacity\n","        print(f\"    s_nom: {old_s_nom} → {required_capacity:.1f} MW\")\n","\n","        # Make sure line is not extendable\n","        if 's_nom_extendable' not in network.lines.columns:\n","            network.lines['s_nom_extendable'] = False\n","        network.lines.loc[line_name, 's_nom_extendable'] = False\n","        print(f\"    s_nom_extendable: → False\")\n","\n","    return network\n","\n","def remove_offshore_wind(network):\n","    \"\"\"\n","    Remove offshore wind generators.\n","    All of these have zero nominal capacity (likely missing data).\n","    Need to remove them to avoid division by zero error in constraint check for slack gens.\n","    Problem is still feasible without offwind slack since pypsa optimize still feasible.\n","    \"\"\"\n","\n","    # First, identify offshore wind generators\n","    offwind_gens = network.generators[\n","        network.generators.index.str.contains('offwind', case=False, na=False)\n","    ].index\n","\n","    print(f\"Found {len(offwind_gens)} offshore wind generators:\")\n","    print(offwind_gens.tolist())\n","\n","    # Check their properties\n","    offwind_data = network.generators.loc[offwind_gens, ['p_nom', 'control', 'carrier']]\n","    print(\"\\nOffshore wind generator details:\")\n","    print(offwind_data)\n","\n","    # Remove offshore wind generators one by one\n","    print(f\"\\nRemoving {len(offwind_gens)} offshore wind generators...\")\n","    for gen in offwind_gens:\n","        network.remove(\"Generator\", gen)\n","\n","def create_pypsa_network(network_file):\n","    \"\"\"Create a PyPSA network from the .nc file.\"\"\"\n","    # Initialize network\n","    network = pypsa.Network(network_file)\n","    for storage_name in network.storage_units.index:\n","        # Use .loc for direct assignment to avoid SettingWithCopyWarning\n","        network.storage_units.loc[storage_name, 'cyclic_state_of_charge'] = False\n","\n","        # Set marginal_cost to 0.01\n","        network.storage_units.loc[storage_name, 'marginal_cost'] = 0.01\n","\n","        # Set marginal_cost_storage to 0.01\n","        network.storage_units.loc[storage_name, 'marginal_cost_storage'] = 0.01\n","\n","        # Set spill_cost to 0.1\n","        network.storage_units.loc[storage_name, 'spill_cost'] = 0.1\n","\n","        network.storage_units.loc[storage_name, 'efficiency_store'] = 0.866025 #use phs efficiency (hydro didnt have an efficiency, but i want to model them all as the same)\n","\n","        # Fix unrealistic max_hours values\n","        current_max_hours = network.storage_units.loc[storage_name, 'max_hours']\n","\n","        if 'PHS' in storage_name:\n","            # PHS with missing data - set to typical range\n","            network.storage_units.loc[storage_name, 'max_hours'] = 8.0\n","            print(f\"Fixed {storage_name}: set max_hours to 8.0\")\n","\n","        elif 'hydro' in storage_name:\n","            # Hydro with unrealistic data - set to validated range\n","            network.storage_units.loc[storage_name, 'max_hours'] = 6.0\n","            print(f\"Fixed {storage_name}: corrected max_hours from {current_max_hours} to 6.0\")\n","\n","\n","    fix_artificial_lines_reasonable(network)\n","    remove_offshore_wind(network)\n","\n","    return network"]},{"cell_type":"code","execution_count":6,"id":"b8f1d307","metadata":{"id":"b8f1d307","executionInfo":{"status":"ok","timestamp":1757610540722,"user_tz":-120,"elapsed":432,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["class EnvDispatchConstr(gym.Env):\n","    \"\"\"\n","    OpenAI Gym environment for Optimal Power Flow using PyPSA.\n","    Enhanced to handle dispatchable generators, renewable generators, and storage units.\n","\n","    Action Space: Continuous setpoints for all controllable components within their capacity limits\n","    - Dispatchable generators: scaled between p_min_pu*p_nom and p_max_pu*p_nom\n","    - Renewable generators: scaled between 0 and current p_max_pu*p_nom (time-varying)\n","    - Storage units: scaled between -p_nom (charging) and +p_nom (discharging)\n","    (This follows http://arxiv.org/abs/2403.17831.)\n","\n","    Has train/test split functionality\n","    \"\"\"\n","\n","    def __init__(self, network_file, no_convergence_lpf_penalty, reward_scale_factor, constraint_penalty_factor=10, seed=None,\n","                 #test_start_date='2013-12-01 00:00:00', fixed_episode_length=None\n","                ):\n","        super().__init__()\n","        if seed is not None:\n","            np.random.seed(seed)  # Set initial seed\n","\n","        self.network_file = network_file # Store network file path\n","\n","        # Use provided network or create new one\n","        self.network =create_pypsa_network(network_file)\n","        self.reward_scale_factor=reward_scale_factor\n","\n","        #self.test_start_date = pd.Timestamp(test_start_date)\n","        #Omit self._train_test_snapshots()\n","\n","        self.penalty_factor= constraint_penalty_factor\n","        self.no_convergence_lpf_penalty= no_convergence_lpf_penalty\n","        self.reward_method = \"summation\" # Default reward method for the base class\n","\n","        # Omit episode length configuration\n","\n","        # Episode management\n","        self.total_snapshots = len(self.network.snapshots)\n","        self.snapshot_idx = 0  # Current snapshot index (cycles through all snapshots)\n","\n","        # Initialize component categorization\n","        self._categorize_components()\n","\n","        # Create action space\n","        self._create_action_space()\n","\n","        # Initialize the network state\n","        self.reset()\n","\n","        # Create observation space\n","        low_bounds, high_bounds = self.create_observation_bounds()\n","        self.observation_space = spaces.Box(\n","            low=low_bounds,\n","            high=high_bounds,\n","            dtype=np.float32\n","        )\n","\n","        slack_generators = self.network.generators[self.network.generators.control == \"Slack\"].index\n","\n","        self.n_slack=len(slack_generators)\n","        self.n_lines=len(self.network.lines.index)\n","\n","\n","        total_size_test=(2 * self.n_slack + self.n_lines + 2 * self.n_storage)\n","        self.initial_constr_test = np.zeros(total_size_test, dtype=np.float64)\n","        self.n_constr_test=len(self.initial_constr_test)\n","\n","        # Remove line constraints for performance - only check slack and storage constraints\n","        total_size = (2 * self.n_slack + 2 * self.n_storage)\n","        self.initial_constr = np.zeros(total_size, dtype=np.float64)\n","        self.n_constr=len(self.initial_constr)\n","\n","        # Cache component mappings for performance optimization\n","        # self._cache_component_mappings()\n","        self._initialize_power_flow_matrices()\n","\n","\n","    #Omit _train_test_snapshots which defines self.train_snapshots and self.test_snapshots\n","    def _initialize_power_flow_matrices(self):\n","        \"\"\"Pre-compute network topology and power flow matrices for fast LPF.\"\"\"\n","        print(\"Pre-computing network topology and power flow matrices...\")\n","\n","        # Step 1: Determine network topology (identifies sub-networks)\n","        self.network.determine_network_topology()\n","\n","        # Step 2: Pre-compute power flow matrices for each sub-network\n","        for sub in self.network.sub_networks.obj:\n","            sub.calculate_B_H()\n","\n","        print(f\"Initialized {len(self.network.sub_networks.obj)} sub-networks for fast power flow\")\n","\n","    def _categorize_components(self):\n","        \"\"\"\n","        Categorize generators and identify storage units for action space.\n","        \"\"\"\n","        # Get generators with time-varying p_max_pu (renewable generators)\n","        renewable_gens = self.network.generators_t.p_max_pu.columns\n","\n","        slack_generators = self.network.generators[self.network.generators.control == \"Slack\"].index\n","        # in the 10-node SA network there are 4 slack gens so this should return a list of indexes\n","\n","        # Dispatchable generators: not slack, not renewable\n","        self.dispatchable_gens = self.network.generators[\n","            (~self.network.generators.index.isin(slack_generators)) &\n","            (~self.network.generators.index.isin(renewable_gens))\n","        ].index\n","\n","        # Renewable generators: have time-varying p_max_pu, not slack\n","        self.renewable_gens = self.network.generators[\n","            (self.network.generators.index.isin(renewable_gens)) &\n","            (~self.network.generators.index.isin(slack_generators))\n","        ].index\n","\n","        # Storage units (if any exist in the network)\n","        self.storage_units = self.network.storage_units.index\n","\n","        # Store names as lists for easier indexing\n","        self.dispatchable_names = list(self.dispatchable_gens)\n","        self.renewable_names = list(self.renewable_gens)\n","        self.storage_names = list(self.storage_units)\n","\n","        # Store counts\n","        self.n_dispatchable = len(self.dispatchable_names)\n","        self.n_renewable = len(self.renewable_names)\n","        self.n_storage = len(self.storage_names)\n","\n","        # Get static limits for dispatchable generators\n","        if self.n_dispatchable > 0:\n","            dispatchable_df = self.network.generators.loc[self.dispatchable_gens]\n","            self.disp_p_min = (dispatchable_df.p_min_pu * dispatchable_df.p_nom).values#returns numpy arrays\n","            self.disp_p_max = (dispatchable_df.p_max_pu * dispatchable_df.p_nom).values\n","        else:\n","            self.disp_p_min = np.array([])\n","            self.disp_p_max = np.array([])\n","\n","        # Get nominal capacities and minimum limits for renewable generators\n","        if self.n_renewable > 0:\n","            renewable_df = self.network.generators.loc[self.renewable_gens]\n","            self.renewable_p_nom = renewable_df.p_nom.values\n","            self.renewable_p_min_pu = renewable_df.p_min_pu.values\n","        else:\n","            self.renewable_p_nom = np.array([])\n","            self.renewable_p_min_pu = np.array([])\n","\n","        # Classify storage types based on p_min_pu\n","        if self.n_storage > 0:\n","            storage_df = self.network.storage_units.loc[self.storage_units]\n","\n","            # Bidirectional storage (PHS): p_min_pu < 0\n","            self.bidirectional_storage = storage_df[storage_df.p_min_pu < 0].index\n","\n","            # Unidirectional storage (Hydro): p_min_pu >= 0\n","            self.unidirectional_storage = storage_df[storage_df.p_min_pu >= 0].index\n","\n","            self.n_bidirectional = len(self.bidirectional_storage)\n","            self.n_unidirectional = len(self.unidirectional_storage)\n","\n","            # Store names as lists\n","            self.bidirectional_names = list(self.bidirectional_storage)\n","            self.unidirectional_names = list(self.unidirectional_storage)\n","        else:\n","            self.bidirectional_storage = pd.Index([])\n","            self.unidirectional_storage = pd.Index([])\n","            self.n_bidirectional = 0\n","            self.n_unidirectional = 0\n","            self.bidirectional_names = []\n","            self.unidirectional_names = []\n","\n","    def _cache_component_mappings(self):\n","        \"\"\"Cache component-to-bus mappings and indices for fast power balance calculations.\"\"\"\n","        # Cache bus mappings\n","        self._load_buses = self.network.loads['bus'].values\n","        self._gen_buses = self.network.generators['bus'].values\n","        self._storage_buses = self.network.storage_units['bus'].values if len(self.storage_names) > 0 else np.array([])\n","\n","        # Cache component indices for iloc access\n","        self._all_buses = self.network.buses.index\n","        self._load_names = self.network.loads.index\n","        self._gen_names = self.network.generators.index\n","\n","        # Cache non-slack generator info\n","        self._non_slack_gens = self.network.generators[self.network.generators.control != \"Slack\"].index\n","        self._non_slack_gen_buses = self.network.generators.loc[self._non_slack_gens, 'bus'].values\n","\n","        # Cache slack generator info\n","        self._slack_gens = self.network.generators[self.network.generators.control == \"Slack\"].index\n","        if len(self._slack_gens) > 1:\n","            slack_p_noms = self.network.generators.loc[self._slack_gens, 'p_nom']\n","            self._slack_weights = (slack_p_noms / slack_p_noms.sum()).values\n","        else:\n","            self._slack_weights = None\n","\n","        # Pre-create component-to-index mappings for fast iloc access\n","        self._load_idx_map = {name: idx for idx, name in enumerate(self._load_names)}\n","        self._gen_idx_map = {name: idx for idx, name in enumerate(self._gen_names)}\n","        self._storage_idx_map = {name: idx for idx, name in enumerate(self.storage_names)}\n","\n","    def _create_action_space(self):\n","        \"\"\"\n","        Create action space with four distinct parts:\n","        1. Dispatchable generators: [0,1] scaled to [p_min, p_max]\n","        2. Renewable generators: [0,1] scaled to [0, current_p_max_pu * p_nom]\n","        3. Storage p_store: [0,1] scaled to [0,p_nom] (charging magnitude)\n","        4. Storage p_dispatch: [0,1] scaled to [0, p_nom] (discharging magnitude)\n","\n","        Create action space with different handling for storage types:\n","        - Bidirectional storage (PHS): 2 actions (p_store, p_dispatch)\n","        - Unidirectional storage (Hydro): 1 action (p_dispatch only)\n","        \"\"\"\n","        total_actions = (self.n_dispatchable + self.n_renewable +\n","                    (2 * self.n_bidirectional) + self.n_unidirectional)\n","        self.action_space = gym.spaces.Box(0, 1, shape=(total_actions,))\n","\n","        # Store action space structure\n","        current_idx = 0\n","\n","        self.action_structure = {\n","            'dispatchable': {\n","                'start': current_idx,\n","                'end': current_idx + self.n_dispatchable,\n","                'count': self.n_dispatchable\n","            }\n","        }\n","        current_idx += self.n_dispatchable\n","\n","        self.action_structure['renewable'] = {\n","            'start': current_idx,\n","            'end': current_idx + self.n_renewable,\n","            'count': self.n_renewable\n","        }\n","        current_idx += self.n_renewable\n","\n","        # Bidirectional storage (2 actions each)\n","        self.action_structure['bidirectional_p_store'] = {\n","            'start': current_idx,\n","            'end': current_idx + self.n_bidirectional,\n","            'count': self.n_bidirectional\n","        }\n","        current_idx += self.n_bidirectional\n","\n","        self.action_structure['bidirectional_p_dispatch'] = {\n","            'start': current_idx,\n","            'end': current_idx + self.n_bidirectional,\n","            'count': self.n_bidirectional\n","        }\n","        current_idx += self.n_bidirectional\n","\n","        # Unidirectional storage (1 action each)\n","        self.action_structure['unidirectional_p_dispatch'] = {\n","            'start': current_idx,\n","            'end': current_idx + self.n_unidirectional,\n","            'count': self.n_unidirectional\n","        }\n","\n","    def _get_storage_observation(self):\n","        \"\"\"\n","        Get current storage unit states for observation.\n","        Returns current inflow (normalized) for each storage unit.\n","        \"\"\"\n","        if self.n_storage == 0:\n","            return np.array([])\n","\n","        current_snapshot = self.network.snapshots[self.snapshot_idx]\n","        storage_obs = []\n","\n","        for storage_name in self.storage_names:\n","            # Current Inflow (normalized by p_nom)\n","            p_nom = self.network.storage_units.loc[storage_name, 'p_nom']\n","            if hasattr(self.network.storage_units_t, 'inflow') and storage_name in self.network.storage_units_t.inflow.columns:\n","                current_inflow = self.network.storage_units_t.inflow.loc[current_snapshot, storage_name]\n","                # Normalize by p_nom for consistent scaling\n","                normalized_inflow = current_inflow / p_nom if p_nom > 0 else 0\n","            else:\n","                # If no inflow data exists, use zero\n","                normalized_inflow = 0.0\n","            storage_obs.append(normalized_inflow)\n","\n","        return np.array(storage_obs, dtype=np.float32)\n","\n","    def create_storage_observation_bounds(self):\n","        \"\"\"\n","        Create bounds for storage unit observations.\n","        Only includes inflow bounds since SOC is excluded.\n","        \"\"\"\n","        if self.n_storage == 0:\n","            return np.array([]), np.array([])\n","\n","        values_per_storage = 1  # Only inflow now\n","        total_storage_obs = self.n_storage * values_per_storage\n","\n","        low_bounds = np.zeros(total_storage_obs)\n","        high_bounds = np.zeros(total_storage_obs)\n","\n","        for i, storage_name in enumerate(self.storage_names):\n","            # Inflow bounds: Get from historical data\n","            if hasattr(self.network.storage_units_t, 'inflow'):\n","                p_nom = self.network.storage_units.loc[storage_name, 'p_nom']\n","                if storage_name in self.network.storage_units_t.inflow.columns:\n","                    inflow_data = self.network.storage_units_t.inflow[storage_name]\n","\n","                    min_inflow_norm = inflow_data.min() / p_nom if p_nom > 0 else 0\n","                    max_inflow_norm = inflow_data.max() / p_nom if p_nom > 0 else 0\n","\n","                    low_bounds[i] = min_inflow_norm\n","                    high_bounds[i] = max_inflow_norm\n","                else:\n","                    # If inflow data exists but not for this specific storage unit\n","                    low_bounds[i] = 0.0\n","                    high_bounds[i] = 0.0\n","            else:\n","                # No inflow data\n","                low_bounds[i] = 0.0\n","                high_bounds[i] = 0.0\n","\n","        return low_bounds.astype(np.float32), high_bounds.astype(np.float32)\n","\n","    def create_observation_bounds(self):\n","        \"\"\"\n","        Create bounds for the observation space based on:\n","        - Load p_set values\n","        - Renewable generator p_max_pu values\n","        - Storage unit current inflow (normalized)\n","        \"\"\"\n","        # 1. Load bounds\n","        load_p_set_all = self.network.loads_t.p_set  # DataFrame with all snapshots and loads\n","        load_low_bounds = load_p_set_all.min(axis=0).values  # Min across all snapshots for each load\n","        load_high_bounds = load_p_set_all.max(axis=0).values  # Max across all snapshots for each load\n","\n","        # 2. Renewable generator bounds\n","        if self.n_renewable > 0:\n","            renewable_p_max_pu_all = self.network.generators_t.p_max_pu[self.renewable_names]\n","            renewable_low_bounds = renewable_p_max_pu_all.min(axis=0).values\n","            renewable_high_bounds = renewable_p_max_pu_all.max(axis=0).values\n","        else:\n","            renewable_low_bounds = np.array([])\n","            renewable_high_bounds = np.array([])\n","\n","        # 3. Storage bounds (current inflow)\n","        storage_low_bounds, storage_high_bounds = self.create_storage_observation_bounds()\n","\n","        # 4. Combine all bounds\n","        low_bounds = np.concatenate([load_low_bounds, renewable_low_bounds, storage_low_bounds])\n","        high_bounds = np.concatenate([load_high_bounds, renewable_high_bounds, storage_high_bounds])\n","\n","        return low_bounds.astype(np.float32), high_bounds.astype(np.float32)\n","\n","    def _get_observation(self):\n","        \"\"\"\n","        Get current network state as observation.\n","\n","        Returns observation vector with structure:\n","        [load_1_demand, load_2_demand, ..., load_n_demand,\n","        renewable_1_p_max_pu, renewable_2_p_max_pu, ..., renewable_m_p_max_pu,\n","        storage_1_current_inflow_norm, storage_2_current_inflow_norm, ..., storage_k_current_inflow_norm]\n","        \"\"\"\n","\n","        # 1. Load demands (dynamic values at current snapshot)\n","        load_demands = self.network.loads_t.p_set.iloc[self.snapshot_idx].values\n","\n","        # 2. Renewable generator p_max_pu values (time-varying availability at current snapshot)\n","        if self.n_renewable > 0:\n","            renewable_p_max_pu = self.network.generators_t.p_max_pu.iloc[self.snapshot_idx][self.renewable_names].values\n","        else:\n","            renewable_p_max_pu = np.array([])\n","\n","        # 3. Storage states (previous SOC normalized + current inflow normalized)\n","        storage_states = self._get_storage_observation()\n","\n","        # 4. Combine all observations\n","        observation = np.concatenate([load_demands, renewable_p_max_pu, storage_states])\n","\n","        return observation.astype(np.float32)\n","\n","    def reset_network(self):\n","        \"\"\"Reset and ensure essential DataFrames exist.\"\"\"\n","        #Note that we do not just create a new network here, as this consumes more memory and previously led to a segmentation fault\n","        # we reset these ttributes for all snapshots, but they all start empty when the network is created so i think that's fine\n","        # Initialize/reset generators_t.p_set\n","        if not hasattr(self.network.generators_t, 'p_set') or self.network.generators_t.p_set.empty:\n","            self.network.generators_t.p_set = pd.DataFrame(\n","                0.0,\n","                index=self.network.snapshots,\n","                columns=self.network.generators.index\n","            )\n","        else:\n","            self.network.generators_t.p_set.iloc[:, :] = 0.0\n","\n","        # Initialize/reset storage_units_t attributes\n","        if not hasattr(self.network.storage_units_t, 'p_set') or self.network.storage_units_t.p_set.empty:\n","            self.network.storage_units_t.p_set = pd.DataFrame(\n","                0.0,\n","                index=self.network.snapshots,\n","                columns=self.network.storage_units.index\n","            )\n","        else:\n","            self.network.storage_units_t.p_set.iloc[:, :] = 0.0\n","\n","\n","        if not hasattr(self.network.storage_units_t, 'p_dispatch') or self.network.storage_units_t.p_dispatch.empty:\n","            self.network.storage_units_t.p_dispatch = pd.DataFrame(\n","                0.0,\n","                index=self.network.snapshots,\n","                columns=self.network.storage_units.index\n","            )\n","        else:\n","            self.network.storage_units_t.p_dispatch.iloc[:, :] = 0.0\n","\n","        if not hasattr(self.network.storage_units_t, 'p_store') or self.network.storage_units_t.p_store.empty:\n","            self.network.storage_units_t.p_store = pd.DataFrame(\n","                0.0,\n","                index=self.network.snapshots,\n","                columns=self.network.storage_units.index\n","            )\n","        else:\n","            self.network.storage_units_t.p_store.iloc[:, :] = 0.0\n","\n","        if not hasattr(self.network.storage_units_t, 'state_of_charge') or self.network.storage_units_t.state_of_charge.empty:\n","            self.network.storage_units_t.state_of_charge = pd.DataFrame(\n","                0.0,\n","                index=self.network.snapshots,\n","                columns=self.network.storage_units.index\n","            )\n","        else:\n","            self.network.storage_units_t.state_of_charge.iloc[:, :] = 0.0\n","\n","        if not hasattr(self.network.storage_units_t, 'spill') or self.network.storage_units_t.spill.empty:\n","            self.network.storage_units_t.spill = pd.DataFrame(\n","                0.0,\n","                index=self.network.snapshots,\n","                columns=self.network.storage_units.index\n","            )\n","        else:\n","            self.network.storage_units_t.spill.iloc[:, :] = 0.0\n","\n","    def reset(self, seed=None, options=None):\n","        \"\"\"\n","        Reset to training data with proper episode length handling.\n","        \"\"\"\n","        # Set seed but don't use it since start from first timestep in data\n","        if seed is not None:\n","            np.random.seed(seed)\n","\n","        # Reset counter\n","        self.snapshot_idx = 0\n","\n","        self.reset_network()\n","\n","        obs = self._get_observation()\n","        info = {\n","            'snapshot_idx': self.snapshot_idx,\n","            'is_training': True\n","        }\n","\n","        return obs, info\n","\n","    # omit reset_for_testing; we will cycle through train data for initial testing\n","    # omit get_test_snapshots\n","    # omit compute_storage_power_bounds; we don't use it since now enforce storage unit constraint with penalty\n","\n","    def scale_action(self, action):\n","        \"\"\"\n","        Simplified storage action scaling to avoid infeasible bounds.\n","        \"\"\"\n","        scaled_actions = {}\n","\n","        # Dispatchable generators\n","        if self.n_dispatchable > 0:\n","            disp_actions = action[self.action_structure['dispatchable']['start']:\n","                                self.action_structure['dispatchable']['end']]\n","            scaled_actions['dispatchable'] = self.disp_p_min + disp_actions * (self.disp_p_max - self.disp_p_min)\n","        else:\n","            scaled_actions['dispatchable'] = np.array([])\n","\n","        # Renewable generators\n","        if self.n_renewable > 0:\n","            renewable_actions = action[self.action_structure['renewable']['start']:\n","                                    self.action_structure['renewable']['end']]\n","            current_p_max_pu = self.network.generators_t.p_max_pu.iloc[self.snapshot_idx][self.renewable_names].values\n","            current_p_max = current_p_max_pu * self.renewable_p_nom\n","            current_p_min = self.renewable_p_min_pu * self.renewable_p_nom\n","            scaled_actions['renewable'] = current_p_min + renewable_actions * (current_p_max - current_p_min)\n","        else:\n","            scaled_actions['renewable'] = np.array([])\n","\n","        # Simplified storage scaling\n","        # Bidirectional storage scaling\n","        if self.n_bidirectional > 0:\n","            bid_p_store_actions = action[self.action_structure['bidirectional_p_store']['start']:\n","                                       self.action_structure['bidirectional_p_store']['end']]\n","            bid_p_dispatch_actions = action[self.action_structure['bidirectional_p_dispatch']['start']:\n","                                           self.action_structure['bidirectional_p_dispatch']['end']]\n","\n","            scaled_p_store_bid = np.zeros(self.n_bidirectional)\n","            scaled_p_dispatch_bid = np.zeros(self.n_bidirectional)\n","\n","            for i, storage_name in enumerate(self.bidirectional_names):\n","                storage_df = self.network.storage_units.loc[storage_name]\n","                p_nom = storage_df.p_nom\n","                p_max_pu = storage_df.p_max_pu\n","                p_bound = p_nom * p_max_pu\n","\n","                scaled_p_store_bid[i] = bid_p_store_actions[i] * p_bound\n","                scaled_p_dispatch_bid[i] = bid_p_dispatch_actions[i] * p_bound\n","\n","            scaled_actions['bidirectional_p_store'] = scaled_p_store_bid\n","            scaled_actions['bidirectional_p_dispatch'] = scaled_p_dispatch_bid\n","        else:\n","            scaled_actions['bidirectional_p_store'] = np.array([])\n","            scaled_actions['bidirectional_p_dispatch'] = np.array([])\n","\n","        # Unidirectional storage scaling (p_dispatch only)\n","        if self.n_unidirectional > 0:\n","            uni_p_dispatch_actions = action[self.action_structure['unidirectional_p_dispatch']['start']:\n","                                           self.action_structure['unidirectional_p_dispatch']['end']]\n","\n","            scaled_p_dispatch_uni = np.zeros(self.n_unidirectional)\n","\n","            for i, storage_name in enumerate(self.unidirectional_names):\n","                storage_df = self.network.storage_units.loc[storage_name]\n","                p_nom = storage_df.p_nom\n","                p_max_pu = storage_df.p_max_pu\n","                p_bound = p_nom * p_max_pu\n","\n","                scaled_p_dispatch_uni[i] = uni_p_dispatch_actions[i] * p_bound\n","\n","            scaled_actions['unidirectional_p_dispatch'] = scaled_p_dispatch_uni\n","        else:\n","            scaled_actions['unidirectional_p_dispatch'] = np.array([])\n","\n","        return scaled_actions\n","\n","    def _simplified_power_balance(self):\n","        \"\"\"\n","        Optimized power balance calculation using vectorized operations and cached mappings.\n","        \"\"\"\n","        snapshot_idx = self.snapshot_idx\n","\n","        # 1. Vectorized generator updates using iloc\n","        if len(self._non_slack_gens) > 0:\n","            # Get column indices for non-slack generators\n","            non_slack_cols = [self.network.generators_t.p_set.columns.get_loc(gen) for gen in self._non_slack_gens]\n","\n","            # Vectorized copy from p_set to p\n","            p_set_values = self.network.generators_t.p_set.iloc[snapshot_idx, non_slack_cols].values\n","\n","            # Set realized power\n","            for i, gen_name in enumerate(self._non_slack_gens):\n","                gen_col = self.network.generators_t.p.columns.get_loc(gen_name)\n","                self.network.generators_t.p.iloc[snapshot_idx, gen_col] = p_set_values[i]\n","\n","        # 2. Vectorized storage updates using iloc\n","        if len(self.storage_names) > 0:\n","            storage_cols = [self.network.storage_units_t.p_set.columns.get_loc(name) for name in self.storage_names]\n","            p_set_values = self.network.storage_units_t.p_set.iloc[snapshot_idx, storage_cols].values\n","\n","            for i, storage_name in enumerate(self.storage_names):\n","                storage_col = self.network.storage_units_t.p.columns.get_loc(storage_name)\n","                self.network.storage_units_t.p.iloc[snapshot_idx, storage_col] = p_set_values[i]\n","\n","        # 3. Vectorized bus power calculation using cached mappings\n","        # Get all power values at once using iloc\n","        load_powers = -self.network.loads_t.p_set.iloc[snapshot_idx].values  # Negative for consumption\n","\n","        if len(self._non_slack_gens) > 0:\n","            non_slack_gen_cols = [self.network.generators_t.p.columns.get_loc(gen) for gen in self._non_slack_gens]\n","            gen_powers = self.network.generators_t.p.iloc[snapshot_idx, non_slack_gen_cols].values\n","        else:\n","            gen_powers = np.array([])\n","\n","        if len(self.storage_names) > 0:\n","            storage_cols = [self.network.storage_units_t.p.columns.get_loc(name) for name in self.storage_names]\n","            storage_powers = self.network.storage_units_t.p.iloc[snapshot_idx, storage_cols].values\n","        else:\n","            storage_powers = np.array([])\n","\n","        # Use pandas Series with cached bus mappings for fast groupby\n","        load_series = pd.Series(load_powers, index=self._load_names)\n","        load_bus_power = load_series.groupby(self._load_buses).sum()\n","\n","        if len(gen_powers) > 0:\n","            gen_series = pd.Series(gen_powers, index=self._non_slack_gens)\n","            gen_bus_power = gen_series.groupby(self._non_slack_gen_buses).sum()\n","        else:\n","            gen_bus_power = pd.Series(dtype=float)\n","\n","        if len(storage_powers) > 0:\n","            storage_series = pd.Series(storage_powers, index=self.storage_names)\n","            storage_bus_power = storage_series.groupby(self._storage_buses).sum()\n","        else:\n","            storage_bus_power = pd.Series(dtype=float)\n","\n","        # Combine all bus injections efficiently\n","        total_bus_injection = (load_bus_power.reindex(self._all_buses, fill_value=0) +\n","                              gen_bus_power.reindex(self._all_buses, fill_value=0) +\n","                              storage_bus_power.reindex(self._all_buses, fill_value=0))\n","\n","        # 4. Calculate total imbalance\n","        total_imbalance = total_bus_injection.sum()\n","\n","        # 5. Vectorized slack generator update using iloc\n","        if len(self._slack_gens) == 1:\n","            slack_gen = self._slack_gens[0]\n","            slack_col_set = self.network.generators_t.p_set.columns.get_loc(slack_gen)\n","            slack_col_p = self.network.generators_t.p.columns.get_loc(slack_gen)\n","\n","            current_p_set = self.network.generators_t.p_set.iloc[snapshot_idx, slack_col_set]\n","            self.network.generators_t.p.iloc[snapshot_idx, slack_col_p] = current_p_set - total_imbalance\n","\n","        elif len(self._slack_gens) > 1:\n","            # Multiple slack generators with cached weights\n","            slack_cols_set = [self.network.generators_t.p_set.columns.get_loc(gen) for gen in self._slack_gens]\n","            slack_cols_p = [self.network.generators_t.p.columns.get_loc(gen) for gen in self._slack_gens]\n","\n","            current_p_sets = self.network.generators_t.p_set.iloc[snapshot_idx, slack_cols_set].values\n","            slack_adjustments = self._slack_weights * (-total_imbalance)\n","            new_p_values = current_p_sets + slack_adjustments\n","\n","            for i, slack_col_p in enumerate(slack_cols_p):\n","                self.network.generators_t.p.iloc[snapshot_idx, slack_col_p] = new_p_values[i]\n","\n","    def _update_storage_soc_single_snapshot(self, storage_name):\n","        if self.snapshot_idx == 0:\n","            # For first snapshot, previous SOC is the initial value\n","            soc_prev = self.network.storage_units.state_of_charge_initial.loc[storage_name]\n","        else:\n","            previous_snapshot = self.network.snapshots[self.snapshot_idx - 1]\n","            soc_prev = self.network.storage_units_t.state_of_charge.loc[previous_snapshot, storage_name]\n","\n","        current_snapshot = self.network.snapshots[self.snapshot_idx]\n","\n","        #Get storage parameters\n","        storage_unit = self.network.storage_units.loc[storage_name]\n","        soc_max = storage_unit.p_nom * storage_unit.max_hours\n","        eff_store = storage_unit.efficiency_store\n","        eff_dispatch = storage_unit.efficiency_dispatch\n","        standing_loss = storage_unit.standing_loss\n","\n","        # Get time step\n","        if hasattr(self.network.snapshot_weightings, 'stores'):\n","            delta_t = self.network.snapshot_weightings.stores.iloc[self.snapshot_idx]\n","        else:\n","            delta_t = self.network.snapshot_weightings.iloc[self.snapshot_idx]\n","\n","        eff_standing = (1 - standing_loss) ** delta_t\n","\n","        # Get current operations (these determine the SOC change)\n","        p_store = self.network.storage_units_t.p_store.loc[current_snapshot, storage_name]\n","        p_dispatch = self.network.storage_units_t.p_dispatch.loc[current_snapshot, storage_name]\n","        if storage_name in self.network.storage_units_t.inflow.columns:\n","          inflow = self.network.storage_units_t.inflow.loc[current_snapshot, storage_name]\n","        else:\n","          inflow=0\n","\n","        # Calculate SOC without spill (could be non-zero even if soc_prev=0)\n","        soc_without_spill = (soc_prev * eff_standing +\n","                            (p_store * eff_store - p_dispatch/eff_dispatch + inflow) * delta_t)\n","\n","        # Calculate required spill\n","        required_spill = max(0, (soc_without_spill - soc_max) / delta_t)\n","\n","        # Final SOC after spill\n","        soc_actual = min(soc_without_spill, soc_max)\n","\n","        # Update the network\n","        self.network.storage_units_t.state_of_charge.loc[current_snapshot, storage_name] = soc_actual\n","        if hasattr(self.network, 'storage_units_t') and 'spill' in self.network.storage_units_t:\n","            self.network.storage_units_t.spill.loc[current_snapshot, storage_name] = required_spill\n","\n","    def evaluate_objective_direct(self, current_snapshot):\n","        \"\"\"\n","        Direct evaluation of PyPSA operational objective function terms.\n","\n","        This function evaluates only the operational terms (marginal costs) that PyPSA\n","        optimizes for generators and storage units, excluding capital costs and other\n","        investment-related terms.\n","\n","        Returns\n","        -------\n","        float\n","            Total operational cost for the current snapshot including snapshot weighting\n","        \"\"\"\n","        total_cost = 0.0\n","\n","        # Get snapshot weighting for proper cost calculation\n","        snapshot_weighting = self.network.snapshot_weightings.objective.loc[current_snapshot]\n","\n","        # Generator operational costs\n","        if len(self.network.generators) > 0:\n","            # Get marginal costs and power output\n","            gen_marginal_costs = self.network.generators['marginal_cost']\n","\n","            gen_power = self.network.generators_t.p.loc[current_snapshot]\n","\n","            # Calculate generator operational cost\n","            gen_cost = (gen_marginal_costs * gen_power).sum()\n","            total_cost += gen_cost\n","\n","        # Storage unit operational costs\n","        if len(self.network.storage_units) > 0:\n","            # Marginal cost for storage dispatch (discharge)\n","            storage_marginal_costs = self.network.storage_units['marginal_cost']\n","            storage_p_dispatch = self.network.storage_units_t.p_dispatch.loc[current_snapshot]\n","            storage_cost = (storage_marginal_costs * storage_p_dispatch).sum()\n","            #multiply correpsonding entries of the pandas columns and then sum them\n","            total_cost += storage_cost\n","\n","            # Marginal cost for storage charging\n","            storage_marginal_costs_storage = self.network.storage_units['marginal_cost_storage']\n","            storage_store_power = self.network.storage_units_t.p_store.loc[current_snapshot]\n","            storage_store_cost = (storage_marginal_costs_storage * storage_store_power).sum()\n","            total_cost += storage_store_cost\n","\n","            spill_costs = self.network.storage_units['spill_cost']\n","            spill_amounts = self.network.storage_units_t.spill.loc[current_snapshot]\n","            spill_cost = (spill_costs * spill_amounts).sum()\n","            total_cost += spill_cost\n","\n","        # Apply snapshot weighting (this is crucial for proper cost calculation)\n","        total_cost *= snapshot_weighting\n","\n","        return total_cost\n","\n","    def _calculate_reward(self):\n","        \"\"\"Calculate reward using stored objective components.\"\"\"\n","        # Get the current snapshot name\n","\n","        current_snapshot = self.network.snapshots[self.snapshot_idx]\n","        return -1*self.reward_scale_factor * self.evaluate_objective_direct(current_snapshot)\n","\n","    def calculate_reward_no_penalty(self):\n","        # Get base reward from objective function (negative for minimization)\n","        base_reward = self._calculate_reward()\n","\n","        current_snapshot = self.network.snapshots[self.snapshot_idx]\n","\n","        # Initialize constraint tracking\n","        constraint_results=self.initial_constr.copy()  # Use copy to avoid modifying original\n","\n","        constraint_results_idx=0\n","        slack_generators = self.network.generators[self.network.generators.control == \"Slack\"].index\n","        if not slack_generators.empty:\n","            for gen_name in slack_generators:\n","                # Get actual power output after power flow\n","                p_actual = self.network.generators_t.p.loc[current_snapshot, gen_name]\n","\n","                # Get limits\n","                p_min = self.network.generators.loc[gen_name, 'p_min_pu'] * self.network.generators.loc[gen_name, 'p_nom']\n","                p_max = self.network.generators.loc[gen_name, 'p_max_pu'] * self.network.generators.loc[gen_name, 'p_nom']\n","\n","                # Check lower bound\n","                if p_actual < p_min:\n","                    violation = min(float((p_min - p_actual)/(p_max-p_min)), 1.0)\n","                    constraint_results[constraint_results_idx]=violation\n","                #if not violated, the entry remains at zero\n","                #The violation represents \"what fraction of the allowable operating range am I violating by?\"\n","\n","                # Check upper bound\n","                if p_actual > p_max:\n","                    violation = min(float((p_actual - p_max)/(p_max-p_min)), 1.0)\n","                    constraint_results[constraint_results_idx+self.n_slack]=violation\n","\n","                constraint_results_idx+=1\n","\n","        constraint_results_idx=2 * self.n_slack\n","\n","        # 3. Check SOC constraints for storage units\n","        #In PyPSA, storage unit SOC bounds are: 0 ≤ soc ≤ 1 * (p_nom * max_hours)\n","        # Even for PHS, SOC is nonnegative since its the energy stored in the reservoir (always ≥ 0)\n","        if self.n_storage > 0:\n","            for storage_name in self.storage_names:\n","                # Get current SOC\n","                current_soc = self.network.storage_units_t.state_of_charge.loc[current_snapshot, storage_name]\n","\n","                # Get SOC limits\n","                storage_unit = self.network.storage_units.loc[storage_name]\n","                soc_min = 0.0  # Minimum SOC is typically 0\n","                soc_max = storage_unit.p_nom * storage_unit.max_hours  # Maximum energy capacity\n","\n","                # Check lower SOC bound\n","                if current_soc < soc_min:\n","                    violation = min(float((soc_min - current_soc)/(soc_max-soc_min)),1.0)\n","                    constraint_results[constraint_results_idx]=violation\n","\n","                # Check upper SOC bound\n","                if current_soc > soc_max:\n","                    violation = min(float((current_soc - soc_max)/(soc_max-soc_min)),1.0)\n","                    constraint_results[constraint_results_idx+self.n_storage]=violation\n","\n","        return base_reward, constraint_results\n","\n","    def calculate_reward_no_penalty_test(self):\n","        # Get base reward from objective function (negative for minimization)\n","        current_snapshot = self.network.snapshots[self.snapshot_idx]\n","        base_reward = self.evaluate_objective_direct(current_snapshot)\n","\n","        current_snapshot = self.network.snapshots[self.snapshot_idx]\n","\n","        # Initialize constraint tracking\n","        constraint_results=self.initial_constr_test.copy()  # Use copy to avoid modifying original\n","\n","        constraint_results_idx=0\n","        slack_generators = self.network.generators[self.network.generators.control == \"Slack\"].index\n","        if not slack_generators.empty:\n","            for gen_name in slack_generators:\n","                # Get actual power output after power flow\n","                p_actual = self.network.generators_t.p.loc[current_snapshot, gen_name]\n","\n","                # Get limits\n","                p_min = self.network.generators.loc[gen_name, 'p_min_pu'] * self.network.generators.loc[gen_name, 'p_nom']\n","                p_max = self.network.generators.loc[gen_name, 'p_max_pu'] * self.network.generators.loc[gen_name, 'p_nom']\n","\n","                # Check lower bound\n","                if p_actual < p_min:\n","                    violation = min(float((p_min - p_actual)/(p_max-p_min)), 1.0)\n","                    constraint_results[constraint_results_idx]=violation\n","                #if not violated, the entry remains at zero\n","                #The violation represents \"what fraction of the allowable operating range am I violating by?\"\n","\n","                # Check upper bound\n","                if p_actual > p_max:\n","                    violation = min(float((p_actual - p_max)/(p_max-p_min)), 1.0)\n","                    constraint_results[constraint_results_idx+self.n_slack]=violation\n","\n","                constraint_results_idx+=1\n","\n","        constraint_results_idx=2 * self.n_slack\n","\n","        # 3. Check SOC constraints for storage units\n","        #In PyPSA, storage unit SOC bounds are: 0 ≤ soc ≤ 1 * (p_nom * max_hours)\n","        # Even for PHS, SOC is nonnegative since its the energy stored in the reservoir (always ≥ 0)\n","        if self.n_storage > 0:\n","            for storage_name in self.storage_names:\n","                # Get current SOC\n","                current_soc = self.network.storage_units_t.state_of_charge.loc[current_snapshot, storage_name]\n","\n","                # Get SOC limits\n","                storage_unit = self.network.storage_units.loc[storage_name]\n","                soc_min = 0.0  # Minimum SOC is typically 0\n","                soc_max = storage_unit.p_nom * storage_unit.max_hours  # Maximum energy capacity\n","\n","                # Check lower SOC bound\n","                if current_soc < soc_min:\n","                    violation = min(float((soc_min - current_soc)/(soc_max-soc_min)),1.0)\n","                    constraint_results[constraint_results_idx]=violation\n","\n","                # Check upper SOC bound\n","                if current_soc > soc_max:\n","                    violation = min(float((current_soc - soc_max)/(soc_max-soc_min)),1.0)\n","                    constraint_results[constraint_results_idx+self.n_storage]=violation\n","\n","        constraint_results_idx=2 * self.n_slack+2*self.n_storage\n","        # 2. Check line flow constraints\n","        for line_name in self.network.lines.index:\n","            # Get line parameters\n","            s_nom = self.network.lines.loc[line_name, 's_nom']\n","            s_max_pu = 1.0  # Default, or get from lines_t.s_max_pu if it exists\n","\n","            # Calculate active power limit (this is what PyPSA's linear constraints check)\n","            s_max = s_max_pu * s_nom\n","\n","            # Get active power flow from the linear power flow\n","            # In PyPSA's linear formulation, this is the 's' variable value\n","            p0 = abs(self.network.lines_t.p0.loc[current_snapshot, line_name])\n","\n","            # Check if active power flow exceeds limit\n","            if p0 > s_max:\n","                violation = min(float((p0 - s_max)/s_max),1.0)\n","                constraint_results[constraint_results_idx]=violation\n","            constraint_results_idx+=1\n","\n","        return base_reward, constraint_results\n","\n","    def calculate_constrained_reward(self):\n","        \"\"\"\n","        Calculate reward using summation method with dynamic constraint checking.\n","\n","        Summation method:\n","        - Reward = -J(s) - P(s)\n","        \"\"\"\n","        base_reward, constraint_results = self.calculate_reward_no_penalty()\n","\n","        # Calculate penalty\n","        total_violation = np.sum(constraint_results)\n","        penalty = self.penalty_factor * (total_violation/self.n_constr)\n","\n","        #Compute scaled base reward\n","        scaled_base_reward = base_reward\n","\n","        # Calculate final reward using summation method\n","        constrained_reward = scaled_base_reward - penalty\n","\n","        return constrained_reward, constraint_results\n","\n","    def take_action(self, action):\n","        scaled_actions = self.scale_action(action)\n","        # Apply dispatchable generator setpoints\n","        if self.n_dispatchable > 0:\n","            for i, gen_name in enumerate(self.dispatchable_names):\n","                self.network.generators_t.p_set.iloc[self.snapshot_idx, self.network.generators_t.p_set.columns.get_loc(gen_name)] = scaled_actions['dispatchable'][i]\n","\n","        # Apply renewable generator setpoints\n","        if self.n_renewable > 0:\n","            for i, gen_name in enumerate(self.renewable_names):\n","                self.network.generators_t.p_set.iloc[self.snapshot_idx,\n","                    self.network.generators_t.p_set.columns.get_loc(gen_name)] = scaled_actions['renewable'][i]\n","\n","        # Apply bidirectional storage setpoints\n","        if self.n_bidirectional > 0:\n","            for i, storage_name in enumerate(self.bidirectional_names):\n","                self.network.storage_units_t.p_store.iloc[self.snapshot_idx,\n","                    self.network.storage_units_t.p_store.columns.get_loc(storage_name)] = scaled_actions['bidirectional_p_store'][i]\n","                self.network.storage_units_t.p_dispatch.iloc[self.snapshot_idx,\n","                    self.network.storage_units_t.p_dispatch.columns.get_loc(storage_name)] = scaled_actions['bidirectional_p_dispatch'][i]\n","                self.network.storage_units_t.p_set.iloc[self.snapshot_idx,\n","                    self.network.storage_units_t.p_set.columns.get_loc(storage_name)] = (\n","                        scaled_actions['bidirectional_p_dispatch'][i] - scaled_actions['bidirectional_p_store'][i])\n","\n","        # Apply unidirectional storage setpoints\n","        if self.n_unidirectional > 0:\n","            for i, storage_name in enumerate(self.unidirectional_names):\n","                # Only p_dispatch is controllable, p_store is always 0\n","                self.network.storage_units_t.p_store.iloc[self.snapshot_idx,\n","                    self.network.storage_units_t.p_store.columns.get_loc(storage_name)] = 0.0\n","                self.network.storage_units_t.p_dispatch.iloc[self.snapshot_idx,\n","                    self.network.storage_units_t.p_dispatch.columns.get_loc(storage_name)] = scaled_actions['unidirectional_p_dispatch'][i]\n","                self.network.storage_units_t.p_set.iloc[self.snapshot_idx,\n","                    self.network.storage_units_t.p_set.columns.get_loc(storage_name)] = scaled_actions['unidirectional_p_dispatch'][i]\n","\n","        # Update SOC for all storage units\n","        all_storage_names = self.bidirectional_names + self.unidirectional_names\n","        for storage_name in all_storage_names:\n","            if self.snapshot_idx > 0:\n","                self._update_storage_soc_single_snapshot(storage_name)\n","\n","    def _simplified_power_balance(self):\n","        \"\"\"\n","        Simplified power balance calculation that sets generator and storage realized values\n","        to their setpoints and calculates slack generator dispatch without full power flow.\n","\n","        Based on PyPSA's approach but optimized for cases where line flows aren't needed.\n","        \"\"\"\n","        current_snapshot = self.network.snapshots[self.snapshot_idx]\n","\n","        # 1. Set non-slack generator realized power to their setpoints\n","        # (This is what PyPSA does in _calculate_controllable_nodal_power_balance)\n","        non_slack_gens = self.network.generators[self.network.generators.control != \"Slack\"].index\n","        for gen_name in non_slack_gens:\n","            p_set = self.network.generators_t.p_set.loc[current_snapshot, gen_name]\n","            self.network.generators_t.p.loc[current_snapshot, gen_name] = p_set\n","\n","        # 2. Set storage unit realized power to their setpoints\n","        # PyPSA uses p_set for storage units as the net dispatch (positive = discharge, negative = charge)\n","        for storage_name in self.storage_names:\n","            p_set = self.network.storage_units_t.p_set.loc[current_snapshot, storage_name]\n","            self.network.storage_units_t.p.loc[current_snapshot, storage_name] = p_set\n","\n","        # 3. Calculate bus power injections (similar to PyPSA's approach)\n","        buses_o = self.network.buses.index\n","\n","        # Initialize bus power injections to load demands (negative = consumption)\n","        bus_p_injection = pd.Series(0.0, index=buses_o)\n","\n","        # Add load consumption (loads have negative sign in PyPSA)\n","        for load_name in self.network.loads.index:\n","            bus = self.network.loads.loc[load_name, 'bus']\n","            p_load = self.network.loads_t.p_set.loc[current_snapshot, load_name]\n","            bus_p_injection[bus] -= p_load  # Loads consume power\n","\n","        # Add non-slack generator injections (positive = generation)\n","        for gen_name in non_slack_gens:\n","            bus = self.network.generators.loc[gen_name, 'bus']\n","            p_gen = self.network.generators_t.p.loc[current_snapshot, gen_name]\n","            bus_p_injection[bus] += p_gen\n","\n","        # Add storage unit injections (positive = discharge, negative = charge)\n","        for storage_name in self.storage_names:\n","            bus = self.network.storage_units.loc[storage_name, 'bus']\n","            p_storage = self.network.storage_units_t.p.loc[current_snapshot, storage_name]\n","            bus_p_injection[bus] += p_storage\n","\n","        # 4. Calculate total system imbalance\n","        total_imbalance = bus_p_injection.sum()\n","\n","        # 5. Distribute imbalance to slack generators\n","        # (Following PyPSA's approach in sub_network_pf_singlebus)\n","        slack_generators = self.network.generators[self.network.generators.control == \"Slack\"].index\n","\n","        if len(slack_generators) == 1:\n","            # Single slack generator takes all imbalance\n","            slack_gen = slack_generators[0]\n","            current_p_set = self.network.generators_t.p_set.loc[current_snapshot, slack_gen]\n","            self.network.generators_t.p.loc[current_snapshot, slack_gen] = current_p_set - total_imbalance\n","        else:\n","            # Multiple slack generators - distribute proportionally to their p_nom\n","            slack_p_noms = self.network.generators.loc[slack_generators, 'p_nom']\n","            slack_weights = slack_p_noms / slack_p_noms.sum()\n","\n","            for slack_gen in slack_generators:\n","                current_p_set = self.network.generators_t.p_set.loc[current_snapshot, slack_gen]\n","                slack_share = slack_weights[slack_gen] * (-total_imbalance)\n","                self.network.generators_t.p.loc[current_snapshot, slack_gen] = current_p_set + slack_share\n","\n","\n","    def step(self, action):\n","        \"\"\"\n","        Execute one time step within the environment.\n","\n","        Args:\n","            action: Array of setpoints for all controllable components [disp_gen1, disp_gen2, ...,\n","                   renewable_gen1, renewable_gen2, ..., storage1, storage2, ...]\n","\n","        Returns:\n","            observation: Network state after action\n","            reward: Reward for this action\n","            terminated: Whether episode is finished due to task completion\n","            truncated: Whether episode is finished due to time limit\n","            info: Additional information\n","        \"\"\"\n","        self.take_action(action)\n","\n","        # Run simplified power balance instead of full power flow\n","        try:\n","            # self._simplified_power_balance()\n","            self.network.lpf(self.network.snapshots[self.snapshot_idx],skip_pre=True)\n","            power_flow_converged = True\n","        except Exception as e:\n","            print(f\"Power balance failed: {e}\")\n","            power_flow_converged = False\n","\n","        if not power_flow_converged:\n","            reward = self.no_convergence_lpf_penalty\n","            constraint_results= np.ones(self.n_constr) * -1# -1 indicates power flow did not converge. If want to get total constraint violation we will need to\n","        else:\n","            # Calculate reward using constrained reward function\n","            reward, constraint_results = self.calculate_constrained_reward()\n","\n","        # Increment step counters\n","        self.snapshot_idx += 1\n","\n","        # Check if episode is done\n","        truncated, terminated = self._check_done()\n","\n","        # Get observation\n","        if terminated or truncated:\n","            observation = np.zeros(self.observation_space.shape, dtype=np.float32)\n","        else:\n","            observation = self._get_observation()\n","\n","        # Additional info\n","        info = {\n","            'power_flow_converged': power_flow_converged,\n","            'snapshot_idx': self.snapshot_idx,\n","            'constraint_results': constraint_results\n","        }\n","\n","        return observation, reward, terminated, truncated, info\n","\n","    def step_test(self, action):\n","        \"\"\"\n","        Execute one time step within the environment. Use reward without penalty so we can compare to the reward from the baseline.\n","\n","        Args:\n","            action: Array of setpoints for all controllable components [disp_gen1, disp_gen2, ...,\n","                   renewable_gen1, renewable_gen2, ..., storage1, storage2, ...]\n","\n","        Returns:\n","            observation: Network state after action\n","            reward: Reward for this action\n","            terminated: Whether episode is finished due to task completion\n","            truncated: Whether episode is finished due to time limit\n","            info: Additional information\n","        \"\"\"\n","        self.take_action(action)\n","\n","        # Run power flow to get new network state\n","        try:\n","            self.network.lpf(self.network.snapshots[self.snapshot_idx], skip_pre=True)\n","            power_flow_converged = True\n","        except Exception as e:\n","            print(f\"Power flow failed: {e}\")\n","            power_flow_converged = False\n","\n","        if not power_flow_converged:\n","            reward = self.no_convergence_lpf_penalty\n","            constraint_results= np.ones(self.n_constr_test) * -1# -1 indicates power flow did not converge. If want to get total constraint violation we will need to\n","        else:\n","            # Calculate reward using constrained reward function\n","            reward, constraint_results = self.calculate_reward_no_penalty_test()\n","\n","        # Increment step counters\n","        self.snapshot_idx += 1\n","\n","        # Check if episode is done\n","        truncated, terminated = self._check_done()\n","        #replaced _check_done_test\n","\n","        # Get observation\n","        if terminated or truncated:\n","            observation = np.zeros(self.observation_space.shape, dtype=np.float32)\n","        else:\n","            observation = self._get_observation()\n","\n","        # Additional info\n","        info = {\n","            'power_flow_converged': power_flow_converged,\n","            'snapshot_idx': self.snapshot_idx,\n","            'constraint_results': constraint_results\n","        }\n","\n","        return observation, reward, terminated, truncated, info\n","\n","    def _check_done(self):\n","        \"\"\"\n","        Modified to handle both fixed and variable episode lengths.\n","        \"\"\"\n","        truncated=False\n","        terminated=False\n","        # For all episodes, stop if we've reached the test data boundary\n","        if self.snapshot_idx >= self.total_snapshots:\n","            terminated=True\n","\n","        return truncated, terminated\n","\n","    #Omit _check_done_test\n","\n","    def seed(self, seed=None):\n","        \"\"\"\n","        Set the random seed for reproducible experiments.\n","        \"\"\"\n","        np.random.seed(seed)\n","        return [seed]\n","\n","        #omit render function\n","\n","# network_file_path= \"/Users/antoniagrindrod/Documents/pypsa-earth_project/pypsa-earth-RL/networks/elec_s_10_ec_lc1.0_1h.nc\"\n","# input_dir=\"/Users/antoniagrindrod/Documents/pypsa-earth_project/pypsa-earth-RL/RL/var_constraint_map\"\n","# replacement_reward_offset=calculate_offset_k_initialization(network_file=network_file_path, input_dir=input_dir)"]},{"cell_type":"code","execution_count":7,"id":"f9c06b56","metadata":{"id":"f9c06b56","executionInfo":{"status":"ok","timestamp":1757610540846,"user_tz":-120,"elapsed":112,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["from tqdm import tqdm\n","class BackboneNetwork(nn.Module):\n","    def __init__(self, input_features, hidden_dimensions, out_features, dropout):\n","        super(BackboneNetwork, self).__init__()\n","\n","        # SIMPLIFIED: Single hidden layer network for debugging\n","        self.neuralnet = nn.Sequential(\n","            nn.Linear(input_features, hidden_dimensions),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dimensions, hidden_dimensions),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dimensions, out_features)\n","        )\n","\n","    def forward(self, x):\n","        output = self.neuralnet(x)\n","        return output\n","\n","#Define the actor-critic network\n","class actorCritic(nn.Module):\n","    def __init__(self, actor, critic):\n","        super().__init__()\n","        self.actor = actor\n","        self.critic = critic\n","    def forward(self, state):\n","        action_pred = self.actor(state)\n","        value_pred = self.critic(state)\n","        return action_pred, value_pred\n","        #Returns both the action predictions and the value predictions.\n","\n","#We'll use the networks defined above to create an actor and a critic. Then, we will create an agent, including the actor and the critic.\n","#finish this step later\n","# def create_agent(hidden_dimensions, dropout):\n","#     INPUT_FEATURES =env_train.\n","class PPO_agent:\n","    def __init__(self,\n","                 env,\n","                 device,\n","                 run,\n","                 hidden_dimensions,\n","                 dropout, discount_factor,\n","                 max_episodes,\n","                 print_interval,\n","                 PPO_steps,\n","                 n_trials,\n","                 epsilon,\n","                 entropy_coefficient,\n","                 learning_rate,\n","                 batch_size,\n","                 optimizer_name,\n","                 seed, training_start_time=None):\n","\n","        self.seed = seed+20000\n","        if seed is not None:\n","            # Set PyTorch seed for this class\n","            torch.manual_seed(self.seed)\n","            if torch.cuda.is_available():\n","                torch.cuda.manual_seed(self.seed)\n","        self.env = env  # Store the environment as an attribute\n","\n","        self.device = device\n","        self.run = run\n","\n","        # Get observation and action space dimensions for gymnasium environment\n","        obs, _ = self.env.reset()\n","        self.action_dim = self.env.action_space.shape[0]\n","\n","        self.INPUT_FEATURES = obs.shape[0]  # Flattened observation size\n","        self.ACTOR_OUTPUT_FEATURES = self.action_dim* 2  # 2 parameters (alpha, beta) per action dimension\n","\n","        self.HIDDEN_DIMENSIONS = hidden_dimensions\n","\n","        self.CRITIC_OUTPUT_FEATURES = 1\n","        self.DROPOUT = dropout\n","\n","        self.discount_factor = discount_factor\n","        self.max_episodes = max_episodes\n","        self.print_interval = print_interval\n","        self.PPO_steps=PPO_steps\n","        self.n_trials=n_trials\n","        self.epsilon=epsilon\n","        self.entropy_coefficient=entropy_coefficient\n","        self.learning_rate=learning_rate\n","\n","        self.batch_size=batch_size\n","\n","        # Initialize actor network\n","        self.actor = BackboneNetwork(\n","            self.INPUT_FEATURES, self.HIDDEN_DIMENSIONS, self.ACTOR_OUTPUT_FEATURES, self.DROPOUT\n","        ).to(self.device)\n","\n","        # Initialize the final layer bias for Beta distribution\n","        for name, param in self.actor.named_parameters():\n","            if 'neuralnet.4.bias' in name:  # Adjust index based on your network structure\n","                # Initialize to produce alpha=beta=2 (uniform-like distribution centered at 0.5)\n","                param.data.fill_(0.0)  # softplus(0) + 1 = 2\n","                print(f\"Initialized Beta parameters to produce uniform-like distribution\")\n","\n","        # Initialize critic network\n","        self.critic = BackboneNetwork(\n","            self.INPUT_FEATURES, self.HIDDEN_DIMENSIONS, self.CRITIC_OUTPUT_FEATURES, self.DROPOUT\n","        ).to(self.device)\n","\n","        #Better move the .to(self.device) call separately for both self.actor and self.critic. This ensures the individual parts of the model are moved to the correct device before combined into the actorCritic class\n","        # Combine into a single actor-critic model\n","        self.model = actorCritic(self.actor, self.critic)\n","\n","        self.ONE_TENSOR = torch.tensor(1.0, device=self.device)\n","\n","        try:\n","            # Try to get the optimizer from torch.optim based on the provided name\n","            self.optimizer = getattr(torch.optim, optimizer_name)(self.model.parameters(), lr=self.learning_rate)\n","        except AttributeError:\n","            # Raise an error if the optimizer_name is not valid\n","            raise ValueError(f\"Optimizer '{optimizer_name}' is not available in torch.optim.\")\n","\n","    def save_model_to_neptune(agent, neptune_run, run_id=None):\n","        \"\"\"Save the trained model to Neptune - synchronous version\"\"\"\n","        import tempfile\n","        import torch\n","        import json\n","        import os\n","        from datetime import datetime\n","\n","        # Create temporary files for the model components\n","        with tempfile.TemporaryDirectory() as temp_dir:\n","            # Save actor-critic network state dict\n","            if hasattr(agent, 'model') and agent.model is not None:\n","                actor_critic_path = os.path.join(temp_dir, 'actor_critic.pt')\n","                torch.save(agent.model.state_dict(), actor_critic_path)\n","            else:\n","                print(\"Warning: Agent does not have a model attribute to save.\")\n","                return\n","\n","            # Save complete model info\n","            model_info = {\n","                'state_space_dim': agent.INPUT_FEATURES,\n","                'action_space_dim': agent.action_dim,\n","                'hidden_dimensions': agent.HIDDEN_DIMENSIONS,\n","                'dropout': agent.DROPOUT,\n","                'learning_rate': agent.learning_rate,\n","                'discount_factor': agent.discount_factor,\n","                'epsilon': agent.epsilon,\n","                'entropy_coefficient': agent.entropy_coefficient,\n","                'batch_size': agent.batch_size,\n","                'ppo_steps': agent.PPO_steps,\n","                'model_architecture': str(agent.model) if hasattr(agent, 'model') and agent.model is not None else \"N/A\"\n","            }\n","\n","            if run_id is not None:\n","                model_info['run_id'] = run_id\n","\n","            model_info_path = os.path.join(temp_dir, 'model_info.json')\n","            with open(model_info_path, 'w') as f:\n","                json.dump(model_info, f, indent=2)\n","\n","            # Upload to Neptune synchronously\n","            neptune_run[\"model/actor_critic\"].upload(actor_critic_path)\n","            neptune_run[\"model/model_info\"].upload(model_info_path)\n","\n","            # Wait for uploads to complete\n","            neptune_run.wait()\n","\n","            neptune_run[\"model/saved_at\"] = datetime.now().isoformat()\n","\n","            print(f\"✓ Model saved to Neptune\")\n","\n","    def calculate_returns(self, rewards):\n","        returns = []\n","        cumulative_reward = 0\n","        for r in reversed(rewards):\n","            cumulative_reward = r +cumulative_reward*self.discount_factor\n","            returns.insert(0, cumulative_reward)\n","        returns = torch.tensor(returns).to(self.device)\n","\n","        # Only normalize if we have more than one element to avoid std() warning\n","        if returns.numel() > 1:\n","            epsilon = 1e-8  # Small constant to avoid division by zero\n","            returns_std = returns.std()\n","            if not torch.isnan(returns_std) and returns_std >= epsilon:\n","                returns = (returns - returns.mean()) / (returns_std + epsilon)\n","\n","        #I had conceptual trouble with normalizing the reward by an average, because it seemed to me since we're adding more rewards for earlier timesteps, the cumulative reward for earlier times would be a lot larger. But need to consider dicount facotr.\n","        # Future rewards contribute significantly to the cumulative return, so earlier timesteps will likely have larger returns.\n","        #if gamma is close to 0, future rewards have little influence, and the return at each timestep will closely resemble the immediate reward, meaning the pattern might not be as clear.\n","        return returns\n","\n","    #The advantage is calculated as the difference between the value predicted by the critic and the expected return from the actions chosen by the actor according to the policy.\n","    def calculate_advantages(self, returns, values):\n","        advantages = returns - values\n","\n","        # Only normalize if we have more than one element to avoid std() warning\n","        if advantages.numel() > 1:\n","            epsilon = 1e-8\n","            advantages_std = advantages.std()\n","            if not torch.isnan(advantages_std) and advantages_std >= epsilon:\n","                advantages = (advantages - advantages.mean()) / (advantages_std + epsilon)\n","\n","        return advantages\n","\n","    #The standard policy gradient loss is calculated as the product of the policy action probabilities and the advantage function\n","    #The standard policy gradietn loss cannot make corrections for abrupt policy changes. The surrogate loss modifies the standard loss to restrict the amount the policy can change in each iteration.\n","    #The surrogate loss is the minimum of (policy ratio X advantage function) and (clipped value of policy ratio X advantage function) where the policy ratio is between the action probabilities according to the old versus new policies and clipping restricts the value to a region near 1.\n","\n","    def calculate_surrogate_loss(self, actions_log_probability_old, actions_log_probability_new, advantages):\n","        advantages = advantages.detach()\n","        # creates a new tensor that shares the same underlying data as the original tensor but breaks the computation graph. This means:\n","        # The new tensor is treated as a constant with no gradients.\n","        # Any operations involving this tensor do not affect the gradients of earlier computations in the graph.\n","\n","        #If the advantages are not detached, the backpropagation of the loss computed using the surrogate_loss would affect both the actor and the critic networks\n","        # The surrogate loss is meant to update only the policy (actor).\n","        # Allowing gradients to flow back through the advantages would inadvertently update the critic, potentially disrupting its learning process.\n","\n","        policy_ratio  = (actions_log_probability_new - actions_log_probability_old).exp()\n","        surrogate_loss_1 = policy_ratio*advantages\n","        surrogate_loss_2 = torch.clamp(policy_ratio, min =1.0-self.epsilon, max = 1.0+self.epsilon)*advantages\n","        surrogate_loss=torch.min(surrogate_loss_1, surrogate_loss_2)\n","        return surrogate_loss\n","\n","    #TRAINING THE AGENT\n","    #Policy loss is the sum of the surrogate loss and the entropy bonus. It is used to update the actor (policy network)\n","    #Value loss is based on the difference between the value predicted by the critic and the returns (cumulative reward) generated by the policy. This loss is used to update the critic (value network) to make predictions more accurate.\n","\n","    def calculate_losses(self, surrogate_loss, entropy, returns, value_pred):\n","        entropy_bonus = self.entropy_coefficient*entropy\n","        policy_loss = -(surrogate_loss+entropy_bonus).sum()\n","        value_loss = torch.nn.functional.smooth_l1_loss(returns, value_pred).sum() #helps to smoothen the loss function and makes it less sensitive to outliers.\n","        return policy_loss, value_loss\n","\n","    def init_training(self):\n","        #create a set of buffers as empty arrays. To be used during training to store information\n","        states = []\n","        actions = []\n","        actions_log_probability = []\n","        values = []\n","        rewards = []\n","        done = False\n","        episode_reward = 0\n","        return states, actions, actions_log_probability, values, rewards, done, episode_reward\n","\n","    def forward_pass(self, episode=None):  # Add episode_num parameter\n","        # Use different seed for each episode but still reproducible\n","        episode_seed = self.seed + episode\n","        state, _ = self.env.reset(seed=episode_seed)\n","\n","        states, actions, actions_log_probability, values, rewards, done, episode_reward = self.init_training()\n","\n","        state, _ = self.env.reset()  # Gymnasium format returns (obs, info)\n","\n","        self.model.train() # Set model to training mode\n","\n","        # Initialize constraint violation tracking\n","        episode_constraint_violations = None\n","\n","        while True:\n","            with torch.no_grad():\n","                state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n","                states.append(state_tensor)\n","\n","                # Get action predictions and values\n","                action_mean, value_pred = self.model(state_tensor)\n","\n","                # Split actor output into alpha and beta parameters\n","                alpha_raw, beta_raw = torch.split(action_mean, self.action_dim, dim=-1)\n","\n","                # Ensure alpha, beta > 1 for well-behaved Beta distribution\n","                alpha = torch.nn.functional.softplus(alpha_raw).add_(self.ONE_TENSOR)\n","                beta = torch.nn.functional.softplus(beta_raw).add_(self.ONE_TENSOR)\n","\n","                # Create Beta distribution for continuous actions in [0,1]\n","                dist = torch.distributions.Beta(alpha, beta)\n","\n","                action = dist.sample()\n","\n","                # No clamping needed - Beta distribution naturally outputs [0,1]\n","                action_clamped = action\n","\n","                log_prob_action = dist.log_prob(action).sum(dim=-1)  # Sum over action dimensions\n","\n","            # Step environment with numpy action\n","            action_np = action_clamped.detach().cpu().numpy().flatten()\n","            state, reward, terminated, truncated, info = self.env.step(action_np)\n","\n","            # Track total constraint violation (over the full episode) for each constraint.\n","            if 'constraint_results' in info:\n","                if episode_constraint_violations is None:\n","                    # Initialize with the same shape as constraint_results\n","                    episode_constraint_violations = info['constraint_results'].copy()\n","                else:\n","                    # Accumulate violations for each constraint\n","                    episode_constraint_violations += info['constraint_results']\n","\n","            done = terminated or truncated\n","            actions.append(action_clamped)\n","            actions_log_probability.append(log_prob_action)\n","            values.append(value_pred)\n","            rewards.append(reward)\n","            episode_reward += reward\n","\n","            if done:\n","                break\n","        states=torch.cat(states).to(self.device)#converts the list of individual states into a sinlem tensor that is necessary for later processing\n","        #Creates a single tensor with dimensions like (N, state_dim), where: N is the number of states collected in the episode; state_dim is the dimensionality of each state.\n","        #torch.cat() expects a sequence (e.g. list or tuple) of PyTorch tensors as input.\n","        actions=torch.cat(actions).to(self.device)\n","        #Note that, in the loop, both state and action are PyTorch tensors so that states and actions are both lists of PyTorch tensors\n","        actions_log_probability=torch.cat(actions_log_probability).to(self.device)\n","        values=torch.cat(values).squeeze(-1).to(self.device)# .squeeze removes a dimension of size 1 only from tensor at the specified position, in this case, -1, the last dimesion in the tensor. Note that .squeeze() does not do anything if the size of the dimension at the specified potision is not 1.\n","        # print(f\"rewards NaNs: {torch.isnan(torch.tensor(rewards, dtype=torch.float32)).any()}\")\n","        # print(f\"values NaNs: {torch.isnan(torch.tensor(values, dtype=torch.float32)).any()}\")\n","        returns = self.calculate_returns(rewards)\n","        advantages = self.calculate_advantages(returns, values)\n","\n","        # print(f\"Returns NaNs: {torch.isnan(returns).any()}\")\n","        # print(f\"advantages NaNs (after calculation): {torch.isnan(advantages).any()}\")\n","\n","        return episode_reward, states, actions, actions_log_probability, advantages, returns, episode_constraint_violations\n","\n","\n","    def update_policy(self,\n","            states,\n","            actions,\n","            actions_log_probability_old,\n","            advantages,\n","            returns):\n","        #print(f\"Returns NaNs: {torch.isnan(returns).any()}\")\n","        total_policy_loss = 0\n","        total_value_loss = 0\n","        actions_log_probability_old = actions_log_probability_old.detach()\n","        actions=actions.detach()\n","\n","        # print(f\"Returns NaNs: {torch.isnan(returns).any()}\")\n","        # print(f\"advantages NaNs (after calculation): {torch.isnan(advantages).any()}\")\n","\n","\n","        #detach() is used to remove the tensor from the computation graph, meaning no gradients will be calculated for that tensor when performing backpropagation.\n","        #In this context, it's used to ensure that the old actions and log probabilities do not participate in the gradient computation during the optimization of the policy, as we want to update the model based on the current policy rather than the old one.\n","        #print(type(states), type(actions),type(actions_log_probability_old), type(advantages), type(returns))\n","        training_results_dataset= TensorDataset(\n","                states,\n","                actions,\n","                actions_log_probability_old,\n","                advantages,\n","                returns) #TensorDataset class expects all the arguments passed to it to be tensors (or other compatible types like NumPy arrays, which will be automatically converted to tensor\n","        batch_dataset = DataLoader(\n","                training_results_dataset,\n","                batch_size=self.batch_size,\n","                shuffle=False)\n","        #creates a DataLoader instance in PyTorch, which is used to load the training_results_dataset in batches during training.\n","        #batch_size defines how many samples will be included in each batch. The dataset will be divided into batches of size BATCH_SIZE. The model will then process one batch at a time, rather than all of the data at once,\n","        #shuffle argument controls whether or not the data will be shuffled before being split into batches.\n","        #Because shuffle is false, dataloader will provide the batches in the order the data appears in training_results_dataset. In this case, the batches will be formed from consecutive entries in the dataset, and the observations will appear in the same sequence as they are stored in the dataset.\n","        for _ in range(self.PPO_steps):\n","            for batch_idx, (states,actions,actions_log_probability_old, advantages, returns) in enumerate(batch_dataset):\n","                #get new log prob of actions for all input states\n","                action_mean, value_pred = self.model(states)\n","                value_pred = value_pred.squeeze(-1)\n","\n","                # For continuous actions with Beta distribution\n","                alpha_raw, beta_raw = torch.split(action_mean, self.action_dim, dim=-1)\n","\n","                # Ensure alpha, beta > 1 for well-behaved Beta distribution\n","                alpha = torch.nn.functional.softplus(alpha_raw).add_(self.ONE_TENSOR)\n","                beta = torch.nn.functional.softplus(beta_raw).add_(self.ONE_TENSOR)\n","\n","                probability_distribution_new = torch.distributions.Beta(alpha, beta)\n","                entropy = probability_distribution_new.entropy().sum(dim=-1)\n","\n","                #estimate new log probabilities using old actions\n","                actions_log_probability_new = probability_distribution_new.log_prob(actions).sum(dim=-1)\n","                # # Check for NaN or Inf in log probabilities\n","                # if torch.isnan(actions_log_probability_old).any() or torch.isinf(actions_log_probability_old).any():\n","                #     print(\"NaN or Inf detected in actions_log_probability_old!\")\n","                #     return  # You can return or handle this case as needed\n","\n","                # if torch.isnan(actions_log_probability_new).any() or torch.isinf(actions_log_probability_new).any():\n","                #     print(\"NaN or Inf detected in actions_log_probability_new!\")\n","                #     return  # You can return or handle this case as needed\n","\n","                # print(f\"actions_log_probability_old NaNs: {torch.isnan(actions_log_probability_old).any()}\")\n","                # print(f\"actions_log_probability_new NaNs: {torch.isnan(actions_log_probability_new).any()}\")\n","                # print(f\"advantages NaNs: {torch.isnan(advantages).any()}\")\n","\n","                surrogate_loss = self.calculate_surrogate_loss(\n","                    actions_log_probability_old,\n","                    actions_log_probability_new,\n","                    advantages\n","                )\n","\n","                # print(f\"Surrogate Loss NaNs: {torch.isnan(surrogate_loss).any()}\")\n","                # print(f\"Entropy NaNs: {torch.isnan(entropy).any()}\")\n","                # print(f\"Returns NaNs: {torch.isnan(returns).any()}\")\n","                # print(f\"Value Predictions NaNs: {torch.isnan(value_pred).any()}\")\n","\n","                policy_loss, value_loss = self.calculate_losses(\n","                    surrogate_loss,\n","                    entropy,\n","                    returns,\n","                    value_pred\n","                )\n","                self.optimizer.zero_grad() #clear existing gradietns in the optimizer (so that these don't propagate accross multiple .backward(). Ensures each optimization step uses only the gradients computed during the current batch.\n","\n","                # Skip backward pass if loss is NaN\n","                if torch.isnan(policy_loss).any():\n","                    print(\"NaN detected in policy_loss - skipping backward pass!\")\n","                    continue\n","                if torch.isnan(value_loss).any():\n","                    print(\"NaN detected in value_loss - skipping backward pass!\")\n","                    continue\n","\n","                policy_loss.backward() #computes gradients for policy_loss with respect to the agent's parameters\n","                # #Check for NaN gradients after policy_loss backward\n","                # for param in self.model.parameters():\n","                #     if param.grad is not None:  # Check if gradients exist for this parameter\n","                #         if torch.isnan(param.grad).any():\n","                #             print(\"NaN gradient detected in policy_loss!\")\n","                # #             return\n","                value_loss.backward()\n","                # Check for NaN gradients after value_loss backwardor param in self.model.parameters():\n","                # for param in self.model.parameters():\n","                #     if param.grad is not None:  # Check if gradients exist for this parameter\n","                #         if torch.isnan(param.grad).any():\n","                #             print(\"NaN gradient detected in value_loss!\")\n","                #             return\n","\n","                self.optimizer.step()\n","                #The update step is based on the learning rate and other hyperparameters of the optimizer\n","                # The parameters of the agent are adjusted to reduce the policy and value losses.\n","                total_policy_loss += policy_loss.item() #accumulate the scalar value of the policy loss for logging/ analysis\n","                #policy_loss.item() extracts the numerical value of the loss tensor (detaching it from the computational graph).\n","                #This value is added to total_policy_loss to compute the cumulative loss over all batches in the current PPO step.\n","                #Result: tracks the total policy loss for the current training epoch\n","                # The loss over the whole dataset is the sum of the losses over all batches.\n","                #The training dataset is split into batches during the training process. Each batch represents a subset of the collected training data from one episode.\n","                # Loss calculation is performed for each batch (policy loss and value loss)\n","                # for each batch, gradients are calculated with respect to the total loss for that batch and the optimizer then updates the network parameters using these gradients.\n","                # this is because the surrogate loss is only calculated over a single batch of data\n","                #look at the formula for surrogate loss.\n","                # It is written in terms of an expectation ˆ Et[. . .] that indicates the empirical average over a finite batch of samples.\n","                # This means you have collected a set of data (time steps) from the environment, and you're averaging over these data points. The hat symbol implies you're approximating the true expectation with a finite sample of data from the environment. This empirical average can be computed as the mean of values from the sampled transitions\n","                # the expectation is taken over all the data you've collected\n","                #If you're training with multiple batches (i.e., collecting data in chunks), then you can think of the expectation as being computed over each batch.\n","                #The overall expectation can indeed be seen as the sum of expectations computed for each batch, but The expectation of the sum is generally not exactly equal to the sum of the expectations unless the samples are independent, but in practical reinforcement learning algorithms, it's typically a good enough approximation\n","                #For samples to be independent, the outcome of one sample must not provide any information about the outcome of another. Specifically, in the context of reinforcement learning, this means that the states, actions, rewards, and subsequent states observed in different time steps or different episodes should be independent of each other.\n","                total_value_loss += value_loss.item()\n","                #Notice that we are calculating an empirical average, which is already an approximation on the true value (the true expectation would be the average over an infinite amount of data, and the empirical average is the average over the finite amount of data that we have collected).\n","                #But furthermore, we are approximating even the empirical average istelf. The empirical average is the average over all our collected datal, but here we actually batch our data, calculate average over each batch and then sum these averages, which is not exaclty equal to the average of the sums (but is a decent approximation).\n","        return total_policy_loss / self.PPO_steps, total_value_loss / self.PPO_steps\n","\n","    def train(self):\n","        train_rewards = []\n","        avg_rewards =[]\n","        violation_rates=[]\n","        # test_rewards = []\n","        policy_losses = []\n","        value_losses = []\n","        #lens = []\n","\n","\n","        for episode in range(1, self.max_episodes + 1):\n","\n","            #check timing for forward pass\n","            # Perform a forward pass and collect experience\n","            train_reward, states, actions, actions_log_probability, advantages, returns, episode_constraint_violations = self.forward_pass(episode)\n","\n","            #check timing for policy update\n","            # Update the policy using the experience collected\n","            policy_loss, value_loss = self.update_policy(\n","                states,\n","                actions,\n","                actions_log_probability,\n","                advantages,\n","                returns)\n","\n","            # Log the results\n","            policy_losses.append(policy_loss)\n","            value_losses.append(value_loss)\n","            train_rewards.append(train_reward)\n","            self.run[\"policy_loss\"].log(policy_loss)\n","            self.run[\"value_loss\"].log(value_loss)\n","            self.run[\"train_reward\"].log(train_reward)\n","            # Total episode return (discounted)\n","            self.run[\"episode_return\"].log(returns[0].item())  # The discounted version\n","            # Log episode constraint violations array (total violation per constraint)\n","            # Log individual total constraint violations for episode\n","            for i, violation in enumerate(episode_constraint_violations):\n","                self.run[f\"constraint_{i}\"].log(float(violation))\n","\n","            # Log sum of violations for all constraints\n","            self.run[\"total_constraint_violation\"].log(float(np.sum(episode_constraint_violations)))\n","\n","\n","            # Print with new metrics and save model at interval\n","            if episode % self.print_interval == 0:\n","                print(f'Episode: {episode:3} ')\n","                self.save_model_to_neptune(self.run)\n","                #the model will get overridden each time you save. Neptune will keep only the most recent version of the model files.\n","\n","        return train_rewards\n","\n","def plot_train_rewards(train_rewards, reward_threshold):\n","    plt.figure(figsize=(12, 8))\n","    plt.plot(train_rewards, label='Training Reward')\n","    plt.xlabel('Episode', fontsize=20)\n","    plt.ylabel('Training Reward', fontsize=20)\n","    plt.hlines(reward_threshold, 0, len(train_rewards), color='y')\n","    plt.legend(loc='lower right')\n","    plt.grid()\n","    plt.show()\n","\n","def plot_test_rewards(test_rewards, reward_threshold):\n","    plt.figure(figsize=(12, 8))\n","    plt.plot(test_rewards, label='Testing Reward')\n","    plt.xlabel('Episode', fontsize=20)\n","    plt.ylabel('Testing Reward', fontsize=20)\n","    plt.hlines(reward_threshold, 0, len(test_rewards), color='y')\n","    plt.legend(loc='lower right')\n","    plt.grid()\n","    plt.show()\n","\n","def plot_losses(policy_losses, value_losses):\n","    plt.figure(figsize=(12, 8))\n","    plt.plot(value_losses, label='Value Losses')\n","    plt.plot(policy_losses, label='Policy Losses')\n","    plt.xlabel('Episode', fontsize=20)\n","    plt.ylabel('Loss', fontsize=20)\n","    plt.legend(loc='lower right')\n","    plt.grid()\n","    plt.show()"]},{"cell_type":"code","execution_count":8,"id":"acf82e05","metadata":{"id":"acf82e05","executionInfo":{"status":"ok","timestamp":1757610541113,"user_tz":-120,"elapsed":56,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["class EnvDispatchReplacement(EnvDispatchConstr):\n","    \"\"\"\n","    Environment using the Replacement reward method instead of Summation.\n","\n","    Inherits from Env2Gen1LoadConstr but modifies the reward calculation\n","    to implement the replacement method from the RL-OPF paper.\n","    \"\"\"\n","\n","    def __init__(self,network_file,no_convergence_lpf_penalty, reward_scale_factor, constraint_penalty_factor=10, seed=None, offset_k=2500):\n","        \"\"\"\n","        Initialize the replacement reward environment.\n","\n","        Parameters:\n","        -----------\n","        network_file : str\n","            Path to the PyPSA network file\n","        episode_length : int, optional\n","            Length of episodes (defaults to total snapshots)\n","        constraint_penalty_factor : float\n","            Penalty factor for constraint violations\n","        offset_k : float\n","            Offset value for replacement reward method\n","        test_start_date : str\n","            Start date for test period (everything from this date onwards is test data)\n","        fixed_episode_length : int, optional\n","            Fixed episode length if specified, otherwise episodes are variable\n","        \"\"\"\n","        # Call parent constructor - this will initialize all base attributes\n","        super().__init__(network_file, no_convergence_lpf_penalty, reward_scale_factor, constraint_penalty_factor=10, seed=None)\n","\n","        # Add replacement-specific attributes\n","        self.offset_k = offset_k\n","        self.reward_method = \"replacement\"\n","\n","    def calculate_constrained_reward(self):\n","        \"\"\"\n","        Calculate reward using replacement method with dynamic constraint checking.\n","\n","        Replacement method:\n","        - If all constraints satisfied: return -J(s) + k\n","        - If constraints violated: return -P(s)\n","        \"\"\"\n","        base_reward, constraint_results = self.calculate_reward_no_penalty()\n","\n","        total_violation = np.sum(constraint_results)\n","        penalty = self.penalty_factor * (total_violation/self.n_constr)\n","\n","        #Compute scaled base reward\n","        scaled_base_reward = base_reward\n","\n","        # Apply replacement method\n","        if total_violation==0:\n","            # All constraints satisfied: return optimization reward + offset k\n","            constrained_reward = scaled_base_reward + self.offset_k\n","        else:\n","            constrained_reward = -1*penalty\n","\n","        # Ensure reward is a scalar\n","        if hasattr(constrained_reward, '__len__'):\n","            constrained_reward = float(constrained_reward)\n","\n","        return constrained_reward, constraint_results\n","\n","    def get_reward_method_info(self):\n","        \"\"\"\n","        Get information about the reward method being used.\n","\n","        Returns:\n","        --------\n","        dict: Information about the reward method\n","        \"\"\"\n","        return {\n","            'method': 'replacement',\n","            'offset_k': self.offset_k,\n","            'penalty_factor': self.penalty_factor,\n","            'train_snapshots': self.train_snapshots,\n","            'test_snapshots': self.test_snapshots,\n","            'test_start_date': str(self.test_start_date),\n","            'fixed_episode_length': self.fixed_episode_length\n","        }\n","\n","# network_file_path= \"/Users/antoniagrindrod/Documents/pypsa-earth_project/pypsa-earth-RL/networks/elec_s_10_ec_lc1.0_1h.nc\"\n","# input_dir=\"/Users/antoniagrindrod/Documents/pypsa-earth_project/pypsa-earth-RL/RL/var_constraint_map\"\n","# replacement_reward_offset=calculate_offset_k_initialization(network_file=network_file_path, input_dir=input_dir)"]},{"cell_type":"code","execution_count":9,"id":"b1c78d73-ff58-453e-a6ad-c858c283f157","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b1c78d73-ff58-453e-a6ad-c858c283f157","outputId":"c464da64-6879-4cf0-c9fc-5fb1d28df0a4","executionInfo":{"status":"ok","timestamp":1757610561510,"user_tz":-120,"elapsed":18440,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","def execute_training_simple_constr(env_class, seed):\n","    import os\n","    import torch\n","    import neptune\n","    import random\n","\n","    base_params = {\n","        \"optimizer_name\": \"Adam\",\n","        \"MAX_EPISODES\": 1000,\n","        \"PRINT_INTERVAL\": 10,\n","        \"N_TRIALS\": 8,\n","        \"DROPOUT\": 0,\n","        \"network_file\": \"elec_s_10_ec_lc1.0_1h.nc\",\n","        \"optimization_result_file\": \"elec_s_10_ec_lc1.0_1h_Test_Objective.txt\",\n","        \"reward_scale_factor\": 10**(-8),\n","        \"no_convergence_lpf_penalty\": 100,\n","        \"env_class\": env_class,\n","    }\n","\n","    # Parameters to sweep (from your original code)\n","    sweep_params = {\n","        \"LEARNING_RATE\": [1e-4, 1e-3, 5e-3],\n","        \"EPSILON\": [0.1, 0.2, 0.3],\n","        \"ENTROPY_COEFFICIENT\": [0.01, 0.1],\n","        \"HIDDEN_DIMENSIONS\": [32, 128],\n","        \"PPO_STEPS\": [8, 16],\n","        \"BATCH_SIZE\": [128, 256],\n","        \"DISCOUNT_FACTOR\": [0.95, 0.99],\n","        \"constraint_penalty_factor\": [10**(-1), 0.5*10**(-1)],\n","        \"seed\": seed,\n","    }\n","\n","    # Base priority configurations\n","    priority_configs = [\n","        {\"LEARNING_RATE\": 1e-3, \"EPSILON\": 0.2, \"ENTROPY_COEFFICIENT\": 0.01,\n","         \"HIDDEN_DIMENSIONS\": 128, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256, \"DISCOUNT_FACTOR\": 0.99,\n","         \"constraint_penalty_factor\": 10**(-1), \"seed\": seed},\n","        {\"LEARNING_RATE\": 1e-4, \"EPSILON\": 0.2, \"ENTROPY_COEFFICIENT\": 0.01,\n","         \"HIDDEN_DIMENSIONS\": 128, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256, \"DISCOUNT_FACTOR\": 0.99,\n","         \"constraint_penalty_factor\": 10**(-1), \"seed\": seed},\n","        {\"LEARNING_RATE\": 1e-3, \"EPSILON\": 0.1, \"ENTROPY_COEFFICIENT\": 0.01,\n","         \"HIDDEN_DIMENSIONS\": 128, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256, \"DISCOUNT_FACTOR\": 0.99,\n","         \"constraint_penalty_factor\": 10**(-1), \"seed\": seed},\n","        {\"LEARNING_RATE\": 1e-3, \"EPSILON\": 0.2, \"ENTROPY_COEFFICIENT\": 0.01,\n","         \"HIDDEN_DIMENSIONS\": 128, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256, \"DISCOUNT_FACTOR\": 0.99,\n","         \"constraint_penalty_factor\": 0.5*10**(-1), \"seed\": seed},\n","        {\"LEARNING_RATE\": 1e-4, \"EPSILON\": 0.1, \"ENTROPY_COEFFICIENT\": 0.01,\n","         \"HIDDEN_DIMENSIONS\": 128, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256, \"DISCOUNT_FACTOR\": 0.99,\n","         \"constraint_penalty_factor\": 10**(-1), \"seed\": seed},\n","        {\"LEARNING_RATE\": 1e-3, \"EPSILON\": 0.1, \"ENTROPY_COEFFICIENT\": 0.01,\n","         \"HIDDEN_DIMENSIONS\": 128, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256, \"DISCOUNT_FACTOR\": 0.99,\n","         \"constraint_penalty_factor\": 0.5*10**(-1), \"seed\": seed},\n","    ]\n","\n","\n","    # Generate 10 additional random configurations\n","    def generate_random_config(seed_val):\n","        \"\"\"Generate a random configuration from the sweep parameters\"\"\"\n","        config = {\"seed\": seed_val}\n","        for param, values in sweep_params.items():\n","            if param != \"seed\":  # seed is already set\n","                config[param] = random.choice(values)\n","        return config\n","\n","    # Set random seed for reproducible random config generation\n","    random.seed(seed + 12345)  # Add offset to avoid conflicts with training seed\n","\n","    additional_configs = []\n","    for i in range(10):\n","        random_config = generate_random_config(seed)\n","        additional_configs.append(random_config)\n","\n","    # Combine all configurations\n","    all_configs = priority_configs + additional_configs\n","\n","    # Store results from all configurations\n","    all_results = []\n","\n","    # Loop through each configuration\n","    for config_idx, config in enumerate(all_configs):\n","        config_type = \"priority\" if config_idx < len(priority_configs) else \"random\"\n","        print(f\"Running configuration {config_idx + 1}/{len(all_configs)} ({config_type})\")\n","        print(f\"Config: {config}\")\n","\n","        # Merge base params with current config\n","        full_config = {**base_params, **config}\n","\n","        # Set up paths\n","        network_file = full_config[\"network_file\"]\n","        gdrive_base = '/content/drive/My Drive/Colab_Notebooks'#'./'  # or '/workspace/'\n","        network_file_path = os.path.join(gdrive_base, \"networks_1_year_connected\", network_file)\n","\n","        # Set seeds\n","        current_seed = full_config[\"seed\"]\n","        set_all_seeds(current_seed)\n","\n","        # Calculate offset (only needed for replacement env)\n","        replacement_reward_offset = None\n","        if full_config[\"env_class\"] == \"EnvDispatchReplacement\":\n","            replacement_reward_offset,_,_ = calculate_offset_k_initialization(\n","                network_file=network_file_path,\n","                seed=current_seed,  # Pass the experiment seed\n","                reward_scale_factor=full_config[\"reward_scale_factor\"]\n","            )\n","\n","        # Initialize Neptune\n","        API_TOKEN = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1ODQwZjA5OS05MDFmLTQ2MWYtYWJiMi0yMDkzYmEwNzgzMzEifQ==\"\n","        PROJECT_NAME = \"EnergyGridRL/elec-s-10-ec-lc10-1h-sweep\"\n","        run = neptune.init_run(\n","            project=PROJECT_NAME,\n","            api_token=API_TOKEN\n","        )\n","\n","        # Log parameters\n","        for key, value in full_config.items():\n","            if key not in ['run_id', 'config_name']:\n","                run[f\"parameters/{key}\"] = value\n","\n","        # Log config metadata\n","        run[\"parameters/config_idx\"] = config_idx\n","        run[\"parameters/config_type\"] = config_type\n","\n","        if replacement_reward_offset is not None:\n","            run[\"replacement_reward_offset\"] = replacement_reward_offset\n","\n","        # Create environment based on env_class\n","        if full_config[\"env_class\"] == \"EnvDispatchConstr\":\n","            env = EnvDispatchConstr(\n","                network_file=network_file_path,\n","                no_convergence_lpf_penalty=full_config[\"no_convergence_lpf_penalty\"],\n","                reward_scale_factor=full_config[\"reward_scale_factor\"],\n","                constraint_penalty_factor=full_config[\"constraint_penalty_factor\"],\n","                seed=current_seed\n","            )\n","\n","        elif full_config[\"env_class\"] == \"EnvDispatchReplacement\":\n","            env = EnvDispatchReplacement(\n","                network_file=network_file_path,\n","                no_convergence_lpf_penalty=full_config[\"no_convergence_lpf_penalty\"],\n","                reward_scale_factor=full_config[\"reward_scale_factor\"],\n","                constraint_penalty_factor=full_config[\"constraint_penalty_factor\"],\n","                offset_k=replacement_reward_offset,\n","                seed=current_seed\n","            )\n","        else:\n","            raise ValueError(f\"Unknown environment class: {full_config['env_class']}\")\n","\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        agent = PPO_agent(\n","            env=env,\n","            run=run,\n","            device=device,\n","            hidden_dimensions=full_config[\"HIDDEN_DIMENSIONS\"],\n","            dropout=full_config[\"DROPOUT\"],\n","            discount_factor=full_config[\"DISCOUNT_FACTOR\"],\n","            optimizer_name=full_config[\"optimizer_name\"],\n","            max_episodes=full_config[\"MAX_EPISODES\"],\n","            print_interval=full_config[\"PRINT_INTERVAL\"],\n","            PPO_steps=full_config[\"PPO_STEPS\"],\n","            n_trials=full_config[\"N_TRIALS\"],\n","            epsilon=full_config[\"EPSILON\"],\n","            entropy_coefficient=full_config[\"ENTROPY_COEFFICIENT\"],\n","            learning_rate=full_config[\"LEARNING_RATE\"],\n","            batch_size=full_config[\"BATCH_SIZE\"],\n","            seed=current_seed\n","        )\n","\n","        # Train\n","        try:\n","            train_rewards = agent.train()\n","\n","            # Store results\n","            result = {\n","                'config_idx': config_idx,\n","                'config_type': config_type,\n","                'config': full_config.copy(),\n","                'train_rewards': train_rewards,\n","                'final_reward': train_rewards[-1] if train_rewards else None\n","            }\n","            all_results.append(result)\n","\n","            print(f\"Configuration {config_idx + 1} completed successfully\")\n","\n","        except Exception as e:\n","            print(f\"Configuration {config_idx + 1} failed with error: {e}\")\n","            result = {\n","                'config_idx': config_idx,\n","                'config_type': config_type,\n","                'config': full_config.copy(),\n","                'error': str(e),\n","                'train_rewards': None,\n","                'final_reward': None\n","            }\n","            all_results.append(result)\n","\n","        finally:\n","            # Always stop the Neptune run\n","            run.stop()\n","\n","    # Print summary\n","    print(f\"\\nTraining completed for all {len(all_configs)} configurations\")\n","    print(f\"Priority configs: {len(priority_configs)}\")\n","    print(f\"Random configs: {len(additional_configs)}\")\n","    successful_runs = [r for r in all_results if 'error' not in r]\n","    print(f\"Successful runs: {len(successful_runs)}/{len(all_configs)}\")\n","\n","    # Print summary by type\n","    priority_successful = [r for r in all_results if r.get('config_type') == 'priority' and 'error' not in r]\n","    random_successful = [r for r in all_results if r.get('config_type') == 'random' and 'error' not in r]\n","    print(f\"Priority successful: {len(priority_successful)}/{len(priority_configs)}\")\n","    print(f\"Random successful: {len(random_successful)}/{len(additional_configs)}\")\n","\n","    return all_results"]},{"cell_type":"code","execution_count":15,"id":"499f4fab-c345-4402-b023-9d5d50f2c8b7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"499f4fab-c345-4402-b023-9d5d50f2c8b7","outputId":"2b22341a-9d36-4031-b569-0f07da2a3cae","executionInfo":{"status":"error","timestamp":1757603495046,"user_tz":-120,"elapsed":3134198,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running configuration 1/16 (priority)\n","Config: {'LEARNING_RATE': 0.001, 'EPSILON': 0.2, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 128, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0.1, 'seed': 35}\n","Sampling 1000 random states to calculate offset k...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:pypsa.network.io:Importing network from PyPSA version v0.0.0 while current version is v0.35.2. Read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html to prepare your network for import.\n"]},{"output_type":"stream","name":"stdout","text":["Fixed ZA0 0 PHS: set max_hours to 8.0\n","Fixed ZA0 5 PHS: set max_hours to 8.0\n","Fixed ZA0 6 hydro: corrected max_hours from 3831.6270020496813 to 6.0\n","=== FIXING ARTIFICIAL LINES WITH REASONABLE CAPACITY ===\n","Found 3 artificial lines to fix:\n","\n"," Fixing: lines new ZA0 4 <-> ZA2 0 AC\n","    Connected buses: ZA0 4 ↔ ZA2 0\n","    Bus demands: ZA0 4: 15945.8 MW, ZA2 0: 452.6 MW\n","    s_nom: 0.0 → 47837.3 MW\n","    s_nom_extendable: → False\n","\n"," Fixing: lines new ZA0 0 <-> ZA1 0 AC\n","    Connected buses: ZA0 0 ↔ ZA1 0\n","    Bus demands: ZA0 0: 3513.0 MW, ZA1 0: 1386.9 MW\n","    s_nom: 0.0 → 10538.9 MW\n","    s_nom_extendable: → False\n","\n"," Fixing: lines new ZA0 0 <-> ZA3 0 AC\n","    Connected buses: ZA0 0 ↔ ZA3 0\n","    Bus demands: ZA0 0: 3513.0 MW, ZA3 0: 721.1 MW\n","    s_nom: 0.0 → 10538.9 MW\n","    s_nom_extendable: → False\n","Found 12 offshore wind generators:\n","['ZA0 1 offwind-ac', 'ZA0 1 offwind-dc', 'ZA0 5 offwind-ac', 'ZA0 5 offwind-dc', 'ZA0 7 offwind-ac', 'ZA0 7 offwind-dc', 'ZA0 8 offwind-ac', 'ZA0 8 offwind-dc', 'ZA1 0 offwind-ac', 'ZA1 0 offwind-dc', 'ZA3 0 offwind-ac', 'ZA3 0 offwind-dc']\n","\n","Offshore wind generator details:\n","                  p_nom control     carrier\n","Generator                                  \n","ZA0 1 offwind-ac    0.0          offwind-ac\n","ZA0 1 offwind-dc    0.0          offwind-dc\n","ZA0 5 offwind-ac    0.0          offwind-ac\n","ZA0 5 offwind-dc    0.0          offwind-dc\n","ZA0 7 offwind-ac    0.0          offwind-ac\n","ZA0 7 offwind-dc    0.0          offwind-dc\n","ZA0 8 offwind-ac    0.0          offwind-ac\n","ZA0 8 offwind-dc    0.0          offwind-dc\n","ZA1 0 offwind-ac    0.0   Slack  offwind-ac\n","ZA1 0 offwind-dc    0.0          offwind-dc\n","ZA3 0 offwind-ac    0.0   Slack  offwind-ac\n","ZA3 0 offwind-dc    0.0          offwind-dc\n","\n","Removing 12 offshore wind generators...\n","Identified 10 constraints:\n","  0: p_min_ZA0 0 coal\n","  1: p_min_ZA2 0 onwind\n","  2: p_max_ZA0 0 coal\n","  3: p_max_ZA2 0 onwind\n","  4: soc_min_ZA0 0 PHS\n","  5: soc_min_ZA0 5 PHS\n","  6: soc_min_ZA0 6 hydro\n","  7: soc_max_ZA0 0 PHS\n","  8: soc_max_ZA0 5 PHS\n","  9: soc_max_ZA0 6 hydro\n","  Completed 200/1000 samples...\n","  Completed 400/1000 samples...\n","  Completed 600/1000 samples...\n","  Completed 800/1000 samples...\n","  Completed 1000/1000 samples...\n","k_worst = |0.02| = 0.02\n","k_mean = |0.01| = 0.01\n","  Successfully sampled 1000/1000 states\n","  Objective value range: [0.01, 0.02]\n","  Constraint DataFrame shape: (1000, 13)\n"]},{"output_type":"stream","name":"stderr","text":["[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs-legacy.neptune.ai/logging/source_code/\n"]},{"output_type":"stream","name":"stdout","text":["[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/elec-s-10-ec-lc10-1h-sweep/e/EL-21\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:pypsa.network.io:Importing network from PyPSA version v0.0.0 while current version is v0.35.2. Read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html to prepare your network for import.\n"]},{"output_type":"stream","name":"stdout","text":["Fixed ZA0 0 PHS: set max_hours to 8.0\n","Fixed ZA0 5 PHS: set max_hours to 8.0\n","Fixed ZA0 6 hydro: corrected max_hours from 3831.6270020496813 to 6.0\n","=== FIXING ARTIFICIAL LINES WITH REASONABLE CAPACITY ===\n","Found 3 artificial lines to fix:\n","\n"," Fixing: lines new ZA0 4 <-> ZA2 0 AC\n","    Connected buses: ZA0 4 ↔ ZA2 0\n","    Bus demands: ZA0 4: 15945.8 MW, ZA2 0: 452.6 MW\n","    s_nom: 0.0 → 47837.3 MW\n","    s_nom_extendable: → False\n","\n"," Fixing: lines new ZA0 0 <-> ZA1 0 AC\n","    Connected buses: ZA0 0 ↔ ZA1 0\n","    Bus demands: ZA0 0: 3513.0 MW, ZA1 0: 1386.9 MW\n","    s_nom: 0.0 → 10538.9 MW\n","    s_nom_extendable: → False\n","\n"," Fixing: lines new ZA0 0 <-> ZA3 0 AC\n","    Connected buses: ZA0 0 ↔ ZA3 0\n","    Bus demands: ZA0 0: 3513.0 MW, ZA3 0: 721.1 MW\n","    s_nom: 0.0 → 10538.9 MW\n","    s_nom_extendable: → False\n","Found 12 offshore wind generators:\n","['ZA0 1 offwind-ac', 'ZA0 1 offwind-dc', 'ZA0 5 offwind-ac', 'ZA0 5 offwind-dc', 'ZA0 7 offwind-ac', 'ZA0 7 offwind-dc', 'ZA0 8 offwind-ac', 'ZA0 8 offwind-dc', 'ZA1 0 offwind-ac', 'ZA1 0 offwind-dc', 'ZA3 0 offwind-ac', 'ZA3 0 offwind-dc']\n","\n","Offshore wind generator details:\n","                  p_nom control     carrier\n","Generator                                  \n","ZA0 1 offwind-ac    0.0          offwind-ac\n","ZA0 1 offwind-dc    0.0          offwind-dc\n","ZA0 5 offwind-ac    0.0          offwind-ac\n","ZA0 5 offwind-dc    0.0          offwind-dc\n","ZA0 7 offwind-ac    0.0          offwind-ac\n","ZA0 7 offwind-dc    0.0          offwind-dc\n","ZA0 8 offwind-ac    0.0          offwind-ac\n","ZA0 8 offwind-dc    0.0          offwind-dc\n","ZA1 0 offwind-ac    0.0   Slack  offwind-ac\n","ZA1 0 offwind-dc    0.0          offwind-dc\n","ZA3 0 offwind-ac    0.0   Slack  offwind-ac\n","ZA3 0 offwind-dc    0.0          offwind-dc\n","\n","Removing 12 offshore wind generators...\n","Initialized Beta parameters to produce uniform-like distribution\n","[neptune] [info   ] Shutting down background jobs, please wait a moment...\n","[neptune] [info   ] Done!\n","[neptune] [info   ] All 0 operations synced, thanks for waiting!\n","[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/elec-s-10-ec-lc10-1h-sweep/e/EL-21/metadata\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2272747924.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecute_training_simple_constr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"EnvDispatchReplacement\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-2001258354.py\u001b[0m in \u001b[0;36mexecute_training_simple_constr\u001b[0;34m(env_class, seed)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mtrain_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# Store results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-943494204.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m#check timing for forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# Perform a forward pass and collect experience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mtrain_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_log_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_constraint_violations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;31m#check timing for policy update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-943494204.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self, episode)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;31m# Step environment with numpy action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0maction_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# Track total constraint violation (over the full episode) for each constraint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-463419176.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;31m# self._simplified_power_balance()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlpf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshot_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0mpower_flow_converged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pypsa/network/power_flow.py\u001b[0m in \u001b[0;36mlpf\u001b[0;34m(n, snapshots, skip_pre)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \"\"\"\n\u001b[1;32m    764\u001b[0m         \u001b[0msns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"snapshots\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0m_network_prepare_and_run_pf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     def pf(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pypsa/common.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maliases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeprecated_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             )\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pypsa/network/power_flow.py\u001b[0m in \u001b[0;36m_network_prepare_and_run_pf\u001b[0;34m(n, snapshots, skip_pre, linear, distribute_slack, slack_weights, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0msub_network_pf_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_pre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pypsa/network/power_flow.py\u001b[0m in \u001b[0;36mlpf\u001b[0;34m(self, snapshots, skip_pre)\u001b[0m\n\u001b[1;32m   1688\u001b[0m                 \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p_set\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"active\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m             )\n\u001b[0;32m-> 1690\u001b[0;31m             \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"active\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_p_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0;31m# set the power injection at each node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4821\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4822\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4823\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4825\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4941\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4942\u001b[0m         \u001b[0mindex_resolvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_index_resolvers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4943\u001b[0;31m         \u001b[0mcolumn_resolvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cleaned_column_resolvers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4944\u001b[0m         \u001b[0mresolvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_resolvers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_resolvers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"target\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_cleaned_column_resolvers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m         return {\n\u001b[1;32m    660\u001b[0m             clean_column_name(k): Series(\n\u001b[0;32m--> 661\u001b[0;31m                 \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m             ).__finalize__(self)\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_column_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6459\u001b[0m         \"\"\"\n\u001b[1;32m   6460\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6463\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6318\u001b[0m         \u001b[0;31m# (note that this matches __getattr__, above).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_names_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6320\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6322\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mvalidate_all_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{type(self).__name__}.name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["execute_training_simple_constr(env_class=\"EnvDispatchReplacement\", seed=35)"]},{"cell_type":"code","execution_count":null,"id":"68ca6b38-facb-4894-a27e-96bdd6e6eb76","metadata":{"id":"68ca6b38-facb-4894-a27e-96bdd6e6eb76","executionInfo":{"status":"aborted","timestamp":1757603495048,"user_tz":-120,"elapsed":3224428,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["# execute_training_simple_constr(env_class=\"EnvDispatchConstr\", seed=61)"]},{"cell_type":"code","execution_count":null,"id":"cad4760c-975a-48d8-96c8-83b4488d1f09","metadata":{"id":"cad4760c-975a-48d8-96c8-83b4488d1f09","executionInfo":{"status":"aborted","timestamp":1757603495049,"user_tz":-120,"elapsed":3224427,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["# execute_training_simple_constr(env_class=\"EnvDispatchConstr\", seed=7)"]},{"cell_type":"code","execution_count":10,"id":"6b945825-230e-4cd2-a329-8b4c84add5a3","metadata":{"id":"6b945825-230e-4cd2-a329-8b4c84add5a3","executionInfo":{"status":"ok","timestamp":1757610561570,"user_tz":-120,"elapsed":58,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["import tempfile\n","import torch\n","import json\n","import os\n","import neptune\n","\n","def load_model_from_neptune(neptune_run, device='cpu'):\n","    \"\"\"\n","    Load model state dict and configuration from Neptune\n","\n","    Args:\n","        neptune_run: Neptune run object (can be existing run or fetched run)\n","        device: Device to load the model on ('cpu' or 'cuda')\n","\n","    Returns:\n","        tuple: (model_state_dict, model_config)\n","    \"\"\"\n","    with tempfile.TemporaryDirectory() as temp_dir:\n","        # Download actor-critic model state dict\n","        actor_critic_path = os.path.join(temp_dir, 'actor_critic.pt')\n","        neptune_run[\"model/actor_critic\"].download(actor_critic_path)\n","\n","        # Download model configuration\n","        model_info_path = os.path.join(temp_dir, 'model_info.json')\n","        neptune_run[\"model/model_info\"].download(model_info_path)\n","\n","        # Load state dict\n","        model_state_dict = torch.load(actor_critic_path, map_location=device,weights_only=True)\n","\n","        # Load configuration\n","        with open(model_info_path, 'r') as f:\n","            model_config = json.load(f)\n","\n","        print(f\"✓ Model loaded from Neptune\")\n","        print(f\"✓ Model architecture: {model_config.get('model_architecture', 'N/A')}\")\n","\n","        return model_state_dict, model_config\n","\n","def reconstruct_agent_from_saved_model(model_state_dict, model_config, env, device='cpu', run=None):\n","    \"\"\"\n","    Reconstruct a PPO agent from saved model state and configuration\n","\n","    Args:\n","        model_state_dict: PyTorch state dict loaded from Neptune\n","        model_config: Configuration dictionary loaded from Neptune\n","        env: Environment instance (needed for observation/action space info)\n","        device: Device to load the model on ('cpu' or 'cuda')\n","        run: Neptune run object for logging (optional, can be None for inference)\n","\n","    Returns:\n","        PPO_agent: Reconstructed agent ready for inference or further training\n","    \"\"\"\n","\n","    # Create agent with saved configuration\n","    # Note: Some parameters are not critical for inference and can use defaults\n","    agent = PPO_agent(\n","        env=env,\n","        device=device,\n","        run=run,  # Can be None for inference\n","        hidden_dimensions=model_config['hidden_dimensions'],\n","        dropout=model_config['dropout'],\n","        discount_factor=model_config['discount_factor'],\n","        max_episodes=1,  # Not needed for inference\n","        print_interval=1,  # Not needed for inference\n","        PPO_steps=model_config['ppo_steps'],\n","        n_trials=1,  # Not needed for inference\n","        epsilon=model_config['epsilon'],\n","        entropy_coefficient=model_config['entropy_coefficient'],\n","        learning_rate=model_config['learning_rate'],\n","        batch_size=model_config['batch_size'],\n","        optimizer_name='Adam',  # Default, not critical for inference\n","        seed=42,  # Default, can be any value\n","        training_start_time=None\n","    )\n","\n","    # Load the saved state dict into the model\n","    agent.model.load_state_dict(model_state_dict)\n","\n","    # Set model to evaluation mode\n","    agent.model.eval()\n","\n","    print(f\"✓ Agent reconstructed successfully\")\n","    print(f\"✓ Input features: {agent.INPUT_FEATURES}\")\n","    print(f\"✓ Action dimensions: {agent.action_dim}\")\n","    print(f\"✓ Hidden dimensions: {agent.HIDDEN_DIMENSIONS}\")\n","\n","    return agent\n","\n","def load_trained_agent_from_neptune(run_id, project_name, env, device='cpu'):\n","    \"\"\"\n","    Complete function to load a trained agent from Neptune using run ID\n","\n","    Args:\n","        run_id: Neptune run ID (e.g., 'PROJECT-123')\n","        project_name: Neptune project name (e.g., 'username/project-name')\n","        env: Environment instance\n","        device: Device to load model on\n","\n","    Returns:\n","        PPO_agent: Loaded agent ready for inference\n","    \"\"\"\n","\n","    # Initialize Neptune and fetch the run\n","    print(f\"Fetching Neptune run: {run_id}\")\n","    run = neptune.init_run(\n","        project=project_name,\n","        run=run_id,\n","        mode=\"read-only\"\n","    )\n","\n","    try:\n","        # Load model and config from Neptune\n","        model_state_dict, model_config = load_model_from_neptune(run, device)\n","\n","        # Reconstruct agent\n","        agent = reconstruct_agent_from_saved_model(\n","            model_state_dict,\n","            model_config,\n","            env,\n","            device,\n","            run=None  # No need for logging during inference\n","        )\n","\n","        return agent\n","\n","    finally:\n","        # Close the Neptune run\n","        run.stop()"]},{"cell_type":"code","execution_count":null,"id":"c945eb83-1113-4bee-a1e4-974d02010abd","metadata":{"id":"c945eb83-1113-4bee-a1e4-974d02010abd","executionInfo":{"status":"aborted","timestamp":1757603495064,"user_tz":-120,"elapsed":3224438,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["# !pip install ipdb\n","# import ipdb\n","def evaluate_deterministic(env, agent, optimal_objective_value, seed=35):\n","    \"\"\"\n","    Deterministic evaluation of trained agent on test data.\n","    Uses Beta distribution mean for consistent, reproducible results.\n","    \"\"\"\n","\n","    # Set seed for full reproducibility\n","    set_all_seeds(seed)\n","\n","    # Reset environment to test data start\n","    obs, info = env.reset(seed=seed)\n","    agent.model.eval()\n","\n","    # Track metrics\n","    rl_total_reward = 0.0\n","    total_test_snapshots = env.total_snapshots\n","    rewards= []\n","    violations={}\n","    # Extract constraint names in the correct order\n","    slack_generators = env.network.generators[env.network.generators.control == \"Slack\"].index\n","\n","    #remove this because don't check line constraints during training\n","    line_names = env.network.lines.index\n","    storage_names = env.storage_names\n","\n","    # Build constraint names in the order they appear in info['constraint_results']\n","    constraint_names = []\n","\n","    # p_min for each slack generator\n","    for gen_name in slack_generators:\n","        constraint_names.append(f\"p_min_{gen_name}\")\n","\n","    # p_max for each slack generator\n","    for gen_name in slack_generators:\n","        constraint_names.append(f\"p_max_{gen_name}\")\n","\n","    # # s_max for each line\n","\n","    # soc_min for each storage\n","    for storage_name in storage_names:\n","        constraint_names.append(f\"soc_min_{storage_name}\")\n","\n","    # soc_max for each storage\n","    for storage_name in storage_names:\n","        constraint_names.append(f\"soc_max_{storage_name}\")\n","\n","    for line_name in line_names:\n","        constraint_names.append(f\"s_max_{line_name}\")\n","\n","    constraint_names.append(\"redundant_entry1\")\n","    constraint_names.append(\"redundant_entry2\")\n","    first_violation_append=True\n","    # Run agent on all test snapshots\n","    for step in range(total_test_snapshots):\n","        # Get DETERMINISTIC action from PPO agent\n","        with torch.no_grad():\n","            obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(agent.device)\n","            action_mean, _ = agent.model(obs_tensor)\n","\n","            action_dim = env.action_space.shape[0]\n","            alpha_raw, beta_raw = torch.split(action_mean, action_dim, dim=-1)\n","            alpha = torch.nn.functional.softplus(alpha_raw) + 1.0\n","            beta = torch.nn.functional.softplus(beta_raw) + 1.0\n","\n","            # DETERMINISTIC: Use mean of Beta distribution\n","            action_tensor = alpha / (alpha + beta)\n","            action = action_tensor.detach().cpu().numpy().flatten()\n","        # Take step in environment\n","        obs, reward, terminated, truncated, info = env.step_test(action) #call step_test for base reward without penalty/without offset k\n","        if first_violation_append:\n","            for i in range(len(constraint_names)):\n","                violations[\"violations_\"+constraint_names[i]]=np.zeros(total_test_snapshots)\n","            first_violation_append=False\n","        for i, violation in enumerate(info[\"constraint_results\"]):\n","                violations[\"violations_\"+constraint_names[i]][step]=violation\n","\n","        rewards.append(reward)\n","\n","        if terminated or truncated:\n","            break\n","\n","    # Calculate MAPE using only valid samples (Equation 22)\n","    if len(valid_rewards) > 0:\n","        total_reward = sum(rewards)\n","        mape = abs(valid_total_reward - optimal_objective_value) / abs(optimal_objective_value) * 100.0\n","\n","    avg_violation={}\n","    for i in range(len(constraint_names)):\n","        avg_violations[\"avg_violation_\"+constraint_names[i]]=np.sum(violations[\"violations_\"+constraint_names[i]])/len(violations[\"violations_\"+constraint_names[i]])\n","\n","\n","    results = {\n","        'mape': mape,\n","        'rl_total_objective': sum(rewards),  # Keep total for comparison\n","        'optimal_total_objective': optimal_objective_value,\n","        'total_test_snapshots': total_test_snapshots,\n","        'evaluation_method': 'deterministic',\n","        'rewards':rewards,\n","        'violations':violations\n","    }\n","\n","    combined_results = {**results, **violations,**avg_violation}\n","\n","    return results"]},{"cell_type":"code","execution_count":11,"id":"b907f1b5-1658-4ed3-9e3e-4154326745c6","metadata":{"id":"b907f1b5-1658-4ed3-9e3e-4154326745c6","executionInfo":{"status":"ok","timestamp":1757610639125,"user_tz":-120,"elapsed":48,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["def evaluate_deterministic(env, agent, optimal_objective_value, seed=35):\n","    \"\"\"\n","    Deterministic evaluation of trained agent on test data.\n","    Uses Beta distribution mean for consistent, reproducible results.\n","    \"\"\"\n","\n","    # Set seed for full reproducibility\n","    set_all_seeds(seed)\n","\n","    # Reset environment to test data start\n","    obs, info = env.reset(seed=seed)\n","    agent.model.eval()\n","\n","    # Track metrics\n","    rl_total_reward = 0.0\n","    total_test_snapshots = env.total_snapshots\n","    rewards = []\n","    violations = {}\n","\n","    # Extract constraint names in the correct order\n","    slack_generators = env.network.generators[env.network.generators.control == \"Slack\"].index\n","    line_names = env.network.lines.index\n","    storage_names = env.storage_names\n","\n","    # Build constraint names in the order they appear in info['constraint_results']\n","    constraint_names = []\n","\n","    # p_min for each slack generator\n","    for gen_name in slack_generators:\n","        constraint_names.append(f\"p_min_{gen_name}\")\n","\n","    # p_max for each slack generator\n","    for gen_name in slack_generators:\n","        constraint_names.append(f\"p_max_{gen_name}\")\n","\n","    # soc_min for each storage\n","    for storage_name in storage_names:\n","        constraint_names.append(f\"soc_min_{storage_name}\")\n","\n","    # soc_max for each storage\n","    for storage_name in storage_names:\n","        constraint_names.append(f\"soc_max_{storage_name}\")\n","\n","    # s_max for each line (only for step_test which includes line constraints)\n","    for line_name in line_names:\n","        constraint_names.append(f\"s_max_{line_name}\")\n","\n","    constraint_names.append(\"redundant_entry1\")\n","    constraint_names.append(\"redundant_entry2\")\n","    first_violation_append = True\n","\n","    # Run agent on all test snapshots\n","    for step in range(total_test_snapshots):\n","        # Get DETERMINISTIC action from PPO agent\n","        with torch.no_grad():\n","            obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(agent.device)\n","            action_mean, *_ = agent.model(obs_tensor)  # Fixed: obs_tensor instead of obs*tensor\n","\n","            action_dim = env.action_space.shape[0]\n","            alpha_raw, beta_raw = torch.split(action_mean, action_dim, dim=-1)\n","            alpha = torch.nn.functional.softplus(alpha_raw) + 1.0\n","            beta = torch.nn.functional.softplus(beta_raw) + 1.0\n","\n","            # DETERMINISTIC: Use mean of Beta distribution\n","            action_tensor = alpha / (alpha + beta)\n","            action = action_tensor.detach().cpu().numpy().flatten()\n","\n","        # Take step in environment\n","        obs, reward, terminated, truncated, info = env.step_test(action)\n","\n","        if first_violation_append:\n","            for i in range(len(constraint_names)):\n","                violations[f\"violations_{constraint_names[i]}\"] = np.zeros(total_test_snapshots)\n","            first_violation_append = False\n","\n","        for i, violation in enumerate(info[\"constraint_results\"]):\n","            violations[f\"violations_{constraint_names[i]}\"][step] = violation\n","\n","        rewards.append(reward)\n","        if terminated or truncated:\n","            break\n","\n","    # Calculate MAPE using total rewards (Fixed: removed undefined variables)\n","    total_reward = sum(rewards)\n","    mape = abs(total_reward - optimal_objective_value) / abs(optimal_objective_value) * 100.0\n","\n","    # Calculate average violations\n","    avg_violations = {}  # Fixed: consistent variable name\n","    for i in range(len(constraint_names)):\n","        constraint_name = constraint_names[i]\n","        violation_key = f\"violations_{constraint_name}\"\n","        avg_key = f\"avg_violation_{constraint_name}\"\n","        avg_violations[avg_key] = np.sum(violations[violation_key]) / len(violations[violation_key])\n","\n","    results = {\n","        'mape': mape,\n","        'rl_total_objective': total_reward,  # Fixed: use total_reward instead of sum(rewards)\n","        'optimal_total_objective': optimal_objective_value,\n","        'total_test_snapshots': total_test_snapshots,\n","        'evaluation_method': 'deterministic',\n","        'rewards': rewards,\n","        'violations': violations\n","    }\n","\n","    # Combine all results\n","    combined_results = {**results, **violations, **avg_violations}\n","    return combined_results  # Fixed: return combined_results instead of results"]},{"cell_type":"code","execution_count":12,"id":"58758d63-f334-446d-a6c7-85c98dcbc164","metadata":{"id":"58758d63-f334-446d-a6c7-85c98dcbc164","executionInfo":{"status":"ok","timestamp":1757610642400,"user_tz":-120,"elapsed":5,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}}},"outputs":[],"source":["import time\n","def evaluate_trained_agent(run_id, env_class, seed=42):\n","    \"\"\"\n","    Evaluate a trained PPO agent from Neptune\n","\n","    Args:\n","        run_id: Neptune run ID to load the trained agent from\n","        seed: Random seed for reproducible evaluation\n","    \"\"\"\n","\n","    # Set all seeds for reproducibility\n","    set_all_seeds(seed)\n","\n","    # Configuration (should match training config for environment setup)\n","    config = {\n","        \"network_file\": \"elec_s_10_ec_lc1.0_1h.nc\",\n","        \"optimization_result_file\": \"elec_s_10_ec_lc1.0_1h_Test_Objective.txt\",\n","        \"constraint_penalty_factor\": 1,\n","        \"env_class\": env_class,\n","        \"seed\": seed\n","    }\n","\n","    # Set up paths\n","    gdrive_base = '/content/drive/My Drive/Colab_Notebooks'  # or '/workspace/'\n","    network_file_path = os.path.join(gdrive_base, \"networks_1_year_connected\", config[\"network_file\"])\n","    optimization_result_path = os.path.join(gdrive_base, \"optimized_network\", config[\"optimization_result_file\"])\n","\n","    # Load optimization result (optimal objective value)\n","    with open(optimization_result_path, 'r') as f:\n","        objective = float(f.read().strip())\n","\n","    # Multiply by negative one since comparing to reward found by RL agent\n","    objective = -1 * objective\n","\n","    # Calculate offset if using replacement environment\n","    replacement_reward_offset = None\n","\n","    # Create test environment (same type as training)\n","    # Create environment based on env_class\n","    if config[\"env_class\"] == \"EnvDispatchConstr\":\n","        env = EnvDispatchConstr(\n","            network_file=network_file_path,\n","            no_convergence_lpf_penalty=1,\n","            reward_scale_factor=1,\n","            constraint_penalty_factor=1,\n","            seed=seed\n","        )\n","\n","    elif config[\"env_class\"] == \"EnvDispatchReplacement\":\n","        env = EnvDispatchReplacement(\n","            network_file=network_file_path,\n","            no_convergence_lpf_penalty=1,\n","            reward_scale_factor=1,\n","            constraint_penalty_factor=1,\n","            offset_k=replacement_reward_offset,\n","            seed=seed\n","        )\n","\n","    # Connect to the existing training run for logging evaluation results\n","    API_TOKEN = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1ODQwZjA5OS05MDFmLTQ2MWYtYWJiMi0yMDkzYmEwNzgzMzEifQ==\"\n","    PROJECT_NAME = \"EnergyGridRL/elec-s-10-ec-lc10-1h-Sweep\"\n","\n","    # Reconnect to the existing training run\n","    print(f\"Connecting to existing training run: {run_id}\")\n","    eval_run = neptune.init_run(\n","        project=PROJECT_NAME,\n","        api_token=API_TOKEN,\n","        with_id=run_id,  # Connect to existing run using with_id\n","        mode=\"async\"  # Use async mode to append to existing run\n","    )\n","\n","    try:\n","        # Log evaluation metadata\n","        eval_run[\"evaluation/optimal_objective\"] = objective\n","        eval_run[\"evaluation/seed\"] = seed\n","        eval_run[\"evaluation/env_class\"] = config[\"env_class\"]\n","        eval_run[\"evaluation/network_file\"] = config[\"network_file\"]\n","        eval_run[\"evaluation/timestamp\"] = time.time()\n","\n","        if replacement_reward_offset is not None:\n","            eval_run[\"evaluation/replacement_reward_offset\"] = replacement_reward_offset\n","\n","        # Load trained agent from Neptune (using a separate read-only connection)\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        print(f\"Loading agent from run: {run_id}\")\n","\n","        # Create read-only connection for loading the model\n","        read_run = neptune.init_run(\n","            project=PROJECT_NAME,\n","            api_token=API_TOKEN,\n","            with_id=run_id,  # Use with_id instead of run\n","            mode=\"read-only\"\n","        )\n","\n","        try:\n","            # Load model and config from Neptune\n","            model_state_dict, model_config = load_model_from_neptune(read_run, device)\n","\n","            # Reconstruct agent\n","            agent = reconstruct_agent_from_saved_model(\n","                model_state_dict,\n","                model_config,\n","                env,\n","                device,\n","                run=None\n","            )\n","        finally:\n","            read_run.stop()\n","\n","        print(\"Agent loaded successfully. Starting evaluation...\")\n","\n","        # Evaluate the agent\n","        test_results = evaluate_deterministic(env, agent, objective, seed=seed)\n","\n","        # Log all test results to the same training run\n","        for key, value in test_results.items():\n","            if key not in ['rewards', 'violations']:  # Log individual arrays separately if needed\n","                eval_run[f\"evaluation/{key}\"] = value\n","\n","        # # Log rewards and violations as series if you want to plot them\n","        # if 'rewards' in test_results:\n","        #     for i, reward in enumerate(test_results['rewards']):\n","        #         eval_run[f\"evaluation/step_rewards\"].log(reward)\n","\n","        # if 'violations' in test_results:\n","        #     for i, violation in enumerate(test_results['violations']):\n","        #         eval_run[f\"evaluation/step_violations\"].log(violation)\n","\n","        return test_results\n","\n","    finally:\n","        # Stop the evaluation run\n","        eval_run.stop()\n","\n","def evaluate_multiple_agents(run_ids, seed=42):\n","    \"\"\"\n","    Evaluate multiple trained agents and compare results\n","\n","    Args:\n","        run_ids: List of Neptune run IDs to evaluate\n","        seed: Random seed for reproducible evaluation\n","\n","    Returns:\n","        dict: Comparison results for all agents\n","    \"\"\"\n","\n","    comparison_results = {}\n","\n","    for run_id in run_ids:\n","        print(f\"\\nEvaluating agent from run: {run_id}\")\n","        try:\n","            results = evaluate_trained_agent(run_id, seed=seed)\n","            comparison_results[run_id] = results\n","        except Exception as e:\n","            print(f\"Error evaluating run {run_id}: {str(e)}\")\n","            comparison_results[run_id] = None\n","\n","    # Print comparison summary\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"COMPARISON SUMMARY\")\n","    print(\"=\"*80)\n","    print(f\"{'Run ID':<15} {'MAPE (%)':<10} {'Violations (%)':<15} {'Total Reward':<15}\")\n","    print(\"-\" * 80)\n","\n","    for run_id, results in comparison_results.items():\n","        if results is not None:\n","            print(f\"{run_id:<15} {results['mape']:<10.2f} {results['constraint_violation_percentage']:<15.2f} {results['rl_total_objective']:<15.2f}\")\n","        else:\n","            print(f\"{run_id:<15} {'ERROR':<10} {'ERROR':<15} {'ERROR':<15}\")\n","\n","    print(\"=\"*80)\n","\n","    return comparison_results"]},{"cell_type":"code","execution_count":13,"id":"ee297598-438f-4144-84ac-d513bd8eb4bb","metadata":{"id":"ee297598-438f-4144-84ac-d513bd8eb4bb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757612683790,"user_tz":-120,"elapsed":2036974,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}},"outputId":"3f9bfd5d-5a77-49ea-e197-1b7ddbf69744"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pypsa.network.io:Importing network from PyPSA version v0.0.0 while current version is v0.35.2. Read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html to prepare your network for import.\n"]},{"output_type":"stream","name":"stdout","text":["Fixed ZA0 0 PHS: set max_hours to 8.0\n","Fixed ZA0 5 PHS: set max_hours to 8.0\n","Fixed ZA0 6 hydro: corrected max_hours from 3831.6270020496813 to 6.0\n","=== FIXING ARTIFICIAL LINES WITH REASONABLE CAPACITY ===\n","Found 3 artificial lines to fix:\n","\n"," Fixing: lines new ZA0 4 <-> ZA2 0 AC\n","    Connected buses: ZA0 4 ↔ ZA2 0\n","    Bus demands: ZA0 4: 15945.8 MW, ZA2 0: 452.6 MW\n","    s_nom: 0.0 → 47837.3 MW\n","    s_nom_extendable: → False\n","\n"," Fixing: lines new ZA0 0 <-> ZA1 0 AC\n","    Connected buses: ZA0 0 ↔ ZA1 0\n","    Bus demands: ZA0 0: 3513.0 MW, ZA1 0: 1386.9 MW\n","    s_nom: 0.0 → 10538.9 MW\n","    s_nom_extendable: → False\n","\n"," Fixing: lines new ZA0 0 <-> ZA3 0 AC\n","    Connected buses: ZA0 0 ↔ ZA3 0\n","    Bus demands: ZA0 0: 3513.0 MW, ZA3 0: 721.1 MW\n","    s_nom: 0.0 → 10538.9 MW\n","    s_nom_extendable: → False\n","Found 12 offshore wind generators:\n","['ZA0 1 offwind-ac', 'ZA0 1 offwind-dc', 'ZA0 5 offwind-ac', 'ZA0 5 offwind-dc', 'ZA0 7 offwind-ac', 'ZA0 7 offwind-dc', 'ZA0 8 offwind-ac', 'ZA0 8 offwind-dc', 'ZA1 0 offwind-ac', 'ZA1 0 offwind-dc', 'ZA3 0 offwind-ac', 'ZA3 0 offwind-dc']\n","\n","Offshore wind generator details:\n","                  p_nom control     carrier\n","Generator                                  \n","ZA0 1 offwind-ac    0.0          offwind-ac\n","ZA0 1 offwind-dc    0.0          offwind-dc\n","ZA0 5 offwind-ac    0.0          offwind-ac\n","ZA0 5 offwind-dc    0.0          offwind-dc\n","ZA0 7 offwind-ac    0.0          offwind-ac\n","ZA0 7 offwind-dc    0.0          offwind-dc\n","ZA0 8 offwind-ac    0.0          offwind-ac\n","ZA0 8 offwind-dc    0.0          offwind-dc\n","ZA1 0 offwind-ac    0.0   Slack  offwind-ac\n","ZA1 0 offwind-dc    0.0          offwind-dc\n","ZA3 0 offwind-ac    0.0   Slack  offwind-ac\n","ZA3 0 offwind-dc    0.0          offwind-dc\n","\n","Removing 12 offshore wind generators...\n","Connecting to existing training run: EL-14\n"]},{"output_type":"stream","name":"stderr","text":["[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs-legacy.neptune.ai/logging/source_code/\n"]},{"output_type":"stream","name":"stdout","text":["[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/elec-s-10-ec-lc10-1h-sweep/e/EL-14\n","Loading agent from run: EL-14\n","[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/elec-s-10-ec-lc10-1h-sweep/e/EL-14\n","✓ Model loaded from Neptune\n","✓ Model architecture: actorCritic(\n","  (actor): BackboneNetwork(\n","    (neuralnet): Sequential(\n","      (0): Linear(in_features=45, out_features=128, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=128, out_features=128, bias=True)\n","      (3): ReLU()\n","      (4): Linear(in_features=128, out_features=92, bias=True)\n","    )\n","  )\n","  (critic): BackboneNetwork(\n","    (neuralnet): Sequential(\n","      (0): Linear(in_features=45, out_features=128, bias=True)\n","      (1): ReLU()\n","      (2): Linear(in_features=128, out_features=128, bias=True)\n","      (3): ReLU()\n","      (4): Linear(in_features=128, out_features=1, bias=True)\n","    )\n","  )\n",")\n","Initialized Beta parameters to produce uniform-like distribution\n","✓ Agent reconstructed successfully\n","✓ Input features: 45\n","✓ Action dimensions: 46\n","✓ Hidden dimensions: 128\n","[neptune] [info   ] Shutting down background jobs, please wait a moment...\n","[neptune] [info   ] Done!\n","[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/elec-s-10-ec-lc10-1h-sweep/e/EL-14/metadata\n","Agent loaded successfully. Starting evaluation...\n","[neptune] [info   ] Shutting down background jobs, please wait a moment...\n","[neptune] [info   ] Done!\n","[neptune] [info   ] Waiting for the remaining 36 operations to synchronize with Neptune. Do not kill this process.\n"]},{"output_type":"stream","name":"stderr","text":["[neptune] [warning] NeptuneUnsupportedType: You're attempting to log a type that is not directly supported by Neptune (<class 'numpy.ndarray'>).\n","        Convert the value to a supported type, such as a string or float, or use stringify_unsupported(obj)\n","        for dictionaries or collections that contain unsupported values.\n","        For more, see https://docs-legacy.neptune.ai/help/value_of_unsupported_type\n"]},{"output_type":"stream","name":"stdout","text":["[neptune] [info   ] All 36 operations synced, thanks for waiting!\n","[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/elec-s-10-ec-lc10-1h-sweep/e/EL-14/metadata\n"]}],"source":["test_results=evaluate_trained_agent(\"EL-14\", \"EnvDispatchReplacement\", seed=35)"]},{"cell_type":"code","execution_count":15,"id":"6a7feb85-503c-4916-8da0-e2ed7fc873a8","metadata":{"id":"6a7feb85-503c-4916-8da0-e2ed7fc873a8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757612750082,"user_tz":-120,"elapsed":313,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}},"outputId":"750e0c81-2f56-4e85-c417-3db492eed5bb"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pypsa.network.io:Importing network from PyPSA version v0.0.0 while current version is v0.35.2. Read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html to prepare your network for import.\n"]},{"output_type":"stream","name":"stdout","text":["Fixed ZA0 0 PHS: set max_hours to 8.0\n","Fixed ZA0 5 PHS: set max_hours to 8.0\n","Fixed ZA0 6 hydro: corrected max_hours from 3831.6270020496813 to 6.0\n","=== FIXING ARTIFICIAL LINES WITH REASONABLE CAPACITY ===\n","Found 3 artificial lines to fix:\n","\n"," Fixing: lines new ZA0 4 <-> ZA2 0 AC\n","    Connected buses: ZA0 4 ↔ ZA2 0\n","    Bus demands: ZA0 4: 15945.8 MW, ZA2 0: 452.6 MW\n","    s_nom: 0.0 → 47837.3 MW\n","    s_nom_extendable: → False\n","\n"," Fixing: lines new ZA0 0 <-> ZA1 0 AC\n","    Connected buses: ZA0 0 ↔ ZA1 0\n","    Bus demands: ZA0 0: 3513.0 MW, ZA1 0: 1386.9 MW\n","    s_nom: 0.0 → 10538.9 MW\n","    s_nom_extendable: → False\n","\n"," Fixing: lines new ZA0 0 <-> ZA3 0 AC\n","    Connected buses: ZA0 0 ↔ ZA3 0\n","    Bus demands: ZA0 0: 3513.0 MW, ZA3 0: 721.1 MW\n","    s_nom: 0.0 → 10538.9 MW\n","    s_nom_extendable: → False\n","Found 12 offshore wind generators:\n","['ZA0 1 offwind-ac', 'ZA0 1 offwind-dc', 'ZA0 5 offwind-ac', 'ZA0 5 offwind-dc', 'ZA0 7 offwind-ac', 'ZA0 7 offwind-dc', 'ZA0 8 offwind-ac', 'ZA0 8 offwind-dc', 'ZA1 0 offwind-ac', 'ZA1 0 offwind-dc', 'ZA3 0 offwind-ac', 'ZA3 0 offwind-dc']\n","\n","Offshore wind generator details:\n","                  p_nom control     carrier\n","Generator                                  \n","ZA0 1 offwind-ac    0.0          offwind-ac\n","ZA0 1 offwind-dc    0.0          offwind-dc\n","ZA0 5 offwind-ac    0.0          offwind-ac\n","ZA0 5 offwind-dc    0.0          offwind-dc\n","ZA0 7 offwind-ac    0.0          offwind-ac\n","ZA0 7 offwind-dc    0.0          offwind-dc\n","ZA0 8 offwind-ac    0.0          offwind-ac\n","ZA0 8 offwind-dc    0.0          offwind-dc\n","ZA1 0 offwind-ac    0.0   Slack  offwind-ac\n","ZA1 0 offwind-dc    0.0          offwind-dc\n","ZA3 0 offwind-ac    0.0   Slack  offwind-ac\n","ZA3 0 offwind-dc    0.0          offwind-dc\n","\n","Removing 12 offshore wind generators...\n"]}],"source":["network_file = \"elec_s_10_ec_lc1.0_1h.nc\"\n","\n","gdrive_base = '/content/drive/My Drive/Colab_Notebooks'  # or '/workspace/'\n","network_file_path = os.path.join(gdrive_base, \"networks_1_year_connected\", network_file)\n","\n","env = EnvDispatchReplacement(\n","            network_file=network_file_path,\n","            no_convergence_lpf_penalty=1,\n","            reward_scale_factor=1,\n","            constraint_penalty_factor=1,\n","            offset_k=0,\n","            seed=35\n","        )\n","# Extract constraint names in the correct order\n","slack_generators = env.network.generators[env.network.generators.control == \"Slack\"].index\n","line_names = env.network.lines.index\n","storage_names = env.storage_names\n","\n","# Build constraint names in the order they appear in info['constraint_results']\n","constraint_names = []\n","\n","# p_min for each slack generator\n","for gen_name in slack_generators:\n","    constraint_names.append(f\"p_min_{gen_name}\")\n","\n","# p_max for each slack generator\n","for gen_name in slack_generators:\n","    constraint_names.append(f\"p_max_{gen_name}\")\n","\n","# soc_min for each storage\n","for storage_name in storage_names:\n","    constraint_names.append(f\"soc_min_{storage_name}\")\n","\n","# soc_max for each storage\n","for storage_name in storage_names:\n","    constraint_names.append(f\"soc_max_{storage_name}\")\n","\n","# s_max for each line (only for step_test which includes line constraints)\n","for line_name in line_names:\n","    constraint_names.append(f\"s_max_{line_name}\")\n","\n","constraint_names.append(\"redundant_entry1\")\n","constraint_names.append(\"redundant_entry2\")"]},{"cell_type":"code","execution_count":16,"id":"7a530c66-f67c-4138-8570-8cb7d5355f39","metadata":{"id":"7a530c66-f67c-4138-8570-8cb7d5355f39","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757612754092,"user_tz":-120,"elapsed":4,"user":{"displayName":"Antonia Grindrod","userId":"16615895593703421331"}},"outputId":"c95d062e-db2b-45ca-9b5e-d90f0c863501"},"outputs":[{"output_type":"stream","name":"stdout","text":["MAPE:  205.67762552470347 %\n","p_min_ZA0 0 coal : 0.0\n","p_min_ZA2 0 onwind : 0.0\n","p_max_ZA0 0 coal : 0.9138832624457134\n","p_max_ZA2 0 onwind : 0.0\n","soc_min_ZA0 0 PHS : 0.993249433326811\n","soc_min_ZA0 5 PHS : 0.0\n","soc_min_ZA0 6 hydro : 0.0\n","soc_max_ZA0 0 PHS : 0.0\n","soc_max_ZA0 5 PHS : 0.0\n","soc_max_ZA0 6 hydro : 0.0\n","s_max_0 : 0.0\n","s_max_1 : 0.0\n","s_max_10 : 0.0\n","s_max_11 : 0.0\n","s_max_12 : 0.0\n","s_max_13 : 0.0\n","s_max_14 : 0.0\n","s_max_15 : 0.0\n","s_max_2 : 0.0\n","s_max_3 : 0.0\n","s_max_4 : 0.0\n","s_max_5 : 0.0\n","s_max_6 : 0.0\n","s_max_7 : 0.0\n","s_max_8 : 0.0\n","s_max_9 : 0.0\n","s_max_lines new ZA0 4 <-> ZA2 0 AC : 0.0\n","s_max_lines new ZA0 0 <-> ZA1 0 AC : 0.0\n","s_max_lines new ZA0 0 <-> ZA3 0 AC : 0.0\n","redundant_entry1 : 0.0\n","redundant_entry2 : 0.0\n"]}],"source":["print(\"MAPE: \",test_results['mape'],\"%\")\n","for i in range(len(constraint_names)):\n","        constraint_name = constraint_names[i]\n","        violation_key = f\"violations_{constraint_name}\"\n","        avg_key = f\"avg_violation_{constraint_name}\"\n","        print(constraint_name, \":\",test_results[avg_key])"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":5}
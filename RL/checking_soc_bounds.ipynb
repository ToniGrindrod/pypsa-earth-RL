{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119bc77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/swagger_spec_validator/validator12.py:18: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/swagger_spec_validator/validator12.py:18: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/swagger_spec_validator/ref_validators.py:14: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema.validators import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/swagger_spec_validator/validator20.py:18: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema.validators import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/bravado_core/swagger20_validator.py:6: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/bravado_core/swagger20_validator.py:6: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema import RefResolver\n",
      "/Users/antoniagrindrod/miniconda3/envs/pypsa-earth-rl/lib/python3.11/site-packages/bravado_core/spec.py:14: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.\n",
      "  from jsonschema.validators import RefResolver\n",
      "[neptune] [warning] NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs-legacy.neptune.ai/setup/upgrading/\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# Suppress PyPSA INFO messages (keep warnings and errors)\n",
    "logging.getLogger('pypsa').setLevel(logging.WARNING)\n",
    "\n",
    "import pypsa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "import gc\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import neptune\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "#import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcdc27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_artificial_lines_reasonable(network):\n",
    "    \"\"\"\n",
    "    Fix artificial lines with reasonable capacity values:\n",
    "    - s_nom = based on connected bus demand (with safety factor)\n",
    "    - s_nom_extendable = False (non-extendable)\n",
    "    - Keep capacity high enough to meet demand\n",
    "    \"\"\"\n",
    "    print(\"=== FIXING ARTIFICIAL LINES WITH REASONABLE CAPACITY ===\")\n",
    "\n",
    "    # Find artificial lines\n",
    "    artificial_lines = [line for line in network.lines.index\n",
    "                       if any(keyword in str(line).lower() for keyword in ['new', '<->', 'artificial'])]\n",
    "\n",
    "    if not artificial_lines:\n",
    "        # If no artificial lines found by name, look for lines with s_nom=0\n",
    "        # which is often a sign of artificial lines\n",
    "        zero_capacity_lines = network.lines[network.lines.s_nom == 0].index.tolist()\n",
    "        if zero_capacity_lines:\n",
    "            artificial_lines = zero_capacity_lines\n",
    "\n",
    "    print(f\"Found {len(artificial_lines)} artificial lines to fix:\")\n",
    "\n",
    "    # Get maximum demand per bus across all snapshots\n",
    "    bus_max_demand = {}\n",
    "    for bus in network.buses.index:\n",
    "        bus_demand = 0\n",
    "        for load_name, load in network.loads.iterrows():\n",
    "            if load.bus == bus and load_name in network.loads_t.p_set.columns:\n",
    "                bus_demand = max(bus_demand, network.loads_t.p_set[load_name].max())\n",
    "        bus_max_demand[bus] = bus_demand\n",
    "\n",
    "    # Fix each artificial line with reasonable capacity\n",
    "    for line_name in artificial_lines:\n",
    "        # Get connected buses\n",
    "        bus0 = network.lines.loc[line_name, 'bus0']\n",
    "        bus1 = network.lines.loc[line_name, 'bus1']\n",
    "\n",
    "        # Get maximum demand at these buses\n",
    "        bus0_demand = bus_max_demand.get(bus0, 0)\n",
    "        bus1_demand = bus_max_demand.get(bus1, 0)\n",
    "\n",
    "        # Calculate required capacity with safety factor\n",
    "        # Use 3x the higher demand to ensure adequate capacity\n",
    "        safety_factor = 3.0\n",
    "        required_capacity = max(bus0_demand, bus1_demand) * safety_factor\n",
    "\n",
    "        # Ensure minimum reasonable capacity (1000 MW)\n",
    "        required_capacity = max(required_capacity, 1000)\n",
    "\n",
    "        print(f\"\\n Fixing: {line_name}\")\n",
    "        print(f\"    Connected buses: {bus0} ↔ {bus1}\")\n",
    "        print(f\"    Bus demands: {bus0}: {bus0_demand:.1f} MW, {bus1}: {bus1_demand:.1f} MW\")\n",
    "\n",
    "        # Set s_nom to required capacity\n",
    "        old_s_nom = network.lines.loc[line_name, 's_nom']\n",
    "        network.lines.loc[line_name, 's_nom'] = required_capacity\n",
    "        print(f\"    s_nom: {old_s_nom} → {required_capacity:.1f} MW\")\n",
    "\n",
    "        # Make sure line is not extendable\n",
    "        if 's_nom_extendable' not in network.lines.columns:\n",
    "            network.lines['s_nom_extendable'] = False\n",
    "        network.lines.loc[line_name, 's_nom_extendable'] = False\n",
    "        print(f\"    s_nom_extendable: → False\")\n",
    "\n",
    "    return network\n",
    "\n",
    "def remove_offshore_wind(network):\n",
    "    \"\"\"\n",
    "    Remove offshore wind generators. \n",
    "    All of these have zero nominal capacity (likely missing data). \n",
    "    Need to remove them to avoid division by zero error in constraint check for slack gens.\n",
    "    Problem is still feasible without offwind slack since pypsa optimize still feasible.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, identify offshore wind generators\n",
    "    offwind_gens = network.generators[\n",
    "        network.generators.index.str.contains('offwind', case=False, na=False)\n",
    "    ].index\n",
    "    \n",
    "    print(f\"Found {len(offwind_gens)} offshore wind generators:\")\n",
    "    print(offwind_gens.tolist())\n",
    "    \n",
    "    # Check their properties\n",
    "    offwind_data = network.generators.loc[offwind_gens, ['p_nom', 'control', 'carrier']]\n",
    "    print(\"\\nOffshore wind generator details:\")\n",
    "    print(offwind_data)\n",
    "    \n",
    "    # Remove offshore wind generators one by one\n",
    "    print(f\"\\nRemoving {len(offwind_gens)} offshore wind generators...\")\n",
    "    for gen in offwind_gens:\n",
    "        network.remove(\"Generator\", gen)\n",
    "\n",
    "def create_pypsa_network(network_file):\n",
    "    \"\"\"Create a PyPSA network from the .nc file.\"\"\"\n",
    "    # Initialize network\n",
    "    network = pypsa.Network(network_file)\n",
    "    for storage_name in network.storage_units.index:\n",
    "        # Use .loc for direct assignment to avoid SettingWithCopyWarning\n",
    "        network.storage_units.loc[storage_name, 'cyclic_state_of_charge'] = False\n",
    "\n",
    "        # Set marginal_cost to 0.01\n",
    "        network.storage_units.loc[storage_name, 'marginal_cost'] = 0.01\n",
    "\n",
    "        # Set marginal_cost_storage to 0.01\n",
    "        network.storage_units.loc[storage_name, 'marginal_cost_storage'] = 0.01\n",
    "\n",
    "        # Set spill_cost to 0.1\n",
    "        network.storage_units.loc[storage_name, 'spill_cost'] = 0.1\n",
    "\n",
    "        network.storage_units.loc[storage_name, 'efficiency_store'] = 0.866025 #use phs efficiency (hydro didnt have an efficiency, but i want to model them all as the same)\n",
    "\n",
    "        # Fix unrealistic max_hours values\n",
    "        current_max_hours = network.storage_units.loc[storage_name, 'max_hours']\n",
    "\n",
    "        if 'PHS' in storage_name:\n",
    "            # PHS with missing data - set to typical range\n",
    "            network.storage_units.loc[storage_name, 'max_hours'] = 8.0\n",
    "            print(f\"Fixed {storage_name}: set max_hours to 8.0\")\n",
    "\n",
    "        elif 'hydro' in storage_name:\n",
    "            # Hydro with unrealistic data - set to validated range\n",
    "            network.storage_units.loc[storage_name, 'max_hours'] = 6.0\n",
    "            print(f\"Fixed {storage_name}: corrected max_hours from {current_max_hours} to 6.0\")\n",
    "\n",
    "\n",
    "    fix_artificial_lines_reasonable(network)\n",
    "    remove_offshore_wind(network)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c997fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed ZA0 0 PHS: set max_hours to 8.0\n",
      "Fixed ZA0 5 PHS: set max_hours to 8.0\n",
      "Fixed ZA0 6 hydro: corrected max_hours from 3831.6270020496813 to 6.0\n",
      "=== FIXING ARTIFICIAL LINES WITH REASONABLE CAPACITY ===\n",
      "Found 3 artificial lines to fix:\n",
      "\n",
      " Fixing: lines new ZA0 4 <-> ZA2 0 AC\n",
      "    Connected buses: ZA0 4 ↔ ZA2 0\n",
      "    Bus demands: ZA0 4: 15945.8 MW, ZA2 0: 452.6 MW\n",
      "    s_nom: 0.0 → 47837.3 MW\n",
      "    s_nom_extendable: → False\n",
      "\n",
      " Fixing: lines new ZA0 0 <-> ZA1 0 AC\n",
      "    Connected buses: ZA0 0 ↔ ZA1 0\n",
      "    Bus demands: ZA0 0: 3513.0 MW, ZA1 0: 1386.9 MW\n",
      "    s_nom: 0.0 → 10538.9 MW\n",
      "    s_nom_extendable: → False\n",
      "\n",
      " Fixing: lines new ZA0 0 <-> ZA3 0 AC\n",
      "    Connected buses: ZA0 0 ↔ ZA3 0\n",
      "    Bus demands: ZA0 0: 3513.0 MW, ZA3 0: 721.1 MW\n",
      "    s_nom: 0.0 → 10538.9 MW\n",
      "    s_nom_extendable: → False\n",
      "Found 12 offshore wind generators:\n",
      "['ZA0 1 offwind-ac', 'ZA0 1 offwind-dc', 'ZA0 5 offwind-ac', 'ZA0 5 offwind-dc', 'ZA0 7 offwind-ac', 'ZA0 7 offwind-dc', 'ZA0 8 offwind-ac', 'ZA0 8 offwind-dc', 'ZA1 0 offwind-ac', 'ZA1 0 offwind-dc', 'ZA3 0 offwind-ac', 'ZA3 0 offwind-dc']\n",
      "\n",
      "Offshore wind generator details:\n",
      "                  p_nom control     carrier\n",
      "Generator                                  \n",
      "ZA0 1 offwind-ac    0.0          offwind-ac\n",
      "ZA0 1 offwind-dc    0.0          offwind-dc\n",
      "ZA0 5 offwind-ac    0.0          offwind-ac\n",
      "ZA0 5 offwind-dc    0.0          offwind-dc\n",
      "ZA0 7 offwind-ac    0.0          offwind-ac\n",
      "ZA0 7 offwind-dc    0.0          offwind-dc\n",
      "ZA0 8 offwind-ac    0.0          offwind-ac\n",
      "ZA0 8 offwind-dc    0.0          offwind-dc\n",
      "ZA1 0 offwind-ac    0.0   Slack  offwind-ac\n",
      "ZA1 0 offwind-dc    0.0          offwind-dc\n",
      "ZA3 0 offwind-ac    0.0   Slack  offwind-ac\n",
      "ZA3 0 offwind-dc    0.0          offwind-dc\n",
      "\n",
      "Removing 12 offshore wind generators...\n"
     ]
    }
   ],
   "source": [
    "network = create_pypsa_network(\"elec_s_10_ec_lc1.0_1h.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fa3b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage Unit SOC Bounds Analysis\n",
      "==================================================\n",
      "Number of storage units: 3\n",
      "\n",
      "Storage Unit Parameters:\n",
      "------------------------------\n",
      "Storage Unit: ZA0 0 PHS\n",
      "  p_nom: 2332.00 MW\n",
      "  max_hours: 8.00 hours\n",
      "  SOC_min: 0.00 MWh\n",
      "  SOC_max: 18656.00 MWh\n",
      "  Initial SOC: 0.00 MWh\n",
      "  Efficiency store: 0.866\n",
      "  Efficiency dispatch: 0.866\n",
      "  Standing loss: 0.000000\n",
      "\n",
      "Storage Unit: ZA0 5 PHS\n",
      "  p_nom: 560.00 MW\n",
      "  max_hours: 8.00 hours\n",
      "  SOC_min: 0.00 MWh\n",
      "  SOC_max: 4480.00 MWh\n",
      "  Initial SOC: 0.00 MWh\n",
      "  Efficiency store: 0.866\n",
      "  Efficiency dispatch: 0.866\n",
      "  Standing loss: 0.000000\n",
      "\n",
      "Storage Unit: ZA0 6 hydro\n",
      "  p_nom: 600.00 MW\n",
      "  max_hours: 6.00 hours\n",
      "  SOC_min: 0.00 MWh\n",
      "  SOC_max: 3600.00 MWh\n",
      "  Initial SOC: 0.00 MWh\n",
      "  Efficiency store: 0.866\n",
      "  Efficiency dispatch: 0.900\n",
      "  Standing loss: 0.000000\n",
      "\n",
      "Time-varying Parameters:\n",
      "-------------------------\n",
      "Inflow data exists:\n",
      "  ZA0 0 PHS: No inflow data\n",
      "  ZA0 5 PHS: No inflow data\n",
      "  ZA0 6 hydro: min=1.91, max=1439.78, mean=43.96 MW\n",
      "\n",
      "Snapshot Information:\n",
      "--------------------\n",
      "Total snapshots: 8760\n",
      "Storage time steps (delta_t): min=1.000, max=1.000, mean=1.000\n",
      "\n",
      "Potential SOC Violation Analysis:\n",
      "-----------------------------------\n",
      "  ZA0 0 PHS: Initial SOC very low (0.000 MWh) - likely to violate SOC_min\n",
      "  ZA0 0 PHS: Dispatch efficiency < 1.0 (0.866) - energy lost during discharge\n",
      "  ZA0 5 PHS: Initial SOC very low (0.000 MWh) - likely to violate SOC_min\n",
      "  ZA0 5 PHS: Dispatch efficiency < 1.0 (0.866) - energy lost during discharge\n",
      "  ZA0 6 hydro: Initial SOC very low (0.000 MWh) - likely to violate SOC_min\n",
      "  ZA0 6 hydro: Dispatch efficiency < 1.0 (0.900) - energy lost during discharge\n",
      "\n",
      "Network Overview:\n",
      "====================\n",
      "Generators: 43\n",
      "Loads: 13\n",
      "Lines: 19\n",
      "Storage units: 3\n",
      "Snapshots: 8760\n"
     ]
    }
   ],
   "source": [
    "# Get all storage units\n",
    "storage_units = network.storage_units\n",
    "\n",
    "print(\"Storage Unit SOC Bounds Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of storage units: {len(storage_units)}\")\n",
    "print()\n",
    "\n",
    "if len(storage_units) > 0:\n",
    "    # Check basic storage unit parameters\n",
    "    print(\"Storage Unit Parameters:\")\n",
    "    print(\"-\" * 30)\n",
    "    for storage_name in storage_units.index:\n",
    "        storage_unit = storage_units.loc[storage_name]\n",
    "        \n",
    "        # Calculate SOC bounds\n",
    "        p_nom = storage_unit['p_nom']\n",
    "        max_hours = storage_unit['max_hours']\n",
    "        soc_max = p_nom * max_hours  # Maximum energy capacity\n",
    "        soc_min = 0.0  # Typically 0 in PyPSA\n",
    "        \n",
    "        print(f\"Storage Unit: {storage_name}\")\n",
    "        print(f\"  p_nom: {p_nom:.2f} MW\")\n",
    "        print(f\"  max_hours: {max_hours:.2f} hours\")\n",
    "        print(f\"  SOC_min: {soc_min:.2f} MWh\")\n",
    "        print(f\"  SOC_max: {soc_max:.2f} MWh\")\n",
    "        print(f\"  Initial SOC: {storage_unit.get('state_of_charge_initial', 0):.2f} MWh\")\n",
    "        \n",
    "        # Check if there are any non-standard SOC limits\n",
    "        if 'soc_min_pu' in storage_unit.index:\n",
    "            print(f\"  SOC_min_pu: {storage_unit['soc_min_pu']}\")\n",
    "        if 'soc_max_pu' in storage_unit.index:\n",
    "            print(f\"  SOC_max_pu: {storage_unit['soc_max_pu']}\")\n",
    "            \n",
    "        # Check efficiency parameters\n",
    "        print(f\"  Efficiency store: {storage_unit.get('efficiency_store', 1.0):.3f}\")\n",
    "        print(f\"  Efficiency dispatch: {storage_unit.get('efficiency_dispatch', 1.0):.3f}\")\n",
    "        print(f\"  Standing loss: {storage_unit.get('standing_loss', 0.0):.6f}\")\n",
    "        print()\n",
    "\n",
    "    # Check if there are time-varying inflows\n",
    "    print(\"Time-varying Parameters:\")\n",
    "    print(\"-\" * 25)\n",
    "    if hasattr(network.storage_units_t, 'inflow'):\n",
    "        print(\"Inflow data exists:\")\n",
    "        inflow_data = network.storage_units_t.inflow\n",
    "        for storage_name in storage_units.index:\n",
    "            if storage_name in inflow_data.columns:\n",
    "                inflow_series = inflow_data[storage_name]\n",
    "                print(f\"  {storage_name}: min={inflow_series.min():.2f}, max={inflow_series.max():.2f}, mean={inflow_series.mean():.2f} MW\")\n",
    "            else:\n",
    "                print(f\"  {storage_name}: No inflow data\")\n",
    "    else:\n",
    "        print(\"No inflow data found\")\n",
    "    print()\n",
    "\n",
    "    # Check snapshot weightings that affect SOC updates\n",
    "    print(\"Snapshot Information:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Total snapshots: {len(network.snapshots)}\")\n",
    "    if hasattr(network, 'snapshot_weightings'):\n",
    "        if hasattr(network.snapshot_weightings, 'stores'):\n",
    "            delta_t_values = network.snapshot_weightings.stores\n",
    "            print(f\"Storage time steps (delta_t): min={delta_t_values.min():.3f}, max={delta_t_values.max():.3f}, mean={delta_t_values.mean():.3f}\")\n",
    "        else:\n",
    "            delta_t_values = network.snapshot_weightings\n",
    "            print(f\"General time steps: min={delta_t_values.min():.3f}, max={delta_t_values.max():.3f}, mean={delta_t_values.mean():.3f}\")\n",
    "    print()\n",
    "\n",
    "    # Additional analysis: Check which storage unit might violate SOC_min\n",
    "    print(\"Potential SOC Violation Analysis:\")\n",
    "    print(\"-\" * 35)\n",
    "    for storage_name in storage_units.index:\n",
    "        storage_unit = storage_units.loc[storage_name]\n",
    "        initial_soc = storage_unit.get('state_of_charge_initial', 0)\n",
    "        p_nom = storage_unit['p_nom']\n",
    "        \n",
    "        # Check if initial SOC is already at or near zero\n",
    "        if initial_soc <= 0.1:  # Within 0.1 MWh of zero\n",
    "            print(f\"  {storage_name}: Initial SOC very low ({initial_soc:.3f} MWh) - likely to violate SOC_min\")\n",
    "        \n",
    "        # Check standing losses\n",
    "        standing_loss = storage_unit.get('standing_loss', 0.0)\n",
    "        if standing_loss > 0:\n",
    "            print(f\"  {storage_name}: Has standing losses ({standing_loss:.6f}) - could lead to SOC violations\")\n",
    "            \n",
    "        # Check efficiency losses\n",
    "        eff_dispatch = storage_unit.get('efficiency_dispatch', 1.0)\n",
    "        if eff_dispatch < 1.0:\n",
    "            print(f\"  {storage_name}: Dispatch efficiency < 1.0 ({eff_dispatch:.3f}) - energy lost during discharge\")\n",
    "\n",
    "else:\n",
    "    print(\"No storage units found in the network!\")\n",
    "\n",
    "# Also check the overall network structure\n",
    "print(\"\\nNetwork Overview:\")\n",
    "print(\"=\" * 20)\n",
    "print(f\"Generators: {len(network.generators)}\")\n",
    "print(f\"Loads: {len(network.loads)}\")\n",
    "print(f\"Lines: {len(network.lines)}\")\n",
    "print(f\"Storage units: {len(network.storage_units)}\")\n",
    "print(f\"Snapshots: {len(network.snapshots)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypsa-earth-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PJfT8e2MPYnj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJfT8e2MPYnj",
        "outputId": "7fcc1ecc-556f-4b92-e128-3eb0399ab15b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypsa\n",
            "  Downloading pypsa-0.35.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pypsa) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pypsa) (1.16.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from pypsa) (2.2.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (from pypsa) (2025.7.1)\n",
            "Collecting netcdf4 (from pypsa)\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting linopy>=0.4 (from pypsa)\n",
            "  Downloading linopy-0.5.5-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pypsa) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from pypsa) (5.24.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from pypsa) (0.13.2)\n",
            "Requirement already satisfied: geopandas>=0.9 in /usr/local/lib/python3.11/dist-packages (from pypsa) (1.1.1)\n",
            "Collecting shapely<2.1 (from pypsa)\n",
            "  Downloading shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: networkx>=2 in /usr/local/lib/python3.11/dist-packages (from pypsa) (3.5)\n",
            "Collecting deprecation (from pypsa)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting validators (from pypsa)\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: highspy in /usr/local/lib/python3.11/dist-packages (from pypsa) (1.11.0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas>=0.9->pypsa) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas>=0.9->pypsa) (25.0)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from geopandas>=0.9->pypsa) (3.7.1)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.11/dist-packages (from linopy>=0.4->pypsa) (1.4.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from linopy>=0.4->pypsa) (0.12.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from linopy>=0.4->pypsa) (2.11.0)\n",
            "Requirement already satisfied: dask>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from linopy>=0.4->pypsa) (2025.5.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from linopy>=0.4->pypsa) (1.25.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from linopy>=0.4->pypsa) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->pypsa) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->pypsa) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->pypsa) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypsa) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypsa) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypsa) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypsa) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypsa) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypsa) (3.2.3)\n",
            "Collecting cftime (from netcdf4->pypsa)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netcdf4->pypsa) (2025.7.14)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->pypsa) (8.5.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (2025.3.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (6.0.2)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (8.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24->pypsa) (1.17.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=0.18.0->linopy>=0.4->pypsa) (3.23.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask>=0.18.0->linopy>=0.4->pypsa) (1.0.0)\n",
            "Downloading pypsa-0.35.1-py3-none-any.whl (267 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.3/267.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading linopy-0.5.5-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators, shapely, deprecation, cftime, netcdf4, linopy, pypsa\n",
            "  Attempting uninstall: shapely\n",
            "    Found existing installation: shapely 2.1.1\n",
            "    Uninstalling shapely-2.1.1:\n",
            "      Successfully uninstalled shapely-2.1.1\n",
            "Successfully installed cftime-1.6.4.post1 deprecation-2.1.0 linopy-0.5.5 netcdf4-1.7.2 pypsa-0.35.1 shapely-2.0.7 validators-0.35.0\n",
            "Collecting neptune-client\n",
            "  Downloading neptune_client-1.14.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (3.1.45)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (11.3.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.10.1)\n",
            "Collecting boto3>=1.28.0 (from neptune-client)\n",
            "  Downloading boto3-1.39.16-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting bravado<12.0.0,>=11.0.0 (from neptune-client)\n",
            "  Downloading bravado-11.1.0-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (8.2.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (1.0.0)\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (3.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from neptune-client) (25.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.2.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from neptune-client) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (1.17.0)\n",
            "Collecting swagger-spec-validator>=2.7.4 (from neptune-client)\n",
            "  Downloading swagger_spec_validator-3.0.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (4.14.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (2.5.0)\n",
            "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.11/dist-packages (from neptune-client) (1.8.0)\n",
            "Collecting botocore<1.40.0,>=1.39.16 (from boto3>=1.28.0->neptune-client)\n",
            "  Downloading botocore-1.39.16-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.0->neptune-client)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.28.0->neptune-client)\n",
            "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting bravado-core>=5.16.1 (from bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading bravado-core-6.1.1.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting monotonic (from bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0.2)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (3.20.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=2.0.8->neptune-client) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->neptune-client) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->neptune-client) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->neptune-client) (2025.7.14)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.25.0)\n",
            "Requirement already satisfied: importlib-resources>=1.3 in /usr/local/lib/python3.11/dist-packages (from swagger-spec-validator>=2.7.4->neptune-client) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->neptune-client) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->neptune-client) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->neptune-client) (2025.2)\n",
            "Collecting jsonref (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.26.0)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (3.0.0)\n",
            "Collecting rfc3339-validator (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>0.1.0 (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (24.11.1)\n",
            "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client)\n",
            "  Downloading types_python_dateutil-2.9.0.20250708-py3-none-any.whl.metadata (1.9 kB)\n",
            "Downloading neptune_client-1.14.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.39.16-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bravado-11.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Downloading swagger_spec_validator-3.0.4-py2.py3-none-any.whl (28 kB)\n",
            "Downloading botocore-1.39.16-py3-none-any.whl (13.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m141.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20250708-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: bravado-core\n",
            "  Building wheel for bravado-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bravado-core: filename=bravado_core-6.1.1-py2.py3-none-any.whl size=67675 sha256=38a5ee06cdec1e7663aa5cb168ff10df85e2c7911dff93981403cc1f36ba0487\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/d7/1c/1d707a21e0a0323bdbfbb2f6de125ae6bb70d62aa2838df321\n",
            "Successfully built bravado-core\n",
            "Installing collected packages: monotonic, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, lark, jsonref, jmespath, fqdn, rfc3987-syntax, botocore, arrow, s3transfer, isoduration, swagger-spec-validator, boto3, bravado-core, bravado, neptune-client\n",
            "Successfully installed arrow-1.3.0 boto3-1.39.16 botocore-1.39.16 bravado-11.1.0 bravado-core-6.1.1 fqdn-1.5.1 isoduration-20.11.0 jmespath-1.0.1 jsonref-1.1.0 lark-1.2.2 monotonic-1.6 neptune-client-1.14.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 s3transfer-0.13.1 swagger-spec-validator-3.0.4 types-python-dateutil-2.9.0.20250708 uri-template-1.3.0\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypsa\n",
        "!pip install neptune-client\n",
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ce4a5972",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce4a5972",
        "outputId": "455d40ec-6a70-4dd5-f92a-93ed5c2b6a0b"
      },
      "outputs": [],
      "source": [
        "import pypsa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "import gc\n",
        "import psutil\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import neptune\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "74d9a0a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypsa.io:Importing network from PyPSA version v0.30.3 while current version is v0.33.2. Read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html to prepare your network for import.\n",
            "INFO:pypsa.io:Imported network elec_s_5_ec_lcopt_3h.nc has buses, carriers, generators, lines, loads, storage_units\n"
          ]
        }
      ],
      "source": [
        "n = pypsa.Network(\"/Users/antoniagrindrod/Documents/pypsa-earth_project/pypsa-earth-RL/networks/elec_s_5_ec_lcopt_3h.nc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5021f607",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 03:00:00',\n",
            "               '2013-01-01 06:00:00', '2013-01-01 09:00:00',\n",
            "               '2013-01-01 12:00:00', '2013-01-01 15:00:00',\n",
            "               '2013-01-01 18:00:00', '2013-01-01 21:00:00',\n",
            "               '2013-01-02 00:00:00', '2013-01-02 03:00:00',\n",
            "               ...\n",
            "               '2013-12-30 18:00:00', '2013-12-30 21:00:00',\n",
            "               '2013-12-31 00:00:00', '2013-12-31 03:00:00',\n",
            "               '2013-12-31 06:00:00', '2013-12-31 09:00:00',\n",
            "               '2013-12-31 12:00:00', '2013-12-31 15:00:00',\n",
            "               '2013-12-31 18:00:00', '2013-12-31 21:00:00'],\n",
            "              dtype='datetime64[ns]', name='snapshot', length=2920, freq=None)\n"
          ]
        }
      ],
      "source": [
        "print(n.snapshots)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9db9ca87",
      "metadata": {
        "id": "9db9ca87"
      },
      "outputs": [],
      "source": [
        "def create_pypsa_network(network_file):\n",
        "    \"\"\"Create a PyPSA network from the .nc file.\"\"\"\n",
        "    # Initialize network\n",
        "    n = pypsa.Network(network_file)\n",
        "\n",
        "    return n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "hbJnmzIwvPrO",
      "metadata": {
        "id": "hbJnmzIwvPrO"
      },
      "outputs": [],
      "source": [
        "def calculate_offset_k_initialization(envClass=Env2Gen1LoadConstr,k_method='mean', k_samples=1000):\n",
        "   \"\"\"\n",
        "   Calculate the offset k for replacement reward method.\n",
        "   This ensures valid states always have higher rewards than invalid states.\n",
        "\n",
        "   Parameters:\n",
        "   -----------\n",
        "   k_samples : int\n",
        "       Number of random samples to use for estimation\n",
        "   k_method : str\n",
        "       Method to calculate k: 'mean' or 'worst_case'\n",
        "\n",
        "   Returns:\n",
        "   --------\n",
        "   float: Offset value k\n",
        "   \"\"\"\n",
        "   print(f\"Sampling {k_samples} random states to calculate offset k...\")\n",
        "\n",
        "   temp_env = envClass()\n",
        "   #this initializes episode_length to number of snapshots and constraint_penalty_factor to None.\n",
        "   #I'm just making this env to access certain attributes/ methods; which should be fine since none of these attributes/methods reference these two parameters.\n",
        "\n",
        "   objective_values = []\n",
        "   successful_samples = 0\n",
        "\n",
        "   try:\n",
        "       for i in range(k_samples):\n",
        "           try:\n",
        "               # STEP 1: Sample ONE random snapshot (random state)\n",
        "               random_snapshot_idx = np.random.randint(0, temp_env.total_snapshots)\n",
        "\n",
        "               # STEP 2: Sample ONE random action for that state\n",
        "               random_action = np.random.random(temp_env.n_non_slack)\n",
        "               scaled_action = temp_env.scale_action(random_action)\n",
        "\n",
        "               # STEP 3: Apply the action to the sampled state\n",
        "               for j, gen_name in enumerate(temp_env.non_slack_names):\n",
        "                   temp_env.network.generators_t.p_set.iloc[random_snapshot_idx,\n",
        "                       temp_env.network.generators_t.p_set.columns.get_loc(gen_name)] = scaled_action[j]\n",
        "\n",
        "               # STEP 4: Evaluate objective for this ONE state-action combination\n",
        "               temp_env.snapshot_idx = random_snapshot_idx  # Set snapshot for evaluation\n",
        "               temp_env.network.lpf()\n",
        "               obj_value = temp_env._evaluate_stored_objective()\n",
        "               objective_values.append(obj_value)\n",
        "               successful_samples += 1\n",
        "\n",
        "               # Progress indicator every 200 samples\n",
        "               if (i + 1) % 200 == 0:\n",
        "                   print(f\"  Completed {i + 1}/{k_samples} samples...\")\n",
        "\n",
        "           except Exception as e:\n",
        "               # Skip failed samples but continue\n",
        "               if i < 5:  # Only print first few errors to avoid spam\n",
        "                   print(f\"  Sample {i} failed: {e}\")\n",
        "               continue\n",
        "\n",
        "       # Calculate offset based on method\n",
        "       if objective_values:\n",
        "           if k_method == 'worst_case':\n",
        "               k = abs(max(objective_values))\n",
        "               print(f\"  Using worst-case method: k = |{max(objective_values):.2f}| = {k:.2f}\")\n",
        "           else:  # method == 'mean'\n",
        "               mean_val = np.mean(objective_values)\n",
        "               k = abs(mean_val)\n",
        "               print(f\"  Using mean method: k = |{mean_val:.2f}| = {k:.2f}\")\n",
        "\n",
        "           print(f\"  Successfully sampled {successful_samples}/{k_samples} states\")\n",
        "           print(f\"  Objective value range: [{min(objective_values):.2f}, {max(objective_values):.2f}]\")\n",
        "       else:\n",
        "           print(\"  Warning: No successful samples, using default k value\")\n",
        "           k = 2500  # Default fallback value\n",
        "\n",
        "   finally:\n",
        "       # Clean up temporary environment (optional but good practice)\n",
        "       del temp_env\n",
        "\n",
        "   return k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cae12ed9",
      "metadata": {
        "id": "cae12ed9"
      },
      "outputs": [],
      "source": [
        "def get_variable_value(network,var_name):\n",
        "        \"\"\"\n",
        "        Get the current value of a single optimization variable from the network.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        network : pypsa.Network\n",
        "            The PyPSA network object\n",
        "        var_name : str\n",
        "            Variable name like 'Generator-p[snapshot=now,Generator=coal_gen_1]'\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        float : current value of the variable\n",
        "        \"\"\"\n",
        "        # Parse the variable name\n",
        "        # Format: ComponentName-attribute[dimension1=value1,dimension2=value2,...]\n",
        "\n",
        "        # Split on first '[' to separate base name from coordinates\n",
        "        if '[' in var_name:\n",
        "            base_name, coords_str = var_name.split('[', 1)\n",
        "            coords_str = coords_str.rstrip(']')  # Remove trailing ']'\n",
        "        else:\n",
        "            base_name = var_name\n",
        "            coords_str = \"\"\n",
        "\n",
        "        # Parse base name: ComponentName-attribute\n",
        "        component_name, attribute = base_name.split('-', 1)\n",
        "\n",
        "        # Parse coordinates if they exist\n",
        "        coords = {}\n",
        "        if coords_str:\n",
        "            # Split by comma and parse key=value pairs\n",
        "            for coord_pair in coords_str.split(','):\n",
        "                key, value = coord_pair.split('=', 1)\n",
        "                coords[key.strip()] = value.strip()\n",
        "\n",
        "        # Determine if this has time dimension (snapshot)\n",
        "        has_snapshot = 'snapshot' in coords\n",
        "\n",
        "        if has_snapshot:\n",
        "            # Access dynamic dataframe using n.dynamic()\n",
        "            snapshot_value = coords['snapshot']\n",
        "            component_instance = coords[component_name]\n",
        "\n",
        "            # Special handling for branch flow variables\n",
        "            if component_name in network.passive_branch_components and attribute == 's':\n",
        "                # For branch components, 's' is stored as 'p0' in the network\n",
        "                # We can use p0 directly as the value of 's'\n",
        "                try:\n",
        "                    return network.dynamic(component_name)['p0'].loc[snapshot_value, component_instance]\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Could not get flow value for {var_name}: {e}\")\n",
        "                    return 0.0\n",
        "\n",
        "            # Get dynamic data for normal case\n",
        "            dynamic_data = network.dynamic(component_name)\n",
        "\n",
        "            # Access the specific attribute DataFrame\n",
        "            if attribute in dynamic_data:\n",
        "                return dynamic_data[attribute].loc[snapshot_value, component_instance]\n",
        "            else:\n",
        "                raise KeyError(f\"Attribute {attribute} not found in dynamic data for {component_name}\")\n",
        "\n",
        "        else:\n",
        "            # Access static dataframe using n.static()\n",
        "            component_instance = coords[component_name]\n",
        "\n",
        "            # Get static data\n",
        "            static_data = network.static(component_name)\n",
        "\n",
        "            # Access the value\n",
        "            return static_data.loc[component_instance, attribute]\n",
        "\n",
        "def create_variable_values_mapping(network, variable_names):\n",
        "        \"\"\"\n",
        "        Create a mapping from optimization variable names to their current values in the network.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        network : pypsa.Network\n",
        "            The PyPSA network object\n",
        "        variable_names : list\n",
        "            List of variable names like ['Generator-p[snapshot=now,Generator=coal_gen_1]', ...]\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        dict : mapping from variable name to current value\n",
        "        \"\"\"\n",
        "        var_values = {}\n",
        "\n",
        "        for var_name in variable_names:\n",
        "            try:\n",
        "                value = get_variable_value(network,var_name)\n",
        "                var_values[var_name] = value\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not get value for {var_name}: {e}\")\n",
        "                var_values[var_name] = 0.0  # Default fallback\n",
        "\n",
        "        return var_values\n",
        "\n",
        "def evaluate_objective(var_id_to_name, network, snapshot_idx):\n",
        "        \"\"\"\n",
        "        Direct evaluation without mock objects.\n",
        "        Only includes terms from the current snapshot in the objective function.\n",
        "        \"\"\"\n",
        "        temp_model = network.optimize.create_model()\n",
        "\n",
        "        # Extract objective components\n",
        "        obj_expr = temp_model.objective\n",
        "        objective_vars = obj_expr.vars.copy()\n",
        "        objective_coeffs = obj_expr.coeffs.copy()\n",
        "        objective_const = obj_expr.const.copy() if hasattr(obj_expr, 'const') else 0\n",
        "\n",
        "        # Get variable name mapping for current network\n",
        "        id_to_name = var_id_to_name\n",
        "\n",
        "        # Get the current snapshot name\n",
        "        current_snapshot = snapshot_idx\n",
        "\n",
        "        # Get current variable values\n",
        "        variable_names = []\n",
        "        var_indices = []\n",
        "        vars_flat = objective_vars.values.flatten()\n",
        "        coeffs_flat = objective_coeffs.values.flatten()\n",
        "\n",
        "        # Filter variables to only include those from the current snapshot\n",
        "        for i, var_id in enumerate(vars_flat):\n",
        "            if var_id != -1 and var_id in id_to_name:\n",
        "                var_name = id_to_name[var_id]\n",
        "                # Check if this variable belongs to the current snapshot\n",
        "                if 'snapshot=' in var_name:\n",
        "                    # Extract the snapshot value from the variable name\n",
        "                    snapshot_part = var_name.split('snapshot=')[1].split(',')[0].split(']')[0]\n",
        "                    if snapshot_part == str(current_snapshot):\n",
        "                        variable_names.append(var_name)\n",
        "                        var_indices.append(i)\n",
        "                else:\n",
        "                    # Include variables without snapshot dimension (like investment variables)\n",
        "                    variable_names.append(var_name)\n",
        "                    var_indices.append(i)\n",
        "\n",
        "        var_values = create_variable_values_mapping(network,variable_names)\n",
        "\n",
        "        # Direct mathematical evaluation using only variables from current snapshot\n",
        "        if var_indices:\n",
        "            result = np.sum(coeffs_flat[var_indices] *\n",
        "                        [var_values.get(name, 0) for name in variable_names]) + \\\n",
        "                    objective_const\n",
        "        else:\n",
        "            # If no variables for this snapshot, just return the constant\n",
        "            result = objective_const\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6fe8e8c8",
      "metadata": {
        "id": "6fe8e8c8"
      },
      "outputs": [],
      "source": [
        "def evaluate_baseline_reward(network_file, env, agent):\n",
        "    network_baseline=create_pypsa_network(network_file)#network to run pypsa optimize on\n",
        "    network_baseline.optimize()\n",
        "    snapshots=network_baseline.snapshots\n",
        "    objective_sum=0\n",
        "    for snapshot_idx in range(len(snapshots)):\n",
        "        objective_sum+=evaluate_objective(env.var_id_to_name, network_baseline, snapshots[snapshot_idx])\n",
        "    baseline_reward_value=-objective_sum*(env.episode_length/ len(snapshots))#assuming episode length is a multiple of the number of snapshots\n",
        "    #reward is -1 times the objective value\n",
        "    return baseline_reward_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b8f1d307",
      "metadata": {
        "id": "b8f1d307"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypsa.io:Importing network from PyPSA version v0.30.3 while current version is v0.33.2. Read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html to prepare your network for import.\n",
            "INFO:pypsa.io:Imported network elec_s_5_ec_lcopt_3h.nc has buses, carriers, generators, lines, loads, storage_units\n",
            "WARNING:pypsa.consistency:The following lines have carriers which are not defined:\n",
            "Index(['0', '1', '2', '3', '4', '5', '6'], dtype='object', name='Line')\n",
            "WARNING:pypsa.consistency:The following buses have carriers which are not defined:\n",
            "Index(['ZA0 0', 'ZA0 1', 'ZA0 2', 'ZA0 3', 'ZA0 4', 'ZA1 0', 'ZA2 0', 'ZA3 0'], dtype='object', name='Bus')\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 1107\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m constraint_name, violation \u001b[38;5;129;01min\u001b[39;00m violations\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1105\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mviolation\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1107\u001b[0m \u001b[43mEnv2Gen1LoadConstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/antoniagrindrod/Documents/pypsa-earth_project/pypsa-earth-RL/networks/elec_s_5_ec_lcopt_3h.nc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[23], line 21\u001b[0m, in \u001b[0;36mEnv2Gen1LoadConstr.__init__\u001b[0;34m(self, network_file, episode_length, constraint_penalty_factor)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Use provided network or create new one\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m=\u001b[39mcreate_pypsa_network(network_file)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_optimization_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty_factor\u001b[38;5;241m=\u001b[39mconstraint_penalty_factor\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Episode management\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[23], line 123\u001b[0m, in \u001b[0;36mEnv2Gen1LoadConstr._initialize_optimization_components\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m coord_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim_idx, dim_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(var_labels\u001b[38;5;241m.\u001b[39mdims):\n\u001b[0;32m--> 123\u001b[0m     coord_val \u001b[38;5;241m=\u001b[39m \u001b[43mcoords\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdim_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m[unravel_idx[dim_idx]]\n\u001b[1;32m    124\u001b[0m     coord_values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoord_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m full_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(coord_values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/pypsa-za/lib/python3.10/site-packages/xarray/core/dataarray.py:823\u001b[0m, in \u001b[0;36mDataArray.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    812\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m    The array's data converted to numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m    to this array may be reflected in the DataArray as well.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/pypsa-za/lib/python3.10/site-packages/xarray/core/variable.py:508\u001b[0m, in \u001b[0;36mVariable.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    507\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/pypsa-za/lib/python3.10/site-packages/xarray/core/variable.py:302\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    304\u001b[0m         kind \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind\n",
            "File \u001b[0;32m~/miniconda3/envs/pypsa-za/lib/python3.10/site-packages/xarray/core/indexing.py:1774\u001b[0m, in \u001b[0;36mPandasIndexingAdapter.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m   1771\u001b[0m         \u001b[38;5;66;03m# this might not be public API\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(np\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mVersion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(array\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/pypsa-za/lib/python3.10/site-packages/packaging/version.py:207\u001b[0m, in \u001b[0;36mVersion.__init__\u001b[0;34m(self, version)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidVersion(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Store the parsed out pieces of the version\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version \u001b[38;5;241m=\u001b[39m _Version(\n\u001b[1;32m    206\u001b[0m     epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m--> 207\u001b[0m     release\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelease\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    208\u001b[0m     pre\u001b[38;5;241m=\u001b[39m_parse_letter_version(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_l\u001b[39m\u001b[38;5;124m\"\u001b[39m), match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_n\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m    209\u001b[0m     post\u001b[38;5;241m=\u001b[39m_parse_letter_version(\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mmatch\u001b[39;00m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_l\u001b[39m\u001b[38;5;124m\"\u001b[39m), match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_n1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_n2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    211\u001b[0m     ),\n\u001b[1;32m    212\u001b[0m     dev\u001b[38;5;241m=\u001b[39m_parse_letter_version(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_l\u001b[39m\u001b[38;5;124m\"\u001b[39m), match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_n\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m    213\u001b[0m     local\u001b[38;5;241m=\u001b[39m_parse_local_version(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m    214\u001b[0m )\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Generate a key which will be used for sorting\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key \u001b[38;5;241m=\u001b[39m _cmpkey(\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version\u001b[38;5;241m.\u001b[39mepoch,\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version\u001b[38;5;241m.\u001b[39mrelease,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version\u001b[38;5;241m.\u001b[39mlocal,\n\u001b[1;32m    224\u001b[0m )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class Env2Gen1LoadConstr(gym.Env):\n",
        "    \"\"\"\n",
        "    OpenAI Gym environment for Optimal Power Flow using PyPSA.\n",
        "    Simple example with 2 generators and 1 load.\n",
        "    Implemented without constraints (omitted bus voltage limits, line limits, etc.).\n",
        "\n",
        "    Action Space: Continuous setpoints for generators within their capacity limits\n",
        "    Observation Space: Network state, represented by:\n",
        "    - the active and reactive power of all loads,\n",
        "    - the reactive power prices of all generators,\n",
        "    - the active power setpoints of all generators\n",
        "    (This follows http://arxiv.org/abs/2403.17831. Additional variables can be added optionally)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,network_file, episode_length=None, constraint_penalty_factor=100):\n",
        "        super(Env2Gen1LoadConstr, self).__init__()\n",
        "\n",
        "        # Use provided network or create new one\n",
        "        self.network =create_pypsa_network(network_file)\n",
        "\n",
        "        self._initialize_optimization_components()\n",
        "        self.penalty_factor=constraint_penalty_factor\n",
        "\n",
        "        # Episode management\n",
        "        self.total_snapshots = len(self.network.snapshots)\n",
        "        self.episode_length = episode_length if episode_length is not None else self.total_snapshots\n",
        "        self.current_step = 0  # Steps within current episode\n",
        "        self.snapshot_idx = 0  # Current snapshot index (cycles through all snapshots)\n",
        "\n",
        "        # Find the slack generator\n",
        "        # The agent will only be able to control the active power setpoints of generators that are not the slack generator\n",
        "        self.slack_generator_idx = self.network.generators[self.network.generators.control == \"Slack\"].index\n",
        "        #Note that there should only ever be one slack bus.\n",
        "        #Need to implement handling for multiple generators control set to \"Slack\",\n",
        "        #In that case, will need to designate one for slack and change control of others\n",
        "        #TO DO: Implement handling for multiple slack generators\n",
        "\n",
        "        #Get indices of all generators that are not the slack generator (after ensuring there is only one slack generator)\n",
        "        self.non_slack_gens = self.network.generators[self.network.generators.control != \"Slack\"].index #must explicitly search again, can't reference results of last query since this may have changed since choosing slack generator\n",
        "        self.non_slack_names = list(self.non_slack_gens)\n",
        "        self.n_non_slack = len(self.non_slack_names)\n",
        "        self.non_slack_df = self.network.generators.loc[self.non_slack_gens]  # Fixed: was non_slack_generators\n",
        "        # The agent will only be able to control the active power setpoints of generators that are not the slack generator\n",
        "\n",
        "        # Get generator limits (in MW)\n",
        "        self.a_min = (self.non_slack_df.p_min_pu * self.non_slack_df.p_nom).values\n",
        "        self.a_max = (self.non_slack_df.p_max_pu * self.non_slack_df.p_nom).values\n",
        "        #TO DO: When generalize, control of the generator will determine the action space of the agent\n",
        "        # Whichever quantity is controllable, according to the control, will be the quantity the agent chooses as its action (e.g. could be active or reactive power)\n",
        "        # Then we would need to change the bounds of the the relevant bounds will be the actions space to be the min and max of whatever the quantity is\n",
        "\n",
        "        # Define action space: continuous setpoints for each generator within limits\n",
        "        # Action space is a Box with shape (n_non_slack,) where each element has value between 0 and 1.\n",
        "        self.action_space = gym.spaces.Box(0, 1, shape=(self.n_non_slack,))\n",
        "\n",
        "        # Define observation space - network state\n",
        "        # This will include: generator outputs, loads, voltages, line flows, etc.\n",
        "        # For simplicity, let's include key network variables\n",
        "        # obs_dim = (self.n_non_slack+1)+len(self.network.loads)\n",
        "        # First term: self.n_non_slack: Active power outputs of all non-slackgenerators! Actually I removed this because that actually corresponds to the action choice.\n",
        "        # TO DO: Later we might need to include a history of the network as part of the observation - to obey ramp constraints etc.\n",
        "        #Second term: Cost function components (start with one each - marginal cost) of all generators, including slack\n",
        "        # Third term: Active power of load demands\n",
        "        # TO DO: include power of storage units and noncontrollable generators (small generators and storage units; not including slack generator) in observation space\n",
        "\n",
        "\n",
        "        #TO DO: If use .pf instead of .lpf, add another of each term for active power AND reactive power\n",
        "        #include the power of the slack generator in the observation, since agent's action (choice of active power for non-slack generators influences power of slack generator, through power flow calculations)\n",
        "\n",
        "        # Initialize the network state\n",
        "        self.reset()\n",
        "\n",
        "        # Observation space is bounded - you may want to adjust these bounds based on your system\n",
        "\n",
        "        # Create observation space\n",
        "        low_bounds, high_bounds = self.create_observation_bounds()\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=low_bounds,\n",
        "            high=high_bounds,\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        #Bounds are set according to specific component of the observation\n",
        "        #Could set the bounds of active power of each generator to correspond to min and max p\n",
        "\n",
        "    def _initialize_optimization_components(self):\n",
        "        \"\"\"\n",
        "        Initialize all optimization components in one pass to avoid creating multiple models.\n",
        "        This method:\n",
        "        1. Creates the optimization model once\n",
        "        2. Extracts objective components (vars, coeffs, const)\n",
        "        3. Creates the variable ID to name mapping\n",
        "        4. Extracts constraints\n",
        "        5. Cleans up the model\n",
        "        \"\"\"\n",
        "        # Create model once - this is an expensive operation\n",
        "        temp_model = self.network.optimize.create_model()\n",
        "\n",
        "        # Extract objective components\n",
        "        obj_expr = temp_model.objective\n",
        "        self.objective_vars = obj_expr.vars.copy()\n",
        "        self.objective_coeffs = obj_expr.coeffs.copy()\n",
        "        self.objective_const = obj_expr.const.copy() if hasattr(obj_expr, 'const') else 0\n",
        "\n",
        "        # Create variable ID to name mapping\n",
        "        self.var_id_to_name = {}\n",
        "        for var_name, variable in temp_model.variables.items():\n",
        "            # Get the variable labels (IDs) for this variable\n",
        "            var_labels = variable.labels\n",
        "\n",
        "            if hasattr(var_labels, 'values'):\n",
        "                # Multi-dimensional variable\n",
        "                labels_flat = var_labels.values.flatten()\n",
        "                for i, label in enumerate(labels_flat):\n",
        "                    if label != -1:  # -1 means no variable\n",
        "                        # Create a name that includes the index for multi-dim variables\n",
        "                        coords = variable.labels.coords\n",
        "                        if len(coords) > 0:\n",
        "                            # Get the coordinate values for this flat index\n",
        "                            unravel_idx = np.unravel_index(i, var_labels.shape)\n",
        "                            coord_values = []\n",
        "                            for dim_idx, dim_name in enumerate(var_labels.dims):\n",
        "                                coord_val = coords[dim_name].values[unravel_idx[dim_idx]]\n",
        "                                coord_values.append(f\"{dim_name}={coord_val}\")\n",
        "                            full_name = f\"{var_name}[{','.join(coord_values)}]\"\n",
        "                        else:\n",
        "                            full_name = f\"{var_name}[{i}]\"\n",
        "                        self.var_id_to_name[label] = full_name\n",
        "            else:\n",
        "                # Scalar variable\n",
        "                self.var_id_to_name[var_labels] = var_name\n",
        "\n",
        "        # Store constraint information\n",
        "        self.constraints = {}\n",
        "        for name, constraint_group in temp_model.constraints.items():\n",
        "            # Check if this is a constraint group with multiple individual constraints\n",
        "            if hasattr(constraint_group.lhs, 'shape') and len(constraint_group.lhs.shape) > 0:\n",
        "                # This is a constraint group with multiple individual constraints\n",
        "                # We need to extract each individual constraint\n",
        "\n",
        "                # Get the dimensions of the constraint group\n",
        "                dims = constraint_group.lhs.dims if hasattr(constraint_group.lhs, 'dims') else []\n",
        "\n",
        "                # If it has dimensions, iterate through each individual constraint\n",
        "                if dims:\n",
        "                    # Get coordinate values for each dimension\n",
        "                    coords = {}\n",
        "                    for dim in dims:\n",
        "                        if hasattr(constraint_group.lhs, 'coords') and dim in constraint_group.lhs.coords:\n",
        "                            coords[dim] = constraint_group.lhs.coords[dim].values\n",
        "\n",
        "                    # Create a flat iterator through all combinations of coordinates\n",
        "                    if coords:\n",
        "                        try:\n",
        "                            # Create all combinations of coordinate indices - only use dimensions that exist in coords\n",
        "                            valid_dims = [dim for dim in dims if dim in coords]\n",
        "                            if not valid_dims:\n",
        "                                # No valid dimensions found, skip this constraint group\n",
        "                                print(f\"Warning: No valid dimensions found for constraint {name}\")\n",
        "                                continue\n",
        "\n",
        "                            # Create shape tuple for ndindex\n",
        "                            shape_tuple = tuple(len(coords[dim]) for dim in valid_dims)\n",
        "                            if not shape_tuple:\n",
        "                                # Empty shape tuple, skip this constraint group\n",
        "                                print(f\"Warning: Empty shape tuple for constraint {name}\")\n",
        "                                continue\n",
        "\n",
        "                            # Create iterator\n",
        "                            indices = np.ndindex(shape_tuple)\n",
        "\n",
        "                            # Iterate through all combinations\n",
        "                            for idx in indices:\n",
        "                                try:\n",
        "                                    # Create a key for this specific constraint\n",
        "                                    coord_values = []\n",
        "                                    for i, dim in enumerate(valid_dims):\n",
        "                                        coord_values.append(f\"{dim}={coords[dim][idx[i]]}\")\n",
        "\n",
        "                                    specific_key = f\"{name}[{','.join(coord_values)}]\"\n",
        "\n",
        "                                    # Extract the specific constraint values - with error handling\n",
        "                                    try:\n",
        "                                        # For LHS\n",
        "                                        if hasattr(constraint_group.lhs, 'vars') and hasattr(constraint_group.lhs, 'coeffs'):\n",
        "                                            # Create a proper index for this specific constraint\n",
        "                                            # We need to map our valid_dims indices to the full dims indices\n",
        "\n",
        "                                            # For linear expressions - safely get values\n",
        "                                            try:\n",
        "                                                if hasattr(constraint_group.lhs.vars, '__getitem__'):\n",
        "                                                    lhs_vars = constraint_group.lhs.vars[idx]\n",
        "                                                    #condition is evaluating to true and type(constraint_group.lhs.vars) is <class 'xarray.core.dataarray.DataArray'>\n",
        "                                                else:\n",
        "                                                    lhs_vars = constraint_group.lhs.vars\n",
        "\n",
        "                                                if hasattr(constraint_group.lhs.coeffs, '__getitem__'):\n",
        "                                                    lhs_coeffs = constraint_group.lhs.coeffs[idx]\n",
        "                                                else:\n",
        "                                                    lhs_coeffs = constraint_group.lhs.coeffs\n",
        "                                            except Exception as e:\n",
        "                                                print(f\"Warning: Error accessing constraint values for {specific_key}: {e}\")\n",
        "                                                continue\n",
        "\n",
        "                                            # Create a new linear expression for this specific constraint\n",
        "                                            specific_lhs = type('LinearExpr', (), {\n",
        "                                                'vars': np.array([[lhs_vars]]) if np.isscalar(lhs_vars) else np.array([lhs_vars]),\n",
        "                                                'coeffs': np.array([[lhs_coeffs]]) if np.isscalar(lhs_coeffs) else np.array([lhs_coeffs]),\n",
        "                                                'copy': lambda self: self\n",
        "                                            })\n",
        "\n",
        "                                            # Add constant if it exists - safely\n",
        "                                            if hasattr(constraint_group.lhs, 'const'):\n",
        "                                                try:\n",
        "                                                    if hasattr(constraint_group.lhs.const, '__getitem__'):\n",
        "                                                        const_val = constraint_group.lhs.const[idx]\n",
        "                                                    else:\n",
        "                                                        const_val = constraint_group.lhs.const\n",
        "                                                    specific_lhs.const = np.array([[const_val]]) if np.isscalar(const_val) else np.array([const_val])\n",
        "                                                except Exception as e:\n",
        "                                                    # If error accessing const, just use 0\n",
        "                                                    specific_lhs.const = 0\n",
        "                                                    print(f\"Warning: Error accessing const for {specific_key}: {e}\")\n",
        "                                        # else:\n",
        "                                        #     # For simple values\n",
        "                                        #     try:\n",
        "                                        #         if hasattr(constraint_group.lhs, '__getitem__'):\n",
        "                                        #             specific_lhs = constraint_group.lhs[idx]\n",
        "                                        #         else:\n",
        "                                        #             specific_lhs = constraint_group.lhs\n",
        "                                        #     except Exception as e:\n",
        "                                        #         print(f\"Warning: Error accessing LHS for {specific_key}: {e}\")\n",
        "                                        #         continue\n",
        "\n",
        "                                        # For RHS - safely\n",
        "                                        try:\n",
        "                                            if hasattr(constraint_group.rhs, '__getitem__'):\n",
        "                                                rhs_val = constraint_group.rhs[idx]\n",
        "                                            else:\n",
        "                                                rhs_val = constraint_group.rhs\n",
        "                                            specific_rhs = np.array([[rhs_val]]) if np.isscalar(rhs_val) else np.array([rhs_val])\n",
        "                                        except Exception as e:\n",
        "                                            print(f\"Warning: Error accessing RHS for {specific_key}: {e}\")\n",
        "                                            continue\n",
        "\n",
        "                                        # For sign - safely\n",
        "                                        try:\n",
        "                                            if hasattr(constraint_group.sign, '__getitem__'):\n",
        "                                                sign_val = constraint_group.sign[idx].values.item()\n",
        "                                            else:\n",
        "                                                sign_val = constraint_group.sign\n",
        "                                            specific_sign = np.array([sign_val]) if np.isscalar(sign_val) else np.array([sign_val])\n",
        "                                        except Exception as e:\n",
        "                                            print(f\"Warning: Error accessing sign for {specific_key}: {e}\")\n",
        "                                            specific_sign = np.array(['>=']) # Default sign\n",
        "\n",
        "                                        # Store this specific constraint\n",
        "                                        self.constraints[specific_key] = {\n",
        "                                            'lhs': specific_lhs,\n",
        "                                            'rhs': specific_rhs,\n",
        "                                            'sign': specific_sign\n",
        "                                        }\n",
        "                                    except Exception as e:\n",
        "                                        print(f\"Warning: Error processing constraint {specific_key}: {e}\")\n",
        "                                        continue\n",
        "                                except Exception as e:\n",
        "                                    print(f\"Warning: Error creating key for constraint: {e}\")\n",
        "                                    continue\n",
        "                        except Exception as e:\n",
        "                            print(f\"Warning: Error creating indices for constraint {name}: {e}\")\n",
        "                            continue\n",
        "                else: #no case handling for when no dimensions but still has shape\n",
        "                    print(f\"Warning: No dimensions found for constraint {name}\")\n",
        "                    continue\n",
        "            else:\n",
        "                # This is a single constraint, store it directly\n",
        "                try:\n",
        "                    self.constraints[name] = {\n",
        "                        'lhs': constraint_group.lhs.copy() if hasattr(constraint_group.lhs, 'copy') else constraint_group.lhs,\n",
        "                        'rhs': constraint_group.rhs.copy() if hasattr(constraint_group.rhs, 'copy') else constraint_group.rhs,\n",
        "                        'sign': constraint_group.sign\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error storing single constraint {name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        # Clean up to free memory\n",
        "        del temp_model, obj_expr\n",
        "        gc.collect()\n",
        "\n",
        "    def create_observation_bounds(self):\n",
        "        \"\"\"\n",
        "        Create bounds for the observation space based on generator costs and load power\n",
        "        \"\"\"\n",
        "        # --- Generator Cost Bounds ---\n",
        "        gen_cost_lower = []\n",
        "        gen_cost_upper = []\n",
        "\n",
        "        for gen in self.network.generators.index:\n",
        "            # Get generator specs\n",
        "            p_nom = self.network.generators.loc[gen, \"p_nom\"]\n",
        "            p_min_pu = self.network.generators.loc[gen, \"p_min_pu\"]\n",
        "            p_max_pu = self.network.generators.loc[gen, \"p_max_pu\"]\n",
        "            marginal_cost = self.network.generators.loc[gen, \"marginal_cost\"]\n",
        "\n",
        "            # Min cost: generator at minimum output\n",
        "            min_cost = p_min_pu * p_nom * marginal_cost\n",
        "\n",
        "            # Max cost: generator at maximum output\n",
        "            max_cost = p_max_pu * p_nom * marginal_cost\n",
        "            #TO DO: add other cost function components if applicable\n",
        "            gen_cost_lower.append(min_cost)\n",
        "            gen_cost_upper.append(max_cost)\n",
        "\n",
        "        # --- Load Power Bounds ---\n",
        "        load_p_lower = []\n",
        "        load_p_upper = []\n",
        "\n",
        "        for load in self.network.loads.index:\n",
        "            # Get load specs\n",
        "            p_nom = self.network.loads.loc[load, \"p_set\"]#TO DO: not sure if this is correct. in general might not set p_set when specifying load component (might instead specifiy p_nom)\n",
        "\n",
        "            # If you have time series data for loads\n",
        "            if hasattr(self.network, \"loads_t\") and not self.network.loads_t.p.empty:\n",
        "                min_load = self.network.loads_t.p.iloc[self.snapshot_idx].min()\n",
        "                max_load = self.network.loads_t.p.iloc[self.snapshot_idx].max()\n",
        "            else:\n",
        "                # If no time series, use p_set with some margin\n",
        "                min_load = 0.7 * p_nom  # Assumption: load can go down to 70%\n",
        "                max_load = 1.3 * p_nom  # Assumption: load can go up to 130%\n",
        "\n",
        "            load_p_lower.append(min_load)\n",
        "            load_p_upper.append(max_load)\n",
        "\n",
        "        # Combine all bounds\n",
        "        low_bounds = np.concatenate([gen_cost_lower, load_p_lower]).astype(np.float32)\n",
        "        high_bounds = np.concatenate([gen_cost_upper, load_p_upper]).astype(np.float32)\n",
        "\n",
        "        return low_bounds, high_bounds\n",
        "\n",
        "    def reset_network(self):\n",
        "        \"\"\"Reset and ensure essential DataFrames exist.\"\"\"\n",
        "        #Note that we do not just create a new network here, as this consumes more memory and previously led to a segmentation fault\n",
        "        # TO DO: For a general network, we would need to reset all time-varying data (i.e. all components with time-varying data)\n",
        "        # Ensure generators_t DataFrames exist and are reset\n",
        "        if not hasattr(self.network, 'generators_t'):\n",
        "            # This shouldn't happen with PyPSA, but just in case\n",
        "            pass\n",
        "\n",
        "        # Initialize/reset generators_t.p\n",
        "        if not hasattr(self.network.generators_t, 'p') or self.network.generators_t.p.empty:\n",
        "            self.network.generators_t.p = pd.DataFrame(\n",
        "                0.0,\n",
        "                index=self.network.snapshots,\n",
        "                columns=self.network.generators.index\n",
        "            )\n",
        "        else:\n",
        "            self.network.generators_t.p.iloc[:, :] = 0.0\n",
        "\n",
        "        # Initialize/reset generators_t.p_set\n",
        "        if not hasattr(self.network.generators_t, 'p_set') or self.network.generators_t.p_set.empty:\n",
        "            self.network.generators_t.p_set = pd.DataFrame(\n",
        "                0.0,\n",
        "                index=self.network.snapshots,\n",
        "                columns=self.network.generators.index\n",
        "            )\n",
        "        else:\n",
        "            self.network.generators_t.p_set.iloc[:, :] = 0.0\n",
        "\n",
        "        # Initialize/reset loads_t.p based on loads_t.p_set\n",
        "        if not hasattr(self.network.loads_t, 'p') or self.network.loads_t.p.empty:\n",
        "            # Create loads_t.p dataframe with same structure as loads_t.p_set\n",
        "            self.network.loads_t.p = self.network.loads_t.p_set.copy()\n",
        "        else:\n",
        "            # Reset loads_t.p to match loads_t.p_set\n",
        "            self.network.loads_t.p.iloc[:, :] = self.network.loads_t.p_set.values\n",
        "        # # Reset other existing time-series DataFrames (but don't create new ones)\n",
        "        # component_types = ['loads', 'buses', 'lines', 'storage_units', 'transformers']\n",
        "\n",
        "        # for comp_type in component_types:\n",
        "        #     comp_t_name = f\"{comp_type}_t\"\n",
        "        #     if hasattr(self.network, comp_t_name):\n",
        "        #         comp_t = getattr(self.network, comp_t_name)\n",
        "\n",
        "        #         for attr_name in dir(comp_t):\n",
        "        #             if not attr_name.startswith('_'):\n",
        "        #                 try:\n",
        "        #                     attr_value = getattr(comp_t, attr_name)\n",
        "        #                     if isinstance(attr_value, pd.DataFrame) and not attr_value.empty:\n",
        "        #                         attr_value.iloc[:, :] = 0.0\n",
        "        #                 except Exception as e:\n",
        "        #                     pass  # Skip problematic attributes\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        \"\"\"\n",
        "        Reset the environment to initial state.\n",
        "        Returns initial observation and info (gymnasium format).\n",
        "        \"\"\"\n",
        "        # Set seed if provided\n",
        "        if seed is not None:\n",
        "            self.seed(seed)\n",
        "\n",
        "        # Reset episode counters\n",
        "        self.current_step = 0\n",
        "        self.snapshot_idx = 0\n",
        "\n",
        "        self.reset_network()\n",
        "        #self._test_hidden_references()\n",
        "        #can run that instead to check if there are hidden references preventing network cleanup\n",
        "\n",
        "        # Get initial observation\n",
        "        obs = self._get_observation()\n",
        "\n",
        "        # Info dict for gymnasium compatibility\n",
        "        info = {\n",
        "            'current_step': self.current_step,\n",
        "            'snapshot_idx': self.snapshot_idx\n",
        "        }\n",
        "\n",
        "        return obs, info\n",
        "\n",
        "    def _get_observation(self):\n",
        "        \"\"\"\n",
        "        Get current network state as observation.\n",
        "        \"\"\"\n",
        "        obs_components = []\n",
        "\n",
        "        # obs_dim = (self.n_non_slack+1)+len(self.network.loads)\n",
        "        # First term: self.n_non_slack: Active power outputs of all non-slackgenerators! Actually I removed this because that actually corresponds to the action choice.\n",
        "        # TO DO: Later we might need to include a history of the network as part of the observation - to obey ramp constraints etc.\n",
        "        # Second term: Cost function components (start with one each - marginal cost) of all generators, including slack\n",
        "        # Third term: Active power of load demands\n",
        "\n",
        "\n",
        "        # Generator power costs (for now just marginal) - TO DO: change this to include more components of cost function to make this more accurate\n",
        "        gen_costs = self.network.generators.marginal_cost.values #TO DO: not sure if the marginal_cost should be accessed from generators_t instead (would do generators.marginal_cost.iloc[snapshot_idx].values). But then not static\n",
        "        obs_components.append(gen_costs)\n",
        "\n",
        "        load_demands = np.array([])\n",
        "        # Load demands - handle case where we might have empty loads_t.p\n",
        "        if hasattr(self.network, 'loads_t') and not self.network.loads_t.p.empty:\n",
        "            load_demands = self.network.loads_t.p.iloc[self.snapshot_idx].values\n",
        "        obs_components.append(load_demands)\n",
        "\n",
        "        #The following line should be uncommented when want to enforce network constraints via action masking\n",
        "        #obs_components.append(self._get_mask())\n",
        "\n",
        "        # TO DO: Could later try to add bus voltages etc. and see if difference on agent learning. (Paper says these are optional components of the observation space)\n",
        "        # Concatenate all observation components\n",
        "        observation = np.concatenate(obs_components).astype(np.float32)\n",
        "\n",
        "        return observation\n",
        "\n",
        "    def scale_action(self, action):\n",
        "        \"\"\"\n",
        "        Scale action from [0,1] range to [self.a_min, self.a_max] range.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        action : numpy.ndarray\n",
        "            Action values in range [0,1]\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        numpy.ndarray\n",
        "            Scaled action in range [self.a_min, self.a_max]\n",
        "        \"\"\"\n",
        "        return self.a_min + action * (self.a_max - self.a_min)\n",
        "\n",
        "    def get_variable_value(self, var_name):\n",
        "        \"\"\"\n",
        "        Get the current value of a single optimization variable from the network.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        network : pypsa.Network\n",
        "            The PyPSA network object\n",
        "        var_name : str\n",
        "            Variable name like 'Generator-p[snapshot=now,Generator=coal_gen_1]'\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        float : current value of the variable\n",
        "        \"\"\"\n",
        "        # Parse the variable name\n",
        "        # Format: ComponentName-attribute[dimension1=value1,dimension2=value2,...]\n",
        "\n",
        "        # Split on first '[' to separate base name from coordinates\n",
        "        if '[' in var_name:\n",
        "            base_name, coords_str = var_name.split('[', 1)\n",
        "            coords_str = coords_str.rstrip(']')  # Remove trailing ']'\n",
        "        else:\n",
        "            base_name = var_name\n",
        "            coords_str = \"\"\n",
        "\n",
        "        # Parse base name: ComponentName-attribute\n",
        "        component_name, attribute = base_name.split('-', 1)\n",
        "\n",
        "        # Parse coordinates if they exist\n",
        "        coords = {}\n",
        "        if coords_str:\n",
        "            # Split by comma and parse key=value pairs\n",
        "            for coord_pair in coords_str.split(','):\n",
        "                key, value = coord_pair.split('=', 1)\n",
        "                coords[key.strip()] = value.strip()\n",
        "\n",
        "        # Determine if this has time dimension (snapshot)\n",
        "        has_snapshot = 'snapshot' in coords\n",
        "\n",
        "        if has_snapshot:\n",
        "            # Access dynamic dataframe using n.dynamic()\n",
        "            snapshot_value = coords['snapshot']\n",
        "            component_instance = coords[component_name]\n",
        "\n",
        "            # Special handling for branch flow variables\n",
        "            if component_name in self.network.passive_branch_components and attribute == 's':\n",
        "                # For branch components, 's' is stored as 'p0' in the network\n",
        "                # We can use p0 directly as the value of 's'\n",
        "                try:\n",
        "                    return self.network.dynamic(component_name)['p0'].loc[snapshot_value, component_instance]\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Could not get flow value for {var_name}: {e}\")\n",
        "                    return 0.0\n",
        "\n",
        "            # Get dynamic data for normal case\n",
        "            dynamic_data = self.network.dynamic(component_name)\n",
        "\n",
        "            # Access the specific attribute DataFrame\n",
        "            if attribute in dynamic_data:\n",
        "                return dynamic_data[attribute].loc[snapshot_value, component_instance]\n",
        "            else:\n",
        "                raise KeyError(f\"Attribute {attribute} not found in dynamic data for {component_name}\")\n",
        "\n",
        "        else:\n",
        "            # Access static dataframe using n.static()\n",
        "            component_instance = coords[component_name]\n",
        "\n",
        "            # Get static data\n",
        "            static_data = self.network.static(component_name)\n",
        "\n",
        "            # Access the value\n",
        "            return static_data.loc[component_instance, attribute]\n",
        "\n",
        "\n",
        "    def create_variable_values_mapping(self,variable_names):\n",
        "        \"\"\"\n",
        "        Create a mapping from optimization variable names to their current values in the network.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        network : pypsa.Network\n",
        "            The PyPSA network object\n",
        "        variable_names : list\n",
        "            List of variable names like ['Generator-p[snapshot=now,Generator=coal_gen_1]', ...]\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        dict : mapping from variable name to current value\n",
        "        \"\"\"\n",
        "        var_values = {}\n",
        "\n",
        "        for var_name in variable_names:\n",
        "            try:\n",
        "                value = self.get_variable_value(var_name)\n",
        "                var_values[var_name] = value\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not get value for {var_name}: {e}\")\n",
        "                var_values[var_name] = 0.0  # Default fallback\n",
        "\n",
        "        return var_values\n",
        "\n",
        "    def _evaluate_stored_objective(self):\n",
        "        \"\"\"\n",
        "        Direct evaluation without mock objects.\n",
        "        Only includes terms from the current snapshot in the objective function.\n",
        "        \"\"\"\n",
        "        # Get variable name mapping for current network\n",
        "        id_to_name = self.var_id_to_name\n",
        "\n",
        "        # Get the current snapshot name\n",
        "        current_snapshot = self.network.snapshots[self.snapshot_idx]\n",
        "\n",
        "        # Get current variable values\n",
        "        variable_names = []\n",
        "        var_indices = []\n",
        "        vars_flat = self.objective_vars.values.flatten()\n",
        "        coeffs_flat = self.objective_coeffs.values.flatten()\n",
        "\n",
        "        # Filter variables to only include those from the current snapshot\n",
        "        for i, var_id in enumerate(vars_flat):\n",
        "            if var_id != -1 and var_id in id_to_name:\n",
        "                var_name = id_to_name[var_id]\n",
        "                # Check if this variable belongs to the current snapshot\n",
        "                if 'snapshot=' in var_name:\n",
        "                    # Extract the snapshot value from the variable name\n",
        "                    snapshot_part = var_name.split('snapshot=')[1].split(',')[0].split(']')[0]\n",
        "                    if snapshot_part == str(current_snapshot):\n",
        "                        variable_names.append(var_name)\n",
        "                        var_indices.append(i)\n",
        "                else:\n",
        "                    # Include variables without snapshot dimension (like investment variables)\n",
        "                    variable_names.append(var_name)\n",
        "                    var_indices.append(i)\n",
        "\n",
        "        var_values = self.create_variable_values_mapping(variable_names)\n",
        "\n",
        "        # Direct mathematical evaluation using only variables from current snapshot\n",
        "        if var_indices:\n",
        "            result = np.sum(coeffs_flat[var_indices] *\n",
        "                        [var_values.get(name, 0) for name in variable_names]) + \\\n",
        "                    self.objective_const\n",
        "        else:\n",
        "            # If no variables for this snapshot, just return the constant\n",
        "            result = self.objective_const\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _evaluate_constraint(self, constraint_key):\n",
        "        \"\"\"\n",
        "        Evaluate a single constraint using current network values.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        constraint_key : str\n",
        "            Key of the specific constraint to evaluate\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        tuple: (bool, float)\n",
        "            Boolean indicating if constraint is satisfied, and violation amount (0 if satisfied)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if constraint_key not in self.constraints:\n",
        "                return True, 0\n",
        "\n",
        "            constraint = self.constraints[constraint_key]\n",
        "            lhs = constraint['lhs']\n",
        "            rhs = constraint['rhs']\n",
        "            sign = constraint['sign']\n",
        "        except Exception as e:\n",
        "            print(f\"Error accessing constraint {constraint_key}: {e}\")\n",
        "            return True, 0  # Default to no violation on error\n",
        "\n",
        "        # Get variable name mapping for current network\n",
        "        id_to_name = self.var_id_to_name\n",
        "\n",
        "        # Evaluate LHS if it's a linear expression\n",
        "        lhs_value = 0\n",
        "        if hasattr(lhs, 'vars') and hasattr(lhs, 'coeffs'):\n",
        "            # Get current variable values\n",
        "            variable_names = []\n",
        "            vars_flat = lhs.vars.flatten()  # Flatten to handle any dimensionality\n",
        "            coeffs_flat = lhs.coeffs.flatten()  # Flatten coefficients as well\n",
        "\n",
        "            # Create a mask for valid variable indices (not -1)\n",
        "            valid_indices = vars_flat != -1\n",
        "\n",
        "            # Filter out -1 indices\n",
        "            valid_vars = vars_flat[valid_indices]\n",
        "            valid_coeffs = coeffs_flat[valid_indices]\n",
        "\n",
        "            # Get variable names only for valid indices\n",
        "            for var_id in valid_vars:\n",
        "                if var_id in id_to_name:\n",
        "                    variable_names.append(id_to_name[var_id])\n",
        "\n",
        "            # Get variable values\n",
        "            var_values = self.create_variable_values_mapping(variable_names)\n",
        "\n",
        "            # Direct mathematical evaluation using only valid variables and coefficients\n",
        "            try:\n",
        "                # Convert variable values to numpy array\n",
        "                var_values_array = np.array([var_values.get(name, 0) for name in variable_names])\n",
        "\n",
        "                # Calculate LHS value using only valid variables and coefficients\n",
        "                lhs_value = np.sum(valid_coeffs * var_values_array)\n",
        "\n",
        "                # Add constant if it exists\n",
        "                if hasattr(lhs, 'const'):\n",
        "                    lhs_value += lhs.const.item() if hasattr(lhs.const, 'item') else lhs.const\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in constraint evaluation for {constraint_key}: {e}\")\n",
        "                return True, 0  # Skip this constraint on error\n",
        "        else:\n",
        "            # If it's a constant or simple value\n",
        "            lhs_value = lhs\n",
        "\n",
        "        # Get RHS value (will be a constant)\n",
        "        rhs_value = rhs\n",
        "\n",
        "        # Check constraint satisfaction based on sign\n",
        "        try:\n",
        "            # Handle both scalar and array values\n",
        "            if sign == '==':\n",
        "                if isinstance(lhs_value, (np.ndarray, list)) or isinstance(rhs_value, (np.ndarray, list)):\n",
        "                    # Convert to numpy arrays if needed\n",
        "                    lhs_array = np.asarray(lhs_value)\n",
        "                    rhs_array = np.asarray(rhs_value)\n",
        "\n",
        "                    # Handle shape mismatches\n",
        "                    if lhs_array.shape != rhs_array.shape:\n",
        "                        if np.isscalar(lhs_array) or len(lhs_array.shape) == 0:\n",
        "                            lhs_array = np.full_like(rhs_array, lhs_array)\n",
        "                        elif np.isscalar(rhs_array) or len(rhs_array.shape) == 0:\n",
        "                            rhs_array = np.full_like(lhs_array, rhs_array)\n",
        "                        else:\n",
        "                            # If shapes still don't match, return no violation\n",
        "                            print(f\"Shape mismatch in constraint {constraint_key}: {lhs_array.shape} vs {rhs_array.shape}\")\n",
        "                            return True, 0\n",
        "\n",
        "                    satisfied = np.all(np.isclose(lhs_array, rhs_array))\n",
        "                    violation = float(np.sum(np.abs(lhs_array - rhs_array)))\n",
        "                else:\n",
        "                    satisfied = np.isclose(lhs_value, rhs_value)\n",
        "                    violation = float(abs(lhs_value - rhs_value))\n",
        "            elif sign == '<=':\n",
        "                if isinstance(lhs_value, (np.ndarray, list)) or isinstance(rhs_value, (np.ndarray, list)):\n",
        "                    # Convert to numpy arrays if needed\n",
        "                    lhs_array = np.asarray(lhs_value)\n",
        "                    rhs_array = np.asarray(rhs_value)\n",
        "\n",
        "                    # Handle shape mismatches\n",
        "                    if lhs_array.shape != rhs_array.shape:\n",
        "                        if np.isscalar(lhs_array) or len(lhs_array.shape) == 0:\n",
        "                            lhs_array = np.full_like(rhs_array, lhs_array)\n",
        "                        elif np.isscalar(rhs_array) or len(rhs_array.shape) == 0:\n",
        "                            rhs_array = np.full_like(lhs_array, rhs_array)\n",
        "                        else:\n",
        "                            # If shapes still don't match, return no violation\n",
        "                            print(f\"Shape mismatch in constraint {constraint_key}: {lhs_array.shape} vs {rhs_array.shape}\")\n",
        "                            return True, 0\n",
        "\n",
        "                    satisfied = np.all(lhs_array <= rhs_array)\n",
        "                    violation = float(np.sum(np.maximum(0, lhs_array - rhs_array)))\n",
        "                else:\n",
        "                    satisfied = lhs_value <= rhs_value\n",
        "                    violation = float(max(0, lhs_value - rhs_value))\n",
        "            elif sign == '>=':\n",
        "                if isinstance(lhs_value, (np.ndarray, list)) or isinstance(rhs_value, (np.ndarray, list)):\n",
        "                    # Convert to numpy arrays if needed\n",
        "                    lhs_array = np.asarray(lhs_value)\n",
        "                    rhs_array = np.asarray(rhs_value)\n",
        "\n",
        "                    # Handle shape mismatches - don't think I need this\n",
        "                    if lhs_array.shape != rhs_array.shape:\n",
        "                        if np.isscalar(lhs_array) or len(lhs_array.shape) == 0:\n",
        "                            lhs_array = np.full_like(rhs_array, lhs_array)\n",
        "                        elif np.isscalar(rhs_array) or len(rhs_array.shape) == 0:\n",
        "                            rhs_array = np.full_like(lhs_array, rhs_array)\n",
        "                        else:\n",
        "                            # If shapes still don't match, return no violation\n",
        "                            print(f\"Shape mismatch in constraint {constraint_key}: {lhs_array.shape} vs {rhs_array.shape}\")\n",
        "                            return True, 0\n",
        "\n",
        "                    satisfied = np.all(lhs_array >= rhs_array)\n",
        "                    violation = float(np.sum(np.maximum(0, rhs_array - lhs_array)))\n",
        "                else:\n",
        "                    satisfied = lhs_value >= rhs_value\n",
        "                    violation = float(max(0, rhs_value - lhs_value))\n",
        "            else:\n",
        "                # Unknown sign\n",
        "                satisfied = True\n",
        "                violation = 0\n",
        "\n",
        "            # Ensure violation is a scalar\n",
        "            if hasattr(violation, '__len__'):\n",
        "                violation = float(np.sum(violation))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error comparing constraint values for {constraint_key}: {e}\")\n",
        "            print(f\"LHS type: {type(lhs_value)}, RHS type: {type(rhs_value)}\")\n",
        "            print(f\"LHS: {lhs_value}, RHS: {rhs_value}\")\n",
        "            satisfied = True\n",
        "            violation = 0\n",
        "\n",
        "        return satisfied, violation\n",
        "\n",
        "    def _evaluate_all_constraints(self):\n",
        "        \"\"\"\n",
        "        Evaluate constraints relevant to the current snapshot.\n",
        "        Only includes constraints that:\n",
        "        1. Are for the current snapshot only, or\n",
        "        2. Link the current snapshot with previous snapshots (but not future snapshots)\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        dict: Information about constraint violations\n",
        "        \"\"\"\n",
        "        results = {\n",
        "            'all_satisfied': True,\n",
        "            'violations': {},\n",
        "            'total_violation': 0.0,\n",
        "            'violations_by_group': {}  # Track violations by constraint group\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Get the current snapshot name\n",
        "            current_snapshot = self.network.snapshots[self.snapshot_idx]\n",
        "\n",
        "            # Evaluate each individual constraint that's relevant to the current snapshot\n",
        "            for constraint_key in self.constraints:\n",
        "                try:\n",
        "                    # Check if this constraint is relevant to the current snapshot\n",
        "                    is_relevant = False\n",
        "\n",
        "                    # If constraint has no snapshot specification, include it\n",
        "                    if 'snapshot=' not in constraint_key:\n",
        "                        is_relevant = True\n",
        "                    else:\n",
        "                        # Extract all snapshots mentioned in this constraint\n",
        "                        constraint_snapshots = []\n",
        "                        parts = constraint_key.split('snapshot=')\n",
        "                        for i in range(1, len(parts)):\n",
        "                            snapshot_val = parts[i].split(',')[0].split(']')[0]\n",
        "                            constraint_snapshots.append(snapshot_val)\n",
        "\n",
        "                        # Include if current snapshot is mentioned\n",
        "                        if str(current_snapshot) in constraint_snapshots:\n",
        "                            # Check if any future snapshots are mentioned\n",
        "                            has_future_snapshots = False\n",
        "                            for snap in constraint_snapshots:\n",
        "                                try:\n",
        "                                    # Find the index of this snapshot in the network's snapshots\n",
        "                                    snap_idx = list(self.network.snapshots).index(snap)\n",
        "                                    if snap_idx > self.snapshot_idx:\n",
        "                                        has_future_snapshots = True\n",
        "                                        break\n",
        "                                except (ValueError, TypeError):\n",
        "                                    # If snapshot can't be found or compared, skip this check\n",
        "                                    pass\n",
        "\n",
        "                            # Include if no future snapshots are mentioned\n",
        "                            if not has_future_snapshots:\n",
        "                                is_relevant = True\n",
        "\n",
        "                    # Only evaluate if the constraint is relevant\n",
        "                    if is_relevant:\n",
        "                        satisfied, violation = self._evaluate_constraint(constraint_key)\n",
        "                        if not satisfied:\n",
        "                            results['all_satisfied'] = False\n",
        "                            results['violations'][constraint_key] = float(violation)  # Ensure it's a scalar\n",
        "                            results['total_violation'] += float(violation)\n",
        "\n",
        "                            # Also track violations by constraint group (original name without coordinates)\n",
        "                            if '[' in constraint_key:\n",
        "                                group_name = constraint_key.split('[')[0]\n",
        "                                if group_name not in results['violations_by_group']:\n",
        "                                    results['violations_by_group'][group_name] = 0.0\n",
        "                                results['violations_by_group'][group_name] += float(violation)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error evaluating constraint {constraint_key}: {e}\")\n",
        "                    # Continue with other constraints\n",
        "        except Exception as e:\n",
        "            print(f\"Error in constraint evaluation: {e}\")\n",
        "            # Return default results\n",
        "\n",
        "        return results\n",
        "\n",
        "    def calculate_constrained_reward(self):\n",
        "        \"\"\"\n",
        "        Calculate reward with constraint violation penalties.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        float: Reward value with constraint penalties\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Get base reward from objective function\n",
        "            base_reward = self._calculate_reward()\n",
        "\n",
        "            # Evaluate constraints\n",
        "            constraint_results = self._evaluate_all_constraints()\n",
        "\n",
        "            # Apply penalty for constraint violations\n",
        "            # Using a high penalty factor to make violations very noticeable\n",
        "            # Increased from 100.0 to make violations more obvious\n",
        "\n",
        "            # Ensure total_violation is a scalar\n",
        "            total_violation = float(constraint_results['total_violation'])\n",
        "            penalty = self.penalty_factor * total_violation\n",
        "\n",
        "            # Final reward is base reward minus penalties\n",
        "            constrained_reward = base_reward - penalty\n",
        "\n",
        "            # Ensure reward is a scalar\n",
        "            if hasattr(constrained_reward, '__len__'):\n",
        "                constrained_reward = float(constrained_reward)\n",
        "\n",
        "            return constrained_reward, constraint_results\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating constrained reward: {e}\")\n",
        "            # Fall back to unconstrained reward\n",
        "            return self._calculate_reward()\n",
        "\n",
        "    def _calculate_reward(self):\n",
        "        \"\"\"Calculate reward using stored objective components.\"\"\"\n",
        "        # Create a minimal mock expression or use your evaluation directly\n",
        "        return -1 * self._evaluate_stored_objective()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Execute one time step within the environment.\n",
        "\n",
        "        Args:\n",
        "            action: Array of generator setpoints [gen1_setpoint, gen2_setpoint, ...]\n",
        "\n",
        "        Returns:\n",
        "            observation: Network state after action\n",
        "            reward: Reward for this action\n",
        "            terminated: Whether episode is finished due to task completion\n",
        "            truncated: Whether episode is finished due to time limit\n",
        "            info: Additional information\n",
        "        \"\"\"\n",
        "        scaled_action = self.scale_action(action)\n",
        "\n",
        "        # Update generator setpoints for non-slack generators only\n",
        "        for i, gen_name in enumerate(self.non_slack_names):\n",
        "            self.network.generators_t.p_set.iloc[self.snapshot_idx,\n",
        "                self.network.generators_t.p_set.columns.get_loc(gen_name)] = scaled_action[i]\n",
        "        # Run power flow to get new network state\n",
        "        try:\n",
        "            # You can choose linear or non-linear power flow\n",
        "            self.network.lpf()  # Linear power flow\n",
        "            # print(self.network.generators_t.p.loc['now'])  # Commented out to reduce output\n",
        "            # self.network.pf()  # Non-linear power flow (alternative)\n",
        "\n",
        "            power_flow_converged = True\n",
        "        except Exception as e:\n",
        "            print(f\"Power flow failed: {e}\")\n",
        "            power_flow_converged = False\n",
        "\n",
        "        # Calculate reward using constrained reward function\n",
        "        reward, constraint_results = self.calculate_constrained_reward()\n",
        "        #reward=self._calculate_reward()\n",
        "\n",
        "        # Increment step counters\n",
        "        self.current_step += 1\n",
        "        self.snapshot_idx += 1\n",
        "\n",
        "        # Handle cycling through snapshots\n",
        "        if self.snapshot_idx >= self.total_snapshots:\n",
        "            self.snapshot_idx = 0  # Reset to beginning\n",
        "            self.reset_network()\n",
        "            #self._test_hidden_references()\n",
        "            #can run that instead to check if there are hidden references preventing network cleanup\n",
        "\n",
        "\n",
        "        # Get new observation\n",
        "        observation = self._get_observation()\n",
        "\n",
        "        # Check if episode is done\n",
        "        episode_done = self._check_done()\n",
        "\n",
        "        # In gymnasium, we need to separate terminated vs truncated\n",
        "        terminated = False  # Task completion (not applicable here)\n",
        "        truncated = episode_done  # Time limit reached\n",
        "\n",
        "        # Additional info\n",
        "        info = {\n",
        "            'generator_setpoints': scaled_action,\n",
        "            'power_flow_converged': power_flow_converged,\n",
        "            'generator_names': self.non_slack_names,\n",
        "            'current_step': self.current_step,\n",
        "            'snapshot_idx': self.snapshot_idx,\n",
        "            'constraints_satisfied': constraint_results['all_satisfied'],\n",
        "            'constraint_violations': constraint_results['violations'],\n",
        "            'total_violation': constraint_results['total_violation']\n",
        "        }\n",
        "\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "\n",
        "    def _check_done(self):\n",
        "        \"\"\"\n",
        "        Check if episode should terminate.\n",
        "\n",
        "        Episode terminates when we've reached the specified episode length.\n",
        "        \"\"\"\n",
        "        if self.current_step >= self.episode_length:\n",
        "            return True\n",
        "\n",
        "        # TO DO: add other cases might want to terminate\n",
        "        # You might want to terminate on:\n",
        "        # - Power flow convergence failure\n",
        "        # - Voltage limit violations\n",
        "        # - Line overloads\n",
        "\n",
        "        return False\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        \"\"\"\n",
        "        Set the random seed for reproducible experiments.\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_constraint_info(self):\n",
        "        \"\"\"\n",
        "        Get detailed information about the constraints in the model.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        dict: Detailed information about constraints and their current status\n",
        "        \"\"\"\n",
        "        # Evaluate all constraints\n",
        "        all_results = self._evaluate_all_constraints()\n",
        "\n",
        "        # Organize constraint information by groups and individual constraints\n",
        "        constraint_info = {\n",
        "            'all_satisfied': all_results['all_satisfied'],\n",
        "            'total_violation': all_results['total_violation'],\n",
        "            'groups': {},\n",
        "            'individual': {}\n",
        "        }\n",
        "\n",
        "        # Group constraints by their base name\n",
        "        for constraint_key in self.constraints:\n",
        "            # Evaluate this specific constraint\n",
        "            satisfied, violation = self._evaluate_constraint(constraint_key)\n",
        "\n",
        "            # Store individual constraint info\n",
        "            constraint_info['individual'][constraint_key] = {\n",
        "                'satisfied': satisfied,\n",
        "                'violation': violation,\n",
        "                'sign': self.constraints[constraint_key]['sign']\n",
        "            }\n",
        "\n",
        "            # Also group by constraint type\n",
        "            if '[' in constraint_key:\n",
        "                group_name = constraint_key.split('[')[0]\n",
        "                if group_name not in constraint_info['groups']:\n",
        "                    constraint_info['groups'][group_name] = {\n",
        "                        'count': 0,\n",
        "                        'satisfied_count': 0,\n",
        "                        'violated_count': 0,\n",
        "                        'total_violation': 0.0,\n",
        "                        'max_violation': 0.0,\n",
        "                        'sign': self.constraints[constraint_key]['sign']\n",
        "                    }\n",
        "\n",
        "                group_info = constraint_info['groups'][group_name]\n",
        "                group_info['count'] += 1\n",
        "\n",
        "                if satisfied:\n",
        "                    group_info['satisfied_count'] += 1\n",
        "                else:\n",
        "                    group_info['violated_count'] += 1\n",
        "                    group_info['total_violation'] += violation\n",
        "                    group_info['max_violation'] = max(group_info['max_violation'], violation)\n",
        "            else:\n",
        "                # Handle standalone constraints\n",
        "                if 'standalone' not in constraint_info['groups']:\n",
        "                    constraint_info['groups']['standalone'] = {\n",
        "                        'count': 0,\n",
        "                        'satisfied_count': 0,\n",
        "                        'violated_count': 0,\n",
        "                        'total_violation': 0.0,\n",
        "                        'max_violation': 0.0\n",
        "                    }\n",
        "\n",
        "                group_info = constraint_info['groups']['standalone']\n",
        "                group_info['count'] += 1\n",
        "\n",
        "                if satisfied:\n",
        "                    group_info['satisfied_count'] += 1\n",
        "                else:\n",
        "                    group_info['violated_count'] += 1\n",
        "                    group_info['total_violation'] += violation\n",
        "                    group_info['max_violation'] = max(group_info['max_violation'], violation)\n",
        "\n",
        "        return constraint_info\n",
        "\n",
        "    def render(self, mode='human', info=None):\n",
        "        \"\"\"\n",
        "        Render the environment state.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        mode : str\n",
        "            Rendering mode (only 'human' supported)\n",
        "        info : dict, optional\n",
        "            Information dictionary from step() method containing constraint data\n",
        "        \"\"\"\n",
        "        print(\"=== Current Network State ===\")\n",
        "        print(f\"Episode step: {self.current_step}/{self.episode_length}\")\n",
        "        print(f\"Snapshot index: {self.snapshot_idx}/{self.total_snapshots}\")\n",
        "        print(f\"Current snapshot: {self.network.snapshots[self.snapshot_idx]}\")\n",
        "        print(f\"Generator setpoints: {self.network.generators_t.p_set.iloc[self.snapshot_idx].values}\")\n",
        "        print(f\"Load values: {self.network.loads_t.p_set.iloc[self.snapshot_idx].values}\")\n",
        "\n",
        "        all_satisfied = info['constraints_satisfied']\n",
        "        total_violation = info['total_violation']\n",
        "        violations = info['constraint_violations']\n",
        "\n",
        "\n",
        "        print(f\"All constraints satisfied: {all_satisfied}\")\n",
        "        print(f\"Total constraint violation: {total_violation:.4f}\")\n",
        "\n",
        "        # Show violated constraints if any\n",
        "        if not all_satisfied and violations:\n",
        "            print(\"\\n=== Constraint Violations ===\")\n",
        "            for constraint_name, violation in violations.items():\n",
        "                print(f\"  {constraint_name}: {violation:.4f}\")\n",
        "\n",
        "Env2Gen1LoadConstr(network_file=\"/Users/antoniagrindrod/Documents/pypsa-earth_project/pypsa-earth-RL/networks/elec_s_5_ec_lcopt_3h.nc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d07d586e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "__main__.Env2Gen1LoadConstr"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Env2Gen1LoadConstr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c06b56",
      "metadata": {
        "id": "f9c06b56"
      },
      "outputs": [],
      "source": [
        "class BackboneNetwork(nn.Module):\n",
        "    def __init__(self, input_features, hidden_dimensions, out_features, dropout):\n",
        "        super(BackboneNetwork, self).__init__()\n",
        "\n",
        "        # SIMPLIFIED: Single hidden layer network for debugging\n",
        "        self.neuralnet = nn.Sequential(\n",
        "            nn.Linear(input_features, hidden_dimensions),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dimensions, hidden_dimensions),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dimensions, out_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.neuralnet(x)\n",
        "        return output\n",
        "\n",
        "#Define the actor-critic network\n",
        "class actorCritic(nn.Module):\n",
        "    def __init__(self, actor, critic):\n",
        "        super().__init__()\n",
        "        self.actor = actor\n",
        "        self.critic = critic\n",
        "    def forward(self, state):\n",
        "        action_pred = self.actor(state)\n",
        "        value_pred = self.critic(state)\n",
        "        return action_pred, value_pred\n",
        "        #Returns both the action predictions and the value predictions.\n",
        "\n",
        "#We'll use the networks defined above to create an actor and a critic. Then, we will create an agent, including the actor and the critic.\n",
        "#finish this step later\n",
        "# def create_agent(hidden_dimensions, dropout):\n",
        "#     INPUT_FEATURES =env_train.\n",
        "class PPO_agent:\n",
        "    def __init__(self,\n",
        "                 env,\n",
        "                 device,\n",
        "                 run,\n",
        "                 hidden_dimensions,\n",
        "                 dropout, discount_factor,\n",
        "                 max_episodes,\n",
        "                 print_interval,\n",
        "                 PPO_steps,\n",
        "                 n_trials,\n",
        "                 epsilon,\n",
        "                 entropy_coefficient,\n",
        "                 learning_rate,\n",
        "                 batch_size,\n",
        "                 optimizer_name,\n",
        "                 seed):\n",
        "\n",
        "        self.seed = seed\n",
        "        if seed is not None:\n",
        "            # Set PyTorch seed for this class\n",
        "            torch.manual_seed(seed)\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.manual_seed(seed)\n",
        "\n",
        "        self.env = env  # Store the environment as an attribute\n",
        "\n",
        "        self.device = device\n",
        "        self.run = run\n",
        "\n",
        "        # Get observation and action space dimensions for gymnasium environment\n",
        "        obs, _ = self.env.reset()\n",
        "\n",
        "        self.INPUT_FEATURES = obs.shape[0]  # Flattened observation size\n",
        "        self.ACTOR_OUTPUT_FEATURES = self.env.action_space.shape[0]* 2  # 2 parameters (alpha, beta) per action dimension\n",
        "\n",
        "        self.HIDDEN_DIMENSIONS = hidden_dimensions\n",
        "\n",
        "        self.CRITIC_OUTPUT_FEATURES = 1\n",
        "        self.DROPOUT = dropout\n",
        "\n",
        "        self.discount_factor = discount_factor\n",
        "        self.max_episodes = max_episodes\n",
        "        self.print_interval = print_interval\n",
        "        self.PPO_steps=PPO_steps\n",
        "        self.n_trials=n_trials\n",
        "        self.epsilon=epsilon\n",
        "        self.entropy_coefficient=entropy_coefficient\n",
        "        self.learning_rate=learning_rate\n",
        "\n",
        "        self.batch_size=batch_size\n",
        "\n",
        "        # Initialize actor network\n",
        "        self.actor = BackboneNetwork(\n",
        "            self.INPUT_FEATURES, self.HIDDEN_DIMENSIONS, self.ACTOR_OUTPUT_FEATURES, self.DROPOUT\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Initialize the final layer bias for Beta distribution\n",
        "        for name, param in self.actor.named_parameters():\n",
        "            if 'neuralnet.4.bias' in name:  # Adjust index based on your network structure\n",
        "                # Initialize to produce alpha=beta=2 (uniform-like distribution centered at 0.5)\n",
        "                param.data.fill_(0.0)  # softplus(0) + 1 = 2\n",
        "                print(f\"Initialized Beta parameters to produce uniform-like distribution\")\n",
        "\n",
        "        # Initialize critic network\n",
        "        self.critic = BackboneNetwork(\n",
        "            self.INPUT_FEATURES, self.HIDDEN_DIMENSIONS, self.CRITIC_OUTPUT_FEATURES, self.DROPOUT\n",
        "        ).to(self.device)\n",
        "\n",
        "        #Better move the .to(self.device) call separately for both self.actor and self.critic. This ensures the individual parts of the model are moved to the correct device before combined into the actorCritic class\n",
        "        # Combine into a single actor-critic model\n",
        "        self.model = actorCritic(self.actor, self.critic)\n",
        "\n",
        "        try:\n",
        "            # Try to get the optimizer from torch.optim based on the provided name\n",
        "            self.optimizer = getattr(torch.optim, optimizer_name)(self.model.parameters(), lr=self.learning_rate)\n",
        "        except AttributeError:\n",
        "            # Raise an error if the optimizer_name is not valid\n",
        "            raise ValueError(f\"Optimizer '{optimizer_name}' is not available in torch.optim.\")\n",
        "\n",
        "    def calculate_returns(self, rewards):\n",
        "        returns = []\n",
        "        cumulative_reward = 0\n",
        "        for r in reversed(rewards):\n",
        "            cumulative_reward = r +cumulative_reward*self.discount_factor\n",
        "            returns.insert(0, cumulative_reward)\n",
        "        returns = torch.tensor(returns).to(self.device)\n",
        "\n",
        "        # Only normalize if we have more than one element to avoid std() warning\n",
        "        if returns.numel() > 1:\n",
        "            epsilon = 1e-8  # Small constant to avoid division by zero\n",
        "            returns_std = returns.std()\n",
        "            if not torch.isnan(returns_std) and returns_std >= epsilon:\n",
        "                returns = (returns - returns.mean()) / (returns_std + epsilon)\n",
        "\n",
        "        #I had conceptual trouble with normalizing the reward by an average, because it seemed to me since we're adding more rewards for earlier timesteps, the cumulative reward for earlier times would be a lot larger. But need to consider dicount facotr.\n",
        "        # Future rewards contribute significantly to the cumulative return, so earlier timesteps will likely have larger returns.\n",
        "        #if gamma is close to 0, future rewards have little influence, and the return at each timestep will closely resemble the immediate reward, meaning the pattern might not be as clear.\n",
        "        return returns\n",
        "\n",
        "    #The advantage is calculated as the difference between the value predicted by the critic and the expected return from the actions chosen by the actor according to the policy.\n",
        "    def calculate_advantages(self, returns, values):\n",
        "        advantages = returns - values\n",
        "\n",
        "        # Only normalize if we have more than one element to avoid std() warning\n",
        "        if advantages.numel() > 1:\n",
        "            epsilon = 1e-8\n",
        "            advantages_std = advantages.std()\n",
        "            if not torch.isnan(advantages_std) and advantages_std >= epsilon:\n",
        "                advantages = (advantages - advantages.mean()) / (advantages_std + epsilon)\n",
        "\n",
        "        return advantages\n",
        "\n",
        "    #The standard policy gradient loss is calculated as the product of the policy action probabilities and the advantage function\n",
        "    #The standard policy gradietn loss cannot make corrections for abrupt policy changes. The surrogate loss modifies the standard loss to restrict the amount the policy can change in each iteration.\n",
        "    #The surrogate loss is the minimum of (policy ratio X advantage function) and (clipped value of policy ratio X advantage function) where the policy ratio is between the action probabilities according to the old versus new policies and clipping restricts the value to a region near 1.\n",
        "\n",
        "    def calculate_surrogate_loss(self, actions_log_probability_old, actions_log_probability_new, advantages):\n",
        "        advantages = advantages.detach()\n",
        "        # creates a new tensor that shares the same underlying data as the original tensor but breaks the computation graph. This means:\n",
        "        # The new tensor is treated as a constant with no gradients.\n",
        "        # Any operations involving this tensor do not affect the gradients of earlier computations in the graph.\n",
        "\n",
        "        #If the advantages are not detached, the backpropagation of the loss computed using the surrogate_loss would affect both the actor and the critic networks\n",
        "        # The surrogate loss is meant to update only the policy (actor).\n",
        "        # Allowing gradients to flow back through the advantages would inadvertently update the critic, potentially disrupting its learning process.\n",
        "\n",
        "        policy_ratio  = (actions_log_probability_new - actions_log_probability_old).exp()\n",
        "        surrogate_loss_1 = policy_ratio*advantages\n",
        "        surrogate_loss_2 = torch.clamp(policy_ratio, min =1.0-self.epsilon, max = 1.0+self.epsilon)*advantages\n",
        "        surrogate_loss=torch.min(surrogate_loss_1, surrogate_loss_2)\n",
        "        return surrogate_loss\n",
        "\n",
        "    #TRAINING THE AGENT\n",
        "    #Policy loss is the sum of the surrogate loss and the entropy bonus. It is used to update the actor (policy network)\n",
        "    #Value loss is based on the difference between the value predicted by the critic and the returns (cumulative reward) generated by the policy. This loss is used to update the critic (value network) to make predictions more accurate.\n",
        "\n",
        "    def calculate_losses(self, surrogate_loss, entropy, returns, value_pred):\n",
        "        entropy_bonus = self.entropy_coefficient*entropy\n",
        "        policy_loss = -(surrogate_loss+entropy_bonus).sum()\n",
        "        value_loss = torch.nn.functional.smooth_l1_loss(returns, value_pred).sum() #helps to smoothen the loss function and makes it less sensitive to outliers.\n",
        "        return policy_loss, value_loss\n",
        "\n",
        "    def init_training(self):\n",
        "        #create a set of buffers as empty arrays. To be used during training to store information\n",
        "        states = []\n",
        "        actions = []\n",
        "        actions_log_probability = []\n",
        "        values = []\n",
        "        rewards = []\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "        return states, actions, actions_log_probability, values, rewards, done, episode_reward\n",
        "\n",
        "    def forward_pass(self):#this is just the training function (might just want to rename it)\n",
        "        # # === DETAILED OBJECT ANALYSIS ===\n",
        "        # import psutil\n",
        "        # import gc\n",
        "\n",
        "        # if not hasattr(self, '_episode_counter'):\n",
        "        #     self._episode_counter = 0\n",
        "        # self._episode_counter += 1\n",
        "\n",
        "        # mem_mb = psutil.Process().memory_info().rss / 1024 / 1024\n",
        "\n",
        "        # # Get ALL objects with \"Network\" in their type name\n",
        "        # network_objects = [obj for obj in gc.get_objects() if 'network' in str(type(obj)).lower()]\n",
        "\n",
        "        # print(f\"\\n=== EPISODE {self._episode_counter} OBJECT ANALYSIS ===\")\n",
        "        # print(f\"Memory: {mem_mb:.1f}MB\")\n",
        "        # print(f\"Total objects with 'network' in type: {len(network_objects)}\")\n",
        "\n",
        "        # # Count by exact type\n",
        "        # type_counts = {}\n",
        "        # for obj in network_objects:\n",
        "        #     obj_type = str(type(obj))\n",
        "        #     type_counts[obj_type] = type_counts.get(obj_type, 0) + 1\n",
        "\n",
        "        # # Print breakdown\n",
        "        # for obj_type, count in type_counts.items():\n",
        "        #     print(f\"  {obj_type}: {count}\")\n",
        "\n",
        "        # # Show actual PyPSA Network objects specifically\n",
        "        # actual_networks = [obj for obj in gc.get_objects() if type(obj).__name__ == 'Network' and 'pypsa' in str(type(obj))]\n",
        "        # print(f\"Actual PyPSA Network objects: {len(actual_networks)}\")\n",
        "\n",
        "        # if len(actual_networks) <= 5:  # Only print if reasonable number\n",
        "        #     for i, net in enumerate(actual_networks):\n",
        "        #         print(f\"  Network {i+1}: {id(net)} - {type(net)}\")\n",
        "\n",
        "        # network_id = id(self.env.network) if hasattr(self.env, 'network') else None\n",
        "        # print(f\"Current env.network ID: {network_id}\")\n",
        "        # print(\"=\" * 50)\n",
        "        # # === END ANALYSIS ===\n",
        "\n",
        "        # Reset environment with seed\n",
        "        if self.seed is not None:\n",
        "            state, _ = self.env.reset(seed=self.seed)\n",
        "        else:\n",
        "            state, _ = self.env.reset()\n",
        "\n",
        "        states, actions, actions_log_probability, values, rewards, done, episode_reward = self.init_training()\n",
        "\n",
        "        # Add this line to track violations\n",
        "        total_violations = 0\n",
        "\n",
        "        # # Create fresh network for each episode to avoid memory corruption\n",
        "        # fresh_network = create_pypsa_network()\n",
        "        # self.env.network = fresh_network\n",
        "\n",
        "        state, _ = self.env.reset()  # Gymnasium format returns (obs, info)\n",
        "\n",
        "        self.model.train() # Set model to training mode\n",
        "\n",
        "        while True:\n",
        "            state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
        "            states.append(state_tensor)\n",
        "\n",
        "            # Get action predictions and values\n",
        "            action_mean, value_pred = self.model(state_tensor)\n",
        "\n",
        "\n",
        "\n",
        "            # Split actor output into alpha and beta parameters\n",
        "            action_dim = self.env.action_space.shape[0]\n",
        "            alpha_raw, beta_raw = torch.split(action_mean, action_dim, dim=-1)\n",
        "\n",
        "            # Ensure alpha, beta > 1 for well-behaved Beta distribution\n",
        "            alpha = torch.nn.functional.softplus(alpha_raw) + 1.0\n",
        "            beta = torch.nn.functional.softplus(beta_raw) + 1.0\n",
        "\n",
        "            # Create Beta distribution for continuous actions in [0,1]\n",
        "            dist = torch.distributions.Beta(alpha, beta)\n",
        "            action = dist.sample()\n",
        "\n",
        "            # No clamping needed - Beta distribution naturally outputs [0,1]\n",
        "            action_clamped = action\n",
        "\n",
        "            log_prob_action = dist.log_prob(action).sum(dim=-1)  # Sum over action dimensions\n",
        "\n",
        "            # Step environment with numpy action\n",
        "            action_np = action_clamped.detach().cpu().numpy().flatten()\n",
        "            state, reward, terminated, truncated, info = self.env.step(action_np)\n",
        "            done = terminated or truncated\n",
        "\n",
        "            #accumulate violations for the epsiode\n",
        "            total_violations += sum(info['constraint_violations'].values())\n",
        "\n",
        "            actions.append(action_clamped)\n",
        "            actions_log_probability.append(log_prob_action)\n",
        "            values.append(value_pred)\n",
        "            rewards.append(reward)\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        states=torch.cat(states).to(self.device)#converts the list of individual states into a sinlem tensor that is necessary for later processing\n",
        "        #Creates a single tensor with dimensions like (N, state_dim), where: N is the number of states collected in the episode; state_dim is the dimensionality of each state.\n",
        "        #torch.cat() expects a sequence (e.g. list or tuple) of PyTorch tensors as input.\n",
        "        actions=torch.cat(actions).to(self.device)\n",
        "        #Note that, in the loop, both state and action are PyTorch tensors so that states and actions are both lists of PyTorch tensors\n",
        "        actions_log_probability=torch.cat(actions_log_probability).to(self.device)\n",
        "        values=torch.cat(values).squeeze(-1).to(self.device)# .squeeze removes a dimension of size 1 only from tensor at the specified position, in this case, -1, the last dimesion in the tensor. Note that .squeeze() does not do anything if the size of the dimension at the specified potision is not 1.\n",
        "        # print(f\"rewards NaNs: {torch.isnan(torch.tensor(rewards, dtype=torch.float32)).any()}\")\n",
        "        # print(f\"values NaNs: {torch.isnan(torch.tensor(values, dtype=torch.float32)).any()}\")\n",
        "        returns = self.calculate_returns(rewards)\n",
        "        advantages = self.calculate_advantages(returns, values)\n",
        "\n",
        "        # print(f\"Returns NaNs: {torch.isnan(returns).any()}\")\n",
        "        # print(f\"advantages NaNs (after calculation): {torch.isnan(advantages).any()}\")\n",
        "\n",
        "        return episode_reward, states, actions, actions_log_probability, advantages, returns, total_violations\n",
        "\n",
        "\n",
        "    def update_policy(self,\n",
        "            states,\n",
        "            actions,\n",
        "            actions_log_probability_old,\n",
        "            advantages,\n",
        "            returns):\n",
        "        #print(f\"Returns NaNs: {torch.isnan(returns).any()}\")\n",
        "        total_policy_loss = 0\n",
        "        total_value_loss = 0\n",
        "        actions_log_probability_old = actions_log_probability_old.detach()\n",
        "        actions=actions.detach()\n",
        "\n",
        "        # print(f\"Returns NaNs: {torch.isnan(returns).any()}\")\n",
        "        # print(f\"advantages NaNs (after calculation): {torch.isnan(advantages).any()}\")\n",
        "\n",
        "\n",
        "        #detach() is used to remove the tensor from the computation graph, meaning no gradients will be calculated for that tensor when performing backpropagation.\n",
        "        #In this context, it's used to ensure that the old actions and log probabilities do not participate in the gradient computation during the optimization of the policy, as we want to update the model based on the current policy rather than the old one.\n",
        "        #print(type(states), type(actions),type(actions_log_probability_old), type(advantages), type(returns))\n",
        "        training_results_dataset= TensorDataset(\n",
        "                states,\n",
        "                actions,\n",
        "                actions_log_probability_old,\n",
        "                advantages,\n",
        "                returns) #TensorDataset class expects all the arguments passed to it to be tensors (or other compatible types like NumPy arrays, which will be automatically converted to tensor\n",
        "        batch_dataset = DataLoader(\n",
        "                training_results_dataset,\n",
        "                batch_size=self.batch_size,\n",
        "                shuffle=False)\n",
        "        #creates a DataLoader instance in PyTorch, which is used to load the training_results_dataset in batches during training.\n",
        "        #batch_size defines how many samples will be included in each batch. The dataset will be divided into batches of size BATCH_SIZE. The model will then process one batch at a time, rather than all of the data at once,\n",
        "        #shuffle argument controls whether or not the data will be shuffled before being split into batches.\n",
        "        #Because shuffle is false, dataloader will provide the batches in the order the data appears in training_results_dataset. In this case, the batches will be formed from consecutive entries in the dataset, and the observations will appear in the same sequence as they are stored in the dataset.\n",
        "        for _ in range(self.PPO_steps):\n",
        "            for batch_idx, (states,actions,actions_log_probability_old, advantages, returns) in enumerate(batch_dataset):\n",
        "                #get new log prob of actions for all input states\n",
        "                action_mean, value_pred = self.model(states)\n",
        "                value_pred = value_pred.squeeze(-1)\n",
        "\n",
        "                # For continuous actions with Beta distribution\n",
        "                action_dim = self.env.action_space.shape[0]\n",
        "                alpha_raw, beta_raw = torch.split(action_mean, action_dim, dim=-1)\n",
        "\n",
        "                # Ensure alpha, beta > 1 for well-behaved Beta distribution\n",
        "                alpha = torch.nn.functional.softplus(alpha_raw) + 1.0\n",
        "                beta = torch.nn.functional.softplus(beta_raw) + 1.0\n",
        "\n",
        "                probability_distribution_new = torch.distributions.Beta(alpha, beta)\n",
        "                entropy = probability_distribution_new.entropy().sum(dim=-1)\n",
        "\n",
        "                #estimate new log probabilities using old actions\n",
        "                actions_log_probability_new = probability_distribution_new.log_prob(actions).sum(dim=-1)\n",
        "                # # Check for NaN or Inf in log probabilities\n",
        "                # if torch.isnan(actions_log_probability_old).any() or torch.isinf(actions_log_probability_old).any():\n",
        "                #     print(\"NaN or Inf detected in actions_log_probability_old!\")\n",
        "                #     return  # You can return or handle this case as needed\n",
        "\n",
        "                # if torch.isnan(actions_log_probability_new).any() or torch.isinf(actions_log_probability_new).any():\n",
        "                #     print(\"NaN or Inf detected in actions_log_probability_new!\")\n",
        "                #     return  # You can return or handle this case as needed\n",
        "\n",
        "                # print(f\"actions_log_probability_old NaNs: {torch.isnan(actions_log_probability_old).any()}\")\n",
        "                # print(f\"actions_log_probability_new NaNs: {torch.isnan(actions_log_probability_new).any()}\")\n",
        "                # print(f\"advantages NaNs: {torch.isnan(advantages).any()}\")\n",
        "\n",
        "                surrogate_loss = self.calculate_surrogate_loss(\n",
        "                    actions_log_probability_old,\n",
        "                    actions_log_probability_new,\n",
        "                    advantages\n",
        "                )\n",
        "\n",
        "                # print(f\"Surrogate Loss NaNs: {torch.isnan(surrogate_loss).any()}\")\n",
        "                # print(f\"Entropy NaNs: {torch.isnan(entropy).any()}\")\n",
        "                # print(f\"Returns NaNs: {torch.isnan(returns).any()}\")\n",
        "                # print(f\"Value Predictions NaNs: {torch.isnan(value_pred).any()}\")\n",
        "\n",
        "                policy_loss, value_loss = self.calculate_losses(\n",
        "                    surrogate_loss,\n",
        "                    entropy,\n",
        "                    returns,\n",
        "                    value_pred\n",
        "                )\n",
        "                self.optimizer.zero_grad() #clear existing gradietns in the optimizer (so that these don't propagate accross multiple .backward(). Ensures each optimization step uses only the gradients computed during the current batch.\n",
        "\n",
        "                # Skip backward pass if loss is NaN\n",
        "                if torch.isnan(policy_loss).any():\n",
        "                    print(\"NaN detected in policy_loss - skipping backward pass!\")\n",
        "                    continue\n",
        "                if torch.isnan(value_loss).any():\n",
        "                    print(\"NaN detected in value_loss - skipping backward pass!\")\n",
        "                    continue\n",
        "\n",
        "                policy_loss.backward() #computes gradients for policy_loss with respect to the agent's parameters\n",
        "                # #Check for NaN gradients after policy_loss backward\n",
        "                # for param in self.model.parameters():\n",
        "                #     if param.grad is not None:  # Check if gradients exist for this parameter\n",
        "                #         if torch.isnan(param.grad).any():\n",
        "                #             print(\"NaN gradient detected in policy_loss!\")\n",
        "                # #             return\n",
        "                value_loss.backward()\n",
        "                # Check for NaN gradients after value_loss backwardor param in self.model.parameters():\n",
        "                # for param in self.model.parameters():\n",
        "                #     if param.grad is not None:  # Check if gradients exist for this parameter\n",
        "                #         if torch.isnan(param.grad).any():\n",
        "                #             print(\"NaN gradient detected in value_loss!\")\n",
        "                #             return\n",
        "\n",
        "                self.optimizer.step()\n",
        "                #The update step is based on the learning rate and other hyperparameters of the optimizer\n",
        "                # The parameters of the agent are adjusted to reduce the policy and value losses.\n",
        "                total_policy_loss += policy_loss.item() #accumulate the scalar value of the policy loss for logging/ analysis\n",
        "                #policy_loss.item() extracts the numerical value of the loss tensor (detaching it from the computational graph).\n",
        "                #This value is added to total_policy_loss to compute the cumulative loss over all batches in the current PPO step.\n",
        "                #Result: tracks the total policy loss for the current training epoch\n",
        "                # The loss over the whole dataset is the sum of the losses over all batches.\n",
        "                #The training dataset is split into batches during the training process. Each batch represents a subset of the collected training data from one episode.\n",
        "                # Loss calculation is performed for each batch (policy loss and value loss)\n",
        "                # for each batch, gradients are calculated with respect to the total loss for that batch and the optimizer then updates the network parameters using these gradients.\n",
        "                # this is because the surrogate loss is only calculated over a single batch of data\n",
        "                #look at the formula for surrogate loss.\n",
        "                # It is written in terms of an expectation ˆ Et[. . .] that indicates the empirical average over a finite batch of samples.\n",
        "                # This means you have collected a set of data (time steps) from the environment, and you're averaging over these data points. The hat symbol implies you're approximating the true expectation with a finite sample of data from the environment. This empirical average can be computed as the mean of values from the sampled transitions\n",
        "                # the expectation is taken over all the data you've collected\n",
        "                #If you're training with multiple batches (i.e., collecting data in chunks), then you can think of the expectation as being computed over each batch.\n",
        "                #The overall expectation can indeed be seen as the sum of expectations computed for each batch, but The expectation of the sum is generally not exactly equal to the sum of the expectations unless the samples are independent, but in practical reinforcement learning algorithms, it's typically a good enough approximation\n",
        "                #For samples to be independent, the outcome of one sample must not provide any information about the outcome of another. Specifically, in the context of reinforcement learning, this means that the states, actions, rewards, and subsequent states observed in different time steps or different episodes should be independent of each other.\n",
        "                total_value_loss += value_loss.item()\n",
        "                #Notice that we are calculating an empirical average, which is already an approximation on the true value (the true expectation would be the average over an infinite amount of data, and the empirical average is the average over the finite amount of data that we have collected).\n",
        "                #But furthermore, we are approximating even the empirical average istelf. The empirical average is the average over all our collected datal, but here we actually batch our data, calculate average over each batch and then sum these averages, which is not exaclty equal to the average of the sums (but is a decent approximation).\n",
        "        return total_policy_loss / self.PPO_steps, total_value_loss / self.PPO_steps\n",
        "\n",
        "    def train(self):\n",
        "        train_rewards = []\n",
        "        # test_rewards = []\n",
        "        # policy_losses = []\n",
        "        # value_losses = []\n",
        "        #lens = []\n",
        "\n",
        "        for episode in range(1, self.max_episodes + 1):\n",
        "            # Perform a forward pass and collect experience\n",
        "            train_reward, states, actions, actions_log_probability, advantages, returns, violations = self.forward_pass()\n",
        "\n",
        "            # Update the policy using the experience collected\n",
        "            policy_loss, value_loss = self.update_policy(\n",
        "                states,\n",
        "                actions,\n",
        "                actions_log_probability,\n",
        "                advantages,\n",
        "                returns)\n",
        "            # test_reward = self.evaluate()\n",
        "\n",
        "            # # Visualize the environment if it supports rendering (currently this is done once each episode - might want to change to once every multiple of episodes)\n",
        "            # if hasattr(self.env, \"render\") and callable(getattr(self.env, \"render\", None)):\n",
        "            #   self.env.render()\n",
        "\n",
        "            # Log the results\n",
        "            # policy_losses.append(policy_loss)\n",
        "            # value_losses.append(value_loss)\n",
        "            train_rewards.append(train_reward)\n",
        "            # # run these when back online\n",
        "            # self.run[\"policy_loss\"].log(policy_loss)\n",
        "            # self.run[\"value_loss\"].log(value_loss)\n",
        "            self.run[\"train_reward\"].log(train_reward)\n",
        "            self.run[\"total_violation\"].log(violations)\n",
        "\n",
        "            # Calculate the mean of recent rewards and losses for display\n",
        "            mean_train_rewards = np.mean(train_rewards[-self.n_trials:])\n",
        "            #mean_test_rewards = np.mean(test_rewards[-self.n_trials:])\n",
        "            # mean_abs_policy_loss = np.mean(np.abs(policy_losses[-self.n_trials:]))\n",
        "            # mean_abs_value_loss = np.mean(np.abs(value_losses[-self.n_trials:]))\n",
        "\n",
        "            # Print results at specified intervals\n",
        "            if episode % self.print_interval == 0:\n",
        "                print(f'Episode: {episode:3} | \\\n",
        "                    Train Rewards: {train_reward:3.1f} \\\n",
        "                    Violations: {violations}\\\n",
        "                    Mean Train Rewards: {mean_train_rewards:3.1f}' )\n",
        "                    # \\\n",
        "                    # | Mean Abs Policy Loss: {mean_abs_policy_loss:2.2f} \\\n",
        "                    # | Mean Abs Value Loss: {mean_abs_value_loss:2.2f} ')\n",
        "\n",
        "\n",
        "\n",
        "                                    # | Mean Test Rewards: {mean_test_rewards:3.1f} \\\n",
        "                                    #| \"Episode Len: {np.mean(lens[-self.n_trials:])}\n",
        "\n",
        "\n",
        "\n",
        "            # # Check if reward threshold is reached\n",
        "            # if mean_test_rewards >= self.reward_threshold:\n",
        "            #     print(f'Reached reward threshold in {episode} episodes')\n",
        "            #     break\n",
        "        # Check if the environment has a close method before calling it\n",
        "        # if hasattr(self.env, \"close\") and callable(getattr(self.env, \"close\", None)):\n",
        "        #   self.env.close() #Close environment visualisation after training is done.\n",
        "        return train_rewards\n",
        "\n",
        "def plot_train_rewards(train_rewards, reward_threshold):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(train_rewards, label='Training Reward')\n",
        "    plt.xlabel('Episode', fontsize=20)\n",
        "    plt.ylabel('Training Reward', fontsize=20)\n",
        "    plt.hlines(reward_threshold, 0, len(train_rewards), color='y')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "def plot_test_rewards(test_rewards, reward_threshold):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(test_rewards, label='Testing Reward')\n",
        "    plt.xlabel('Episode', fontsize=20)\n",
        "    plt.ylabel('Testing Reward', fontsize=20)\n",
        "    plt.hlines(reward_threshold, 0, len(test_rewards), color='y')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "def plot_losses(policy_losses, value_losses):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(value_losses, label='Value Losses')\n",
        "    plt.plot(policy_losses, label='Policy Losses')\n",
        "    plt.xlabel('Episode', fontsize=20)\n",
        "    plt.ylabel('Loss', fontsize=20)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf82e05",
      "metadata": {
        "id": "acf82e05"
      },
      "outputs": [],
      "source": [
        "class Env2Gen1LoadConstrReplacement(Env2Gen1LoadConstr):\n",
        "    \"\"\"\n",
        "    Environment using the Replacement reward method instead of Summation.\n",
        "\n",
        "    Inherits from Env2Gen1LoadConstr but modifies the reward calculation\n",
        "    to implement the replacement method from the RL-OPF paper.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, episode_length=None, constraint_penalty_factor=100, offset_k=2500):\n",
        "        super().__init__(episode_length=episode_length, constraint_penalty_factor=constraint_penalty_factor)\n",
        "        self.offset_k = offset_k\n",
        "\n",
        "    def calculate_constrained_reward(self):\n",
        "        \"\"\"\n",
        "        Calculate reward using replacement method with pre-calculated offset k.\n",
        "\n",
        "        Replacement method:\n",
        "        - If all constraints satisfied: return -J(s) + k\n",
        "        - If constraints violated: return -P(s)\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        tuple: (reward, constraint_results)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Get base reward from objective function (negative for minimization)\n",
        "            base_reward = self._calculate_reward()\n",
        "\n",
        "            # Evaluate constraints\n",
        "            constraint_results = self._evaluate_all_constraints()\n",
        "\n",
        "            # Apply replacement method\n",
        "            if constraint_results['all_satisfied']:\n",
        "                # All constraints satisfied: return optimization reward + offset k\n",
        "                constrained_reward = base_reward + self.offset_k\n",
        "            else:\n",
        "                # Constraints violated: return only penalty (negative)\n",
        "                total_violation = float(constraint_results['total_violation'])\n",
        "                constrained_reward = -self.penalty_factor * total_violation\n",
        "\n",
        "            # Ensure reward is a scalar\n",
        "            if hasattr(constrained_reward, '__len__'):\n",
        "                constrained_reward = float(constrained_reward)\n",
        "\n",
        "            return constrained_reward, constraint_results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating replacement reward: {e}\")\n",
        "            # Fall back to base reward on error\n",
        "            return self._calculate_reward(), {\n",
        "                'all_satisfied': True,\n",
        "                'violations': {},\n",
        "                'total_violation': 0.0\n",
        "            }\n",
        "\n",
        "    def get_reward_method_info(self):\n",
        "        \"\"\"\n",
        "        Get information about the reward method being used.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        dict: Information about the reward method\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'method': 'replacement',\n",
        "            'offset_k': self.offset_k,\n",
        "            'k_method': self.k_method,\n",
        "            'k_samples': self.k_samples,\n",
        "            'penalty_factor': self.penalty_factor\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb26605",
      "metadata": {
        "id": "7fb26605"
      },
      "outputs": [],
      "source": [
        "# Add this to your main function or create a new sweep script\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def run_sweep_replacement():\n",
        "    # Base parameters (non-swept parameters)\n",
        "    base_params = {\n",
        "        \"optimizer_name\": \"Adam\",\n",
        "        \"MAX_EPISODES\": 1000,\n",
        "        \"PRINT_INTERVAL\": 10,  # Print less frequently during sweep\n",
        "        \"N_TRIALS\": 100,\n",
        "        \"DROPOUT\": 0,\n",
        "        \"network_file\": \"elec_s_5_ec_lcopt_3h.nc\",\n",
        "    }\n",
        "\n",
        "    # Parameters to sweep (key parameters that affect learning)\n",
        "    sweep_params = {\n",
        "        \"LEARNING_RATE\": [1e-4, 3e-4, 1e-3, 3e-3],\n",
        "        \"EPSILON\": [0.1, 0.2, 0.3],\n",
        "        \"ENTROPY_COEFFICIENT\": [0.01, 0.05, 0.1],\n",
        "        \"HIDDEN_DIMENSIONS\": [32, 64, 128],\n",
        "        \"PPO_STEPS\": [8, 16],\n",
        "        \"BATCH_SIZE\": [128, 256],\n",
        "        \"DISCOUNT_FACTOR\": [0.95, 0.99],\n",
        "        \"constraint_penalty_factor\":[0,25,50,100],\n",
        "        \"episode_length\": [2,4,6],\n",
        "        \"env_class\": [\"Env2Gen1LoadConstr\", \"Env2Gen1LoadConstrReplacement\"] #Will need to change this if you change the env class names\n",
        "    }\n",
        "\n",
        "    replacement_env=Env2Gen1LoadConstrReplacement() #this is used to calculate the offset k for the replacement reward method\n",
        "\n",
        "    # Seeds to use for each configuration\n",
        "    #seeds = [42, 123, 7]  # Using 3 seeds for statistical significance\n",
        "    #seeds = [42]\n",
        "    seeds= [123, 7]\n",
        "\n",
        "    # Generate a subset of combinations to keep the sweep manageable\n",
        "    # We'll use a more focused approach rather than a full grid search\n",
        "\n",
        "    # Priority configurations based on most promising parameter values\n",
        "    # Priority configurations based on most promising parameter values\n",
        "    priority_configs = [\n",
        "        # Config 1: Higher learning rate, exploration focus\n",
        "        {\"LEARNING_RATE\": 1e-3, \"EPSILON\": 0.3, \"ENTROPY_COEFFICIENT\": 0.1,\n",
        "         \"HIDDEN_DIMENSIONS\": 64, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256,\n",
        "         \"DISCOUNT_FACTOR\": 0.99, \"constraint_penalty_factor\":0, \"episode_length\": 4},\n",
        "\n",
        "        # Config 2: Medium learning rate, balanced approach\n",
        "        {\"LEARNING_RATE\": 3e-4, \"EPSILON\": 0.2, \"ENTROPY_COEFFICIENT\": 0.05,\n",
        "         \"HIDDEN_DIMENSIONS\": 64, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256,\n",
        "         \"DISCOUNT_FACTOR\": 0.99, \"constraint_penalty_factor\":0,\"episode_length\": 4},\n",
        "\n",
        "        # Config 3: Conservative updates, larger network\n",
        "        {\"LEARNING_RATE\": 1e-4, \"EPSILON\": 0.1, \"ENTROPY_COEFFICIENT\": 0.01,\n",
        "         \"HIDDEN_DIMENSIONS\": 128, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256,\n",
        "         \"DISCOUNT_FACTOR\": 0.99, \"constraint_penalty_factor\":0,\"episode_length\": 4},\n",
        "\n",
        "        # Config 4: Aggressive learning, smaller network\n",
        "        {\"LEARNING_RATE\": 3e-3, \"EPSILON\": 0.3, \"ENTROPY_COEFFICIENT\": 0.1,\n",
        "         \"HIDDEN_DIMENSIONS\": 32, \"PPO_STEPS\": 8, \"BATCH_SIZE\": 128,\n",
        "         \"DISCOUNT_FACTOR\": 0.95, \"constraint_penalty_factor\":0,\"episode_length\": 4},\n",
        "\n",
        "        # Config 1: Higher learning rate, exploration focus\n",
        "        {\"LEARNING_RATE\": 1e-3, \"EPSILON\": 0.3, \"ENTROPY_COEFFICIENT\": 0.1,\n",
        "         \"HIDDEN_DIMENSIONS\": 64, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256,\n",
        "         \"DISCOUNT_FACTOR\": 0.99, \"constraint_penalty_factor\":100,\"episode_length\": 4},\n",
        "\n",
        "        # Config 2: Medium learning rate, balanced approach\n",
        "        {\"LEARNING_RATE\": 3e-4, \"EPSILON\": 0.2, \"ENTROPY_COEFFICIENT\": 0.05,\n",
        "         \"HIDDEN_DIMENSIONS\": 64, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256,\n",
        "         \"DISCOUNT_FACTOR\": 0.99, \"constraint_penalty_factor\":100,\"episode_length\": 4},\n",
        "\n",
        "        # Config 3: Conservative updates, larger network\n",
        "        {\"LEARNING_RATE\": 1e-4, \"EPSILON\": 0.1, \"ENTROPY_COEFFICIENT\": 0.01,\n",
        "         \"HIDDEN_DIMENSIONS\": 128, \"PPO_STEPS\": 16, \"BATCH_SIZE\": 256,\n",
        "         \"DISCOUNT_FACTOR\": 0.99, \"constraint_penalty_factor\":100,\"episode_length\": 4},\n",
        "\n",
        "        # Config 4: Aggressive learning, smaller network\n",
        "        {\"LEARNING_RATE\": 3e-3, \"EPSILON\": 0.3, \"ENTROPY_COEFFICIENT\": 0.1,\n",
        "         \"HIDDEN_DIMENSIONS\": 32, \"PPO_STEPS\": 8, \"BATCH_SIZE\": 128,\n",
        "         \"DISCOUNT_FACTOR\": 0.95, \"constraint_penalty_factor\":100,\"episode_length\": 4},\n",
        "    ]\n",
        "\n",
        "    # Add some random combinations to explore the space more broadly\n",
        "    config_seed=42\n",
        "    import random\n",
        "    random.seed(config_seed)  # For reproducible random configs\n",
        "\n",
        "    #after setting the seed, perform sampling to determine k and store the result\n",
        "\n",
        "    num_random_configs = 8  # Adjust based on how many total runs you want\n",
        "    random_configs = []\n",
        "\n",
        "    for _ in range(num_random_configs):\n",
        "        config = {param: random.choice(values) for param, values in sweep_params.items()}\n",
        "        random_configs.append(config)\n",
        "\n",
        "    # Combine priority and random configs\n",
        "    all_configs = priority_configs + random_configs\n",
        "\n",
        "    # Print sweep summary\n",
        "    print(f\"Running sweep with {len(all_configs)} configurations and {len(seeds)} seeds\")\n",
        "    print(f\"Total runs: {len(all_configs) * len(seeds)}\")\n",
        "\n",
        "    # Run all configurations\n",
        "    for seed in seeds:\n",
        "        # Set all random seeds\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(seed)\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "        #after setting the seed, perform sampling to determine k and store the result\n",
        "        replacement_reward_offset=calculate_offset_k_initialization(envClass=replacement_env)\n",
        "        for config_idx, config in enumerate(all_configs):\n",
        "              # Create a unique run ID\n",
        "            run_id = f\"sweep_{datetime.now().strftime('%Y%m%d')}_{config_idx}_{seed}\"\n",
        "\n",
        "            my_api=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjZDg3ZjNlYi04MWI3LTQ1ODctOGIxNS1iNTY3ZjgzMGYzMzYifQ==\"\n",
        "\n",
        "            # Initialize Neptune run\n",
        "            run = neptune.init_run(\n",
        "                project='EnergyGridRL/PPO-2snapshots-replacement',\n",
        "                api_token=my_api,\n",
        "                name=f\"Sweep-Config{config_idx}-Seed{seed}\",\n",
        "                tags=[\"hyperparameter_sweep\"]\n",
        "            )\n",
        "\n",
        "            # Combine base params with this config\n",
        "            params = {**base_params, **config}\n",
        "            params[\"SEED\"] = seed\n",
        "\n",
        "            # Log all parameters\n",
        "            for key, value in params.items():\n",
        "                run[f\"parameters/{key}\"] = value\n",
        "\n",
        "            run[\"env_class\"]=params[\"env_class\"]\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"Starting run {config_idx+1}/{len(all_configs)}, seed {seed}\")\n",
        "            print(f\"Parameters: {params}\")\n",
        "            print(f\"{'='*50}\\n\")\n",
        "\n",
        "            try:\n",
        "\n",
        "                # Create environment and agent\n",
        "                if params[\"env_class\"]==\"Env2Gen1LoadConstr\":\n",
        "                    env = Env2Gen1LoadConstr(network_file=params[\"network_file\"], episode_length=params[\"episode_length\"], constraint_penalty_factor=params[\"constraint_penalty_factor\"])\n",
        "                elif params[\"env_class\"]==\"Env2Gen1LoadConstrReplacement\":\n",
        "                    env = Env2Gen1LoadConstrReplacement(network_file=params[\"network_file\"], episode_length=params[\"episode_length\"], constraint_penalty_factor=params[\"constraint_penalty_factor\"], offset_k=replacement_reward_offset)\n",
        "                else:\n",
        "                    raise ValueError(f\"Invalid environment class: {params[\"env_class\"]}\")\n",
        "                env.seed(seed)\n",
        "\n",
        "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "                agent = PPO_agent(\n",
        "                    env=env,\n",
        "                    run=run,\n",
        "                    device=device,\n",
        "                    hidden_dimensions=params[\"HIDDEN_DIMENSIONS\"],\n",
        "                    dropout=params[\"DROPOUT\"],\n",
        "                    discount_factor=params[\"DISCOUNT_FACTOR\"],\n",
        "                    optimizer_name=params[\"optimizer_name\"],\n",
        "                    max_episodes=params[\"MAX_EPISODES\"],\n",
        "                    print_interval=params[\"PRINT_INTERVAL\"],\n",
        "                    PPO_steps=params[\"PPO_STEPS\"],\n",
        "                    n_trials=params[\"N_TRIALS\"],\n",
        "                    epsilon=params[\"EPSILON\"],\n",
        "                    entropy_coefficient=params[\"ENTROPY_COEFFICIENT\"],\n",
        "                    learning_rate=params[\"LEARNING_RATE\"],\n",
        "                    batch_size=params[\"BATCH_SIZE\"],\n",
        "                    seed=seed\n",
        "                )\n",
        "\n",
        "                run[\"replacement_reward\"].log(replacement_reward_offset)\n",
        "\n",
        "                # Train the agent\n",
        "                train_rewards = agent.train()\n",
        "\n",
        "                # Log final performance metrics\n",
        "                run[\"results/final_reward\"] = train_rewards[-1]\n",
        "                run[\"results/mean_last_100_reward\"] = np.mean(train_rewards[-100:])\n",
        "                run[\"results/best_reward\"] = np.max(train_rewards)\n",
        "                run[\"results/baseline_reward\"]= evaluate_baseline_reward(network_file=params[\"network_file\"], env=env, agent=agent)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in run: {e}\")\n",
        "                run[\"results/error\"] = str(e)\n",
        "\n",
        "            # Close the Neptune run\n",
        "            run.stop()\n",
        "\n",
        "            # Small delay to avoid API rate limits\n",
        "            time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99a34ee8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99a34ee8",
        "outputId": "41dab4e1-dd25-4399-da7a-0ac5009911f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Episode: 980 |                     Train Rewards: 94.9                     Violations: 0                    Mean Train Rewards: 77.2\n",
            "Episode: 990 |                     Train Rewards: 69.4                     Violations: 2.799140214920037                    Mean Train Rewards: 82.1\n",
            "Episode: 1000 |                     Train Rewards: 64.1                     Violations: 0                    Mean Train Rewards: 81.5\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-27/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-28\n",
            "\n",
            "==================================================\n",
            "Starting run 5/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.001, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -1541.8                     Violations: 15.785999298095703                    Mean Train Rewards: -5077.3\n",
            "Episode:  20 |                     Train Rewards: -104.8                     Violations: 1.6408884525299001                    Mean Train Rewards: -3638.5\n",
            "Episode:  30 |                     Train Rewards: -6.5                     Violations: 0.69374680519104                    Mean Train Rewards: -2453.3\n",
            "Episode:  40 |                     Train Rewards: -209.8                     Violations: 2.339278459548943                    Mean Train Rewards: -1877.1\n",
            "Episode:  50 |                     Train Rewards: 49.9                     Violations: 0                    Mean Train Rewards: -1498.7\n",
            "Episode:  60 |                     Train Rewards: 66.5                     Violations: 0                    Mean Train Rewards: -1274.0\n",
            "Episode:  70 |                     Train Rewards: -141.0                     Violations: 2.4587655067443848                    Mean Train Rewards: -1103.3\n",
            "Episode:  80 |                     Train Rewards: 74.1                     Violations: 0                    Mean Train Rewards: -964.7\n",
            "Episode:  90 |                     Train Rewards: 95.8                     Violations: 0                    Mean Train Rewards: -895.3\n",
            "Episode: 100 |                     Train Rewards: 30.5                     Violations: 0.4603290557861328                    Mean Train Rewards: -803.5\n",
            "Episode: 110 |                     Train Rewards: 111.3                     Violations: 0                    Mean Train Rewards: -301.4\n",
            "Episode: 120 |                     Train Rewards: -509.5                     Violations: 5.547524690628052                    Mean Train Rewards: -99.1\n",
            "Episode: 130 |                     Train Rewards: 93.8                     Violations: 0                    Mean Train Rewards: -99.2\n",
            "Episode: 140 |                     Train Rewards: 109.6                     Violations: 0                    Mean Train Rewards: -86.6\n",
            "Episode: 150 |                     Train Rewards: 65.7                     Violations: 0                    Mean Train Rewards: -92.1\n",
            "Episode: 160 |                     Train Rewards: 130.0                     Violations: 0                    Mean Train Rewards: -78.3\n",
            "Episode: 170 |                     Train Rewards: -116.1                     Violations: 1.8060946464538574                    Mean Train Rewards: -70.6\n",
            "Episode: 180 |                     Train Rewards: 54.6                     Violations: 0                    Mean Train Rewards: -70.2\n",
            "Episode: 190 |                     Train Rewards: 105.3                     Violations: 0                    Mean Train Rewards: -35.1\n",
            "Episode: 200 |                     Train Rewards: -8.8                     Violations: 0.9189867973327637                    Mean Train Rewards: -40.4\n",
            "Episode: 210 |                     Train Rewards: -2.1                     Violations: 0                    Mean Train Rewards: -39.4\n",
            "Episode: 220 |                     Train Rewards: 95.7                     Violations: 0                    Mean Train Rewards: -15.2\n",
            "Episode: 230 |                     Train Rewards: 133.4                     Violations: 0                    Mean Train Rewards: -12.0\n",
            "Episode: 240 |                     Train Rewards: 132.4                     Violations: 0                    Mean Train Rewards: -4.1\n",
            "Episode: 250 |                     Train Rewards: 119.9                     Violations: 0                    Mean Train Rewards: 8.0\n",
            "Episode: 260 |                     Train Rewards: 104.3                     Violations: 0.08030176162719727                    Mean Train Rewards: 12.0\n",
            "Episode: 270 |                     Train Rewards: 34.7                     Violations: 0                    Mean Train Rewards: 20.0\n",
            "Episode: 280 |                     Train Rewards: 21.5                     Violations: 0                    Mean Train Rewards: 24.2\n",
            "Episode: 290 |                     Train Rewards: 113.9                     Violations: 0                    Mean Train Rewards: 31.6\n",
            "Episode: 300 |                     Train Rewards: -155.7                     Violations: 1.9729030132293772                    Mean Train Rewards: 31.1\n",
            "Episode: 310 |                     Train Rewards: 101.3                     Violations: 0                    Mean Train Rewards: 41.8\n",
            "Episode: 320 |                     Train Rewards: 130.4                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 330 |                     Train Rewards: -132.5                     Violations: 1.672769784927361                    Mean Train Rewards: 50.4\n",
            "Episode: 340 |                     Train Rewards: 105.0                     Violations: 0                    Mean Train Rewards: 46.1\n",
            "Episode: 350 |                     Train Rewards: 64.4                     Violations: 0                    Mean Train Rewards: 45.6\n",
            "Episode: 360 |                     Train Rewards: 106.7                     Violations: 0                    Mean Train Rewards: 48.8\n",
            "Episode: 370 |                     Train Rewards: 49.1                     Violations: 0                    Mean Train Rewards: 29.9\n",
            "Episode: 380 |                     Train Rewards: -536.5                     Violations: 5.652863979339585                    Mean Train Rewards: -47.5\n",
            "Episode: 390 |                     Train Rewards: 96.7                     Violations: 0                    Mean Train Rewards: -66.7\n",
            "Episode: 400 |                     Train Rewards: 85.9                     Violations: 0                    Mean Train Rewards: -65.7\n",
            "Episode: 410 |                     Train Rewards: 24.5                     Violations: 0.6816887855529785                    Mean Train Rewards: -69.0\n",
            "Episode: 420 |                     Train Rewards: 10.2                     Violations: 0                    Mean Train Rewards: -67.5\n",
            "Episode: 430 |                     Train Rewards: 99.8                     Violations: 0                    Mean Train Rewards: -62.1\n",
            "Episode: 440 |                     Train Rewards: 86.5                     Violations: 0                    Mean Train Rewards: -59.2\n",
            "Episode: 450 |                     Train Rewards: 10.2                     Violations: 0.5944418907165385                    Mean Train Rewards: -58.6\n",
            "Episode: 460 |                     Train Rewards: 13.3                     Violations: 0                    Mean Train Rewards: -61.1\n",
            "Episode: 470 |                     Train Rewards: -0.6                     Violations: 0.7111334800720144                    Mean Train Rewards: -42.2\n",
            "Episode: 480 |                     Train Rewards: -0.1                     Violations: 1.0125243663787842                    Mean Train Rewards: 32.9\n",
            "Episode: 490 |                     Train Rewards: 4.7                     Violations: 0                    Mean Train Rewards: 48.0\n",
            "Episode: 500 |                     Train Rewards: 47.2                     Violations: 0                    Mean Train Rewards: 53.4\n",
            "Episode: 510 |                     Train Rewards: 141.8                     Violations: 0                    Mean Train Rewards: 56.6\n",
            "Episode: 520 |                     Train Rewards: 86.5                     Violations: 0                    Mean Train Rewards: 56.5\n",
            "Episode: 530 |                     Train Rewards: 103.0                     Violations: 0                    Mean Train Rewards: 52.7\n",
            "Episode: 540 |                     Train Rewards: 161.8                     Violations: 0                    Mean Train Rewards: 52.6\n",
            "Episode: 550 |                     Train Rewards: 73.8                     Violations: 0                    Mean Train Rewards: 45.3\n",
            "Episode: 560 |                     Train Rewards: 130.8                     Violations: 0                    Mean Train Rewards: 35.6\n",
            "Episode: 570 |                     Train Rewards: 67.8                     Violations: 0                    Mean Train Rewards: 26.9\n",
            "Episode: 580 |                     Train Rewards: 15.6                     Violations: 0                    Mean Train Rewards: 27.2\n",
            "Episode: 590 |                     Train Rewards: 116.1                     Violations: 0                    Mean Train Rewards: 24.8\n",
            "Episode: 600 |                     Train Rewards: 28.5                     Violations: 0                    Mean Train Rewards: 24.8\n",
            "Episode: 610 |                     Train Rewards: 88.3                     Violations: 0                    Mean Train Rewards: 23.2\n",
            "Episode: 620 |                     Train Rewards: 91.5                     Violations: 0                    Mean Train Rewards: 22.0\n",
            "Episode: 630 |                     Train Rewards: 29.6                     Violations: 0.7766270637512207                    Mean Train Rewards: 13.2\n",
            "Episode: 640 |                     Train Rewards: 122.1                     Violations: 0                    Mean Train Rewards: 11.9\n",
            "Episode: 650 |                     Train Rewards: 103.7                     Violations: 0                    Mean Train Rewards: 18.1\n",
            "Episode: 660 |                     Train Rewards: 75.8                     Violations: 0                    Mean Train Rewards: 29.5\n",
            "Episode: 670 |                     Train Rewards: 67.5                     Violations: 0.19123196601866965                    Mean Train Rewards: 38.5\n",
            "Episode: 680 |                     Train Rewards: 74.4                     Violations: 0                    Mean Train Rewards: 41.5\n",
            "Episode: 690 |                     Train Rewards: 85.6                     Violations: 0                    Mean Train Rewards: 42.0\n",
            "Episode: 700 |                     Train Rewards: 30.7                     Violations: 0.7485473155975271                    Mean Train Rewards: 46.4\n",
            "Episode: 710 |                     Train Rewards: 98.6                     Violations: 0                    Mean Train Rewards: 51.3\n",
            "Episode: 720 |                     Train Rewards: 86.4                     Violations: 0.16126871109008079                    Mean Train Rewards: 55.2\n",
            "Episode: 730 |                     Train Rewards: 150.9                     Violations: 0                    Mean Train Rewards: 67.7\n",
            "Episode: 740 |                     Train Rewards: 73.0                     Violations: 0.4315519332885742                    Mean Train Rewards: 72.9\n",
            "Episode: 750 |                     Train Rewards: 116.9                     Violations: 0                    Mean Train Rewards: 78.6\n",
            "Episode: 760 |                     Train Rewards: 52.2                     Violations: 0                    Mean Train Rewards: 80.9\n",
            "Episode: 770 |                     Train Rewards: 68.9                     Violations: 0                    Mean Train Rewards: 79.5\n",
            "Episode: 780 |                     Train Rewards: 47.0                     Violations: 0                    Mean Train Rewards: 80.9\n",
            "Episode: 790 |                     Train Rewards: -180.0                     Violations: 2.099059820175171                    Mean Train Rewards: 76.4\n",
            "Episode: 800 |                     Train Rewards: 106.2                     Violations: 0                    Mean Train Rewards: 72.0\n",
            "Episode: 810 |                     Train Rewards: -6.3                     Violations: 0                    Mean Train Rewards: 62.6\n",
            "Episode: 820 |                     Train Rewards: 115.4                     Violations: 0                    Mean Train Rewards: 58.1\n",
            "Episode: 830 |                     Train Rewards: 33.3                     Violations: 0                    Mean Train Rewards: 55.1\n",
            "Episode: 840 |                     Train Rewards: 73.9                     Violations: 0                    Mean Train Rewards: 49.1\n",
            "Episode: 850 |                     Train Rewards: 54.8                     Violations: 0                    Mean Train Rewards: 43.3\n",
            "Episode: 860 |                     Train Rewards: 47.7                     Violations: 0                    Mean Train Rewards: 41.6\n",
            "Episode: 870 |                     Train Rewards: 128.3                     Violations: 0                    Mean Train Rewards: 44.0\n",
            "Episode: 880 |                     Train Rewards: 47.0                     Violations: 0                    Mean Train Rewards: 44.1\n",
            "Episode: 890 |                     Train Rewards: 43.8                     Violations: 0                    Mean Train Rewards: 47.7\n",
            "Episode: 900 |                     Train Rewards: 40.5                     Violations: 0                    Mean Train Rewards: 50.1\n",
            "Episode: 910 |                     Train Rewards: 74.5                     Violations: 0                    Mean Train Rewards: 49.7\n",
            "Episode: 920 |                     Train Rewards: 14.4                     Violations: 0                    Mean Train Rewards: 48.2\n",
            "Episode: 930 |                     Train Rewards: -4.2                     Violations: 0                    Mean Train Rewards: 45.5\n",
            "Episode: 940 |                     Train Rewards: -145.5                     Violations: 2.3842835426330566                    Mean Train Rewards: 48.7\n",
            "Episode: 950 |                     Train Rewards: -200.5                     Violations: 2.9424452781677175                    Mean Train Rewards: 48.3\n",
            "Episode: 960 |                     Train Rewards: 34.8                     Violations: 0                    Mean Train Rewards: 49.6\n",
            "Episode: 970 |                     Train Rewards: 91.6                     Violations: 0                    Mean Train Rewards: 48.2\n",
            "Episode: 980 |                     Train Rewards: 100.8                     Violations: 0                    Mean Train Rewards: 47.4\n",
            "Episode: 990 |                     Train Rewards: 55.5                     Violations: 0.43428778648376465                    Mean Train Rewards: 51.5\n",
            "Episode: 1000 |                     Train Rewards: 74.0                     Violations: 0                    Mean Train Rewards: 54.3\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 18 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 18 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-28/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-29\n",
            "\n",
            "==================================================\n",
            "Starting run 6/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0003, 'EPSILON': 0.2, 'ENTROPY_COEFFICIENT': 0.05, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -1.6                     Violations: 0                    Mean Train Rewards: -4391.9\n",
            "Episode:  20 |                     Train Rewards: -288.6                     Violations: 3.5440826416015554                    Mean Train Rewards: -2516.7\n",
            "Episode:  30 |                     Train Rewards: -47.3                     Violations: 0                    Mean Train Rewards: -1734.1\n",
            "Episode:  40 |                     Train Rewards: -756.0                     Violations: 7.6778757572174                    Mean Train Rewards: -1443.2\n",
            "Episode:  50 |                     Train Rewards: -24.4                     Violations: 0.26673316955565696                    Mean Train Rewards: -1178.8\n",
            "Episode:  60 |                     Train Rewards: 90.2                     Violations: 0                    Mean Train Rewards: -1037.7\n",
            "Episode:  70 |                     Train Rewards: -441.6                     Violations: 5.208967924118042                    Mean Train Rewards: -930.7\n",
            "Episode:  80 |                     Train Rewards: -38.5                     Violations: 0                    Mean Train Rewards: -835.5\n",
            "Episode:  90 |                     Train Rewards: -100.8                     Violations: 1.8073821067809988                    Mean Train Rewards: -760.1\n",
            "Episode: 100 |                     Train Rewards: -135.3                     Violations: 2.2125864028930664                    Mean Train Rewards: -701.9\n",
            "Episode: 110 |                     Train Rewards: 82.6                     Violations: 0                    Mean Train Rewards: -272.3\n",
            "Episode: 120 |                     Train Rewards: -839.7                     Violations: 8.39743971824646                    Mean Train Rewards: -230.2\n",
            "Episode: 130 |                     Train Rewards: 25.5                     Violations: 0                    Mean Train Rewards: -234.8\n",
            "Episode: 140 |                     Train Rewards: 68.8                     Violations: 0                    Mean Train Rewards: -174.8\n",
            "Episode: 150 |                     Train Rewards: 70.0                     Violations: 0                    Mean Train Rewards: -165.5\n",
            "Episode: 160 |                     Train Rewards: 118.0                     Violations: 0                    Mean Train Rewards: -138.0\n",
            "Episode: 170 |                     Train Rewards: -426.3                     Violations: 5.011322498321533                    Mean Train Rewards: -123.0\n",
            "Episode: 180 |                     Train Rewards: -189.9                     Violations: 2.332284450531006                    Mean Train Rewards: -116.3\n",
            "Episode: 190 |                     Train Rewards: 33.0                     Violations: 0.19108891487121582                    Mean Train Rewards: -105.8\n",
            "Episode: 200 |                     Train Rewards: 44.1                     Violations: 0                    Mean Train Rewards: -83.0\n",
            "Episode: 210 |                     Train Rewards: 27.6                     Violations: 0                    Mean Train Rewards: -81.2\n",
            "Episode: 220 |                     Train Rewards: -104.2                     Violations: 1.7278695106506419                    Mean Train Rewards: -56.5\n",
            "Episode: 230 |                     Train Rewards: 97.0                     Violations: 0                    Mean Train Rewards: -40.2\n",
            "Episode: 240 |                     Train Rewards: 101.7                     Violations: 0                    Mean Train Rewards: -38.3\n",
            "Episode: 250 |                     Train Rewards: 108.1                     Violations: 0                    Mean Train Rewards: -34.1\n",
            "Episode: 260 |                     Train Rewards: 136.2                     Violations: 0                    Mean Train Rewards: -28.9\n",
            "Episode: 270 |                     Train Rewards: 24.4                     Violations: 0                    Mean Train Rewards: -9.3\n",
            "Episode: 280 |                     Train Rewards: 50.0                     Violations: 0                    Mean Train Rewards: 4.1\n",
            "Episode: 290 |                     Train Rewards: 109.6                     Violations: 0                    Mean Train Rewards: 17.0\n",
            "Episode: 300 |                     Train Rewards: 60.4                     Violations: 0.665351152420044                    Mean Train Rewards: 14.2\n",
            "Episode: 310 |                     Train Rewards: 92.6                     Violations: 0                    Mean Train Rewards: 26.1\n",
            "Episode: 320 |                     Train Rewards: 118.4                     Violations: 0                    Mean Train Rewards: 27.9\n",
            "Episode: 330 |                     Train Rewards: -208.0                     Violations: 2.418060302734375                    Mean Train Rewards: 36.2\n",
            "Episode: 340 |                     Train Rewards: 119.6                     Violations: 0                    Mean Train Rewards: 30.5\n",
            "Episode: 350 |                     Train Rewards: 76.3                     Violations: 0                    Mean Train Rewards: 36.3\n",
            "Episode: 360 |                     Train Rewards: 73.1                     Violations: 0                    Mean Train Rewards: 42.7\n",
            "Episode: 370 |                     Train Rewards: 64.4                     Violations: 0.05427837371826172                    Mean Train Rewards: 42.8\n",
            "Episode: 380 |                     Train Rewards: 80.2                     Violations: 0                    Mean Train Rewards: 44.6\n",
            "Episode: 390 |                     Train Rewards: 90.5                     Violations: 0                    Mean Train Rewards: 40.8\n",
            "Episode: 400 |                     Train Rewards: 127.5                     Violations: 0                    Mean Train Rewards: 43.8\n",
            "Episode: 410 |                     Train Rewards: 113.4                     Violations: 0                    Mean Train Rewards: 48.0\n",
            "Episode: 420 |                     Train Rewards: 12.9                     Violations: 0                    Mean Train Rewards: 50.0\n",
            "Episode: 430 |                     Train Rewards: 90.0                     Violations: 0                    Mean Train Rewards: 55.4\n",
            "Episode: 440 |                     Train Rewards: 96.1                     Violations: 0                    Mean Train Rewards: 62.7\n",
            "Episode: 450 |                     Train Rewards: 141.3                     Violations: 0                    Mean Train Rewards: 64.1\n",
            "Episode: 460 |                     Train Rewards: 79.6                     Violations: 0                    Mean Train Rewards: 65.1\n",
            "Episode: 470 |                     Train Rewards: 10.3                     Violations: 0.6287658214569092                    Mean Train Rewards: 67.8\n",
            "Episode: 480 |                     Train Rewards: 70.8                     Violations: 0.13494729995726829                    Mean Train Rewards: 69.1\n",
            "Episode: 490 |                     Train Rewards: 12.3                     Violations: 0                    Mean Train Rewards: 70.8\n",
            "Episode: 500 |                     Train Rewards: 59.1                     Violations: 0                    Mean Train Rewards: 70.3\n",
            "Episode: 510 |                     Train Rewards: 129.4                     Violations: 0                    Mean Train Rewards: 69.0\n",
            "Episode: 520 |                     Train Rewards: 86.7                     Violations: 0                    Mean Train Rewards: 70.0\n",
            "Episode: 530 |                     Train Rewards: 124.2                     Violations: 0                    Mean Train Rewards: 72.4\n",
            "Episode: 540 |                     Train Rewards: 162.8                     Violations: 0                    Mean Train Rewards: 75.8\n",
            "Episode: 550 |                     Train Rewards: 96.0                     Violations: 0                    Mean Train Rewards: 72.8\n",
            "Episode: 560 |                     Train Rewards: 126.2                     Violations: 0                    Mean Train Rewards: 76.8\n",
            "Episode: 570 |                     Train Rewards: 73.1                     Violations: 0                    Mean Train Rewards: 73.7\n",
            "Episode: 580 |                     Train Rewards: 11.4                     Violations: 0                    Mean Train Rewards: 72.4\n",
            "Episode: 590 |                     Train Rewards: 103.7                     Violations: 0                    Mean Train Rewards: 76.2\n",
            "Episode: 600 |                     Train Rewards: 50.6                     Violations: 0                    Mean Train Rewards: 77.2\n",
            "Episode: 610 |                     Train Rewards: 112.0                     Violations: 0                    Mean Train Rewards: 78.8\n",
            "Episode: 620 |                     Train Rewards: 64.7                     Violations: 0                    Mean Train Rewards: 76.9\n",
            "Episode: 630 |                     Train Rewards: 140.3                     Violations: 0                    Mean Train Rewards: 73.4\n",
            "Episode: 640 |                     Train Rewards: 120.6                     Violations: 0                    Mean Train Rewards: 72.0\n",
            "Episode: 650 |                     Train Rewards: 120.1                     Violations: 0                    Mean Train Rewards: 74.5\n",
            "Episode: 660 |                     Train Rewards: 103.0                     Violations: 0                    Mean Train Rewards: 71.6\n",
            "Episode: 670 |                     Train Rewards: 46.3                     Violations: 0.47284603118896484                    Mean Train Rewards: 74.5\n",
            "Episode: 680 |                     Train Rewards: 67.1                     Violations: 0                    Mean Train Rewards: 78.7\n",
            "Episode: 690 |                     Train Rewards: -1.0                     Violations: 0.5469822883605886                    Mean Train Rewards: 78.4\n",
            "Episode: 700 |                     Train Rewards: 20.6                     Violations: 0.8240604400634837                    Mean Train Rewards: 80.5\n",
            "Episode: 710 |                     Train Rewards: 91.1                     Violations: 0                    Mean Train Rewards: 80.8\n",
            "Episode: 720 |                     Train Rewards: 80.5                     Violations: 0.19974946975708008                    Mean Train Rewards: 85.2\n",
            "Episode: 730 |                     Train Rewards: 136.1                     Violations: 0                    Mean Train Rewards: 87.4\n",
            "Episode: 740 |                     Train Rewards: 90.1                     Violations: 0.1877152919769287                    Mean Train Rewards: 88.3\n",
            "Episode: 750 |                     Train Rewards: 110.4                     Violations: 0                    Mean Train Rewards: 92.7\n",
            "Episode: 760 |                     Train Rewards: 63.3                     Violations: 0                    Mean Train Rewards: 92.9\n",
            "Episode: 770 |                     Train Rewards: 70.8                     Violations: 0                    Mean Train Rewards: 92.0\n",
            "Episode: 780 |                     Train Rewards: 48.3                     Violations: 0                    Mean Train Rewards: 89.5\n",
            "Episode: 790 |                     Train Rewards: 92.6                     Violations: 0                    Mean Train Rewards: 89.7\n",
            "Episode: 800 |                     Train Rewards: 127.1                     Violations: 0                    Mean Train Rewards: 91.8\n",
            "Episode: 810 |                     Train Rewards: 59.7                     Violations: 0                    Mean Train Rewards: 91.4\n",
            "Episode: 820 |                     Train Rewards: 78.4                     Violations: 0                    Mean Train Rewards: 89.6\n",
            "Episode: 830 |                     Train Rewards: 20.0                     Violations: 0                    Mean Train Rewards: 85.3\n",
            "Episode: 840 |                     Train Rewards: 68.3                     Violations: 0                    Mean Train Rewards: 81.3\n",
            "Episode: 850 |                     Train Rewards: 45.5                     Violations: 0                    Mean Train Rewards: 74.9\n",
            "Episode: 860 |                     Train Rewards: 47.6                     Violations: 0                    Mean Train Rewards: 71.8\n",
            "Episode: 870 |                     Train Rewards: 129.6                     Violations: 0                    Mean Train Rewards: 74.8\n",
            "Episode: 880 |                     Train Rewards: 70.2                     Violations: 0                    Mean Train Rewards: 77.4\n",
            "Episode: 890 |                     Train Rewards: 52.8                     Violations: 0                    Mean Train Rewards: 70.9\n",
            "Episode: 900 |                     Train Rewards: 69.1                     Violations: 0                    Mean Train Rewards: 67.5\n",
            "Episode: 910 |                     Train Rewards: 68.0                     Violations: 0                    Mean Train Rewards: 65.2\n",
            "Episode: 920 |                     Train Rewards: 104.9                     Violations: 0                    Mean Train Rewards: 67.1\n",
            "Episode: 930 |                     Train Rewards: 86.3                     Violations: 0                    Mean Train Rewards: 72.4\n",
            "Episode: 940 |                     Train Rewards: -89.2                     Violations: 1.9569182395935059                    Mean Train Rewards: 75.3\n",
            "Episode: 950 |                     Train Rewards: -187.2                     Violations: 3.021075725555413                    Mean Train Rewards: 77.0\n",
            "Episode: 960 |                     Train Rewards: 90.3                     Violations: 0                    Mean Train Rewards: 78.1\n",
            "Episode: 970 |                     Train Rewards: 89.4                     Violations: 0                    Mean Train Rewards: 75.9\n",
            "Episode: 980 |                     Train Rewards: 77.7                     Violations: 0                    Mean Train Rewards: 72.7\n",
            "Episode: 990 |                     Train Rewards: 131.8                     Violations: 0                    Mean Train Rewards: 79.6\n",
            "Episode: 1000 |                     Train Rewards: 89.5                     Violations: 0                    Mean Train Rewards: 82.5\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 16 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 16 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-29/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-30\n",
            "\n",
            "==================================================\n",
            "Starting run 7/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 128, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: 65.3                     Violations: 0                    Mean Train Rewards: -1365.6\n",
            "Episode:  20 |                     Train Rewards: -154.2                     Violations: 2.309706211090088                    Mean Train Rewards: -828.3\n",
            "Episode:  30 |                     Train Rewards: 19.6                     Violations: 0.25286316871643066                    Mean Train Rewards: -570.5\n",
            "Episode:  40 |                     Train Rewards: -300.9                     Violations: 3.046302795410142                    Mean Train Rewards: -513.1\n",
            "Episode:  50 |                     Train Rewards: 40.1                     Violations: 0                    Mean Train Rewards: -419.9\n",
            "Episode:  60 |                     Train Rewards: -273.4                     Violations: 3.4096527099609375                    Mean Train Rewards: -367.5\n",
            "Episode:  70 |                     Train Rewards: -193.1                     Violations: 2.9426658153533936                    Mean Train Rewards: -333.5\n",
            "Episode:  80 |                     Train Rewards: -7.0                     Violations: 0                    Mean Train Rewards: -294.0\n",
            "Episode:  90 |                     Train Rewards: 103.9                     Violations: 0                    Mean Train Rewards: -265.8\n",
            "Episode: 100 |                     Train Rewards: -94.3                     Violations: 1.8495523929595876                    Mean Train Rewards: -249.2\n",
            "Episode: 110 |                     Train Rewards: 82.8                     Violations: 0                    Mean Train Rewards: -114.0\n",
            "Episode: 120 |                     Train Rewards: -32.7                     Violations: 1.465209722518921                    Mean Train Rewards: -98.4\n",
            "Episode: 130 |                     Train Rewards: 34.6                     Violations: 0                    Mean Train Rewards: -109.2\n",
            "Episode: 140 |                     Train Rewards: 54.7                     Violations: 0                    Mean Train Rewards: -73.5\n",
            "Episode: 150 |                     Train Rewards: 86.4                     Violations: 0                    Mean Train Rewards: -67.8\n",
            "Episode: 160 |                     Train Rewards: 95.8                     Violations: 0                    Mean Train Rewards: -58.7\n",
            "Episode: 170 |                     Train Rewards: -331.3                     Violations: 3.978564739227302                    Mean Train Rewards: -46.7\n",
            "Episode: 180 |                     Train Rewards: -176.5                     Violations: 2.256503105163574                    Mean Train Rewards: -47.4\n",
            "Episode: 190 |                     Train Rewards: 30.3                     Violations: 0.25235652923584695                    Mean Train Rewards: -45.7\n",
            "Episode: 200 |                     Train Rewards: 71.1                     Violations: 0                    Mean Train Rewards: -30.1\n",
            "Episode: 210 |                     Train Rewards: 58.8                     Violations: 0                    Mean Train Rewards: -29.3\n",
            "Episode: 220 |                     Train Rewards: -165.8                     Violations: 2.44042515754699                    Mean Train Rewards: -12.8\n",
            "Episode: 230 |                     Train Rewards: 13.1                     Violations: 0.6615185737609863                    Mean Train Rewards: -0.1\n",
            "Episode: 240 |                     Train Rewards: 85.1                     Violations: 0                    Mean Train Rewards: 3.0\n",
            "Episode: 250 |                     Train Rewards: 90.0                     Violations: 0                    Mean Train Rewards: 7.4\n",
            "Episode: 260 |                     Train Rewards: 127.8                     Violations: 0                    Mean Train Rewards: 14.9\n",
            "Episode: 270 |                     Train Rewards: 20.9                     Violations: 0                    Mean Train Rewards: 20.6\n",
            "Episode: 280 |                     Train Rewards: 63.2                     Violations: 0                    Mean Train Rewards: 25.2\n",
            "Episode: 290 |                     Train Rewards: 98.8                     Violations: 0                    Mean Train Rewards: 34.3\n",
            "Episode: 300 |                     Train Rewards: -215.6                     Violations: 2.5601279735565114                    Mean Train Rewards: 28.8\n",
            "Episode: 310 |                     Train Rewards: 82.6                     Violations: 0                    Mean Train Rewards: 31.4\n",
            "Episode: 320 |                     Train Rewards: 98.7                     Violations: 0                    Mean Train Rewards: 35.6\n",
            "Episode: 330 |                     Train Rewards: -117.9                     Violations: 1.4939677715301514                    Mean Train Rewards: 44.6\n",
            "Episode: 340 |                     Train Rewards: 119.1                     Violations: 0                    Mean Train Rewards: 41.9\n",
            "Episode: 350 |                     Train Rewards: 74.0                     Violations: 0                    Mean Train Rewards: 44.6\n",
            "Episode: 360 |                     Train Rewards: 99.1                     Violations: 0                    Mean Train Rewards: 46.5\n",
            "Episode: 370 |                     Train Rewards: 25.6                     Violations: 0.48777103424072266                    Mean Train Rewards: 45.0\n",
            "Episode: 380 |                     Train Rewards: 82.7                     Violations: 0                    Mean Train Rewards: 48.8\n",
            "Episode: 390 |                     Train Rewards: 73.5                     Violations: 0                    Mean Train Rewards: 47.4\n",
            "Episode: 400 |                     Train Rewards: 107.7                     Violations: 0                    Mean Train Rewards: 54.3\n",
            "Episode: 410 |                     Train Rewards: 126.5                     Violations: 0                    Mean Train Rewards: 60.9\n",
            "Episode: 420 |                     Train Rewards: 30.5                     Violations: 0                    Mean Train Rewards: 61.2\n",
            "Episode: 430 |                     Train Rewards: 89.1                     Violations: 0                    Mean Train Rewards: 62.8\n",
            "Episode: 440 |                     Train Rewards: 106.5                     Violations: 0                    Mean Train Rewards: 67.2\n",
            "Episode: 450 |                     Train Rewards: 132.9                     Violations: 0                    Mean Train Rewards: 67.3\n",
            "Episode: 460 |                     Train Rewards: 87.4                     Violations: 0                    Mean Train Rewards: 66.7\n",
            "Episode: 470 |                     Train Rewards: -75.8                     Violations: 1.5801572799682617                    Mean Train Rewards: 72.2\n",
            "Episode: 480 |                     Train Rewards: 111.1                     Violations: 0                    Mean Train Rewards: 71.6\n",
            "Episode: 490 |                     Train Rewards: 40.7                     Violations: 0                    Mean Train Rewards: 73.3\n",
            "Episode: 500 |                     Train Rewards: 69.3                     Violations: 0                    Mean Train Rewards: 73.1\n",
            "Episode: 510 |                     Train Rewards: 125.8                     Violations: 0                    Mean Train Rewards: 71.4\n",
            "Episode: 520 |                     Train Rewards: 82.3                     Violations: 0                    Mean Train Rewards: 71.3\n",
            "Episode: 530 |                     Train Rewards: 120.9                     Violations: 0                    Mean Train Rewards: 75.2\n",
            "Episode: 540 |                     Train Rewards: 143.1                     Violations: 0                    Mean Train Rewards: 79.0\n",
            "Episode: 550 |                     Train Rewards: 100.3                     Violations: 0                    Mean Train Rewards: 79.6\n",
            "Episode: 560 |                     Train Rewards: 148.5                     Violations: 0                    Mean Train Rewards: 83.7\n",
            "Episode: 570 |                     Train Rewards: 120.1                     Violations: 0                    Mean Train Rewards: 81.1\n",
            "Episode: 580 |                     Train Rewards: 35.6                     Violations: 0                    Mean Train Rewards: 82.6\n",
            "Episode: 590 |                     Train Rewards: 109.7                     Violations: 0                    Mean Train Rewards: 84.4\n",
            "Episode: 600 |                     Train Rewards: 55.0                     Violations: 0                    Mean Train Rewards: 84.3\n",
            "Episode: 610 |                     Train Rewards: 94.7                     Violations: 0                    Mean Train Rewards: 85.5\n",
            "Episode: 620 |                     Train Rewards: 65.7                     Violations: 0                    Mean Train Rewards: 84.7\n",
            "Episode: 630 |                     Train Rewards: 129.8                     Violations: 0                    Mean Train Rewards: 82.8\n",
            "Episode: 640 |                     Train Rewards: 113.9                     Violations: 0                    Mean Train Rewards: 81.1\n",
            "Episode: 650 |                     Train Rewards: 141.1                     Violations: 0                    Mean Train Rewards: 81.4\n",
            "Episode: 660 |                     Train Rewards: 137.4                     Violations: 0                    Mean Train Rewards: 74.6\n",
            "Episode: 670 |                     Train Rewards: 49.0                     Violations: 0.41113734245300293                    Mean Train Rewards: 72.8\n",
            "Episode: 680 |                     Train Rewards: 112.4                     Violations: 0                    Mean Train Rewards: 75.8\n",
            "Episode: 690 |                     Train Rewards: -198.7                     Violations: 2.8200888633727956                    Mean Train Rewards: 69.3\n",
            "Episode: 700 |                     Train Rewards: 28.5                     Violations: 0.6915414333343506                    Mean Train Rewards: 70.5\n",
            "Episode: 710 |                     Train Rewards: 92.8                     Violations: 0                    Mean Train Rewards: 72.2\n",
            "Episode: 720 |                     Train Rewards: 53.0                     Violations: 0.48972606658935547                    Mean Train Rewards: 75.9\n",
            "Episode: 730 |                     Train Rewards: 139.4                     Violations: 0                    Mean Train Rewards: 76.3\n",
            "Episode: 740 |                     Train Rewards: 66.0                     Violations: 0.44673919677734375                    Mean Train Rewards: 76.5\n",
            "Episode: 750 |                     Train Rewards: 108.4                     Violations: 0                    Mean Train Rewards: 79.8\n",
            "Episode: 760 |                     Train Rewards: 79.6                     Violations: 0                    Mean Train Rewards: 84.2\n",
            "Episode: 770 |                     Train Rewards: 79.3                     Violations: 0                    Mean Train Rewards: 89.1\n",
            "Episode: 780 |                     Train Rewards: 69.6                     Violations: 0                    Mean Train Rewards: 87.3\n",
            "Episode: 790 |                     Train Rewards: 103.3                     Violations: 0                    Mean Train Rewards: 94.9\n",
            "Episode: 800 |                     Train Rewards: 102.2                     Violations: 0                    Mean Train Rewards: 96.2\n",
            "Episode: 810 |                     Train Rewards: 64.7                     Violations: 0                    Mean Train Rewards: 97.7\n",
            "Episode: 820 |                     Train Rewards: 92.3                     Violations: 0                    Mean Train Rewards: 96.3\n",
            "Episode: 830 |                     Train Rewards: 38.5                     Violations: 0                    Mean Train Rewards: 93.9\n",
            "Episode: 840 |                     Train Rewards: 58.2                     Violations: 0                    Mean Train Rewards: 91.2\n",
            "Episode: 850 |                     Train Rewards: 51.3                     Violations: 0                    Mean Train Rewards: 84.8\n",
            "Episode: 860 |                     Train Rewards: 65.5                     Violations: 0                    Mean Train Rewards: 81.8\n",
            "Episode: 870 |                     Train Rewards: 97.3                     Violations: 0                    Mean Train Rewards: 80.8\n",
            "Episode: 880 |                     Train Rewards: 69.9                     Violations: 0                    Mean Train Rewards: 80.8\n",
            "Episode: 890 |                     Train Rewards: 55.4                     Violations: 0                    Mean Train Rewards: 74.6\n",
            "Episode: 900 |                     Train Rewards: 48.6                     Violations: 0                    Mean Train Rewards: 70.4\n",
            "Episode: 910 |                     Train Rewards: 56.9                     Violations: 0                    Mean Train Rewards: 64.5\n",
            "Episode: 920 |                     Train Rewards: 72.9                     Violations: 0                    Mean Train Rewards: 64.1\n",
            "Episode: 930 |                     Train Rewards: 76.6                     Violations: 0                    Mean Train Rewards: 67.5\n",
            "Episode: 940 |                     Train Rewards: -51.4                     Violations: 1.524718999862671                    Mean Train Rewards: 71.4\n",
            "Episode: 950 |                     Train Rewards: -183.8                     Violations: 2.9911303520202637                    Mean Train Rewards: 74.3\n",
            "Episode: 960 |                     Train Rewards: 124.2                     Violations: 0                    Mean Train Rewards: 75.9\n",
            "Episode: 970 |                     Train Rewards: 122.9                     Violations: 0                    Mean Train Rewards: 76.4\n",
            "Episode: 980 |                     Train Rewards: 93.7                     Violations: 0                    Mean Train Rewards: 78.0\n",
            "Episode: 990 |                     Train Rewards: 125.1                     Violations: 0                    Mean Train Rewards: 84.1\n",
            "Episode: 1000 |                     Train Rewards: 98.7                     Violations: 0                    Mean Train Rewards: 89.1\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 6 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-30/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-31\n",
            "\n",
            "==================================================\n",
            "Starting run 8/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.003, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 32, 'PPO_STEPS': 8, 'BATCH_SIZE': 128, 'DISCOUNT_FACTOR': 0.95, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -22.9                     Violations: 0                    Mean Train Rewards: -1026.8\n",
            "Episode:  20 |                     Train Rewards: -722.6                     Violations: 7.619483470916748                    Mean Train Rewards: -630.2\n",
            "Episode:  30 |                     Train Rewards: -117.0                     Violations: 1.723043918609612                    Mean Train Rewards: -422.4\n",
            "Episode:  40 |                     Train Rewards: -478.3                     Violations: 5.085991621017456                    Mean Train Rewards: -357.6\n",
            "Episode:  50 |                     Train Rewards: -42.0                     Violations: 0.9860479831695486                    Mean Train Rewards: -294.8\n",
            "Episode:  60 |                     Train Rewards: -300.5                     Violations: 3.7770140171051025                    Mean Train Rewards: -272.2\n",
            "Episode:  70 |                     Train Rewards: -80.5                     Violations: 1.763167381286621                    Mean Train Rewards: -259.4\n",
            "Episode:  80 |                     Train Rewards: 49.1                     Violations: 0                    Mean Train Rewards: -226.7\n",
            "Episode:  90 |                     Train Rewards: 86.8                     Violations: 0                    Mean Train Rewards: -213.9\n",
            "Episode: 100 |                     Train Rewards: -315.8                     Violations: 3.6978054046630717                    Mean Train Rewards: -201.6\n",
            "Episode: 110 |                     Train Rewards: 105.6                     Violations: 0                    Mean Train Rewards: -106.3\n",
            "Episode: 120 |                     Train Rewards: -282.6                     Violations: 3.25229883193969                    Mean Train Rewards: -101.8\n",
            "Episode: 130 |                     Train Rewards: 76.8                     Violations: 0                    Mean Train Rewards: -113.6\n",
            "Episode: 140 |                     Train Rewards: 120.8                     Violations: 0                    Mean Train Rewards: -98.2\n",
            "Episode: 150 |                     Train Rewards: 123.2                     Violations: 0                    Mean Train Rewards: -97.8\n",
            "Episode: 160 |                     Train Rewards: 118.8                     Violations: 0                    Mean Train Rewards: -91.9\n",
            "Episode: 170 |                     Train Rewards: -119.6                     Violations: 1.789005994796753                    Mean Train Rewards: -70.1\n",
            "Episode: 180 |                     Train Rewards: -81.0                     Violations: 1.4039599895477295                    Mean Train Rewards: -78.7\n",
            "Episode: 190 |                     Train Rewards: 96.2                     Violations: 0                    Mean Train Rewards: -62.4\n",
            "Episode: 200 |                     Train Rewards: -28.6                     Violations: 1.1724019050598145                    Mean Train Rewards: -47.8\n",
            "Episode: 210 |                     Train Rewards: 21.3                     Violations: 0                    Mean Train Rewards: -42.7\n",
            "Episode: 220 |                     Train Rewards: 121.2                     Violations: 0                    Mean Train Rewards: -15.5\n",
            "Episode: 230 |                     Train Rewards: 117.7                     Violations: 0                    Mean Train Rewards: 0.3\n",
            "Episode: 240 |                     Train Rewards: 136.4                     Violations: 0                    Mean Train Rewards: 4.6\n",
            "Episode: 250 |                     Train Rewards: 137.5                     Violations: 0                    Mean Train Rewards: 10.2\n",
            "Episode: 260 |                     Train Rewards: -1.2                     Violations: 1.3348543643951416                    Mean Train Rewards: 20.5\n",
            "Episode: 270 |                     Train Rewards: 31.6                     Violations: 0                    Mean Train Rewards: 20.8\n",
            "Episode: 280 |                     Train Rewards: 51.2                     Violations: 0                    Mean Train Rewards: 36.1\n",
            "Episode: 290 |                     Train Rewards: 143.6                     Violations: 0                    Mean Train Rewards: 40.8\n",
            "Episode: 300 |                     Train Rewards: -1214.3                     Violations: 12.142632007598877                    Mean Train Rewards: 18.6\n",
            "Episode: 310 |                     Train Rewards: 115.2                     Violations: 0                    Mean Train Rewards: 21.2\n",
            "Episode: 320 |                     Train Rewards: 119.2                     Violations: 0                    Mean Train Rewards: 16.6\n",
            "Episode: 330 |                     Train Rewards: 126.5                     Violations: 0                    Mean Train Rewards: 18.5\n",
            "Episode: 340 |                     Train Rewards: 134.9                     Violations: 0                    Mean Train Rewards: 22.3\n",
            "Episode: 350 |                     Train Rewards: 44.7                     Violations: 0                    Mean Train Rewards: 27.3\n",
            "Episode: 360 |                     Train Rewards: 74.5                     Violations: 0                    Mean Train Rewards: 34.3\n",
            "Episode: 370 |                     Train Rewards: 98.2                     Violations: 0                    Mean Train Rewards: 36.5\n",
            "Episode: 380 |                     Train Rewards: 85.6                     Violations: 0                    Mean Train Rewards: 35.0\n",
            "Episode: 390 |                     Train Rewards: 91.3                     Violations: 0                    Mean Train Rewards: 32.5\n",
            "Episode: 400 |                     Train Rewards: 143.3                     Violations: 0                    Mean Train Rewards: 57.9\n",
            "Episode: 410 |                     Train Rewards: 111.0                     Violations: 0                    Mean Train Rewards: 67.1\n",
            "Episode: 420 |                     Train Rewards: 26.6                     Violations: 0                    Mean Train Rewards: 70.4\n",
            "Episode: 430 |                     Train Rewards: 86.8                     Violations: 0                    Mean Train Rewards: 75.2\n",
            "Episode: 440 |                     Train Rewards: 112.1                     Violations: 0                    Mean Train Rewards: 75.0\n",
            "Episode: 450 |                     Train Rewards: -57.0                     Violations: 1.3383853435516357                    Mean Train Rewards: 78.1\n",
            "Episode: 460 |                     Train Rewards: 52.0                     Violations: 0                    Mean Train Rewards: 76.7\n",
            "Episode: 470 |                     Train Rewards: 17.1                     Violations: 0.6574654579162527                    Mean Train Rewards: 78.2\n",
            "Episode: 480 |                     Train Rewards: 113.6                     Violations: 0                    Mean Train Rewards: 76.6\n",
            "Episode: 490 |                     Train Rewards: 12.5                     Violations: 0                    Mean Train Rewards: 73.4\n",
            "Episode: 500 |                     Train Rewards: 61.3                     Violations: 0                    Mean Train Rewards: 71.1\n",
            "Episode: 510 |                     Train Rewards: 127.5                     Violations: 0                    Mean Train Rewards: 66.5\n",
            "Episode: 520 |                     Train Rewards: 67.0                     Violations: 0                    Mean Train Rewards: 63.5\n",
            "Episode: 530 |                     Train Rewards: 98.7                     Violations: 0                    Mean Train Rewards: 57.5\n",
            "Episode: 540 |                     Train Rewards: -252.6                     Violations: 2.913160324096687                    Mean Train Rewards: 51.6\n",
            "Episode: 550 |                     Train Rewards: 109.5                     Violations: 0                    Mean Train Rewards: 38.9\n",
            "Episode: 560 |                     Train Rewards: -468.5                     Violations: 5.029995441436775                    Mean Train Rewards: 32.9\n",
            "Episode: 570 |                     Train Rewards: 89.9                     Violations: 0                    Mean Train Rewards: 16.0\n",
            "Episode: 580 |                     Train Rewards: 33.8                     Violations: 0                    Mean Train Rewards: 15.4\n",
            "Episode: 590 |                     Train Rewards: 136.1                     Violations: 0                    Mean Train Rewards: 17.7\n",
            "Episode: 600 |                     Train Rewards: 50.1                     Violations: 0                    Mean Train Rewards: 13.9\n",
            "Episode: 610 |                     Train Rewards: 103.1                     Violations: 0                    Mean Train Rewards: 15.8\n",
            "Episode: 620 |                     Train Rewards: 88.7                     Violations: 0                    Mean Train Rewards: 17.8\n",
            "Episode: 630 |                     Train Rewards: 144.1                     Violations: 0                    Mean Train Rewards: 21.1\n",
            "Episode: 640 |                     Train Rewards: 84.3                     Violations: 0                    Mean Train Rewards: 29.1\n",
            "Episode: 650 |                     Train Rewards: 128.0                     Violations: 0                    Mean Train Rewards: 39.6\n",
            "Episode: 660 |                     Train Rewards: 94.4                     Violations: 0                    Mean Train Rewards: 47.0\n",
            "Episode: 670 |                     Train Rewards: 58.0                     Violations: 0.3835642337799072                    Mean Train Rewards: 66.4\n",
            "Episode: 680 |                     Train Rewards: 69.5                     Violations: 0                    Mean Train Rewards: 70.6\n",
            "Episode: 690 |                     Train Rewards: 39.9                     Violations: 0                    Mean Train Rewards: 73.8\n",
            "Episode: 700 |                     Train Rewards: 61.0                     Violations: 0.46073436737059836                    Mean Train Rewards: 77.5\n",
            "Episode: 710 |                     Train Rewards: 79.1                     Violations: 0                    Mean Train Rewards: 78.5\n",
            "Episode: 720 |                     Train Rewards: 15.1                     Violations: 1.0628962516784668                    Mean Train Rewards: 82.7\n",
            "Episode: 730 |                     Train Rewards: 104.0                     Violations: 0.15206575393676047                    Mean Train Rewards: 85.3\n",
            "Episode: 740 |                     Train Rewards: -40.0                     Violations: 1.2164044380187988                    Mean Train Rewards: 85.0\n",
            "Episode: 750 |                     Train Rewards: 144.9                     Violations: 0                    Mean Train Rewards: 90.7\n",
            "Episode: 760 |                     Train Rewards: 67.4                     Violations: 0                    Mean Train Rewards: 91.6\n",
            "Episode: 770 |                     Train Rewards: 100.5                     Violations: 0                    Mean Train Rewards: 91.1\n",
            "Episode: 780 |                     Train Rewards: 67.5                     Violations: 0                    Mean Train Rewards: 93.5\n",
            "Episode: 790 |                     Train Rewards: 135.3                     Violations: 0                    Mean Train Rewards: 93.5\n",
            "Episode: 800 |                     Train Rewards: 119.5                     Violations: 0                    Mean Train Rewards: 95.6\n",
            "Episode: 810 |                     Train Rewards: 46.6                     Violations: 0                    Mean Train Rewards: 92.1\n",
            "Episode: 820 |                     Train Rewards: 80.1                     Violations: 0.037016868591308594                    Mean Train Rewards: 89.2\n",
            "Episode: 830 |                     Train Rewards: 30.4                     Violations: 0                    Mean Train Rewards: 87.1\n",
            "Episode: 840 |                     Train Rewards: 96.5                     Violations: 0                    Mean Train Rewards: 83.0\n",
            "Episode: 850 |                     Train Rewards: 71.2                     Violations: 0                    Mean Train Rewards: 78.1\n",
            "Episode: 860 |                     Train Rewards: 74.3                     Violations: 0                    Mean Train Rewards: 77.9\n",
            "Episode: 870 |                     Train Rewards: 73.8                     Violations: 0.23773550987242942                    Mean Train Rewards: 78.3\n",
            "Episode: 880 |                     Train Rewards: 72.3                     Violations: 0                    Mean Train Rewards: 78.0\n",
            "Episode: 890 |                     Train Rewards: 30.7                     Violations: 0                    Mean Train Rewards: 70.5\n",
            "Episode: 900 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 68.4\n",
            "Episode: 910 |                     Train Rewards: 108.4                     Violations: 0                    Mean Train Rewards: 67.7\n",
            "Episode: 920 |                     Train Rewards: 47.3                     Violations: 0                    Mean Train Rewards: 65.6\n",
            "Episode: 930 |                     Train Rewards: -3.4                     Violations: 0                    Mean Train Rewards: 63.8\n",
            "Episode: 940 |                     Train Rewards: -13.6                     Violations: 0.7991516590118408                    Mean Train Rewards: 66.8\n",
            "Episode: 950 |                     Train Rewards: -216.2                     Violations: 3.1095945835113525                    Mean Train Rewards: 63.1\n",
            "Episode: 960 |                     Train Rewards: 115.7                     Violations: 0                    Mean Train Rewards: 55.0\n",
            "Episode: 970 |                     Train Rewards: 81.2                     Violations: 0                    Mean Train Rewards: 50.5\n",
            "Episode: 980 |                     Train Rewards: 93.8                     Violations: 0                    Mean Train Rewards: 47.0\n",
            "Episode: 990 |                     Train Rewards: 45.1                     Violations: 0.6624186038970947                    Mean Train Rewards: 47.1\n",
            "Episode: 1000 |                     Train Rewards: 73.3                     Violations: 0                    Mean Train Rewards: 50.5\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 6 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-31/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-32\n",
            "\n",
            "==================================================\n",
            "Starting run 9/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: 31.2                     Violations: 35.32756328582764                    Mean Train Rewards: 7.8\n",
            "Episode:  20 |                     Train Rewards: -37.6                     Violations: 0                    Mean Train Rewards: 3.5\n",
            "Episode:  30 |                     Train Rewards: 17.5                     Violations: 0.13150811195373535                    Mean Train Rewards: 1.3\n",
            "Episode:  40 |                     Train Rewards: 0.0                     Violations: 4.278306961059577                    Mean Train Rewards: 4.4\n",
            "Episode:  50 |                     Train Rewards: 26.5                     Violations: 1.3663792610168457                    Mean Train Rewards: 4.9\n",
            "Episode:  60 |                     Train Rewards: 32.2                     Violations: 11.237152814865112                    Mean Train Rewards: 5.9\n",
            "Episode:  70 |                     Train Rewards: 0.0                     Violations: 20.77686667442321                    Mean Train Rewards: 5.3\n",
            "Episode:  80 |                     Train Rewards: 0.0                     Violations: 27.79796600341797                    Mean Train Rewards: 5.7\n",
            "Episode:  90 |                     Train Rewards: 1.8                     Violations: 4.54426646232605                    Mean Train Rewards: 5.9\n",
            "Episode: 100 |                     Train Rewards: -13.4                     Violations: 1.4264845848083496                    Mean Train Rewards: 6.9\n",
            "Episode: 110 |                     Train Rewards: 16.8                     Violations: 1.113119125366211                    Mean Train Rewards: 9.5\n",
            "Episode: 120 |                     Train Rewards: 0.0                     Violations: 12.34248161315918                    Mean Train Rewards: 10.5\n",
            "Episode: 130 |                     Train Rewards: -2.2                     Violations: 4.367026090621948                    Mean Train Rewards: 13.2\n",
            "Episode: 140 |                     Train Rewards: 45.3                     Violations: 0.18912792205809836                    Mean Train Rewards: 13.3\n",
            "Episode: 150 |                     Train Rewards: 32.3                     Violations: 4.90214467048645                    Mean Train Rewards: 15.4\n",
            "Episode: 160 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 15.8\n",
            "Episode: 170 |                     Train Rewards: 19.4                     Violations: 0.12899279594421387                    Mean Train Rewards: 16.8\n",
            "Episode: 180 |                     Train Rewards: 18.3                     Violations: 0                    Mean Train Rewards: 17.6\n",
            "Episode: 190 |                     Train Rewards: 0.0                     Violations: 12.482469081878662                    Mean Train Rewards: 18.4\n",
            "Episode: 200 |                     Train Rewards: 41.8                     Violations: 0.21174192428588157                    Mean Train Rewards: 19.2\n",
            "Episode: 210 |                     Train Rewards: -22.1                     Violations: 0.2318406105041504                    Mean Train Rewards: 17.2\n",
            "Episode: 220 |                     Train Rewards: 58.4                     Violations: 0                    Mean Train Rewards: 18.2\n",
            "Episode: 230 |                     Train Rewards: 0.7                     Violations: 2.3264729976654053                    Mean Train Rewards: 18.7\n",
            "Episode: 240 |                     Train Rewards: 32.6                     Violations: 0.9157979488372803                    Mean Train Rewards: 18.8\n",
            "Episode: 250 |                     Train Rewards: 43.5                     Violations: 0                    Mean Train Rewards: 18.1\n",
            "Episode: 260 |                     Train Rewards: 30.1                     Violations: 0                    Mean Train Rewards: 19.5\n",
            "Episode: 270 |                     Train Rewards: 58.0                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 280 |                     Train Rewards: 23.1                     Violations: 0                    Mean Train Rewards: 23.3\n",
            "Episode: 290 |                     Train Rewards: 35.8                     Violations: 3.3441686630249023                    Mean Train Rewards: 23.7\n",
            "Episode: 300 |                     Train Rewards: 18.5                     Violations: 0                    Mean Train Rewards: 24.4\n",
            "Episode: 310 |                     Train Rewards: -33.3                     Violations: 0                    Mean Train Rewards: 24.3\n",
            "Episode: 320 |                     Train Rewards: 1.1                     Violations: 0                    Mean Train Rewards: 22.1\n",
            "Episode: 330 |                     Train Rewards: 55.0                     Violations: 0                    Mean Train Rewards: 20.6\n",
            "Episode: 340 |                     Train Rewards: 13.3                     Violations: 4.691007137298584                    Mean Train Rewards: 19.5\n",
            "Episode: 350 |                     Train Rewards: 30.3                     Violations: 0                    Mean Train Rewards: 20.0\n",
            "Episode: 360 |                     Train Rewards: 19.5                     Violations: 3.4133994579315186                    Mean Train Rewards: 20.7\n",
            "Episode: 370 |                     Train Rewards: 5.1                     Violations: 2.6864492893218994                    Mean Train Rewards: 20.5\n",
            "Episode: 380 |                     Train Rewards: 32.5                     Violations: 0.23081541061401367                    Mean Train Rewards: 20.1\n",
            "Episode: 390 |                     Train Rewards: 1.7                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 400 |                     Train Rewards: 11.5                     Violations: 0                    Mean Train Rewards: 22.0\n",
            "Episode: 410 |                     Train Rewards: 30.0                     Violations: 0.7748925685882568                    Mean Train Rewards: 24.4\n",
            "Episode: 420 |                     Train Rewards: 63.9                     Violations: 0                    Mean Train Rewards: 27.6\n",
            "Episode: 430 |                     Train Rewards: 33.8                     Violations: 0                    Mean Train Rewards: 28.8\n",
            "Episode: 440 |                     Train Rewards: 38.8                     Violations: 3.1067097187042307                    Mean Train Rewards: 30.3\n",
            "Episode: 450 |                     Train Rewards: 31.6                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 460 |                     Train Rewards: 2.0                     Violations: 0.5039656162261963                    Mean Train Rewards: 31.2\n",
            "Episode: 470 |                     Train Rewards: 48.7                     Violations: 0                    Mean Train Rewards: 32.3\n",
            "Episode: 480 |                     Train Rewards: 27.0                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 490 |                     Train Rewards: 12.4                     Violations: 0                    Mean Train Rewards: 32.9\n",
            "Episode: 500 |                     Train Rewards: 45.5                     Violations: 0                    Mean Train Rewards: 31.6\n",
            "Episode: 510 |                     Train Rewards: 63.1                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 520 |                     Train Rewards: 29.5                     Violations: 0.0705564022064209                    Mean Train Rewards: 32.2\n",
            "Episode: 530 |                     Train Rewards: 23.6                     Violations: 0                    Mean Train Rewards: 31.7\n",
            "Episode: 540 |                     Train Rewards: 21.2                     Violations: 0                    Mean Train Rewards: 31.1\n",
            "Episode: 550 |                     Train Rewards: 24.7                     Violations: 2.889087200164795                    Mean Train Rewards: 30.3\n",
            "Episode: 560 |                     Train Rewards: 23.0                     Violations: 0                    Mean Train Rewards: 29.4\n",
            "Episode: 570 |                     Train Rewards: 15.8                     Violations: 1.7472290992736745                    Mean Train Rewards: 29.0\n",
            "Episode: 580 |                     Train Rewards: 22.3                     Violations: 0                    Mean Train Rewards: 27.9\n",
            "Episode: 590 |                     Train Rewards: 17.8                     Violations: 0.6643080711364746                    Mean Train Rewards: 27.7\n",
            "Episode: 600 |                     Train Rewards: 38.2                     Violations: 0.24789214134216309                    Mean Train Rewards: 29.7\n",
            "Episode: 610 |                     Train Rewards: 52.7                     Violations: 0                    Mean Train Rewards: 30.9\n",
            "Episode: 620 |                     Train Rewards: 69.7                     Violations: 0                    Mean Train Rewards: 30.8\n",
            "Episode: 630 |                     Train Rewards: 23.3                     Violations: 1.1555993556976318                    Mean Train Rewards: 32.5\n",
            "Episode: 640 |                     Train Rewards: 57.0                     Violations: 0                    Mean Train Rewards: 35.8\n",
            "Episode: 650 |                     Train Rewards: 66.9                     Violations: 0                    Mean Train Rewards: 38.3\n",
            "Episode: 660 |                     Train Rewards: 66.8                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 670 |                     Train Rewards: 21.7                     Violations: 0.8872592449188232                    Mean Train Rewards: 39.8\n",
            "Episode: 680 |                     Train Rewards: 35.8                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 690 |                     Train Rewards: 43.3                     Violations: 0                    Mean Train Rewards: 42.0\n",
            "Episode: 700 |                     Train Rewards: 31.4                     Violations: 0                    Mean Train Rewards: 39.4\n",
            "Episode: 710 |                     Train Rewards: 66.1                     Violations: 0                    Mean Train Rewards: 39.0\n",
            "Episode: 720 |                     Train Rewards: 43.2                     Violations: 0                    Mean Train Rewards: 38.7\n",
            "Episode: 730 |                     Train Rewards: 65.6                     Violations: 0                    Mean Train Rewards: 39.6\n",
            "Episode: 740 |                     Train Rewards: 52.1                     Violations: 0                    Mean Train Rewards: 37.9\n",
            "Episode: 750 |                     Train Rewards: -5.7                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 760 |                     Train Rewards: 60.7                     Violations: 0                    Mean Train Rewards: 34.6\n",
            "Episode: 770 |                     Train Rewards: 28.2                     Violations: 0.7347190380096436                    Mean Train Rewards: 35.4\n",
            "Episode: 780 |                     Train Rewards: 45.0                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 790 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 800 |                     Train Rewards: 45.4                     Violations: 0                    Mean Train Rewards: 38.9\n",
            "Episode: 810 |                     Train Rewards: 44.0                     Violations: 2.956589460372925                    Mean Train Rewards: 40.3\n",
            "Episode: 820 |                     Train Rewards: 39.8                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 830 |                     Train Rewards: 38.4                     Violations: 0                    Mean Train Rewards: 39.3\n",
            "Episode: 840 |                     Train Rewards: 22.0                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 850 |                     Train Rewards: 38.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 860 |                     Train Rewards: 57.3                     Violations: 0                    Mean Train Rewards: 41.5\n",
            "Episode: 870 |                     Train Rewards: 32.9                     Violations: 0                    Mean Train Rewards: 41.3\n",
            "Episode: 880 |                     Train Rewards: 43.4                     Violations: 0                    Mean Train Rewards: 41.0\n",
            "Episode: 890 |                     Train Rewards: 29.3                     Violations: 0                    Mean Train Rewards: 40.4\n",
            "Episode: 900 |                     Train Rewards: 80.7                     Violations: 0                    Mean Train Rewards: 40.9\n",
            "Episode: 910 |                     Train Rewards: 45.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 920 |                     Train Rewards: 43.6                     Violations: 0                    Mean Train Rewards: 41.1\n",
            "Episode: 930 |                     Train Rewards: 15.6                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 940 |                     Train Rewards: 42.0                     Violations: 0                    Mean Train Rewards: 40.1\n",
            "Episode: 950 |                     Train Rewards: 27.8                     Violations: 0                    Mean Train Rewards: 38.8\n",
            "Episode: 960 |                     Train Rewards: 38.8                     Violations: 0                    Mean Train Rewards: 37.5\n",
            "Episode: 970 |                     Train Rewards: 30.0                     Violations: 0                    Mean Train Rewards: 37.7\n",
            "Episode: 980 |                     Train Rewards: 18.9                     Violations: 0                    Mean Train Rewards: 35.0\n",
            "Episode: 990 |                     Train Rewards: 28.1                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 1000 |                     Train Rewards: 2.8                     Violations: 0                    Mean Train Rewards: 30.7\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 14 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 14 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-32/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-33\n",
            "\n",
            "==================================================\n",
            "Starting run 10/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -1727.7                     Violations: 17.00602412223816                    Mean Train Rewards: -707.1\n",
            "Episode:  20 |                     Train Rewards: -52.5                     Violations: 0                    Mean Train Rewards: -622.6\n",
            "Episode:  30 |                     Train Rewards: -38.8                     Violations: 0                    Mean Train Rewards: -512.1\n",
            "Episode:  40 |                     Train Rewards: 1.8                     Violations: 0.3179931640624929                    Mean Train Rewards: -448.1\n",
            "Episode:  50 |                     Train Rewards: 0.8                     Violations: 0                    Mean Train Rewards: -371.9\n",
            "Episode:  60 |                     Train Rewards: -42.3                     Violations: 0.04182696342467551                    Mean Train Rewards: -333.5\n",
            "Episode:  70 |                     Train Rewards: -3920.4                     Violations: 39.20382261276245                    Mean Train Rewards: -579.7\n",
            "Episode:  80 |                     Train Rewards: -10129.0                     Violations: 101.29026889801027                    Mean Train Rewards: -1302.8\n",
            "Episode:  90 |                     Train Rewards: -7976.1                     Violations: 79.76141691207886                    Mean Train Rewards: -1905.6\n",
            "Episode: 100 |                     Train Rewards: -2705.1                     Violations: 27.051228284835815                    Mean Train Rewards: -2050.0\n",
            "Episode: 110 |                     Train Rewards: -11090.2                     Violations: 110.90211391448975                    Mean Train Rewards: -2824.1\n",
            "Episode: 120 |                     Train Rewards: -11290.2                     Violations: 112.90231466293335                    Mean Train Rewards: -3850.9\n",
            "Episode: 130 |                     Train Rewards: -9473.6                     Violations: 94.73578453063963                    Mean Train Rewards: -4881.7\n",
            "Episode: 140 |                     Train Rewards: -10624.5                     Violations: 106.24546527862549                    Mean Train Rewards: -5864.3\n",
            "Episode: 150 |                     Train Rewards: -11450.2                     Violations: 114.50229406356813                    Mean Train Rewards: -6639.5\n",
            "Episode: 160 |                     Train Rewards: -4928.4                     Violations: 49.283796548843384                    Mean Train Rewards: -7487.2\n",
            "Episode: 170 |                     Train Rewards: -5207.4                     Violations: 52.07449793815613                    Mean Train Rewards: -7755.2\n",
            "Episode: 180 |                     Train Rewards: -5890.5                     Violations: 58.90467882156372                    Mean Train Rewards: -7715.6\n",
            "Episode: 190 |                     Train Rewards: -9303.2                     Violations: 93.03235530853271                    Mean Train Rewards: -7770.2\n",
            "Episode: 200 |                     Train Rewards: -6603.6                     Violations: 66.03613615036011                    Mean Train Rewards: -8206.4\n",
            "Episode: 210 |                     Train Rewards: -6438.7                     Violations: 64.38650608062743                    Mean Train Rewards: -7905.9\n",
            "Episode: 220 |                     Train Rewards: -9918.5                     Violations: 99.18469905853271                    Mean Train Rewards: -7647.9\n",
            "Episode: 230 |                     Train Rewards: -10693.9                     Violations: 106.93877458572388                    Mean Train Rewards: -7677.8\n",
            "Episode: 240 |                     Train Rewards: -11839.5                     Violations: 118.39463233947752                    Mean Train Rewards: -7750.1\n",
            "Episode: 250 |                     Train Rewards: -10212.9                     Violations: 102.1290373802185                    Mean Train Rewards: -8025.6\n",
            "Episode: 260 |                     Train Rewards: -10775.6                     Violations: 107.756085395813                    Mean Train Rewards: -8242.0\n",
            "Episode: 270 |                     Train Rewards: -11204.0                     Violations: 112.04021692276002                    Mean Train Rewards: -8850.9\n",
            "Episode: 280 |                     Train Rewards: -8935.1                     Violations: 89.35088634490967                    Mean Train Rewards: -9336.6\n",
            "Episode: 290 |                     Train Rewards: -11451.5                     Violations: 114.51456069946286                    Mean Train Rewards: -9638.2\n",
            "Episode: 300 |                     Train Rewards: -9795.5                     Violations: 97.95463800430299                    Mean Train Rewards: -9860.2\n",
            "Episode: 310 |                     Train Rewards: -8982.1                     Violations: 89.82066631317139                    Mean Train Rewards: -10248.2\n",
            "Episode: 320 |                     Train Rewards: -5165.3                     Violations: 51.65264010429381                    Mean Train Rewards: -10120.1\n",
            "Episode: 330 |                     Train Rewards: -11491.8                     Violations: 114.91775035858153                    Mean Train Rewards: -9844.3\n",
            "Episode: 340 |                     Train Rewards: -10652.9                     Violations: 106.52938604354858                    Mean Train Rewards: -9697.2\n",
            "Episode: 350 |                     Train Rewards: -11002.4                     Violations: 110.02422094345096                    Mean Train Rewards: -9677.7\n",
            "Episode: 360 |                     Train Rewards: -10888.3                     Violations: 108.88298273086548                    Mean Train Rewards: -9646.7\n",
            "Episode: 370 |                     Train Rewards: -7682.5                     Violations: 76.82522058486937                    Mean Train Rewards: -9360.6\n",
            "Episode: 380 |                     Train Rewards: -10325.9                     Violations: 103.25872421264648                    Mean Train Rewards: -9144.7\n",
            "Episode: 390 |                     Train Rewards: -1511.2                     Violations: 15.44528841972351                    Mean Train Rewards: -8729.9\n",
            "Episode: 400 |                     Train Rewards: 32.1                     Violations: 0                    Mean Train Rewards: -7962.9\n",
            "Episode: 410 |                     Train Rewards: -3743.0                     Violations: 37.429553270339966                    Mean Train Rewards: -7151.0\n",
            "Episode: 420 |                     Train Rewards: -2694.8                     Violations: 26.947962045669556                    Mean Train Rewards: -6665.8\n",
            "Episode: 430 |                     Train Rewards: -3416.1                     Violations: 34.16116714477539                    Mean Train Rewards: -6151.4\n",
            "Episode: 440 |                     Train Rewards: -8716.5                     Violations: 87.16451644897462                    Mean Train Rewards: -5708.4\n",
            "Episode: 450 |                     Train Rewards: -5848.4                     Violations: 58.48363161087036                    Mean Train Rewards: -5330.8\n",
            "Episode: 460 |                     Train Rewards: -1800.3                     Violations: 18.290140628814697                    Mean Train Rewards: -4696.2\n",
            "Episode: 470 |                     Train Rewards: 80.2                     Violations: 0                    Mean Train Rewards: -3968.1\n",
            "Episode: 480 |                     Train Rewards: 12.0                     Violations: 0                    Mean Train Rewards: -3128.5\n",
            "Episode: 490 |                     Train Rewards: 0.0                     Violations: 0                    Mean Train Rewards: -2552.1\n",
            "Episode: 500 |                     Train Rewards: 7.6                     Violations: 0                    Mean Train Rewards: -2349.5\n",
            "Episode: 510 |                     Train Rewards: 28.9                     Violations: 0                    Mean Train Rewards: -2256.9\n",
            "Episode: 520 |                     Train Rewards: -173.4                     Violations: 1.8983924388885498                    Mean Train Rewards: -2065.6\n",
            "Episode: 530 |                     Train Rewards: 31.5                     Violations: 0                    Mean Train Rewards: -1802.7\n",
            "Episode: 540 |                     Train Rewards: -426.3                     Violations: 3.9474868774414134                    Mean Train Rewards: -1321.4\n",
            "Episode: 550 |                     Train Rewards: -1107.2                     Violations: 11.387583017349243                    Mean Train Rewards: -714.2\n",
            "Episode: 560 |                     Train Rewards: 1.1                     Violations: 0                    Mean Train Rewards: -335.6\n",
            "Episode: 570 |                     Train Rewards: -1023.0                     Violations: 10.438563823699951                    Mean Train Rewards: -280.9\n",
            "Episode: 580 |                     Train Rewards: 54.9                     Violations: 0                    Mean Train Rewards: -261.1\n",
            "Episode: 590 |                     Train Rewards: -447.8                     Violations: 4.542871713638306                    Mean Train Rewards: -236.8\n",
            "Episode: 600 |                     Train Rewards: -166.8                     Violations: 2.0607376098632812                    Mean Train Rewards: -237.0\n",
            "Episode: 610 |                     Train Rewards: 64.4                     Violations: 0                    Mean Train Rewards: -212.2\n",
            "Episode: 620 |                     Train Rewards: 44.2                     Violations: 0                    Mean Train Rewards: -217.4\n",
            "Episode: 630 |                     Train Rewards: -395.4                     Violations: 4.067178964614868                    Mean Train Rewards: -214.7\n",
            "Episode: 640 |                     Train Rewards: 7.4                     Violations: 0                    Mean Train Rewards: -209.0\n",
            "Episode: 650 |                     Train Rewards: 27.0                     Violations: 0                    Mean Train Rewards: -164.9\n",
            "Episode: 660 |                     Train Rewards: -439.6                     Violations: 4.396175146102912                    Mean Train Rewards: -144.8\n",
            "Episode: 670 |                     Train Rewards: -807.8                     Violations: 8.447023630142212                    Mean Train Rewards: -167.1\n",
            "Episode: 680 |                     Train Rewards: 8.6                     Violations: 0                    Mean Train Rewards: -174.3\n",
            "Episode: 690 |                     Train Rewards: 46.1                     Violations: 0                    Mean Train Rewards: -164.9\n",
            "Episode: 700 |                     Train Rewards: 54.2                     Violations: 0                    Mean Train Rewards: -138.8\n",
            "Episode: 710 |                     Train Rewards: -158.0                     Violations: 1.7465794086456228                    Mean Train Rewards: -143.4\n",
            "Episode: 720 |                     Train Rewards: 56.8                     Violations: 0                    Mean Train Rewards: -121.2\n",
            "Episode: 730 |                     Train Rewards: -219.3                     Violations: 2.48626708984375                    Mean Train Rewards: -114.1\n",
            "Episode: 740 |                     Train Rewards: 18.5                     Violations: 0.1361393928527761                    Mean Train Rewards: -115.3\n",
            "Episode: 750 |                     Train Rewards: -22.7                     Violations: 0                    Mean Train Rewards: -108.7\n",
            "Episode: 760 |                     Train Rewards: 70.0                     Violations: 0                    Mean Train Rewards: -100.4\n",
            "Episode: 770 |                     Train Rewards: 47.3                     Violations: 0                    Mean Train Rewards: -72.2\n",
            "Episode: 780 |                     Train Rewards: 22.8                     Violations: 0                    Mean Train Rewards: -62.1\n",
            "Episode: 790 |                     Train Rewards: 9.5                     Violations: 0                    Mean Train Rewards: -62.1\n",
            "Episode: 800 |                     Train Rewards: 28.8                     Violations: 0                    Mean Train Rewards: -62.6\n",
            "Episode: 810 |                     Train Rewards: -268.5                     Violations: 3.0441009998321533                    Mean Train Rewards: -55.3\n",
            "Episode: 820 |                     Train Rewards: 14.3                     Violations: 0                    Mean Train Rewards: -53.8\n",
            "Episode: 830 |                     Train Rewards: 39.7                     Violations: 0                    Mean Train Rewards: -23.7\n",
            "Episode: 840 |                     Train Rewards: 11.3                     Violations: 0                    Mean Train Rewards: -15.6\n",
            "Episode: 850 |                     Train Rewards: 36.6                     Violations: 0                    Mean Train Rewards: -10.7\n",
            "Episode: 860 |                     Train Rewards: 65.6                     Violations: 0                    Mean Train Rewards: -1.4\n",
            "Episode: 870 |                     Train Rewards: 22.7                     Violations: 0                    Mean Train Rewards: 9.2\n",
            "Episode: 880 |                     Train Rewards: 45.2                     Violations: 0                    Mean Train Rewards: 10.5\n",
            "Episode: 890 |                     Train Rewards: 24.0                     Violations: 0                    Mean Train Rewards: 18.5\n",
            "Episode: 900 |                     Train Rewards: -406.2                     Violations: 4.062299728393555                    Mean Train Rewards: 7.0\n",
            "Episode: 910 |                     Train Rewards: 35.4                     Violations: 0                    Mean Train Rewards: 5.5\n",
            "Episode: 920 |                     Train Rewards: 56.8                     Violations: 0                    Mean Train Rewards: 8.0\n",
            "Episode: 930 |                     Train Rewards: 22.1                     Violations: 0                    Mean Train Rewards: 7.5\n",
            "Episode: 940 |                     Train Rewards: -196.7                     Violations: 1.9655847549438477                    Mean Train Rewards: 6.0\n",
            "Episode: 950 |                     Train Rewards: 33.0                     Violations: 0                    Mean Train Rewards: 5.7\n",
            "Episode: 960 |                     Train Rewards: 45.8                     Violations: 0                    Mean Train Rewards: 1.7\n",
            "Episode: 970 |                     Train Rewards: 35.1                     Violations: 0                    Mean Train Rewards: -2.8\n",
            "Episode: 980 |                     Train Rewards: 23.0                     Violations: 0                    Mean Train Rewards: 1.7\n",
            "Episode: 990 |                     Train Rewards: 37.6                     Violations: 0                    Mean Train Rewards: 0.7\n",
            "Episode: 1000 |                     Train Rewards: 3.0                     Violations: 0                    Mean Train Rewards: 13.3\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 22 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 22 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-33/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-34\n",
            "\n",
            "==================================================\n",
            "Starting run 11/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: 31.2                     Violations: 35.32756328582764                    Mean Train Rewards: 7.8\n",
            "Episode:  20 |                     Train Rewards: -37.6                     Violations: 0                    Mean Train Rewards: 3.5\n",
            "Episode:  30 |                     Train Rewards: 17.5                     Violations: 0.13150811195373535                    Mean Train Rewards: 1.3\n",
            "Episode:  40 |                     Train Rewards: 0.0                     Violations: 4.278306961059577                    Mean Train Rewards: 4.4\n",
            "Episode:  50 |                     Train Rewards: 26.5                     Violations: 1.3663792610168457                    Mean Train Rewards: 4.9\n",
            "Episode:  60 |                     Train Rewards: 32.2                     Violations: 11.237152814865112                    Mean Train Rewards: 5.9\n",
            "Episode:  70 |                     Train Rewards: 0.0                     Violations: 20.77686667442321                    Mean Train Rewards: 5.3\n",
            "Episode:  80 |                     Train Rewards: 0.0                     Violations: 27.79796600341797                    Mean Train Rewards: 5.7\n",
            "Episode:  90 |                     Train Rewards: 1.8                     Violations: 4.54426646232605                    Mean Train Rewards: 5.9\n",
            "Episode: 100 |                     Train Rewards: -13.4                     Violations: 1.4264845848083496                    Mean Train Rewards: 6.9\n",
            "Episode: 110 |                     Train Rewards: 16.8                     Violations: 1.113119125366211                    Mean Train Rewards: 9.5\n",
            "Episode: 120 |                     Train Rewards: 0.0                     Violations: 12.34248161315918                    Mean Train Rewards: 10.5\n",
            "Episode: 130 |                     Train Rewards: -2.2                     Violations: 4.367026090621948                    Mean Train Rewards: 13.2\n",
            "Episode: 140 |                     Train Rewards: 45.3                     Violations: 0.18912792205809836                    Mean Train Rewards: 13.3\n",
            "Episode: 150 |                     Train Rewards: 32.3                     Violations: 4.90214467048645                    Mean Train Rewards: 15.4\n",
            "Episode: 160 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 15.8\n",
            "Episode: 170 |                     Train Rewards: 19.4                     Violations: 0.12899279594421387                    Mean Train Rewards: 16.8\n",
            "Episode: 180 |                     Train Rewards: 18.3                     Violations: 0                    Mean Train Rewards: 17.6\n",
            "Episode: 190 |                     Train Rewards: 0.0                     Violations: 12.482469081878662                    Mean Train Rewards: 18.4\n",
            "Episode: 200 |                     Train Rewards: 41.8                     Violations: 0.21174192428588157                    Mean Train Rewards: 19.2\n",
            "Episode: 210 |                     Train Rewards: -22.1                     Violations: 0.2318406105041504                    Mean Train Rewards: 17.2\n",
            "Episode: 220 |                     Train Rewards: 58.4                     Violations: 0                    Mean Train Rewards: 18.2\n",
            "Episode: 230 |                     Train Rewards: 0.7                     Violations: 2.3264729976654053                    Mean Train Rewards: 18.7\n",
            "Episode: 240 |                     Train Rewards: 32.6                     Violations: 0.9157979488372803                    Mean Train Rewards: 18.8\n",
            "Episode: 250 |                     Train Rewards: 43.5                     Violations: 0                    Mean Train Rewards: 18.1\n",
            "Episode: 260 |                     Train Rewards: 30.1                     Violations: 0                    Mean Train Rewards: 19.5\n",
            "Episode: 270 |                     Train Rewards: 58.0                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 280 |                     Train Rewards: 23.1                     Violations: 0                    Mean Train Rewards: 23.3\n",
            "Episode: 290 |                     Train Rewards: 35.8                     Violations: 3.3441686630249023                    Mean Train Rewards: 23.7\n",
            "Episode: 300 |                     Train Rewards: 18.5                     Violations: 0                    Mean Train Rewards: 24.4\n",
            "Episode: 310 |                     Train Rewards: -33.3                     Violations: 0                    Mean Train Rewards: 24.3\n",
            "Episode: 320 |                     Train Rewards: 1.1                     Violations: 0                    Mean Train Rewards: 22.1\n",
            "Episode: 330 |                     Train Rewards: 55.0                     Violations: 0                    Mean Train Rewards: 20.6\n",
            "Episode: 340 |                     Train Rewards: 13.3                     Violations: 4.691007137298584                    Mean Train Rewards: 19.5\n",
            "Episode: 350 |                     Train Rewards: 30.3                     Violations: 0                    Mean Train Rewards: 20.0\n",
            "Episode: 360 |                     Train Rewards: 19.5                     Violations: 3.4133994579315186                    Mean Train Rewards: 20.7\n",
            "Episode: 370 |                     Train Rewards: 5.1                     Violations: 2.6864492893218994                    Mean Train Rewards: 20.5\n",
            "Episode: 380 |                     Train Rewards: 32.5                     Violations: 0.23081541061401367                    Mean Train Rewards: 20.1\n",
            "Episode: 390 |                     Train Rewards: 1.7                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 400 |                     Train Rewards: 11.5                     Violations: 0                    Mean Train Rewards: 22.0\n",
            "Episode: 410 |                     Train Rewards: 30.0                     Violations: 0.7748925685882568                    Mean Train Rewards: 24.4\n",
            "Episode: 420 |                     Train Rewards: 63.9                     Violations: 0                    Mean Train Rewards: 27.6\n",
            "Episode: 430 |                     Train Rewards: 33.8                     Violations: 0                    Mean Train Rewards: 28.8\n",
            "Episode: 440 |                     Train Rewards: 38.8                     Violations: 3.1067097187042307                    Mean Train Rewards: 30.3\n",
            "Episode: 450 |                     Train Rewards: 31.6                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 460 |                     Train Rewards: 2.0                     Violations: 0.5039656162261963                    Mean Train Rewards: 31.2\n",
            "Episode: 470 |                     Train Rewards: 48.7                     Violations: 0                    Mean Train Rewards: 32.3\n",
            "Episode: 480 |                     Train Rewards: 27.0                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 490 |                     Train Rewards: 12.4                     Violations: 0                    Mean Train Rewards: 32.9\n",
            "Episode: 500 |                     Train Rewards: 45.5                     Violations: 0                    Mean Train Rewards: 31.6\n",
            "Episode: 510 |                     Train Rewards: 63.1                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 520 |                     Train Rewards: 29.5                     Violations: 0.0705564022064209                    Mean Train Rewards: 32.2\n",
            "Episode: 530 |                     Train Rewards: 23.6                     Violations: 0                    Mean Train Rewards: 31.7\n",
            "Episode: 540 |                     Train Rewards: 21.2                     Violations: 0                    Mean Train Rewards: 31.1\n",
            "Episode: 550 |                     Train Rewards: 24.7                     Violations: 2.889087200164795                    Mean Train Rewards: 30.3\n",
            "Episode: 560 |                     Train Rewards: 23.0                     Violations: 0                    Mean Train Rewards: 29.4\n",
            "Episode: 570 |                     Train Rewards: 15.8                     Violations: 1.7472290992736745                    Mean Train Rewards: 29.0\n",
            "Episode: 580 |                     Train Rewards: 22.3                     Violations: 0                    Mean Train Rewards: 27.9\n",
            "Episode: 590 |                     Train Rewards: 17.8                     Violations: 0.6643080711364746                    Mean Train Rewards: 27.7\n",
            "Episode: 600 |                     Train Rewards: 38.2                     Violations: 0.24789214134216309                    Mean Train Rewards: 29.7\n",
            "Episode: 610 |                     Train Rewards: 52.7                     Violations: 0                    Mean Train Rewards: 30.9\n",
            "Episode: 620 |                     Train Rewards: 69.7                     Violations: 0                    Mean Train Rewards: 30.8\n",
            "Episode: 630 |                     Train Rewards: 23.3                     Violations: 1.1555993556976318                    Mean Train Rewards: 32.5\n",
            "Episode: 640 |                     Train Rewards: 57.0                     Violations: 0                    Mean Train Rewards: 35.8\n",
            "Episode: 650 |                     Train Rewards: 66.9                     Violations: 0                    Mean Train Rewards: 38.3\n",
            "Episode: 660 |                     Train Rewards: 66.8                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 670 |                     Train Rewards: 21.7                     Violations: 0.8872592449188232                    Mean Train Rewards: 39.8\n",
            "Episode: 680 |                     Train Rewards: 35.8                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 690 |                     Train Rewards: 43.3                     Violations: 0                    Mean Train Rewards: 42.0\n",
            "Episode: 700 |                     Train Rewards: 31.4                     Violations: 0                    Mean Train Rewards: 39.4\n",
            "Episode: 710 |                     Train Rewards: 66.1                     Violations: 0                    Mean Train Rewards: 39.0\n",
            "Episode: 720 |                     Train Rewards: 43.2                     Violations: 0                    Mean Train Rewards: 38.7\n",
            "Episode: 730 |                     Train Rewards: 65.6                     Violations: 0                    Mean Train Rewards: 39.6\n",
            "Episode: 740 |                     Train Rewards: 52.1                     Violations: 0                    Mean Train Rewards: 37.9\n",
            "Episode: 750 |                     Train Rewards: -5.7                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 760 |                     Train Rewards: 60.7                     Violations: 0                    Mean Train Rewards: 34.6\n",
            "Episode: 770 |                     Train Rewards: 28.2                     Violations: 0.7347190380096436                    Mean Train Rewards: 35.4\n",
            "Episode: 780 |                     Train Rewards: 45.0                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 790 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 800 |                     Train Rewards: 45.4                     Violations: 0                    Mean Train Rewards: 38.9\n",
            "Episode: 810 |                     Train Rewards: 44.0                     Violations: 2.956589460372925                    Mean Train Rewards: 40.3\n",
            "Episode: 820 |                     Train Rewards: 39.8                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 830 |                     Train Rewards: 38.4                     Violations: 0                    Mean Train Rewards: 39.3\n",
            "Episode: 840 |                     Train Rewards: 22.0                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 850 |                     Train Rewards: 38.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 860 |                     Train Rewards: 57.3                     Violations: 0                    Mean Train Rewards: 41.5\n",
            "Episode: 870 |                     Train Rewards: 32.9                     Violations: 0                    Mean Train Rewards: 41.3\n",
            "Episode: 880 |                     Train Rewards: 43.4                     Violations: 0                    Mean Train Rewards: 41.0\n",
            "Episode: 890 |                     Train Rewards: 29.3                     Violations: 0                    Mean Train Rewards: 40.4\n",
            "Episode: 900 |                     Train Rewards: 80.7                     Violations: 0                    Mean Train Rewards: 40.9\n",
            "Episode: 910 |                     Train Rewards: 45.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 920 |                     Train Rewards: 43.6                     Violations: 0                    Mean Train Rewards: 41.1\n",
            "Episode: 930 |                     Train Rewards: 15.6                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 940 |                     Train Rewards: 42.0                     Violations: 0                    Mean Train Rewards: 40.1\n",
            "Episode: 950 |                     Train Rewards: 27.8                     Violations: 0                    Mean Train Rewards: 38.8\n",
            "Episode: 960 |                     Train Rewards: 38.8                     Violations: 0                    Mean Train Rewards: 37.5\n",
            "Episode: 970 |                     Train Rewards: 30.0                     Violations: 0                    Mean Train Rewards: 37.7\n",
            "Episode: 980 |                     Train Rewards: 18.9                     Violations: 0                    Mean Train Rewards: 35.0\n",
            "Episode: 990 |                     Train Rewards: 28.1                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 1000 |                     Train Rewards: 2.8                     Violations: 0                    Mean Train Rewards: 30.7\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 26 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 26 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-34/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-35\n",
            "\n",
            "==================================================\n",
            "Starting run 12/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -1727.7                     Violations: 17.00602412223816                    Mean Train Rewards: -707.1\n",
            "Episode:  20 |                     Train Rewards: -52.5                     Violations: 0                    Mean Train Rewards: -622.6\n",
            "Episode:  30 |                     Train Rewards: -38.8                     Violations: 0                    Mean Train Rewards: -512.1\n",
            "Episode:  40 |                     Train Rewards: 1.8                     Violations: 0.3179931640624929                    Mean Train Rewards: -448.1\n",
            "Episode:  50 |                     Train Rewards: 0.8                     Violations: 0                    Mean Train Rewards: -371.9\n",
            "Episode:  60 |                     Train Rewards: -42.3                     Violations: 0.04182696342467551                    Mean Train Rewards: -333.5\n",
            "Episode:  70 |                     Train Rewards: -3920.4                     Violations: 39.20382261276245                    Mean Train Rewards: -579.7\n",
            "Episode:  80 |                     Train Rewards: -10129.0                     Violations: 101.29026889801027                    Mean Train Rewards: -1302.8\n",
            "Episode:  90 |                     Train Rewards: -7976.1                     Violations: 79.76141691207886                    Mean Train Rewards: -1905.6\n",
            "Episode: 100 |                     Train Rewards: -2705.1                     Violations: 27.051228284835815                    Mean Train Rewards: -2050.0\n",
            "Episode: 110 |                     Train Rewards: -11090.2                     Violations: 110.90211391448975                    Mean Train Rewards: -2824.1\n",
            "Episode: 120 |                     Train Rewards: -11290.2                     Violations: 112.90231466293335                    Mean Train Rewards: -3850.9\n",
            "Episode: 130 |                     Train Rewards: -9473.6                     Violations: 94.73578453063963                    Mean Train Rewards: -4881.7\n",
            "Episode: 140 |                     Train Rewards: -10624.5                     Violations: 106.24546527862549                    Mean Train Rewards: -5864.3\n",
            "Episode: 150 |                     Train Rewards: -11450.2                     Violations: 114.50229406356813                    Mean Train Rewards: -6639.5\n",
            "Episode: 160 |                     Train Rewards: -4928.4                     Violations: 49.283796548843384                    Mean Train Rewards: -7487.2\n",
            "Episode: 170 |                     Train Rewards: -5207.4                     Violations: 52.07449793815613                    Mean Train Rewards: -7755.2\n",
            "Episode: 180 |                     Train Rewards: -5890.5                     Violations: 58.90467882156372                    Mean Train Rewards: -7715.6\n",
            "Episode: 190 |                     Train Rewards: -9303.2                     Violations: 93.03235530853271                    Mean Train Rewards: -7770.2\n",
            "Episode: 200 |                     Train Rewards: -6603.6                     Violations: 66.03613615036011                    Mean Train Rewards: -8206.4\n",
            "Episode: 210 |                     Train Rewards: -6438.7                     Violations: 64.38650608062743                    Mean Train Rewards: -7905.9\n",
            "Episode: 220 |                     Train Rewards: -9918.5                     Violations: 99.18469905853271                    Mean Train Rewards: -7647.9\n",
            "Episode: 230 |                     Train Rewards: -10693.9                     Violations: 106.93877458572388                    Mean Train Rewards: -7677.8\n",
            "Episode: 240 |                     Train Rewards: -11839.5                     Violations: 118.39463233947752                    Mean Train Rewards: -7750.1\n",
            "Episode: 250 |                     Train Rewards: -10212.9                     Violations: 102.1290373802185                    Mean Train Rewards: -8025.6\n",
            "Episode: 260 |                     Train Rewards: -10775.6                     Violations: 107.756085395813                    Mean Train Rewards: -8242.0\n",
            "Episode: 270 |                     Train Rewards: -11204.0                     Violations: 112.04021692276002                    Mean Train Rewards: -8850.9\n",
            "Episode: 280 |                     Train Rewards: -8935.1                     Violations: 89.35088634490967                    Mean Train Rewards: -9336.6\n",
            "Episode: 290 |                     Train Rewards: -11451.5                     Violations: 114.51456069946286                    Mean Train Rewards: -9638.2\n",
            "Episode: 300 |                     Train Rewards: -9795.5                     Violations: 97.95463800430299                    Mean Train Rewards: -9860.2\n",
            "Episode: 310 |                     Train Rewards: -8982.1                     Violations: 89.82066631317139                    Mean Train Rewards: -10248.2\n",
            "Episode: 320 |                     Train Rewards: -5165.3                     Violations: 51.65264010429381                    Mean Train Rewards: -10120.1\n",
            "Episode: 330 |                     Train Rewards: -11491.8                     Violations: 114.91775035858153                    Mean Train Rewards: -9844.3\n",
            "Episode: 340 |                     Train Rewards: -10652.9                     Violations: 106.52938604354858                    Mean Train Rewards: -9697.2\n",
            "Episode: 350 |                     Train Rewards: -11002.4                     Violations: 110.02422094345096                    Mean Train Rewards: -9677.7\n",
            "Episode: 360 |                     Train Rewards: -10888.3                     Violations: 108.88298273086548                    Mean Train Rewards: -9646.7\n",
            "Episode: 370 |                     Train Rewards: -7682.5                     Violations: 76.82522058486937                    Mean Train Rewards: -9360.6\n",
            "Episode: 380 |                     Train Rewards: -10325.9                     Violations: 103.25872421264648                    Mean Train Rewards: -9144.7\n",
            "Episode: 390 |                     Train Rewards: -1511.2                     Violations: 15.44528841972351                    Mean Train Rewards: -8729.9\n",
            "Episode: 400 |                     Train Rewards: 32.1                     Violations: 0                    Mean Train Rewards: -7962.9\n",
            "Episode: 410 |                     Train Rewards: -3743.0                     Violations: 37.429553270339966                    Mean Train Rewards: -7151.0\n",
            "Episode: 420 |                     Train Rewards: -2694.8                     Violations: 26.947962045669556                    Mean Train Rewards: -6665.8\n",
            "Episode: 430 |                     Train Rewards: -3416.1                     Violations: 34.16116714477539                    Mean Train Rewards: -6151.4\n",
            "Episode: 440 |                     Train Rewards: -8716.5                     Violations: 87.16451644897462                    Mean Train Rewards: -5708.4\n",
            "Episode: 450 |                     Train Rewards: -5848.4                     Violations: 58.48363161087036                    Mean Train Rewards: -5330.8\n",
            "Episode: 460 |                     Train Rewards: -1800.3                     Violations: 18.290140628814697                    Mean Train Rewards: -4696.2\n",
            "Episode: 470 |                     Train Rewards: 80.2                     Violations: 0                    Mean Train Rewards: -3968.1\n",
            "Episode: 480 |                     Train Rewards: 12.0                     Violations: 0                    Mean Train Rewards: -3128.5\n",
            "Episode: 490 |                     Train Rewards: 0.0                     Violations: 0                    Mean Train Rewards: -2552.1\n",
            "Episode: 500 |                     Train Rewards: 7.6                     Violations: 0                    Mean Train Rewards: -2349.5\n",
            "Episode: 510 |                     Train Rewards: 28.9                     Violations: 0                    Mean Train Rewards: -2256.9\n",
            "Episode: 520 |                     Train Rewards: -173.4                     Violations: 1.8983924388885498                    Mean Train Rewards: -2065.6\n",
            "Episode: 530 |                     Train Rewards: 31.5                     Violations: 0                    Mean Train Rewards: -1802.7\n",
            "Episode: 540 |                     Train Rewards: -426.3                     Violations: 3.9474868774414134                    Mean Train Rewards: -1321.4\n",
            "Episode: 550 |                     Train Rewards: -1107.2                     Violations: 11.387583017349243                    Mean Train Rewards: -714.2\n",
            "Episode: 560 |                     Train Rewards: 1.1                     Violations: 0                    Mean Train Rewards: -335.6\n",
            "Episode: 570 |                     Train Rewards: -1023.0                     Violations: 10.438563823699951                    Mean Train Rewards: -280.9\n",
            "Episode: 580 |                     Train Rewards: 54.9                     Violations: 0                    Mean Train Rewards: -261.1\n",
            "Episode: 590 |                     Train Rewards: -447.8                     Violations: 4.542871713638306                    Mean Train Rewards: -236.8\n",
            "Episode: 600 |                     Train Rewards: -166.8                     Violations: 2.0607376098632812                    Mean Train Rewards: -237.0\n",
            "Episode: 610 |                     Train Rewards: 64.4                     Violations: 0                    Mean Train Rewards: -212.2\n",
            "Episode: 620 |                     Train Rewards: 44.2                     Violations: 0                    Mean Train Rewards: -217.4\n",
            "Episode: 630 |                     Train Rewards: -395.4                     Violations: 4.067178964614868                    Mean Train Rewards: -214.7\n",
            "Episode: 640 |                     Train Rewards: 7.4                     Violations: 0                    Mean Train Rewards: -209.0\n",
            "Episode: 650 |                     Train Rewards: 27.0                     Violations: 0                    Mean Train Rewards: -164.9\n",
            "Episode: 660 |                     Train Rewards: -439.6                     Violations: 4.396175146102912                    Mean Train Rewards: -144.8\n",
            "Episode: 670 |                     Train Rewards: -807.8                     Violations: 8.447023630142212                    Mean Train Rewards: -167.1\n",
            "Episode: 680 |                     Train Rewards: 8.6                     Violations: 0                    Mean Train Rewards: -174.3\n",
            "Episode: 690 |                     Train Rewards: 46.1                     Violations: 0                    Mean Train Rewards: -164.9\n",
            "Episode: 700 |                     Train Rewards: 54.2                     Violations: 0                    Mean Train Rewards: -138.8\n",
            "Episode: 710 |                     Train Rewards: -158.0                     Violations: 1.7465794086456228                    Mean Train Rewards: -143.4\n",
            "Episode: 720 |                     Train Rewards: 56.8                     Violations: 0                    Mean Train Rewards: -121.2\n",
            "Episode: 730 |                     Train Rewards: -219.3                     Violations: 2.48626708984375                    Mean Train Rewards: -114.1\n",
            "Episode: 740 |                     Train Rewards: 18.5                     Violations: 0.1361393928527761                    Mean Train Rewards: -115.3\n",
            "Episode: 750 |                     Train Rewards: -22.7                     Violations: 0                    Mean Train Rewards: -108.7\n",
            "Episode: 760 |                     Train Rewards: 70.0                     Violations: 0                    Mean Train Rewards: -100.4\n",
            "Episode: 770 |                     Train Rewards: 47.3                     Violations: 0                    Mean Train Rewards: -72.2\n",
            "Episode: 780 |                     Train Rewards: 22.8                     Violations: 0                    Mean Train Rewards: -62.1\n",
            "Episode: 790 |                     Train Rewards: 9.5                     Violations: 0                    Mean Train Rewards: -62.1\n",
            "Episode: 800 |                     Train Rewards: 28.8                     Violations: 0                    Mean Train Rewards: -62.6\n",
            "Episode: 810 |                     Train Rewards: -268.5                     Violations: 3.0441009998321533                    Mean Train Rewards: -55.3\n",
            "Episode: 820 |                     Train Rewards: 14.3                     Violations: 0                    Mean Train Rewards: -53.8\n",
            "Episode: 830 |                     Train Rewards: 39.7                     Violations: 0                    Mean Train Rewards: -23.7\n",
            "Episode: 840 |                     Train Rewards: 11.3                     Violations: 0                    Mean Train Rewards: -15.6\n",
            "Episode: 850 |                     Train Rewards: 36.6                     Violations: 0                    Mean Train Rewards: -10.7\n",
            "Episode: 860 |                     Train Rewards: 65.6                     Violations: 0                    Mean Train Rewards: -1.4\n",
            "Episode: 870 |                     Train Rewards: 22.7                     Violations: 0                    Mean Train Rewards: 9.2\n",
            "Episode: 880 |                     Train Rewards: 45.2                     Violations: 0                    Mean Train Rewards: 10.5\n",
            "Episode: 890 |                     Train Rewards: 24.0                     Violations: 0                    Mean Train Rewards: 18.5\n",
            "Episode: 900 |                     Train Rewards: -406.2                     Violations: 4.062299728393555                    Mean Train Rewards: 7.0\n",
            "Episode: 910 |                     Train Rewards: 35.4                     Violations: 0                    Mean Train Rewards: 5.5\n",
            "Episode: 920 |                     Train Rewards: 56.8                     Violations: 0                    Mean Train Rewards: 8.0\n",
            "Episode: 930 |                     Train Rewards: 22.1                     Violations: 0                    Mean Train Rewards: 7.5\n",
            "Episode: 940 |                     Train Rewards: -196.7                     Violations: 1.9655847549438477                    Mean Train Rewards: 6.0\n",
            "Episode: 950 |                     Train Rewards: 33.0                     Violations: 0                    Mean Train Rewards: 5.7\n",
            "Episode: 960 |                     Train Rewards: 45.8                     Violations: 0                    Mean Train Rewards: 1.7\n",
            "Episode: 970 |                     Train Rewards: 35.1                     Violations: 0                    Mean Train Rewards: -2.8\n",
            "Episode: 980 |                     Train Rewards: 23.0                     Violations: 0                    Mean Train Rewards: 1.7\n",
            "Episode: 990 |                     Train Rewards: 37.6                     Violations: 0                    Mean Train Rewards: 0.7\n",
            "Episode: 1000 |                     Train Rewards: 3.0                     Violations: 0                    Mean Train Rewards: 13.3\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-35/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-36\n",
            "\n",
            "==================================================\n",
            "Starting run 13/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: 31.2                     Violations: 35.32756328582764                    Mean Train Rewards: 7.8\n",
            "Episode:  20 |                     Train Rewards: -37.6                     Violations: 0                    Mean Train Rewards: 3.5\n",
            "Episode:  30 |                     Train Rewards: 17.5                     Violations: 0.13150811195373535                    Mean Train Rewards: 1.3\n",
            "Episode:  40 |                     Train Rewards: 0.0                     Violations: 4.278306961059577                    Mean Train Rewards: 4.4\n",
            "Episode:  50 |                     Train Rewards: 26.5                     Violations: 1.3663792610168457                    Mean Train Rewards: 4.9\n",
            "Episode:  60 |                     Train Rewards: 32.2                     Violations: 11.237152814865112                    Mean Train Rewards: 5.9\n",
            "Episode:  70 |                     Train Rewards: 0.0                     Violations: 20.77686667442321                    Mean Train Rewards: 5.3\n",
            "Episode:  80 |                     Train Rewards: 0.0                     Violations: 27.79796600341797                    Mean Train Rewards: 5.7\n",
            "Episode:  90 |                     Train Rewards: 1.8                     Violations: 4.54426646232605                    Mean Train Rewards: 5.9\n",
            "Episode: 100 |                     Train Rewards: -13.4                     Violations: 1.4264845848083496                    Mean Train Rewards: 6.9\n",
            "Episode: 110 |                     Train Rewards: 16.8                     Violations: 1.113119125366211                    Mean Train Rewards: 9.5\n",
            "Episode: 120 |                     Train Rewards: 0.0                     Violations: 12.34248161315918                    Mean Train Rewards: 10.5\n",
            "Episode: 130 |                     Train Rewards: -2.2                     Violations: 4.367026090621948                    Mean Train Rewards: 13.2\n",
            "Episode: 140 |                     Train Rewards: 45.3                     Violations: 0.18912792205809836                    Mean Train Rewards: 13.3\n",
            "Episode: 150 |                     Train Rewards: 32.3                     Violations: 4.90214467048645                    Mean Train Rewards: 15.4\n",
            "Episode: 160 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 15.8\n",
            "Episode: 170 |                     Train Rewards: 19.4                     Violations: 0.12899279594421387                    Mean Train Rewards: 16.8\n",
            "Episode: 180 |                     Train Rewards: 18.3                     Violations: 0                    Mean Train Rewards: 17.6\n",
            "Episode: 190 |                     Train Rewards: 0.0                     Violations: 12.482469081878662                    Mean Train Rewards: 18.4\n",
            "Episode: 200 |                     Train Rewards: 41.8                     Violations: 0.21174192428588157                    Mean Train Rewards: 19.2\n",
            "Episode: 210 |                     Train Rewards: -22.1                     Violations: 0.2318406105041504                    Mean Train Rewards: 17.2\n",
            "Episode: 220 |                     Train Rewards: 58.4                     Violations: 0                    Mean Train Rewards: 18.2\n",
            "Episode: 230 |                     Train Rewards: 0.7                     Violations: 2.3264729976654053                    Mean Train Rewards: 18.7\n",
            "Episode: 240 |                     Train Rewards: 32.6                     Violations: 0.9157979488372803                    Mean Train Rewards: 18.8\n",
            "Episode: 250 |                     Train Rewards: 43.5                     Violations: 0                    Mean Train Rewards: 18.1\n",
            "Episode: 260 |                     Train Rewards: 30.1                     Violations: 0                    Mean Train Rewards: 19.5\n",
            "Episode: 270 |                     Train Rewards: 58.0                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 280 |                     Train Rewards: 23.1                     Violations: 0                    Mean Train Rewards: 23.3\n",
            "Episode: 290 |                     Train Rewards: 35.8                     Violations: 3.3441686630249023                    Mean Train Rewards: 23.7\n",
            "Episode: 300 |                     Train Rewards: 18.5                     Violations: 0                    Mean Train Rewards: 24.4\n",
            "Episode: 310 |                     Train Rewards: -33.3                     Violations: 0                    Mean Train Rewards: 24.3\n",
            "Episode: 320 |                     Train Rewards: 1.1                     Violations: 0                    Mean Train Rewards: 22.1\n",
            "Episode: 330 |                     Train Rewards: 55.0                     Violations: 0                    Mean Train Rewards: 20.6\n",
            "Episode: 340 |                     Train Rewards: 13.3                     Violations: 4.691007137298584                    Mean Train Rewards: 19.5\n",
            "Episode: 350 |                     Train Rewards: 30.3                     Violations: 0                    Mean Train Rewards: 20.0\n",
            "Episode: 360 |                     Train Rewards: 19.5                     Violations: 3.4133994579315186                    Mean Train Rewards: 20.7\n",
            "Episode: 370 |                     Train Rewards: 5.1                     Violations: 2.6864492893218994                    Mean Train Rewards: 20.5\n",
            "Episode: 380 |                     Train Rewards: 32.5                     Violations: 0.23081541061401367                    Mean Train Rewards: 20.1\n",
            "Episode: 390 |                     Train Rewards: 1.7                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 400 |                     Train Rewards: 11.5                     Violations: 0                    Mean Train Rewards: 22.0\n",
            "Episode: 410 |                     Train Rewards: 30.0                     Violations: 0.7748925685882568                    Mean Train Rewards: 24.4\n",
            "Episode: 420 |                     Train Rewards: 63.9                     Violations: 0                    Mean Train Rewards: 27.6\n",
            "Episode: 430 |                     Train Rewards: 33.8                     Violations: 0                    Mean Train Rewards: 28.8\n",
            "Episode: 440 |                     Train Rewards: 38.8                     Violations: 3.1067097187042307                    Mean Train Rewards: 30.3\n",
            "Episode: 450 |                     Train Rewards: 31.6                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 460 |                     Train Rewards: 2.0                     Violations: 0.5039656162261963                    Mean Train Rewards: 31.2\n",
            "Episode: 470 |                     Train Rewards: 48.7                     Violations: 0                    Mean Train Rewards: 32.3\n",
            "Episode: 480 |                     Train Rewards: 27.0                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 490 |                     Train Rewards: 12.4                     Violations: 0                    Mean Train Rewards: 32.9\n",
            "Episode: 500 |                     Train Rewards: 45.5                     Violations: 0                    Mean Train Rewards: 31.6\n",
            "Episode: 510 |                     Train Rewards: 63.1                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 520 |                     Train Rewards: 29.5                     Violations: 0.0705564022064209                    Mean Train Rewards: 32.2\n",
            "Episode: 530 |                     Train Rewards: 23.6                     Violations: 0                    Mean Train Rewards: 31.7\n",
            "Episode: 540 |                     Train Rewards: 21.2                     Violations: 0                    Mean Train Rewards: 31.1\n",
            "Episode: 550 |                     Train Rewards: 24.7                     Violations: 2.889087200164795                    Mean Train Rewards: 30.3\n",
            "Episode: 560 |                     Train Rewards: 23.0                     Violations: 0                    Mean Train Rewards: 29.4\n",
            "Episode: 570 |                     Train Rewards: 15.8                     Violations: 1.7472290992736745                    Mean Train Rewards: 29.0\n",
            "Episode: 580 |                     Train Rewards: 22.3                     Violations: 0                    Mean Train Rewards: 27.9\n",
            "Episode: 590 |                     Train Rewards: 17.8                     Violations: 0.6643080711364746                    Mean Train Rewards: 27.7\n",
            "Episode: 600 |                     Train Rewards: 38.2                     Violations: 0.24789214134216309                    Mean Train Rewards: 29.7\n",
            "Episode: 610 |                     Train Rewards: 52.7                     Violations: 0                    Mean Train Rewards: 30.9\n",
            "Episode: 620 |                     Train Rewards: 69.7                     Violations: 0                    Mean Train Rewards: 30.8\n",
            "Episode: 630 |                     Train Rewards: 23.3                     Violations: 1.1555993556976318                    Mean Train Rewards: 32.5\n",
            "Episode: 640 |                     Train Rewards: 57.0                     Violations: 0                    Mean Train Rewards: 35.8\n",
            "Episode: 650 |                     Train Rewards: 66.9                     Violations: 0                    Mean Train Rewards: 38.3\n",
            "Episode: 660 |                     Train Rewards: 66.8                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 670 |                     Train Rewards: 21.7                     Violations: 0.8872592449188232                    Mean Train Rewards: 39.8\n",
            "Episode: 680 |                     Train Rewards: 35.8                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 690 |                     Train Rewards: 43.3                     Violations: 0                    Mean Train Rewards: 42.0\n",
            "Episode: 700 |                     Train Rewards: 31.4                     Violations: 0                    Mean Train Rewards: 39.4\n",
            "Episode: 710 |                     Train Rewards: 66.1                     Violations: 0                    Mean Train Rewards: 39.0\n",
            "Episode: 720 |                     Train Rewards: 43.2                     Violations: 0                    Mean Train Rewards: 38.7\n",
            "Episode: 730 |                     Train Rewards: 65.6                     Violations: 0                    Mean Train Rewards: 39.6\n",
            "Episode: 740 |                     Train Rewards: 52.1                     Violations: 0                    Mean Train Rewards: 37.9\n",
            "Episode: 750 |                     Train Rewards: -5.7                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 760 |                     Train Rewards: 60.7                     Violations: 0                    Mean Train Rewards: 34.6\n",
            "Episode: 770 |                     Train Rewards: 28.2                     Violations: 0.7347190380096436                    Mean Train Rewards: 35.4\n",
            "Episode: 780 |                     Train Rewards: 45.0                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 790 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 800 |                     Train Rewards: 45.4                     Violations: 0                    Mean Train Rewards: 38.9\n",
            "Episode: 810 |                     Train Rewards: 44.0                     Violations: 2.956589460372925                    Mean Train Rewards: 40.3\n",
            "Episode: 820 |                     Train Rewards: 39.8                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 830 |                     Train Rewards: 38.4                     Violations: 0                    Mean Train Rewards: 39.3\n",
            "Episode: 840 |                     Train Rewards: 22.0                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 850 |                     Train Rewards: 38.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 860 |                     Train Rewards: 57.3                     Violations: 0                    Mean Train Rewards: 41.5\n",
            "Episode: 870 |                     Train Rewards: 32.9                     Violations: 0                    Mean Train Rewards: 41.3\n",
            "Episode: 880 |                     Train Rewards: 43.4                     Violations: 0                    Mean Train Rewards: 41.0\n",
            "Episode: 890 |                     Train Rewards: 29.3                     Violations: 0                    Mean Train Rewards: 40.4\n",
            "Episode: 900 |                     Train Rewards: 80.7                     Violations: 0                    Mean Train Rewards: 40.9\n",
            "Episode: 910 |                     Train Rewards: 45.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 920 |                     Train Rewards: 43.6                     Violations: 0                    Mean Train Rewards: 41.1\n",
            "Episode: 930 |                     Train Rewards: 15.6                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 940 |                     Train Rewards: 42.0                     Violations: 0                    Mean Train Rewards: 40.1\n",
            "Episode: 950 |                     Train Rewards: 27.8                     Violations: 0                    Mean Train Rewards: 38.8\n",
            "Episode: 960 |                     Train Rewards: 38.8                     Violations: 0                    Mean Train Rewards: 37.5\n",
            "Episode: 970 |                     Train Rewards: 30.0                     Violations: 0                    Mean Train Rewards: 37.7\n",
            "Episode: 980 |                     Train Rewards: 18.9                     Violations: 0                    Mean Train Rewards: 35.0\n",
            "Episode: 990 |                     Train Rewards: 28.1                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 1000 |                     Train Rewards: 2.8                     Violations: 0                    Mean Train Rewards: 30.7\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 12 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 12 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-36/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-37\n",
            "\n",
            "==================================================\n",
            "Starting run 14/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -1727.7                     Violations: 17.00602412223816                    Mean Train Rewards: -707.1\n",
            "Episode:  20 |                     Train Rewards: -52.5                     Violations: 0                    Mean Train Rewards: -622.6\n",
            "Episode:  30 |                     Train Rewards: -38.8                     Violations: 0                    Mean Train Rewards: -512.1\n",
            "Episode:  40 |                     Train Rewards: 1.8                     Violations: 0.3179931640624929                    Mean Train Rewards: -448.1\n",
            "Episode:  50 |                     Train Rewards: 0.8                     Violations: 0                    Mean Train Rewards: -371.9\n",
            "Episode:  60 |                     Train Rewards: -42.3                     Violations: 0.04182696342467551                    Mean Train Rewards: -333.5\n",
            "Episode:  70 |                     Train Rewards: -3920.4                     Violations: 39.20382261276245                    Mean Train Rewards: -579.7\n",
            "Episode:  80 |                     Train Rewards: -10129.0                     Violations: 101.29026889801027                    Mean Train Rewards: -1302.8\n",
            "Episode:  90 |                     Train Rewards: -7976.1                     Violations: 79.76141691207886                    Mean Train Rewards: -1905.6\n",
            "Episode: 100 |                     Train Rewards: -2705.1                     Violations: 27.051228284835815                    Mean Train Rewards: -2050.0\n",
            "Episode: 110 |                     Train Rewards: -11090.2                     Violations: 110.90211391448975                    Mean Train Rewards: -2824.1\n",
            "Episode: 120 |                     Train Rewards: -11290.2                     Violations: 112.90231466293335                    Mean Train Rewards: -3850.9\n",
            "Episode: 130 |                     Train Rewards: -9473.6                     Violations: 94.73578453063963                    Mean Train Rewards: -4881.7\n",
            "Episode: 140 |                     Train Rewards: -10624.5                     Violations: 106.24546527862549                    Mean Train Rewards: -5864.3\n",
            "Episode: 150 |                     Train Rewards: -11450.2                     Violations: 114.50229406356813                    Mean Train Rewards: -6639.5\n",
            "Episode: 160 |                     Train Rewards: -4928.4                     Violations: 49.283796548843384                    Mean Train Rewards: -7487.2\n",
            "Episode: 170 |                     Train Rewards: -5207.4                     Violations: 52.07449793815613                    Mean Train Rewards: -7755.2\n",
            "Episode: 180 |                     Train Rewards: -5890.5                     Violations: 58.90467882156372                    Mean Train Rewards: -7715.6\n",
            "Episode: 190 |                     Train Rewards: -9303.2                     Violations: 93.03235530853271                    Mean Train Rewards: -7770.2\n",
            "Episode: 200 |                     Train Rewards: -6603.6                     Violations: 66.03613615036011                    Mean Train Rewards: -8206.4\n",
            "Episode: 210 |                     Train Rewards: -6438.7                     Violations: 64.38650608062743                    Mean Train Rewards: -7905.9\n",
            "Episode: 220 |                     Train Rewards: -9918.5                     Violations: 99.18469905853271                    Mean Train Rewards: -7647.9\n",
            "Episode: 230 |                     Train Rewards: -10693.9                     Violations: 106.93877458572388                    Mean Train Rewards: -7677.8\n",
            "Episode: 240 |                     Train Rewards: -11839.5                     Violations: 118.39463233947752                    Mean Train Rewards: -7750.1\n",
            "Episode: 250 |                     Train Rewards: -10212.9                     Violations: 102.1290373802185                    Mean Train Rewards: -8025.6\n",
            "Episode: 260 |                     Train Rewards: -10775.6                     Violations: 107.756085395813                    Mean Train Rewards: -8242.0\n",
            "Episode: 270 |                     Train Rewards: -11204.0                     Violations: 112.04021692276002                    Mean Train Rewards: -8850.9\n",
            "Episode: 280 |                     Train Rewards: -8935.1                     Violations: 89.35088634490967                    Mean Train Rewards: -9336.6\n",
            "Episode: 290 |                     Train Rewards: -11451.5                     Violations: 114.51456069946286                    Mean Train Rewards: -9638.2\n",
            "Episode: 300 |                     Train Rewards: -9795.5                     Violations: 97.95463800430299                    Mean Train Rewards: -9860.2\n",
            "Episode: 310 |                     Train Rewards: -8982.1                     Violations: 89.82066631317139                    Mean Train Rewards: -10248.2\n",
            "Episode: 320 |                     Train Rewards: -5165.3                     Violations: 51.65264010429381                    Mean Train Rewards: -10120.1\n",
            "Episode: 330 |                     Train Rewards: -11491.8                     Violations: 114.91775035858153                    Mean Train Rewards: -9844.3\n",
            "Episode: 340 |                     Train Rewards: -10652.9                     Violations: 106.52938604354858                    Mean Train Rewards: -9697.2\n",
            "Episode: 350 |                     Train Rewards: -11002.4                     Violations: 110.02422094345096                    Mean Train Rewards: -9677.7\n",
            "Episode: 360 |                     Train Rewards: -10888.3                     Violations: 108.88298273086548                    Mean Train Rewards: -9646.7\n",
            "Episode: 370 |                     Train Rewards: -7682.5                     Violations: 76.82522058486937                    Mean Train Rewards: -9360.6\n",
            "Episode: 380 |                     Train Rewards: -10325.9                     Violations: 103.25872421264648                    Mean Train Rewards: -9144.7\n",
            "Episode: 390 |                     Train Rewards: -1511.2                     Violations: 15.44528841972351                    Mean Train Rewards: -8729.9\n",
            "Episode: 400 |                     Train Rewards: 32.1                     Violations: 0                    Mean Train Rewards: -7962.9\n",
            "Episode: 410 |                     Train Rewards: -3743.0                     Violations: 37.429553270339966                    Mean Train Rewards: -7151.0\n",
            "Episode: 420 |                     Train Rewards: -2694.8                     Violations: 26.947962045669556                    Mean Train Rewards: -6665.8\n",
            "Episode: 430 |                     Train Rewards: -3416.1                     Violations: 34.16116714477539                    Mean Train Rewards: -6151.4\n",
            "Episode: 440 |                     Train Rewards: -8716.5                     Violations: 87.16451644897462                    Mean Train Rewards: -5708.4\n",
            "Episode: 450 |                     Train Rewards: -5848.4                     Violations: 58.48363161087036                    Mean Train Rewards: -5330.8\n",
            "Episode: 460 |                     Train Rewards: -1800.3                     Violations: 18.290140628814697                    Mean Train Rewards: -4696.2\n",
            "Episode: 470 |                     Train Rewards: 80.2                     Violations: 0                    Mean Train Rewards: -3968.1\n",
            "Episode: 480 |                     Train Rewards: 12.0                     Violations: 0                    Mean Train Rewards: -3128.5\n",
            "Episode: 490 |                     Train Rewards: 0.0                     Violations: 0                    Mean Train Rewards: -2552.1\n",
            "Episode: 500 |                     Train Rewards: 7.6                     Violations: 0                    Mean Train Rewards: -2349.5\n",
            "Episode: 510 |                     Train Rewards: 28.9                     Violations: 0                    Mean Train Rewards: -2256.9\n",
            "Episode: 520 |                     Train Rewards: -173.4                     Violations: 1.8983924388885498                    Mean Train Rewards: -2065.6\n",
            "Episode: 530 |                     Train Rewards: 31.5                     Violations: 0                    Mean Train Rewards: -1802.7\n",
            "Episode: 540 |                     Train Rewards: -426.3                     Violations: 3.9474868774414134                    Mean Train Rewards: -1321.4\n",
            "Episode: 550 |                     Train Rewards: -1107.2                     Violations: 11.387583017349243                    Mean Train Rewards: -714.2\n",
            "Episode: 560 |                     Train Rewards: 1.1                     Violations: 0                    Mean Train Rewards: -335.6\n",
            "Episode: 570 |                     Train Rewards: -1023.0                     Violations: 10.438563823699951                    Mean Train Rewards: -280.9\n",
            "Episode: 580 |                     Train Rewards: 54.9                     Violations: 0                    Mean Train Rewards: -261.1\n",
            "Episode: 590 |                     Train Rewards: -447.8                     Violations: 4.542871713638306                    Mean Train Rewards: -236.8\n",
            "Episode: 600 |                     Train Rewards: -166.8                     Violations: 2.0607376098632812                    Mean Train Rewards: -237.0\n",
            "Episode: 610 |                     Train Rewards: 64.4                     Violations: 0                    Mean Train Rewards: -212.2\n",
            "Episode: 620 |                     Train Rewards: 44.2                     Violations: 0                    Mean Train Rewards: -217.4\n",
            "Episode: 630 |                     Train Rewards: -395.4                     Violations: 4.067178964614868                    Mean Train Rewards: -214.7\n",
            "Episode: 640 |                     Train Rewards: 7.4                     Violations: 0                    Mean Train Rewards: -209.0\n",
            "Episode: 650 |                     Train Rewards: 27.0                     Violations: 0                    Mean Train Rewards: -164.9\n",
            "Episode: 660 |                     Train Rewards: -439.6                     Violations: 4.396175146102912                    Mean Train Rewards: -144.8\n",
            "Episode: 670 |                     Train Rewards: -807.8                     Violations: 8.447023630142212                    Mean Train Rewards: -167.1\n",
            "Episode: 680 |                     Train Rewards: 8.6                     Violations: 0                    Mean Train Rewards: -174.3\n",
            "Episode: 690 |                     Train Rewards: 46.1                     Violations: 0                    Mean Train Rewards: -164.9\n",
            "Episode: 700 |                     Train Rewards: 54.2                     Violations: 0                    Mean Train Rewards: -138.8\n",
            "Episode: 710 |                     Train Rewards: -158.0                     Violations: 1.7465794086456228                    Mean Train Rewards: -143.4\n",
            "Episode: 720 |                     Train Rewards: 56.8                     Violations: 0                    Mean Train Rewards: -121.2\n",
            "Episode: 730 |                     Train Rewards: -219.3                     Violations: 2.48626708984375                    Mean Train Rewards: -114.1\n",
            "Episode: 740 |                     Train Rewards: 18.5                     Violations: 0.1361393928527761                    Mean Train Rewards: -115.3\n",
            "Episode: 750 |                     Train Rewards: -22.7                     Violations: 0                    Mean Train Rewards: -108.7\n",
            "Episode: 760 |                     Train Rewards: 70.0                     Violations: 0                    Mean Train Rewards: -100.4\n",
            "Episode: 770 |                     Train Rewards: 47.3                     Violations: 0                    Mean Train Rewards: -72.2\n",
            "Episode: 780 |                     Train Rewards: 22.8                     Violations: 0                    Mean Train Rewards: -62.1\n",
            "Episode: 790 |                     Train Rewards: 9.5                     Violations: 0                    Mean Train Rewards: -62.1\n",
            "Episode: 800 |                     Train Rewards: 28.8                     Violations: 0                    Mean Train Rewards: -62.6\n",
            "Episode: 810 |                     Train Rewards: -268.5                     Violations: 3.0441009998321533                    Mean Train Rewards: -55.3\n",
            "Episode: 820 |                     Train Rewards: 14.3                     Violations: 0                    Mean Train Rewards: -53.8\n",
            "Episode: 830 |                     Train Rewards: 39.7                     Violations: 0                    Mean Train Rewards: -23.7\n",
            "Episode: 840 |                     Train Rewards: 11.3                     Violations: 0                    Mean Train Rewards: -15.6\n",
            "Episode: 850 |                     Train Rewards: 36.6                     Violations: 0                    Mean Train Rewards: -10.7\n",
            "Episode: 860 |                     Train Rewards: 65.6                     Violations: 0                    Mean Train Rewards: -1.4\n",
            "Episode: 870 |                     Train Rewards: 22.7                     Violations: 0                    Mean Train Rewards: 9.2\n",
            "Episode: 880 |                     Train Rewards: 45.2                     Violations: 0                    Mean Train Rewards: 10.5\n",
            "Episode: 890 |                     Train Rewards: 24.0                     Violations: 0                    Mean Train Rewards: 18.5\n",
            "Episode: 900 |                     Train Rewards: -406.2                     Violations: 4.062299728393555                    Mean Train Rewards: 7.0\n",
            "Episode: 910 |                     Train Rewards: 35.4                     Violations: 0                    Mean Train Rewards: 5.5\n",
            "Episode: 920 |                     Train Rewards: 56.8                     Violations: 0                    Mean Train Rewards: 8.0\n",
            "Episode: 930 |                     Train Rewards: 22.1                     Violations: 0                    Mean Train Rewards: 7.5\n",
            "Episode: 940 |                     Train Rewards: -196.7                     Violations: 1.9655847549438477                    Mean Train Rewards: 6.0\n",
            "Episode: 950 |                     Train Rewards: 33.0                     Violations: 0                    Mean Train Rewards: 5.7\n",
            "Episode: 960 |                     Train Rewards: 45.8                     Violations: 0                    Mean Train Rewards: 1.7\n",
            "Episode: 970 |                     Train Rewards: 35.1                     Violations: 0                    Mean Train Rewards: -2.8\n",
            "Episode: 980 |                     Train Rewards: 23.0                     Violations: 0                    Mean Train Rewards: 1.7\n",
            "Episode: 990 |                     Train Rewards: 37.6                     Violations: 0                    Mean Train Rewards: 0.7\n",
            "Episode: 1000 |                     Train Rewards: 3.0                     Violations: 0                    Mean Train Rewards: 13.3\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-37/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-38\n",
            "\n",
            "==================================================\n",
            "Starting run 15/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: 31.2                     Violations: 35.32756328582764                    Mean Train Rewards: 7.8\n",
            "Episode:  20 |                     Train Rewards: -37.6                     Violations: 0                    Mean Train Rewards: 3.5\n",
            "Episode:  30 |                     Train Rewards: 17.5                     Violations: 0.13150811195373535                    Mean Train Rewards: 1.3\n",
            "Episode:  40 |                     Train Rewards: 0.0                     Violations: 4.278306961059577                    Mean Train Rewards: 4.4\n",
            "Episode:  50 |                     Train Rewards: 26.5                     Violations: 1.3663792610168457                    Mean Train Rewards: 4.9\n",
            "Episode:  60 |                     Train Rewards: 32.2                     Violations: 11.237152814865112                    Mean Train Rewards: 5.9\n",
            "Episode:  70 |                     Train Rewards: 0.0                     Violations: 20.77686667442321                    Mean Train Rewards: 5.3\n",
            "Episode:  80 |                     Train Rewards: 0.0                     Violations: 27.79796600341797                    Mean Train Rewards: 5.7\n",
            "Episode:  90 |                     Train Rewards: 1.8                     Violations: 4.54426646232605                    Mean Train Rewards: 5.9\n",
            "Episode: 100 |                     Train Rewards: -13.4                     Violations: 1.4264845848083496                    Mean Train Rewards: 6.9\n",
            "Episode: 110 |                     Train Rewards: 16.8                     Violations: 1.113119125366211                    Mean Train Rewards: 9.5\n",
            "Episode: 120 |                     Train Rewards: 0.0                     Violations: 12.34248161315918                    Mean Train Rewards: 10.5\n",
            "Episode: 130 |                     Train Rewards: -2.2                     Violations: 4.367026090621948                    Mean Train Rewards: 13.2\n",
            "Episode: 140 |                     Train Rewards: 45.3                     Violations: 0.18912792205809836                    Mean Train Rewards: 13.3\n",
            "Episode: 150 |                     Train Rewards: 32.3                     Violations: 4.90214467048645                    Mean Train Rewards: 15.4\n",
            "Episode: 160 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 15.8\n",
            "Episode: 170 |                     Train Rewards: 19.4                     Violations: 0.12899279594421387                    Mean Train Rewards: 16.8\n",
            "Episode: 180 |                     Train Rewards: 18.3                     Violations: 0                    Mean Train Rewards: 17.6\n",
            "Episode: 190 |                     Train Rewards: 0.0                     Violations: 12.482469081878662                    Mean Train Rewards: 18.4\n",
            "Episode: 200 |                     Train Rewards: 41.8                     Violations: 0.21174192428588157                    Mean Train Rewards: 19.2\n",
            "Episode: 210 |                     Train Rewards: -22.1                     Violations: 0.2318406105041504                    Mean Train Rewards: 17.2\n",
            "Episode: 220 |                     Train Rewards: 58.4                     Violations: 0                    Mean Train Rewards: 18.2\n",
            "Episode: 230 |                     Train Rewards: 0.7                     Violations: 2.3264729976654053                    Mean Train Rewards: 18.7\n",
            "Episode: 240 |                     Train Rewards: 32.6                     Violations: 0.9157979488372803                    Mean Train Rewards: 18.8\n",
            "Episode: 250 |                     Train Rewards: 43.5                     Violations: 0                    Mean Train Rewards: 18.1\n",
            "Episode: 260 |                     Train Rewards: 30.1                     Violations: 0                    Mean Train Rewards: 19.5\n",
            "Episode: 270 |                     Train Rewards: 58.0                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 280 |                     Train Rewards: 23.1                     Violations: 0                    Mean Train Rewards: 23.3\n",
            "Episode: 290 |                     Train Rewards: 35.8                     Violations: 3.3441686630249023                    Mean Train Rewards: 23.7\n",
            "Episode: 300 |                     Train Rewards: 18.5                     Violations: 0                    Mean Train Rewards: 24.4\n",
            "Episode: 310 |                     Train Rewards: -33.3                     Violations: 0                    Mean Train Rewards: 24.3\n",
            "Episode: 320 |                     Train Rewards: 1.1                     Violations: 0                    Mean Train Rewards: 22.1\n",
            "Episode: 330 |                     Train Rewards: 55.0                     Violations: 0                    Mean Train Rewards: 20.6\n",
            "Episode: 340 |                     Train Rewards: 13.3                     Violations: 4.691007137298584                    Mean Train Rewards: 19.5\n",
            "Episode: 350 |                     Train Rewards: 30.3                     Violations: 0                    Mean Train Rewards: 20.0\n",
            "Episode: 360 |                     Train Rewards: 19.5                     Violations: 3.4133994579315186                    Mean Train Rewards: 20.7\n",
            "Episode: 370 |                     Train Rewards: 5.1                     Violations: 2.6864492893218994                    Mean Train Rewards: 20.5\n",
            "Episode: 380 |                     Train Rewards: 32.5                     Violations: 0.23081541061401367                    Mean Train Rewards: 20.1\n",
            "Episode: 390 |                     Train Rewards: 1.7                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 400 |                     Train Rewards: 11.5                     Violations: 0                    Mean Train Rewards: 22.0\n",
            "Episode: 410 |                     Train Rewards: 30.0                     Violations: 0.7748925685882568                    Mean Train Rewards: 24.4\n",
            "Episode: 420 |                     Train Rewards: 63.9                     Violations: 0                    Mean Train Rewards: 27.6\n",
            "Episode: 430 |                     Train Rewards: 33.8                     Violations: 0                    Mean Train Rewards: 28.8\n",
            "Episode: 440 |                     Train Rewards: 38.8                     Violations: 3.1067097187042307                    Mean Train Rewards: 30.3\n",
            "Episode: 450 |                     Train Rewards: 31.6                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 460 |                     Train Rewards: 2.0                     Violations: 0.5039656162261963                    Mean Train Rewards: 31.2\n",
            "Episode: 470 |                     Train Rewards: 48.7                     Violations: 0                    Mean Train Rewards: 32.3\n",
            "Episode: 480 |                     Train Rewards: 27.0                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 490 |                     Train Rewards: 12.4                     Violations: 0                    Mean Train Rewards: 32.9\n",
            "Episode: 500 |                     Train Rewards: 45.5                     Violations: 0                    Mean Train Rewards: 31.6\n",
            "Episode: 510 |                     Train Rewards: 63.1                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 520 |                     Train Rewards: 29.5                     Violations: 0.0705564022064209                    Mean Train Rewards: 32.2\n",
            "Episode: 530 |                     Train Rewards: 23.6                     Violations: 0                    Mean Train Rewards: 31.7\n",
            "Episode: 540 |                     Train Rewards: 21.2                     Violations: 0                    Mean Train Rewards: 31.1\n",
            "Episode: 550 |                     Train Rewards: 24.7                     Violations: 2.889087200164795                    Mean Train Rewards: 30.3\n",
            "Episode: 560 |                     Train Rewards: 23.0                     Violations: 0                    Mean Train Rewards: 29.4\n",
            "Episode: 570 |                     Train Rewards: 15.8                     Violations: 1.7472290992736745                    Mean Train Rewards: 29.0\n",
            "Episode: 580 |                     Train Rewards: 22.3                     Violations: 0                    Mean Train Rewards: 27.9\n",
            "Episode: 590 |                     Train Rewards: 17.8                     Violations: 0.6643080711364746                    Mean Train Rewards: 27.7\n",
            "Episode: 600 |                     Train Rewards: 38.2                     Violations: 0.24789214134216309                    Mean Train Rewards: 29.7\n",
            "Episode: 610 |                     Train Rewards: 52.7                     Violations: 0                    Mean Train Rewards: 30.9\n",
            "Episode: 620 |                     Train Rewards: 69.7                     Violations: 0                    Mean Train Rewards: 30.8\n",
            "Episode: 630 |                     Train Rewards: 23.3                     Violations: 1.1555993556976318                    Mean Train Rewards: 32.5\n",
            "Episode: 640 |                     Train Rewards: 57.0                     Violations: 0                    Mean Train Rewards: 35.8\n",
            "Episode: 650 |                     Train Rewards: 66.9                     Violations: 0                    Mean Train Rewards: 38.3\n",
            "Episode: 660 |                     Train Rewards: 66.8                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 670 |                     Train Rewards: 21.7                     Violations: 0.8872592449188232                    Mean Train Rewards: 39.8\n",
            "Episode: 680 |                     Train Rewards: 35.8                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 690 |                     Train Rewards: 43.3                     Violations: 0                    Mean Train Rewards: 42.0\n",
            "Episode: 700 |                     Train Rewards: 31.4                     Violations: 0                    Mean Train Rewards: 39.4\n",
            "Episode: 710 |                     Train Rewards: 66.1                     Violations: 0                    Mean Train Rewards: 39.0\n",
            "Episode: 720 |                     Train Rewards: 43.2                     Violations: 0                    Mean Train Rewards: 38.7\n",
            "Episode: 730 |                     Train Rewards: 65.6                     Violations: 0                    Mean Train Rewards: 39.6\n",
            "Episode: 740 |                     Train Rewards: 52.1                     Violations: 0                    Mean Train Rewards: 37.9\n",
            "Episode: 750 |                     Train Rewards: -5.7                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 760 |                     Train Rewards: 60.7                     Violations: 0                    Mean Train Rewards: 34.6\n",
            "Episode: 770 |                     Train Rewards: 28.2                     Violations: 0.7347190380096436                    Mean Train Rewards: 35.4\n",
            "Episode: 780 |                     Train Rewards: 45.0                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 790 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 800 |                     Train Rewards: 45.4                     Violations: 0                    Mean Train Rewards: 38.9\n",
            "Episode: 810 |                     Train Rewards: 44.0                     Violations: 2.956589460372925                    Mean Train Rewards: 40.3\n",
            "Episode: 820 |                     Train Rewards: 39.8                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 830 |                     Train Rewards: 38.4                     Violations: 0                    Mean Train Rewards: 39.3\n",
            "Episode: 840 |                     Train Rewards: 22.0                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 850 |                     Train Rewards: 38.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 860 |                     Train Rewards: 57.3                     Violations: 0                    Mean Train Rewards: 41.5\n",
            "Episode: 870 |                     Train Rewards: 32.9                     Violations: 0                    Mean Train Rewards: 41.3\n",
            "Episode: 880 |                     Train Rewards: 43.4                     Violations: 0                    Mean Train Rewards: 41.0\n",
            "Episode: 890 |                     Train Rewards: 29.3                     Violations: 0                    Mean Train Rewards: 40.4\n",
            "Episode: 900 |                     Train Rewards: 80.7                     Violations: 0                    Mean Train Rewards: 40.9\n",
            "Episode: 910 |                     Train Rewards: 45.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 920 |                     Train Rewards: 43.6                     Violations: 0                    Mean Train Rewards: 41.1\n",
            "Episode: 930 |                     Train Rewards: 15.6                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 940 |                     Train Rewards: 42.0                     Violations: 0                    Mean Train Rewards: 40.1\n",
            "Episode: 950 |                     Train Rewards: 27.8                     Violations: 0                    Mean Train Rewards: 38.8\n",
            "Episode: 960 |                     Train Rewards: 38.8                     Violations: 0                    Mean Train Rewards: 37.5\n",
            "Episode: 970 |                     Train Rewards: 30.0                     Violations: 0                    Mean Train Rewards: 37.7\n",
            "Episode: 980 |                     Train Rewards: 18.9                     Violations: 0                    Mean Train Rewards: 35.0\n",
            "Episode: 990 |                     Train Rewards: 28.1                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 1000 |                     Train Rewards: 2.8                     Violations: 0                    Mean Train Rewards: 30.7\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-38/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-39\n",
            "\n",
            "==================================================\n",
            "Starting run 16/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: 31.2                     Violations: 35.32756328582764                    Mean Train Rewards: 7.8\n",
            "Episode:  20 |                     Train Rewards: -37.6                     Violations: 0                    Mean Train Rewards: 3.5\n",
            "Episode:  30 |                     Train Rewards: 17.5                     Violations: 0.13150811195373535                    Mean Train Rewards: 1.3\n",
            "Episode:  40 |                     Train Rewards: 0.0                     Violations: 4.278306961059577                    Mean Train Rewards: 4.4\n",
            "Episode:  50 |                     Train Rewards: 26.5                     Violations: 1.3663792610168457                    Mean Train Rewards: 4.9\n",
            "Episode:  60 |                     Train Rewards: 32.2                     Violations: 11.237152814865112                    Mean Train Rewards: 5.9\n",
            "Episode:  70 |                     Train Rewards: 0.0                     Violations: 20.77686667442321                    Mean Train Rewards: 5.3\n",
            "Episode:  80 |                     Train Rewards: 0.0                     Violations: 27.79796600341797                    Mean Train Rewards: 5.7\n",
            "Episode:  90 |                     Train Rewards: 1.8                     Violations: 4.54426646232605                    Mean Train Rewards: 5.9\n",
            "Episode: 100 |                     Train Rewards: -13.4                     Violations: 1.4264845848083496                    Mean Train Rewards: 6.9\n",
            "Episode: 110 |                     Train Rewards: 16.8                     Violations: 1.113119125366211                    Mean Train Rewards: 9.5\n",
            "Episode: 120 |                     Train Rewards: 0.0                     Violations: 12.34248161315918                    Mean Train Rewards: 10.5\n",
            "Episode: 130 |                     Train Rewards: -2.2                     Violations: 4.367026090621948                    Mean Train Rewards: 13.2\n",
            "Episode: 140 |                     Train Rewards: 45.3                     Violations: 0.18912792205809836                    Mean Train Rewards: 13.3\n",
            "Episode: 150 |                     Train Rewards: 32.3                     Violations: 4.90214467048645                    Mean Train Rewards: 15.4\n",
            "Episode: 160 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 15.8\n",
            "Episode: 170 |                     Train Rewards: 19.4                     Violations: 0.12899279594421387                    Mean Train Rewards: 16.8\n",
            "Episode: 180 |                     Train Rewards: 18.3                     Violations: 0                    Mean Train Rewards: 17.6\n",
            "Episode: 190 |                     Train Rewards: 0.0                     Violations: 12.482469081878662                    Mean Train Rewards: 18.4\n",
            "Episode: 200 |                     Train Rewards: 41.8                     Violations: 0.21174192428588157                    Mean Train Rewards: 19.2\n",
            "Episode: 210 |                     Train Rewards: -22.1                     Violations: 0.2318406105041504                    Mean Train Rewards: 17.2\n",
            "Episode: 220 |                     Train Rewards: 58.4                     Violations: 0                    Mean Train Rewards: 18.2\n",
            "Episode: 230 |                     Train Rewards: 0.7                     Violations: 2.3264729976654053                    Mean Train Rewards: 18.7\n",
            "Episode: 240 |                     Train Rewards: 32.6                     Violations: 0.9157979488372803                    Mean Train Rewards: 18.8\n",
            "Episode: 250 |                     Train Rewards: 43.5                     Violations: 0                    Mean Train Rewards: 18.1\n",
            "Episode: 260 |                     Train Rewards: 30.1                     Violations: 0                    Mean Train Rewards: 19.5\n",
            "Episode: 270 |                     Train Rewards: 58.0                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 280 |                     Train Rewards: 23.1                     Violations: 0                    Mean Train Rewards: 23.3\n",
            "Episode: 290 |                     Train Rewards: 35.8                     Violations: 3.3441686630249023                    Mean Train Rewards: 23.7\n",
            "Episode: 300 |                     Train Rewards: 18.5                     Violations: 0                    Mean Train Rewards: 24.4\n",
            "Episode: 310 |                     Train Rewards: -33.3                     Violations: 0                    Mean Train Rewards: 24.3\n",
            "Episode: 320 |                     Train Rewards: 1.1                     Violations: 0                    Mean Train Rewards: 22.1\n",
            "Episode: 330 |                     Train Rewards: 55.0                     Violations: 0                    Mean Train Rewards: 20.6\n",
            "Episode: 340 |                     Train Rewards: 13.3                     Violations: 4.691007137298584                    Mean Train Rewards: 19.5\n",
            "Episode: 350 |                     Train Rewards: 30.3                     Violations: 0                    Mean Train Rewards: 20.0\n",
            "Episode: 360 |                     Train Rewards: 19.5                     Violations: 3.4133994579315186                    Mean Train Rewards: 20.7\n",
            "Episode: 370 |                     Train Rewards: 5.1                     Violations: 2.6864492893218994                    Mean Train Rewards: 20.5\n",
            "Episode: 380 |                     Train Rewards: 32.5                     Violations: 0.23081541061401367                    Mean Train Rewards: 20.1\n",
            "Episode: 390 |                     Train Rewards: 1.7                     Violations: 0                    Mean Train Rewards: 21.4\n",
            "Episode: 400 |                     Train Rewards: 11.5                     Violations: 0                    Mean Train Rewards: 22.0\n",
            "Episode: 410 |                     Train Rewards: 30.0                     Violations: 0.7748925685882568                    Mean Train Rewards: 24.4\n",
            "Episode: 420 |                     Train Rewards: 63.9                     Violations: 0                    Mean Train Rewards: 27.6\n",
            "Episode: 430 |                     Train Rewards: 33.8                     Violations: 0                    Mean Train Rewards: 28.8\n",
            "Episode: 440 |                     Train Rewards: 38.8                     Violations: 3.1067097187042307                    Mean Train Rewards: 30.3\n",
            "Episode: 450 |                     Train Rewards: 31.6                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 460 |                     Train Rewards: 2.0                     Violations: 0.5039656162261963                    Mean Train Rewards: 31.2\n",
            "Episode: 470 |                     Train Rewards: 48.7                     Violations: 0                    Mean Train Rewards: 32.3\n",
            "Episode: 480 |                     Train Rewards: 27.0                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 490 |                     Train Rewards: 12.4                     Violations: 0                    Mean Train Rewards: 32.9\n",
            "Episode: 500 |                     Train Rewards: 45.5                     Violations: 0                    Mean Train Rewards: 31.6\n",
            "Episode: 510 |                     Train Rewards: 63.1                     Violations: 0                    Mean Train Rewards: 31.2\n",
            "Episode: 520 |                     Train Rewards: 29.5                     Violations: 0.0705564022064209                    Mean Train Rewards: 32.2\n",
            "Episode: 530 |                     Train Rewards: 23.6                     Violations: 0                    Mean Train Rewards: 31.7\n",
            "Episode: 540 |                     Train Rewards: 21.2                     Violations: 0                    Mean Train Rewards: 31.1\n",
            "Episode: 550 |                     Train Rewards: 24.7                     Violations: 2.889087200164795                    Mean Train Rewards: 30.3\n",
            "Episode: 560 |                     Train Rewards: 23.0                     Violations: 0                    Mean Train Rewards: 29.4\n",
            "Episode: 570 |                     Train Rewards: 15.8                     Violations: 1.7472290992736745                    Mean Train Rewards: 29.0\n",
            "Episode: 580 |                     Train Rewards: 22.3                     Violations: 0                    Mean Train Rewards: 27.9\n",
            "Episode: 590 |                     Train Rewards: 17.8                     Violations: 0.6643080711364746                    Mean Train Rewards: 27.7\n",
            "Episode: 600 |                     Train Rewards: 38.2                     Violations: 0.24789214134216309                    Mean Train Rewards: 29.7\n",
            "Episode: 610 |                     Train Rewards: 52.7                     Violations: 0                    Mean Train Rewards: 30.9\n",
            "Episode: 620 |                     Train Rewards: 69.7                     Violations: 0                    Mean Train Rewards: 30.8\n",
            "Episode: 630 |                     Train Rewards: 23.3                     Violations: 1.1555993556976318                    Mean Train Rewards: 32.5\n",
            "Episode: 640 |                     Train Rewards: 57.0                     Violations: 0                    Mean Train Rewards: 35.8\n",
            "Episode: 650 |                     Train Rewards: 66.9                     Violations: 0                    Mean Train Rewards: 38.3\n",
            "Episode: 660 |                     Train Rewards: 66.8                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 670 |                     Train Rewards: 21.7                     Violations: 0.8872592449188232                    Mean Train Rewards: 39.8\n",
            "Episode: 680 |                     Train Rewards: 35.8                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 690 |                     Train Rewards: 43.3                     Violations: 0                    Mean Train Rewards: 42.0\n",
            "Episode: 700 |                     Train Rewards: 31.4                     Violations: 0                    Mean Train Rewards: 39.4\n",
            "Episode: 710 |                     Train Rewards: 66.1                     Violations: 0                    Mean Train Rewards: 39.0\n",
            "Episode: 720 |                     Train Rewards: 43.2                     Violations: 0                    Mean Train Rewards: 38.7\n",
            "Episode: 730 |                     Train Rewards: 65.6                     Violations: 0                    Mean Train Rewards: 39.6\n",
            "Episode: 740 |                     Train Rewards: 52.1                     Violations: 0                    Mean Train Rewards: 37.9\n",
            "Episode: 750 |                     Train Rewards: -5.7                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 760 |                     Train Rewards: 60.7                     Violations: 0                    Mean Train Rewards: 34.6\n",
            "Episode: 770 |                     Train Rewards: 28.2                     Violations: 0.7347190380096436                    Mean Train Rewards: 35.4\n",
            "Episode: 780 |                     Train Rewards: 45.0                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 790 |                     Train Rewards: 37.9                     Violations: 0                    Mean Train Rewards: 36.2\n",
            "Episode: 800 |                     Train Rewards: 45.4                     Violations: 0                    Mean Train Rewards: 38.9\n",
            "Episode: 810 |                     Train Rewards: 44.0                     Violations: 2.956589460372925                    Mean Train Rewards: 40.3\n",
            "Episode: 820 |                     Train Rewards: 39.8                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 830 |                     Train Rewards: 38.4                     Violations: 0                    Mean Train Rewards: 39.3\n",
            "Episode: 840 |                     Train Rewards: 22.0                     Violations: 0                    Mean Train Rewards: 40.0\n",
            "Episode: 850 |                     Train Rewards: 38.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 860 |                     Train Rewards: 57.3                     Violations: 0                    Mean Train Rewards: 41.5\n",
            "Episode: 870 |                     Train Rewards: 32.9                     Violations: 0                    Mean Train Rewards: 41.3\n",
            "Episode: 880 |                     Train Rewards: 43.4                     Violations: 0                    Mean Train Rewards: 41.0\n",
            "Episode: 890 |                     Train Rewards: 29.3                     Violations: 0                    Mean Train Rewards: 40.4\n",
            "Episode: 900 |                     Train Rewards: 80.7                     Violations: 0                    Mean Train Rewards: 40.9\n",
            "Episode: 910 |                     Train Rewards: 45.6                     Violations: 0                    Mean Train Rewards: 40.2\n",
            "Episode: 920 |                     Train Rewards: 43.6                     Violations: 0                    Mean Train Rewards: 41.1\n",
            "Episode: 930 |                     Train Rewards: 15.6                     Violations: 0                    Mean Train Rewards: 40.5\n",
            "Episode: 940 |                     Train Rewards: 42.0                     Violations: 0                    Mean Train Rewards: 40.1\n",
            "Episode: 950 |                     Train Rewards: 27.8                     Violations: 0                    Mean Train Rewards: 38.8\n",
            "Episode: 960 |                     Train Rewards: 38.8                     Violations: 0                    Mean Train Rewards: 37.5\n",
            "Episode: 970 |                     Train Rewards: 30.0                     Violations: 0                    Mean Train Rewards: 37.7\n",
            "Episode: 980 |                     Train Rewards: 18.9                     Violations: 0                    Mean Train Rewards: 35.0\n",
            "Episode: 990 |                     Train Rewards: 28.1                     Violations: 0                    Mean Train Rewards: 33.4\n",
            "Episode: 1000 |                     Train Rewards: 2.8                     Violations: 0                    Mean Train Rewards: 30.7\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-39/metadata\n",
            "Running sweep with 16 configurations and 2 seeds\n",
            "Total runs: 32\n",
            "Sampling 1000 random states to calculate offset k...\n",
            "  Completed 200/1000 samples...\n",
            "  Completed 400/1000 samples...\n",
            "  Completed 600/1000 samples...\n",
            "  Completed 800/1000 samples...\n",
            "  Completed 1000/1000 samples...\n",
            "  Using mean method: k = |2543.51| = 2543.51\n",
            "  Successfully sampled 1000/1000 states\n",
            "  Objective value range: [2301.01, 2799.96]\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-40\n",
            "\n",
            "==================================================\n",
            "Starting run 1/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.001, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 4, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -10234.9                     Violations: 0                    Mean Train Rewards: -9979.1\n",
            "Episode:  20 |                     Train Rewards: -10607.8                     Violations: 0                    Mean Train Rewards: -10201.9\n",
            "Episode:  30 |                     Train Rewards: -10479.7                     Violations: 0                    Mean Train Rewards: -10314.0\n",
            "Episode:  40 |                     Train Rewards: -10492.5                     Violations: 0                    Mean Train Rewards: -10340.8\n",
            "Episode:  50 |                     Train Rewards: -10943.9                     Violations: 0                    Mean Train Rewards: -10435.4\n",
            "Episode:  60 |                     Train Rewards: -10717.9                     Violations: 0                    Mean Train Rewards: -10500.2\n",
            "Episode:  70 |                     Train Rewards: -10947.6                     Violations: 0                    Mean Train Rewards: -10530.3\n",
            "Episode:  80 |                     Train Rewards: -10864.8                     Violations: 0                    Mean Train Rewards: -10569.5\n",
            "Episode:  90 |                     Train Rewards: -10519.1                     Violations: 0                    Mean Train Rewards: -10585.6\n",
            "Episode: 100 |                     Train Rewards: -10319.5                     Violations: 0                    Mean Train Rewards: -10565.0\n",
            "Episode: 110 |                     Train Rewards: -10276.4                     Violations: 0                    Mean Train Rewards: -10564.1\n",
            "Episode: 120 |                     Train Rewards: -10181.3                     Violations: 6.2107765674591064                    Mean Train Rewards: -10532.4\n",
            "Episode: 130 |                     Train Rewards: -10155.9                     Violations: 3.7987613677978587                    Mean Train Rewards: -10495.2\n",
            "Episode: 140 |                     Train Rewards: -10420.7                     Violations: 0                    Mean Train Rewards: -10491.4\n",
            "Episode: 150 |                     Train Rewards: -10522.3                     Violations: 0                    Mean Train Rewards: -10458.3\n",
            "Episode: 160 |                     Train Rewards: -10250.0                     Violations: 0                    Mean Train Rewards: -10416.8\n",
            "Episode: 170 |                     Train Rewards: -10426.6                     Violations: 0                    Mean Train Rewards: -10368.2\n",
            "Episode: 180 |                     Train Rewards: -10360.7                     Violations: 49.15649652481078                    Mean Train Rewards: -10304.9\n",
            "Episode: 190 |                     Train Rewards: -10161.8                     Violations: 37.22444534301758                    Mean Train Rewards: -10259.7\n",
            "Episode: 200 |                     Train Rewards: -9867.2                     Violations: 82.64283180236816                    Mean Train Rewards: -10233.1\n",
            "Episode: 210 |                     Train Rewards: -9903.8                     Violations: 49.52457785606384                    Mean Train Rewards: -10253.5\n",
            "Episode: 220 |                     Train Rewards: -9866.6                     Violations: 70.53105354309083                    Mean Train Rewards: -10236.5\n",
            "Episode: 230 |                     Train Rewards: -10054.3                     Violations: 19.70080852508545                    Mean Train Rewards: -10234.3\n",
            "Episode: 240 |                     Train Rewards: -10376.3                     Violations: 0                    Mean Train Rewards: -10213.7\n",
            "Episode: 250 |                     Train Rewards: -9926.6                     Violations: 69.55238342285156                    Mean Train Rewards: -10172.9\n",
            "Episode: 260 |                     Train Rewards: -10576.6                     Violations: 0                    Mean Train Rewards: -10147.7\n",
            "Episode: 270 |                     Train Rewards: -10528.5                     Violations: 0                    Mean Train Rewards: -10151.6\n",
            "Episode: 280 |                     Train Rewards: -9617.2                     Violations: 100.57417750358582                    Mean Train Rewards: -10132.0\n",
            "Episode: 290 |                     Train Rewards: -10392.9                     Violations: 15.58470368385315                    Mean Train Rewards: -10116.2\n",
            "Episode: 300 |                     Train Rewards: -10589.5                     Violations: 1.2304091453552175                    Mean Train Rewards: -10133.2\n",
            "Episode: 310 |                     Train Rewards: -10607.4                     Violations: 0                    Mean Train Rewards: -10148.4\n",
            "Episode: 320 |                     Train Rewards: -10236.9                     Violations: 12.63706922531128                    Mean Train Rewards: -10172.7\n",
            "Episode: 330 |                     Train Rewards: -10405.8                     Violations: 4.846593141555786                    Mean Train Rewards: -10175.6\n",
            "Episode: 340 |                     Train Rewards: -10209.2                     Violations: 35.367326736450195                    Mean Train Rewards: -10193.3\n",
            "Episode: 350 |                     Train Rewards: -10511.8                     Violations: 27.408871650695787                    Mean Train Rewards: -10233.4\n",
            "Episode: 360 |                     Train Rewards: -9953.0                     Violations: 30.960898399353027                    Mean Train Rewards: -10238.8\n",
            "Episode: 370 |                     Train Rewards: -10391.6                     Violations: 4.699435234069824                    Mean Train Rewards: -10222.5\n",
            "Episode: 380 |                     Train Rewards: -10085.3                     Violations: 31.773087978363023                    Mean Train Rewards: -10239.8\n",
            "Episode: 390 |                     Train Rewards: -10400.1                     Violations: 0                    Mean Train Rewards: -10259.9\n",
            "Episode: 400 |                     Train Rewards: -9996.4                     Violations: 87.22869873046874                    Mean Train Rewards: -10254.9\n",
            "Episode: 410 |                     Train Rewards: -10022.3                     Violations: 37.02385425567627                    Mean Train Rewards: -10246.3\n",
            "Episode: 420 |                     Train Rewards: -10471.7                     Violations: 3.0917251110076904                    Mean Train Rewards: -10252.2\n",
            "Episode: 430 |                     Train Rewards: -9910.4                     Violations: 27.83477902412413                    Mean Train Rewards: -10248.5\n",
            "Episode: 440 |                     Train Rewards: -10870.0                     Violations: 0                    Mean Train Rewards: -10238.4\n",
            "Episode: 450 |                     Train Rewards: -10229.5                     Violations: 49.347720146179185                    Mean Train Rewards: -10204.6\n",
            "Episode: 460 |                     Train Rewards: -10000.6                     Violations: 30.372668504714966                    Mean Train Rewards: -10189.9\n",
            "Episode: 470 |                     Train Rewards: -10369.7                     Violations: 39.174113273620605                    Mean Train Rewards: -10208.6\n",
            "Episode: 480 |                     Train Rewards: -10366.3                     Violations: 2.713414430618286                    Mean Train Rewards: -10219.0\n",
            "Episode: 490 |                     Train Rewards: -10043.3                     Violations: 47.52930402755737                    Mean Train Rewards: -10216.6\n",
            "Episode: 500 |                     Train Rewards: -10159.0                     Violations: 10.716019868850701                    Mean Train Rewards: -10225.2\n",
            "Episode: 510 |                     Train Rewards: -10601.3                     Violations: 0                    Mean Train Rewards: -10225.8\n",
            "Episode: 520 |                     Train Rewards: -10460.0                     Violations: 11.975195407867432                    Mean Train Rewards: -10228.9\n",
            "Episode: 530 |                     Train Rewards: -10264.3                     Violations: 34.62583303451538                    Mean Train Rewards: -10233.0\n",
            "Episode: 540 |                     Train Rewards: -10195.2                     Violations: 5.244555473327637                    Mean Train Rewards: -10234.8\n",
            "Episode: 550 |                     Train Rewards: -10497.3                     Violations: 0                    Mean Train Rewards: -10242.2\n",
            "Episode: 560 |                     Train Rewards: -10366.3                     Violations: 0                    Mean Train Rewards: -10259.0\n",
            "Episode: 570 |                     Train Rewards: -10416.2                     Violations: 10.843613147735596                    Mean Train Rewards: -10261.1\n",
            "Episode: 580 |                     Train Rewards: -10228.2                     Violations: 7.361634969711304                    Mean Train Rewards: -10248.5\n",
            "Episode: 590 |                     Train Rewards: -10395.3                     Violations: 9.143670797348022                    Mean Train Rewards: -10247.9\n",
            "Episode: 600 |                     Train Rewards: -10207.4                     Violations: 58.73051643371582                    Mean Train Rewards: -10238.9\n",
            "Episode: 610 |                     Train Rewards: -10499.9                     Violations: 0                    Mean Train Rewards: -10231.1\n",
            "Episode: 620 |                     Train Rewards: -9896.7                     Violations: 58.05919885635376                    Mean Train Rewards: -10210.9\n",
            "Episode: 630 |                     Train Rewards: -10168.9                     Violations: 36.7940402030945                    Mean Train Rewards: -10211.8\n",
            "Episode: 640 |                     Train Rewards: -9967.4                     Violations: 31.431578397750854                    Mean Train Rewards: -10193.7\n",
            "Episode: 650 |                     Train Rewards: -9878.6                     Violations: 50.761427879333496                    Mean Train Rewards: -10196.1\n",
            "Episode: 660 |                     Train Rewards: -10514.2                     Violations: 19.041844606399536                    Mean Train Rewards: -10183.3\n",
            "Episode: 670 |                     Train Rewards: -9945.1                     Violations: 60.54217457771301                    Mean Train Rewards: -10175.5\n",
            "Episode: 680 |                     Train Rewards: -10080.5                     Violations: 13.44677448272705                    Mean Train Rewards: -10167.7\n",
            "Episode: 690 |                     Train Rewards: -10204.4                     Violations: 8.451919555664062                    Mean Train Rewards: -10167.7\n",
            "Episode: 700 |                     Train Rewards: -10051.7                     Violations: 52.978477478027344                    Mean Train Rewards: -10157.7\n",
            "Episode: 710 |                     Train Rewards: -10511.9                     Violations: 0                    Mean Train Rewards: -10155.3\n",
            "Episode: 720 |                     Train Rewards: -10423.6                     Violations: 7.186182737350464                    Mean Train Rewards: -10172.7\n",
            "Episode: 730 |                     Train Rewards: -9737.6                     Violations: 62.057998180389404                    Mean Train Rewards: -10175.5\n",
            "Episode: 740 |                     Train Rewards: -9720.8                     Violations: 65.53183555603027                    Mean Train Rewards: -10187.1\n",
            "Episode: 750 |                     Train Rewards: -10167.2                     Violations: 52.49613523483278                    Mean Train Rewards: -10175.8\n",
            "Episode: 760 |                     Train Rewards: -9656.7                     Violations: 101.10469818115234                    Mean Train Rewards: -10179.5\n",
            "Episode: 770 |                     Train Rewards: -10426.6                     Violations: 0                    Mean Train Rewards: -10170.7\n",
            "Episode: 780 |                     Train Rewards: -10194.3                     Violations: 2.6019954681396413                    Mean Train Rewards: -10169.2\n",
            "Episode: 790 |                     Train Rewards: -10459.4                     Violations: 27.220032215118408                    Mean Train Rewards: -10148.2\n",
            "Episode: 800 |                     Train Rewards: -9826.5                     Violations: 36.12856388092041                    Mean Train Rewards: -10143.0\n",
            "Episode: 810 |                     Train Rewards: -10472.6                     Violations: 33.08539152145387                    Mean Train Rewards: -10136.1\n",
            "Episode: 820 |                     Train Rewards: -9872.5                     Violations: 47.617292404174826                    Mean Train Rewards: -10116.7\n",
            "Episode: 830 |                     Train Rewards: -9613.2                     Violations: 92.87934422492981                    Mean Train Rewards: -10111.2\n",
            "Episode: 840 |                     Train Rewards: -10138.2                     Violations: 38.834637403488145                    Mean Train Rewards: -10098.3\n",
            "Episode: 850 |                     Train Rewards: -10249.2                     Violations: 45.01322031021118                    Mean Train Rewards: -10083.0\n",
            "Episode: 860 |                     Train Rewards: -10020.9                     Violations: 40.79965949058531                    Mean Train Rewards: -10079.5\n",
            "Episode: 870 |                     Train Rewards: -10453.9                     Violations: 0.5947852134704519                    Mean Train Rewards: -10078.1\n",
            "Episode: 880 |                     Train Rewards: -10184.7                     Violations: 37.677106857299805                    Mean Train Rewards: -10090.6\n",
            "Episode: 890 |                     Train Rewards: -9994.5                     Violations: 23.108052015304565                    Mean Train Rewards: -10084.7\n",
            "Episode: 900 |                     Train Rewards: -10013.9                     Violations: 4.836546182632446                    Mean Train Rewards: -10073.3\n",
            "Episode: 910 |                     Train Rewards: -10164.4                     Violations: 4.585288763046265                    Mean Train Rewards: -10090.2\n",
            "Episode: 920 |                     Train Rewards: -10002.6                     Violations: 56.841034889221206                    Mean Train Rewards: -10086.1\n",
            "Episode: 930 |                     Train Rewards: -10387.5                     Violations: 19.849495887756348                    Mean Train Rewards: -10069.2\n",
            "Episode: 940 |                     Train Rewards: -9721.3                     Violations: 60.57940125465392                    Mean Train Rewards: -10074.1\n",
            "Episode: 950 |                     Train Rewards: -9554.7                     Violations: 107.41193413734436                    Mean Train Rewards: -10087.3\n",
            "Episode: 960 |                     Train Rewards: -10211.7                     Violations: 52.11174249649048                    Mean Train Rewards: -10092.5\n",
            "Episode: 970 |                     Train Rewards: -10067.2                     Violations: 45.567309856414795                    Mean Train Rewards: -10082.2\n",
            "Episode: 980 |                     Train Rewards: -10240.9                     Violations: 9.168665409088142                    Mean Train Rewards: -10077.2\n",
            "Episode: 990 |                     Train Rewards: -10055.0                     Violations: 31.580088138580322                    Mean Train Rewards: -10088.5\n",
            "Episode: 1000 |                     Train Rewards: -9747.3                     Violations: 61.53694152832031                    Mean Train Rewards: -10107.2\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 10 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 10 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-40/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-41\n",
            "\n",
            "==================================================\n",
            "Starting run 2/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0003, 'EPSILON': 0.2, 'ENTROPY_COEFFICIENT': 0.05, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 4, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -9981.2                     Violations: 7.934837341308594                    Mean Train Rewards: -9884.3\n",
            "Episode:  20 |                     Train Rewards: -10311.4                     Violations: 0                    Mean Train Rewards: -10012.9\n",
            "Episode:  30 |                     Train Rewards: -10290.6                     Violations: 0                    Mean Train Rewards: -10127.6\n",
            "Episode:  40 |                     Train Rewards: -10175.8                     Violations: 0                    Mean Train Rewards: -10130.4\n",
            "Episode:  50 |                     Train Rewards: -10308.2                     Violations: 0                    Mean Train Rewards: -10173.4\n",
            "Episode:  60 |                     Train Rewards: -10255.5                     Violations: 0                    Mean Train Rewards: -10175.6\n",
            "Episode:  70 |                     Train Rewards: -10322.8                     Violations: 0                    Mean Train Rewards: -10175.8\n",
            "Episode:  80 |                     Train Rewards: -10296.6                     Violations: 0                    Mean Train Rewards: -10186.1\n",
            "Episode:  90 |                     Train Rewards: -10012.6                     Violations: 5.901625156402588                    Mean Train Rewards: -10185.1\n",
            "Episode: 100 |                     Train Rewards: -9918.8                     Violations: 22.71098017692566                    Mean Train Rewards: -10159.9\n",
            "Episode: 110 |                     Train Rewards: -10015.4                     Violations: 3.9878952503204417                    Mean Train Rewards: -10152.0\n",
            "Episode: 120 |                     Train Rewards: -9936.4                     Violations: 14.488457441329949                    Mean Train Rewards: -10128.6\n",
            "Episode: 130 |                     Train Rewards: -9939.6                     Violations: 16.893078088760376                    Mean Train Rewards: -10088.0\n",
            "Episode: 140 |                     Train Rewards: -10103.3                     Violations: 1.0731840133666992                    Mean Train Rewards: -10081.1\n",
            "Episode: 150 |                     Train Rewards: -10169.7                     Violations: 0                    Mean Train Rewards: -10060.5\n",
            "Episode: 160 |                     Train Rewards: -10052.7                     Violations: 2.200697660446167                    Mean Train Rewards: -10056.1\n",
            "Episode: 170 |                     Train Rewards: -10188.1                     Violations: 0                    Mean Train Rewards: -10044.3\n",
            "Episode: 180 |                     Train Rewards: -10087.8                     Violations: 5.243035554885864                    Mean Train Rewards: -10025.4\n",
            "Episode: 190 |                     Train Rewards: -10130.9                     Violations: 0                    Mean Train Rewards: -10016.3\n",
            "Episode: 200 |                     Train Rewards: -10012.6                     Violations: 14.063023328781128                    Mean Train Rewards: -10021.9\n",
            "Episode: 210 |                     Train Rewards: -9594.7                     Violations: 89.45794820785522                    Mean Train Rewards: -10026.2\n",
            "Episode: 220 |                     Train Rewards: -9624.0                     Violations: 81.5182387828827                    Mean Train Rewards: -9998.5\n",
            "Episode: 230 |                     Train Rewards: -9665.4                     Violations: 66.92255496978758                    Mean Train Rewards: -9966.4\n",
            "Episode: 240 |                     Train Rewards: -9955.5                     Violations: 9.931104183197021                    Mean Train Rewards: -9951.7\n",
            "Episode: 250 |                     Train Rewards: -9989.3                     Violations: 11.36077165603637                    Mean Train Rewards: -9935.9\n",
            "Episode: 260 |                     Train Rewards: -10134.1                     Violations: 8.545558452606201                    Mean Train Rewards: -9923.6\n",
            "Episode: 270 |                     Train Rewards: -10103.5                     Violations: 0                    Mean Train Rewards: -9924.7\n",
            "Episode: 280 |                     Train Rewards: -9918.7                     Violations: 16.266170740127563                    Mean Train Rewards: -9919.6\n",
            "Episode: 290 |                     Train Rewards: -10226.9                     Violations: 0                    Mean Train Rewards: -9924.3\n",
            "Episode: 300 |                     Train Rewards: -10435.3                     Violations: 0                    Mean Train Rewards: -9952.7\n",
            "Episode: 310 |                     Train Rewards: -10588.8                     Violations: 0                    Mean Train Rewards: -10013.4\n",
            "Episode: 320 |                     Train Rewards: -10498.1                     Violations: 0                    Mean Train Rewards: -10098.1\n",
            "Episode: 330 |                     Train Rewards: -10615.4                     Violations: 0                    Mean Train Rewards: -10184.1\n",
            "Episode: 340 |                     Train Rewards: -10586.8                     Violations: 0                    Mean Train Rewards: -10243.2\n",
            "Episode: 350 |                     Train Rewards: -10744.3                     Violations: 0                    Mean Train Rewards: -10312.2\n",
            "Episode: 360 |                     Train Rewards: -10619.1                     Violations: 0                    Mean Train Rewards: -10380.1\n",
            "Episode: 370 |                     Train Rewards: -10473.8                     Violations: 0                    Mean Train Rewards: -10422.6\n",
            "Episode: 380 |                     Train Rewards: -10314.0                     Violations: 0                    Mean Train Rewards: -10464.2\n",
            "Episode: 390 |                     Train Rewards: -10291.3                     Violations: 0                    Mean Train Rewards: -10482.7\n",
            "Episode: 400 |                     Train Rewards: -10277.9                     Violations: 0                    Mean Train Rewards: -10478.5\n",
            "Episode: 410 |                     Train Rewards: -10404.2                     Violations: 0                    Mean Train Rewards: -10474.5\n",
            "Episode: 420 |                     Train Rewards: -10438.1                     Violations: 0                    Mean Train Rewards: -10470.3\n",
            "Episode: 430 |                     Train Rewards: -10139.2                     Violations: 0                    Mean Train Rewards: -10448.4\n",
            "Episode: 440 |                     Train Rewards: -10439.9                     Violations: 0                    Mean Train Rewards: -10424.9\n",
            "Episode: 450 |                     Train Rewards: -10211.1                     Violations: 0                    Mean Train Rewards: -10384.4\n",
            "Episode: 460 |                     Train Rewards: -10224.0                     Violations: 0                    Mean Train Rewards: -10341.8\n",
            "Episode: 470 |                     Train Rewards: -10435.7                     Violations: 0                    Mean Train Rewards: -10328.4\n",
            "Episode: 480 |                     Train Rewards: -10387.9                     Violations: 0                    Mean Train Rewards: -10327.3\n",
            "Episode: 490 |                     Train Rewards: -10377.7                     Violations: 0                    Mean Train Rewards: -10334.9\n",
            "Episode: 500 |                     Train Rewards: -10333.0                     Violations: 0                    Mean Train Rewards: -10355.3\n",
            "Episode: 510 |                     Train Rewards: -10323.3                     Violations: 0                    Mean Train Rewards: -10344.2\n",
            "Episode: 520 |                     Train Rewards: -10344.5                     Violations: 0                    Mean Train Rewards: -10328.7\n",
            "Episode: 530 |                     Train Rewards: -10544.9                     Violations: 0                    Mean Train Rewards: -10343.5\n",
            "Episode: 540 |                     Train Rewards: -10753.1                     Violations: 0                    Mean Train Rewards: -10358.0\n",
            "Episode: 550 |                     Train Rewards: -10424.1                     Violations: 0                    Mean Train Rewards: -10377.1\n",
            "Episode: 560 |                     Train Rewards: -10507.7                     Violations: 0                    Mean Train Rewards: -10389.0\n",
            "Episode: 570 |                     Train Rewards: -10747.8                     Violations: 0                    Mean Train Rewards: -10419.4\n",
            "Episode: 580 |                     Train Rewards: -10567.5                     Violations: 0                    Mean Train Rewards: -10446.2\n",
            "Episode: 590 |                     Train Rewards: -10489.9                     Violations: 0                    Mean Train Rewards: -10455.0\n",
            "Episode: 600 |                     Train Rewards: -10642.8                     Violations: 0                    Mean Train Rewards: -10474.2\n",
            "Episode: 610 |                     Train Rewards: -10485.4                     Violations: 0                    Mean Train Rewards: -10490.8\n",
            "Episode: 620 |                     Train Rewards: -10554.8                     Violations: 0                    Mean Train Rewards: -10509.5\n",
            "Episode: 630 |                     Train Rewards: -10439.6                     Violations: 0                    Mean Train Rewards: -10520.8\n",
            "Episode: 640 |                     Train Rewards: -10211.5                     Violations: 0                    Mean Train Rewards: -10512.0\n",
            "Episode: 650 |                     Train Rewards: -10254.6                     Violations: 0                    Mean Train Rewards: -10495.1\n",
            "Episode: 660 |                     Train Rewards: -10120.5                     Violations: 5.308940410614014                    Mean Train Rewards: -10471.4\n",
            "Episode: 670 |                     Train Rewards: -10056.4                     Violations: 1.2540030479431152                    Mean Train Rewards: -10420.7\n",
            "Episode: 680 |                     Train Rewards: -9922.3                     Violations: 15.537158250808723                    Mean Train Rewards: -10350.3\n",
            "Episode: 690 |                     Train Rewards: -10023.3                     Violations: 2.7232277393341064                    Mean Train Rewards: -10307.4\n",
            "Episode: 700 |                     Train Rewards: -9958.4                     Violations: 14.523409605026245                    Mean Train Rewards: -10236.9\n",
            "Episode: 710 |                     Train Rewards: -9998.1                     Violations: 5.8987486362457275                    Mean Train Rewards: -10180.6\n",
            "Episode: 720 |                     Train Rewards: -9976.2                     Violations: 11.514817476272583                    Mean Train Rewards: -10132.5\n",
            "Episode: 730 |                     Train Rewards: -9803.4                     Violations: 39.32019233703613                    Mean Train Rewards: -10073.7\n",
            "Episode: 740 |                     Train Rewards: -9629.2                     Violations: 76.20426416397093                    Mean Train Rewards: -10022.8\n",
            "Episode: 750 |                     Train Rewards: -9793.0                     Violations: 42.2606098651886                    Mean Train Rewards: -9972.6\n",
            "Episode: 760 |                     Train Rewards: -9495.8                     Violations: 121.68343305587769                    Mean Train Rewards: -9923.2\n",
            "Episode: 770 |                     Train Rewards: -9693.2                     Violations: 67.52861022949219                    Mean Train Rewards: -9868.7\n",
            "Episode: 780 |                     Train Rewards: -9646.6                     Violations: 72.19640493392943                    Mean Train Rewards: -9830.9\n",
            "Episode: 790 |                     Train Rewards: -9579.4                     Violations: 91.03111028671265                    Mean Train Rewards: -9781.3\n",
            "Episode: 800 |                     Train Rewards: -9492.7                     Violations: 122.90731906890872                    Mean Train Rewards: -9738.2\n",
            "Episode: 810 |                     Train Rewards: -9647.8                     Violations: 75.08048892021179                    Mean Train Rewards: -9705.0\n",
            "Episode: 820 |                     Train Rewards: -9581.6                     Violations: 89.39233422279358                    Mean Train Rewards: -9667.5\n",
            "Episode: 830 |                     Train Rewards: -9666.5                     Violations: 66.70793056488037                    Mean Train Rewards: -9642.9\n",
            "Episode: 840 |                     Train Rewards: -9733.2                     Violations: 53.35494041442871                    Mean Train Rewards: -9633.9\n",
            "Episode: 850 |                     Train Rewards: -9785.5                     Violations: 42.90584087371826                    Mean Train Rewards: -9624.3\n",
            "Episode: 860 |                     Train Rewards: -9787.9                     Violations: 42.41868019104004                    Mean Train Rewards: -9631.1\n",
            "Episode: 870 |                     Train Rewards: -9917.2                     Violations: 26.281474828720093                    Mean Train Rewards: -9662.1\n",
            "Episode: 880 |                     Train Rewards: -9918.6                     Violations: 20.048798322677612                    Mean Train Rewards: -9698.0\n",
            "Episode: 890 |                     Train Rewards: -9818.3                     Violations: 36.33580565452576                    Mean Train Rewards: -9721.6\n",
            "Episode: 900 |                     Train Rewards: -9875.1                     Violations: 24.986717700958252                    Mean Train Rewards: -9749.8\n",
            "Episode: 910 |                     Train Rewards: -9792.5                     Violations: 41.49233460426329                    Mean Train Rewards: -9783.9\n",
            "Episode: 920 |                     Train Rewards: -9841.0                     Violations: 31.802479028701775                    Mean Train Rewards: -9805.7\n",
            "Episode: 930 |                     Train Rewards: -9929.1                     Violations: 23.485671281814575                    Mean Train Rewards: -9817.2\n",
            "Episode: 940 |                     Train Rewards: -9698.6                     Violations: 60.28617978096008                    Mean Train Rewards: -9826.2\n",
            "Episode: 950 |                     Train Rewards: -9558.2                     Violations: 97.88227200508118                    Mean Train Rewards: -9822.3\n",
            "Episode: 960 |                     Train Rewards: -9661.5                     Violations: 73.35086941719055                    Mean Train Rewards: -9816.2\n",
            "Episode: 970 |                     Train Rewards: -9717.5                     Violations: 57.02040672302246                    Mean Train Rewards: -9788.2\n",
            "Episode: 980 |                     Train Rewards: -9860.3                     Violations: 27.94152855873108                    Mean Train Rewards: -9770.8\n",
            "Episode: 990 |                     Train Rewards: -9922.0                     Violations: 16.76194787025451                    Mean Train Rewards: -9784.7\n",
            "Episode: 1000 |                     Train Rewards: -9738.3                     Violations: 52.340993881225586                    Mean Train Rewards: -9799.3\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 10 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 10 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-41/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-42\n",
            "\n",
            "==================================================\n",
            "Starting run 3/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 128, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 4, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -10898.1                     Violations: 0                    Mean Train Rewards: -10934.5\n",
            "Episode:  20 |                     Train Rewards: -11140.7                     Violations: 0                    Mean Train Rewards: -11020.6\n",
            "Episode:  30 |                     Train Rewards: -11175.4                     Violations: 0                    Mean Train Rewards: -11064.4\n",
            "Episode:  40 |                     Train Rewards: -11173.9                     Violations: 0                    Mean Train Rewards: -11088.4\n",
            "Episode:  50 |                     Train Rewards: -11180.3                     Violations: 0                    Mean Train Rewards: -11104.1\n",
            "Episode:  60 |                     Train Rewards: -11183.1                     Violations: 0                    Mean Train Rewards: -11115.9\n",
            "Episode:  70 |                     Train Rewards: -11182.9                     Violations: 0                    Mean Train Rewards: -11123.4\n",
            "Episode:  80 |                     Train Rewards: -11177.4                     Violations: 0                    Mean Train Rewards: -11129.3\n",
            "Episode:  90 |                     Train Rewards: -11178.6                     Violations: 0                    Mean Train Rewards: -11134.5\n",
            "Episode: 100 |                     Train Rewards: -11194.2                     Violations: 0                    Mean Train Rewards: -11138.8\n",
            "Episode: 110 |                     Train Rewards: -11183.0                     Violations: 0                    Mean Train Rewards: -11162.7\n",
            "Episode: 120 |                     Train Rewards: -11175.0                     Violations: 0                    Mean Train Rewards: -11170.2\n",
            "Episode: 130 |                     Train Rewards: -11172.7                     Violations: 0                    Mean Train Rewards: -11172.4\n",
            "Episode: 140 |                     Train Rewards: -11191.9                     Violations: 0                    Mean Train Rewards: -11174.9\n",
            "Episode: 150 |                     Train Rewards: -11191.2                     Violations: 0                    Mean Train Rewards: -11177.1\n",
            "Episode: 160 |                     Train Rewards: -11183.0                     Violations: 0                    Mean Train Rewards: -11178.4\n",
            "Episode: 170 |                     Train Rewards: -11194.2                     Violations: 0                    Mean Train Rewards: -11180.2\n",
            "Episode: 180 |                     Train Rewards: -11195.0                     Violations: 0                    Mean Train Rewards: -11181.7\n",
            "Episode: 190 |                     Train Rewards: -11194.4                     Violations: 0                    Mean Train Rewards: -11183.1\n",
            "Episode: 200 |                     Train Rewards: -11190.1                     Violations: 0                    Mean Train Rewards: -11184.6\n",
            "Episode: 210 |                     Train Rewards: -11185.4                     Violations: 0                    Mean Train Rewards: -11186.4\n",
            "Episode: 220 |                     Train Rewards: -11189.6                     Violations: 0                    Mean Train Rewards: -11186.9\n",
            "Episode: 230 |                     Train Rewards: -11190.7                     Violations: 0                    Mean Train Rewards: -11188.8\n",
            "Episode: 240 |                     Train Rewards: -11195.6                     Violations: 0                    Mean Train Rewards: -11189.6\n",
            "Episode: 250 |                     Train Rewards: -11194.8                     Violations: 0                    Mean Train Rewards: -11189.9\n",
            "Episode: 260 |                     Train Rewards: -11198.7                     Violations: 0                    Mean Train Rewards: -11190.3\n",
            "Episode: 270 |                     Train Rewards: -11197.0                     Violations: 0                    Mean Train Rewards: -11190.7\n",
            "Episode: 280 |                     Train Rewards: -11191.4                     Violations: 0                    Mean Train Rewards: -11191.2\n",
            "Episode: 290 |                     Train Rewards: -11195.8                     Violations: 0                    Mean Train Rewards: -11191.3\n",
            "Episode: 300 |                     Train Rewards: -11196.8                     Violations: 0                    Mean Train Rewards: -11191.5\n",
            "Episode: 310 |                     Train Rewards: -11197.0                     Violations: 0                    Mean Train Rewards: -11191.8\n",
            "Episode: 320 |                     Train Rewards: -11190.9                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 330 |                     Train Rewards: -11196.0                     Violations: 0                    Mean Train Rewards: -11192.6\n",
            "Episode: 340 |                     Train Rewards: -11193.2                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 350 |                     Train Rewards: -11198.0                     Violations: 0                    Mean Train Rewards: -11193.1\n",
            "Episode: 360 |                     Train Rewards: -11193.4                     Violations: 0                    Mean Train Rewards: -11193.4\n",
            "Episode: 370 |                     Train Rewards: -11192.1                     Violations: 0                    Mean Train Rewards: -11193.2\n",
            "Episode: 380 |                     Train Rewards: -11190.8                     Violations: 0                    Mean Train Rewards: -11193.2\n",
            "Episode: 390 |                     Train Rewards: -11192.5                     Violations: 0                    Mean Train Rewards: -11193.3\n",
            "Episode: 400 |                     Train Rewards: -11193.4                     Violations: 0                    Mean Train Rewards: -11192.9\n",
            "Episode: 410 |                     Train Rewards: -11190.0                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 420 |                     Train Rewards: -11196.9                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 430 |                     Train Rewards: -11193.7                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 440 |                     Train Rewards: -11193.5                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 450 |                     Train Rewards: -11196.5                     Violations: 0                    Mean Train Rewards: -11192.2\n",
            "Episode: 460 |                     Train Rewards: -11196.1                     Violations: 0                    Mean Train Rewards: -11192.1\n",
            "Episode: 470 |                     Train Rewards: -11197.6                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 480 |                     Train Rewards: -11197.5                     Violations: 0                    Mean Train Rewards: -11193.2\n",
            "Episode: 490 |                     Train Rewards: -11194.4                     Violations: 0                    Mean Train Rewards: -11193.7\n",
            "Episode: 500 |                     Train Rewards: -11193.0                     Violations: 0                    Mean Train Rewards: -11194.1\n",
            "Episode: 510 |                     Train Rewards: -11196.5                     Violations: 0                    Mean Train Rewards: -11194.4\n",
            "Episode: 520 |                     Train Rewards: -11196.4                     Violations: 0                    Mean Train Rewards: -11194.6\n",
            "Episode: 530 |                     Train Rewards: -11193.9                     Violations: 0                    Mean Train Rewards: -11194.7\n",
            "Episode: 540 |                     Train Rewards: -11193.7                     Violations: 0                    Mean Train Rewards: -11194.7\n",
            "Episode: 550 |                     Train Rewards: -11196.4                     Violations: 0                    Mean Train Rewards: -11194.6\n",
            "Episode: 560 |                     Train Rewards: -11196.0                     Violations: 0                    Mean Train Rewards: -11194.6\n",
            "Episode: 570 |                     Train Rewards: -11196.3                     Violations: 0                    Mean Train Rewards: -11194.6\n",
            "Episode: 580 |                     Train Rewards: -11194.3                     Violations: 0                    Mean Train Rewards: -11194.3\n",
            "Episode: 590 |                     Train Rewards: -11191.8                     Violations: 0                    Mean Train Rewards: -11194.0\n",
            "Episode: 600 |                     Train Rewards: -11192.5                     Violations: 0                    Mean Train Rewards: -11193.7\n",
            "Episode: 610 |                     Train Rewards: -11195.2                     Violations: 0                    Mean Train Rewards: -11193.1\n",
            "Episode: 620 |                     Train Rewards: -11195.0                     Violations: 0                    Mean Train Rewards: -11192.8\n",
            "Episode: 630 |                     Train Rewards: -11186.2                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 640 |                     Train Rewards: -11185.6                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 650 |                     Train Rewards: -11194.9                     Violations: 0                    Mean Train Rewards: -11192.1\n",
            "Episode: 660 |                     Train Rewards: -11192.1                     Violations: 0                    Mean Train Rewards: -11191.1\n",
            "Episode: 670 |                     Train Rewards: -11193.8                     Violations: 0                    Mean Train Rewards: -11190.8\n",
            "Episode: 680 |                     Train Rewards: -11185.6                     Violations: 0                    Mean Train Rewards: -11190.2\n",
            "Episode: 690 |                     Train Rewards: -11193.9                     Violations: 0                    Mean Train Rewards: -11190.2\n",
            "Episode: 700 |                     Train Rewards: -11191.0                     Violations: 0                    Mean Train Rewards: -11190.2\n",
            "Episode: 710 |                     Train Rewards: -11194.8                     Violations: 0                    Mean Train Rewards: -11190.6\n",
            "Episode: 720 |                     Train Rewards: -11197.9                     Violations: 0                    Mean Train Rewards: -11190.9\n",
            "Episode: 730 |                     Train Rewards: -11190.8                     Violations: 0                    Mean Train Rewards: -11191.2\n",
            "Episode: 740 |                     Train Rewards: -11188.5                     Violations: 0                    Mean Train Rewards: -11191.5\n",
            "Episode: 750 |                     Train Rewards: -11189.6                     Violations: 0                    Mean Train Rewards: -11191.6\n",
            "Episode: 760 |                     Train Rewards: -11189.8                     Violations: 0                    Mean Train Rewards: -11192.6\n",
            "Episode: 770 |                     Train Rewards: -11193.6                     Violations: 0                    Mean Train Rewards: -11192.9\n",
            "Episode: 780 |                     Train Rewards: -11194.1                     Violations: 0                    Mean Train Rewards: -11193.7\n",
            "Episode: 790 |                     Train Rewards: -11194.5                     Violations: 0                    Mean Train Rewards: -11193.8\n",
            "Episode: 800 |                     Train Rewards: -11195.2                     Violations: 0                    Mean Train Rewards: -11194.0\n",
            "Episode: 810 |                     Train Rewards: -11197.3                     Violations: 0                    Mean Train Rewards: -11194.0\n",
            "Episode: 820 |                     Train Rewards: -11194.8                     Violations: 0                    Mean Train Rewards: -11193.8\n",
            "Episode: 830 |                     Train Rewards: -11189.8                     Violations: 0                    Mean Train Rewards: -11193.7\n",
            "Episode: 840 |                     Train Rewards: -11184.8                     Violations: 0                    Mean Train Rewards: -11193.4\n",
            "Episode: 850 |                     Train Rewards: -11194.9                     Violations: 0                    Mean Train Rewards: -11193.3\n",
            "Episode: 860 |                     Train Rewards: -11179.5                     Violations: 0                    Mean Train Rewards: -11192.9\n",
            "Episode: 870 |                     Train Rewards: -11188.2                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 880 |                     Train Rewards: -11143.8                     Violations: 0                    Mean Train Rewards: -11190.0\n",
            "Episode: 890 |                     Train Rewards: -11137.7                     Violations: 0                    Mean Train Rewards: -11185.5\n",
            "Episode: 900 |                     Train Rewards: -11172.5                     Violations: 0                    Mean Train Rewards: -11183.6\n",
            "Episode: 910 |                     Train Rewards: -11177.3                     Violations: 0                    Mean Train Rewards: -11182.7\n",
            "Episode: 920 |                     Train Rewards: -11171.2                     Violations: 0                    Mean Train Rewards: -11180.2\n",
            "Episode: 930 |                     Train Rewards: -11187.3                     Violations: 0                    Mean Train Rewards: -11178.6\n",
            "Episode: 940 |                     Train Rewards: -11165.9                     Violations: 0                    Mean Train Rewards: -11178.0\n",
            "Episode: 950 |                     Train Rewards: -11162.9                     Violations: 0                    Mean Train Rewards: -11175.4\n",
            "Episode: 960 |                     Train Rewards: -11179.2                     Violations: 0                    Mean Train Rewards: -11174.3\n",
            "Episode: 970 |                     Train Rewards: -11179.3                     Violations: 0                    Mean Train Rewards: -11171.4\n",
            "Episode: 980 |                     Train Rewards: -11119.9                     Violations: 0                    Mean Train Rewards: -11170.6\n",
            "Episode: 990 |                     Train Rewards: -11159.6                     Violations: 0                    Mean Train Rewards: -11173.5\n",
            "Episode: 1000 |                     Train Rewards: -11156.5                     Violations: 0                    Mean Train Rewards: -11173.6\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-42/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-43\n",
            "\n",
            "==================================================\n",
            "Starting run 4/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.003, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 32, 'PPO_STEPS': 8, 'BATCH_SIZE': 128, 'DISCOUNT_FACTOR': 0.95, 'constraint_penalty_factor': 0, 'episode_length': 4, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -10829.8                     Violations: 0                    Mean Train Rewards: -10663.4\n",
            "Episode:  20 |                     Train Rewards: -11151.4                     Violations: 0                    Mean Train Rewards: -10852.4\n",
            "Episode:  30 |                     Train Rewards: -11174.7                     Violations: 0                    Mean Train Rewards: -10951.8\n",
            "Episode:  40 |                     Train Rewards: -11154.7                     Violations: 0                    Mean Train Rewards: -10997.9\n",
            "Episode:  50 |                     Train Rewards: -11113.8                     Violations: 0                    Mean Train Rewards: -11021.4\n",
            "Episode:  60 |                     Train Rewards: -10562.4                     Violations: 0                    Mean Train Rewards: -11014.0\n",
            "Episode:  70 |                     Train Rewards: -10443.2                     Violations: 0                    Mean Train Rewards: -10879.6\n",
            "Episode:  80 |                     Train Rewards: -10163.4                     Violations: 47.57256507873535                    Mean Train Rewards: -10786.5\n",
            "Episode:  90 |                     Train Rewards: -9898.3                     Violations: 50.16769170761107                    Mean Train Rewards: -10717.1\n",
            "Episode: 100 |                     Train Rewards: -10566.0                     Violations: 0                    Mean Train Rewards: -10661.0\n",
            "Episode: 110 |                     Train Rewards: -10555.3                     Violations: 0                    Mean Train Rewards: -10615.2\n",
            "Episode: 120 |                     Train Rewards: -10045.5                     Violations: 47.426424026489244                    Mean Train Rewards: -10524.3\n",
            "Episode: 130 |                     Train Rewards: -9804.2                     Violations: 79.19921040534973                    Mean Train Rewards: -10419.5\n",
            "Episode: 140 |                     Train Rewards: -10124.9                     Violations: 48.11403751373291                    Mean Train Rewards: -10320.5\n",
            "Episode: 150 |                     Train Rewards: -10106.8                     Violations: 26.227102279663086                    Mean Train Rewards: -10222.2\n",
            "Episode: 160 |                     Train Rewards: -10055.1                     Violations: 29.044549465179443                    Mean Train Rewards: -10135.5\n",
            "Episode: 170 |                     Train Rewards: -10163.6                     Violations: 5.176469087600708                    Mean Train Rewards: -10121.1\n",
            "Episode: 180 |                     Train Rewards: -10557.5                     Violations: 0                    Mean Train Rewards: -10105.1\n",
            "Episode: 190 |                     Train Rewards: -10085.5                     Violations: 45.35356521606445                    Mean Train Rewards: -10109.0\n",
            "Episode: 200 |                     Train Rewards: -9916.9                     Violations: 56.93794131278992                    Mean Train Rewards: -10098.3\n",
            "Episode: 210 |                     Train Rewards: -9836.3                     Violations: 64.0582823753357                    Mean Train Rewards: -10087.1\n",
            "Episode: 220 |                     Train Rewards: -9795.7                     Violations: 82.49868869781494                    Mean Train Rewards: -10060.7\n",
            "Episode: 230 |                     Train Rewards: -9984.3                     Violations: 31.006951332092285                    Mean Train Rewards: -10057.4\n",
            "Episode: 240 |                     Train Rewards: -10302.7                     Violations: 0                    Mean Train Rewards: -10056.5\n",
            "Episode: 250 |                     Train Rewards: -9842.7                     Violations: 92.49080181121826                    Mean Train Rewards: -10042.7\n",
            "Episode: 260 |                     Train Rewards: -10510.3                     Violations: 9.74129319190979                    Mean Train Rewards: -10040.3\n",
            "Episode: 270 |                     Train Rewards: -10472.4                     Violations: 0                    Mean Train Rewards: -10066.7\n",
            "Episode: 280 |                     Train Rewards: -9543.9                     Violations: 120.33781409263611                    Mean Train Rewards: -10064.7\n",
            "Episode: 290 |                     Train Rewards: -10356.9                     Violations: 20.705840587615967                    Mean Train Rewards: -10049.9\n",
            "Episode: 300 |                     Train Rewards: -10577.2                     Violations: 5.013307332992554                    Mean Train Rewards: -10070.2\n",
            "Episode: 310 |                     Train Rewards: -10600.1                     Violations: 0.9867215156555105                    Mean Train Rewards: -10091.1\n",
            "Episode: 320 |                     Train Rewards: -10214.8                     Violations: 15.203531980514526                    Mean Train Rewards: -10119.3\n",
            "Episode: 330 |                     Train Rewards: -10388.9                     Violations: 7.983645200729356                    Mean Train Rewards: -10127.5\n",
            "Episode: 340 |                     Train Rewards: -10190.7                     Violations: 42.45200157165529                    Mean Train Rewards: -10148.0\n",
            "Episode: 350 |                     Train Rewards: -10507.9                     Violations: 32.83850908279419                    Mean Train Rewards: -10195.8\n",
            "Episode: 360 |                     Train Rewards: -9910.6                     Violations: 37.53846168518065                    Mean Train Rewards: -10203.2\n",
            "Episode: 370 |                     Train Rewards: -10372.0                     Violations: 6.375535726547241                    Mean Train Rewards: -10191.0\n",
            "Episode: 380 |                     Train Rewards: -10053.3                     Violations: 36.99592113494873                    Mean Train Rewards: -10211.4\n",
            "Episode: 390 |                     Train Rewards: -10377.8                     Violations: 0.3232145309448242                    Mean Train Rewards: -10230.4\n",
            "Episode: 400 |                     Train Rewards: -9964.2                     Violations: 96.96208953857422                    Mean Train Rewards: -10225.5\n",
            "Episode: 410 |                     Train Rewards: -9986.1                     Violations: 44.89359259605406                    Mean Train Rewards: -10216.0\n",
            "Episode: 420 |                     Train Rewards: -10456.7                     Violations: 6.001206636428833                    Mean Train Rewards: -10220.7\n",
            "Episode: 430 |                     Train Rewards: -9849.2                     Violations: 40.58003664016725                    Mean Train Rewards: -10215.8\n",
            "Episode: 440 |                     Train Rewards: -10877.4                     Violations: 0                    Mean Train Rewards: -10199.4\n",
            "Episode: 450 |                     Train Rewards: -10202.7                     Violations: 53.430519104003906                    Mean Train Rewards: -10161.7\n",
            "Episode: 460 |                     Train Rewards: -9942.7                     Violations: 41.169174909591675                    Mean Train Rewards: -10148.3\n",
            "Episode: 470 |                     Train Rewards: -10350.9                     Violations: 44.4504714012146                    Mean Train Rewards: -10167.1\n",
            "Episode: 480 |                     Train Rewards: -10322.3                     Violations: 5.7423436641693115                    Mean Train Rewards: -10177.2\n",
            "Episode: 490 |                     Train Rewards: -10143.4                     Violations: 17.82402276992797                    Mean Train Rewards: -10177.1\n",
            "Episode: 500 |                     Train Rewards: -10100.9                     Violations: 15.953879356384277                    Mean Train Rewards: -10185.2\n",
            "Episode: 510 |                     Train Rewards: -10559.0                     Violations: 0                    Mean Train Rewards: -10183.9\n",
            "Episode: 520 |                     Train Rewards: -10420.0                     Violations: 15.495874881744385                    Mean Train Rewards: -10185.5\n",
            "Episode: 530 |                     Train Rewards: -10229.0                     Violations: 42.77837872505188                    Mean Train Rewards: -10187.9\n",
            "Episode: 540 |                     Train Rewards: -10145.9                     Violations: 8.188256025314331                    Mean Train Rewards: -10193.1\n",
            "Episode: 550 |                     Train Rewards: -10465.2                     Violations: 0.2847099304199219                    Mean Train Rewards: -10201.0\n",
            "Episode: 560 |                     Train Rewards: -10326.5                     Violations: 0                    Mean Train Rewards: -10217.4\n",
            "Episode: 570 |                     Train Rewards: -10381.8                     Violations: 14.62693452835083                    Mean Train Rewards: -10220.8\n",
            "Episode: 580 |                     Train Rewards: -10175.6                     Violations: 12.44127631187439                    Mean Train Rewards: -10209.5\n",
            "Episode: 590 |                     Train Rewards: -10346.7                     Violations: 11.855705976486206                    Mean Train Rewards: -10207.5\n",
            "Episode: 600 |                     Train Rewards: -10468.4                     Violations: 0                    Mean Train Rewards: -10200.6\n",
            "Episode: 610 |                     Train Rewards: -10479.7                     Violations: 0                    Mean Train Rewards: -10194.5\n",
            "Episode: 620 |                     Train Rewards: -9830.8                     Violations: 72.69296169281007                    Mean Train Rewards: -10178.7\n",
            "Episode: 630 |                     Train Rewards: -10129.8                     Violations: 43.98936629295349                    Mean Train Rewards: -10180.5\n",
            "Episode: 640 |                     Train Rewards: -9909.0                     Violations: 38.59372138977052                    Mean Train Rewards: -10161.8\n",
            "Episode: 650 |                     Train Rewards: -9787.0                     Violations: 68.13352346420288                    Mean Train Rewards: -10163.1\n",
            "Episode: 660 |                     Train Rewards: -10474.5                     Violations: 24.65083360671997                    Mean Train Rewards: -10149.5\n",
            "Episode: 670 |                     Train Rewards: -9870.3                     Violations: 83.58023524284363                    Mean Train Rewards: -10137.6\n",
            "Episode: 680 |                     Train Rewards: -10014.8                     Violations: 20.815937519073486                    Mean Train Rewards: -10125.7\n",
            "Episode: 690 |                     Train Rewards: -10130.7                     Violations: 16.849164962768555                    Mean Train Rewards: -10125.1\n",
            "Episode: 700 |                     Train Rewards: -9998.3                     Violations: 56.76677227020263                    Mean Train Rewards: -10110.3\n",
            "Episode: 710 |                     Train Rewards: -10474.0                     Violations: 0                    Mean Train Rewards: -10104.7\n",
            "Episode: 720 |                     Train Rewards: -10361.0                     Violations: 13.300769329071045                    Mean Train Rewards: -10117.5\n",
            "Episode: 730 |                     Train Rewards: -9670.0                     Violations: 76.67780995368958                    Mean Train Rewards: -10120.5\n",
            "Episode: 740 |                     Train Rewards: -9654.1                     Violations: 85.99566817283633                    Mean Train Rewards: -10133.2\n",
            "Episode: 750 |                     Train Rewards: -10125.3                     Violations: 58.905696868896484                    Mean Train Rewards: -10121.3\n",
            "Episode: 760 |                     Train Rewards: -9600.5                     Violations: 114.3512463569641                    Mean Train Rewards: -10124.3\n",
            "Episode: 770 |                     Train Rewards: -10380.2                     Violations: 0                    Mean Train Rewards: -10114.0\n",
            "Episode: 780 |                     Train Rewards: -10128.1                     Violations: 11.100827455520623                    Mean Train Rewards: -10112.1\n",
            "Episode: 790 |                     Train Rewards: -10396.7                     Violations: 38.206932544708266                    Mean Train Rewards: -10090.4\n",
            "Episode: 800 |                     Train Rewards: -9725.4                     Violations: 59.21246290206908                    Mean Train Rewards: -10084.7\n",
            "Episode: 810 |                     Train Rewards: -10431.6                     Violations: 39.70668077468872                    Mean Train Rewards: -10078.1\n",
            "Episode: 820 |                     Train Rewards: -9800.5                     Violations: 59.299668073654175                    Mean Train Rewards: -10059.8\n",
            "Episode: 830 |                     Train Rewards: -9538.4                     Violations: 116.91776633262634                    Mean Train Rewards: -10052.3\n",
            "Episode: 840 |                     Train Rewards: -10091.6                     Violations: 47.210460901260376                    Mean Train Rewards: -10036.6\n",
            "Episode: 850 |                     Train Rewards: -10238.2                     Violations: 49.90845322608948                    Mean Train Rewards: -10020.9\n",
            "Episode: 860 |                     Train Rewards: -9971.9                     Violations: 47.983330488204956                    Mean Train Rewards: -10017.9\n",
            "Episode: 870 |                     Train Rewards: -10406.6                     Violations: 6.821998357772827                    Mean Train Rewards: -10020.3\n",
            "Episode: 880 |                     Train Rewards: -10145.0                     Violations: 42.38337039947511                    Mean Train Rewards: -10034.5\n",
            "Episode: 890 |                     Train Rewards: -9923.3                     Violations: 29.873894453048692                    Mean Train Rewards: -10030.0\n",
            "Episode: 900 |                     Train Rewards: -9923.9                     Violations: 15.213367938995361                    Mean Train Rewards: -10016.6\n",
            "Episode: 910 |                     Train Rewards: -10092.1                     Violations: 12.664990425109863                    Mean Train Rewards: -10032.4\n",
            "Episode: 920 |                     Train Rewards: -9933.2                     Violations: 71.74227952957152                    Mean Train Rewards: -10027.6\n",
            "Episode: 930 |                     Train Rewards: -10332.1                     Violations: 29.24921989440918                    Mean Train Rewards: -10008.5\n",
            "Episode: 940 |                     Train Rewards: -9958.4                     Violations: 47.25715756416321                    Mean Train Rewards: -10015.1\n",
            "Episode: 950 |                     Train Rewards: -9471.7                     Violations: 137.31795072555542                    Mean Train Rewards: -10027.0\n",
            "Episode: 960 |                     Train Rewards: -10134.8                     Violations: 55.65293788909912                    Mean Train Rewards: -10029.9\n",
            "Episode: 970 |                     Train Rewards: -9991.3                     Violations: 57.445961236953735                    Mean Train Rewards: -10019.0\n",
            "Episode: 980 |                     Train Rewards: -10195.3                     Violations: 15.40152907371521                    Mean Train Rewards: -10013.0\n",
            "Episode: 990 |                     Train Rewards: -10005.7                     Violations: 39.378485679626465                    Mean Train Rewards: -10023.2\n",
            "Episode: 1000 |                     Train Rewards: -9666.8                     Violations: 81.3473153114319                    Mean Train Rewards: -10044.2\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 16 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 16 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-43/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-44\n",
            "\n",
            "==================================================\n",
            "Starting run 5/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.001, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -10189.4                     Violations: 0                    Mean Train Rewards: -12054.9\n",
            "Episode:  20 |                     Train Rewards: -10506.1                     Violations: 0                    Mean Train Rewards: -11261.5\n",
            "Episode:  30 |                     Train Rewards: -10401.9                     Violations: 0                    Mean Train Rewards: -10997.9\n",
            "Episode:  40 |                     Train Rewards: -10397.2                     Violations: 0                    Mean Train Rewards: -10832.6\n",
            "Episode:  50 |                     Train Rewards: -10818.7                     Violations: 0                    Mean Train Rewards: -10809.9\n",
            "Episode:  60 |                     Train Rewards: -10601.6                     Violations: 0                    Mean Train Rewards: -10785.9\n",
            "Episode:  70 |                     Train Rewards: -10883.7                     Violations: 0                    Mean Train Rewards: -10761.0\n",
            "Episode:  80 |                     Train Rewards: -10830.1                     Violations: 0                    Mean Train Rewards: -10766.5\n",
            "Episode:  90 |                     Train Rewards: -10451.2                     Violations: 0                    Mean Train Rewards: -10755.6\n",
            "Episode: 100 |                     Train Rewards: -10223.3                     Violations: 0                    Mean Train Rewards: -10715.4\n",
            "Episode: 110 |                     Train Rewards: -10429.9                     Violations: 3.7471139430999827                    Mean Train Rewards: -11149.9\n",
            "Episode: 120 |                     Train Rewards: -10422.6                     Violations: 2.15781569480896                    Mean Train Rewards: -11237.5\n",
            "Episode: 130 |                     Train Rewards: -10452.5                     Violations: 0                    Mean Train Rewards: -11238.7\n",
            "Episode: 140 |                     Train Rewards: -10675.6                     Violations: 0                    Mean Train Rewards: -11270.0\n",
            "Episode: 150 |                     Train Rewards: -10882.7                     Violations: 0                    Mean Train Rewards: -11277.1\n",
            "Episode: 160 |                     Train Rewards: -10457.9                     Violations: 0                    Mean Train Rewards: -11275.8\n",
            "Episode: 170 |                     Train Rewards: -10737.9                     Violations: 0                    Mean Train Rewards: -11265.4\n",
            "Episode: 180 |                     Train Rewards: -10567.7                     Violations: 0                    Mean Train Rewards: -11237.1\n",
            "Episode: 190 |                     Train Rewards: -10624.1                     Violations: 0                    Mean Train Rewards: -11220.4\n",
            "Episode: 200 |                     Train Rewards: -10281.9                     Violations: 0                    Mean Train Rewards: -11229.8\n",
            "Episode: 210 |                     Train Rewards: -18203.7                     Violations: 85.89716076850891                    Mean Train Rewards: -10830.0\n",
            "Episode: 220 |                     Train Rewards: -15941.5                     Violations: 62.40302801132202                    Mean Train Rewards: -11206.4\n",
            "Episode: 230 |                     Train Rewards: -11092.1                     Violations: 11.082674264907837                    Mean Train Rewards: -11469.2\n",
            "Episode: 240 |                     Train Rewards: -10647.0                     Violations: 0                    Mean Train Rewards: -11460.1\n",
            "Episode: 250 |                     Train Rewards: -10600.7                     Violations: 0                    Mean Train Rewards: -11441.2\n",
            "Episode: 260 |                     Train Rewards: -10680.2                     Violations: 0                    Mean Train Rewards: -11428.9\n",
            "Episode: 270 |                     Train Rewards: -10480.3                     Violations: 0                    Mean Train Rewards: -11429.4\n",
            "Episode: 280 |                     Train Rewards: -10359.0                     Violations: 2.6071298122405935                    Mean Train Rewards: -11415.5\n",
            "Episode: 290 |                     Train Rewards: -10551.7                     Violations: 0                    Mean Train Rewards: -11419.1\n",
            "Episode: 300 |                     Train Rewards: -11026.5                     Violations: 0                    Mean Train Rewards: -11447.6\n",
            "Episode: 310 |                     Train Rewards: -11114.1                     Violations: 0                    Mean Train Rewards: -11302.1\n",
            "Episode: 320 |                     Train Rewards: -11008.7                     Violations: 0                    Mean Train Rewards: -10896.3\n",
            "Episode: 330 |                     Train Rewards: -11040.6                     Violations: 0                    Mean Train Rewards: -10681.7\n",
            "Episode: 340 |                     Train Rewards: -10938.1                     Violations: 0                    Mean Train Rewards: -10737.3\n",
            "Episode: 350 |                     Train Rewards: -10936.2                     Violations: 0                    Mean Train Rewards: -10773.3\n",
            "Episode: 360 |                     Train Rewards: -10383.7                     Violations: 0                    Mean Train Rewards: -10793.9\n",
            "Episode: 370 |                     Train Rewards: -13551.4                     Violations: 33.70565056800842                    Mean Train Rewards: -11433.2\n",
            "Episode: 380 |                     Train Rewards: -14873.1                     Violations: 48.31146955490114                    Mean Train Rewards: -11787.9\n",
            "Episode: 390 |                     Train Rewards: -10745.7                     Violations: 3.7423157691955566                    Mean Train Rewards: -12108.6\n",
            "Episode: 400 |                     Train Rewards: -21107.1                     Violations: 111.44504070281982                    Mean Train Rewards: -12547.8\n",
            "Episode: 410 |                     Train Rewards: -12477.1                     Violations: 22.280369997024536                    Mean Train Rewards: -12686.4\n",
            "Episode: 420 |                     Train Rewards: -10656.8                     Violations: 0                    Mean Train Rewards: -12857.6\n",
            "Episode: 430 |                     Train Rewards: -16084.7                     Violations: 63.66779685020447                    Mean Train Rewards: -13392.5\n",
            "Episode: 440 |                     Train Rewards: -10897.0                     Violations: 0                    Mean Train Rewards: -13530.9\n",
            "Episode: 450 |                     Train Rewards: -14908.3                     Violations: 47.26218938827515                    Mean Train Rewards: -13714.9\n",
            "Episode: 460 |                     Train Rewards: -15219.6                     Violations: 51.585421562194824                    Mean Train Rewards: -13895.6\n",
            "Episode: 470 |                     Train Rewards: -12391.9                     Violations: 18.7750244140625                    Mean Train Rewards: -13464.7\n",
            "Episode: 480 |                     Train Rewards: -10490.9                     Violations: 0                    Mean Train Rewards: -13216.2\n",
            "Episode: 490 |                     Train Rewards: -11547.2                     Violations: 13.283507823944085                    Mean Train Rewards: -13045.2\n",
            "Episode: 500 |                     Train Rewards: -10748.0                     Violations: 5.82930326461792                    Mean Train Rewards: -12656.6\n",
            "Episode: 510 |                     Train Rewards: -10438.2                     Violations: 0                    Mean Train Rewards: -12648.0\n",
            "Episode: 520 |                     Train Rewards: -11495.3                     Violations: 11.089249849319458                    Mean Train Rewards: -12554.0\n",
            "Episode: 530 |                     Train Rewards: -11785.3                     Violations: 13.911716938018799                    Mean Train Rewards: -12128.4\n",
            "Episode: 540 |                     Train Rewards: -10297.0                     Violations: 0                    Mean Train Rewards: -11998.8\n",
            "Episode: 550 |                     Train Rewards: -10497.2                     Violations: 0                    Mean Train Rewards: -11922.0\n",
            "Episode: 560 |                     Train Rewards: -10395.8                     Violations: 0                    Mean Train Rewards: -11882.9\n",
            "Episode: 570 |                     Train Rewards: -10932.9                     Violations: 4.504212141036987                    Mean Train Rewards: -11796.2\n",
            "Episode: 580 |                     Train Rewards: -10475.2                     Violations: 1.753016710281372                    Mean Train Rewards: -11898.1\n",
            "Episode: 590 |                     Train Rewards: -11046.2                     Violations: 6.209840774536133                    Mean Train Rewards: -11775.0\n",
            "Episode: 600 |                     Train Rewards: -15442.2                     Violations: 51.52058362960814                    Mean Train Rewards: -11900.9\n",
            "Episode: 610 |                     Train Rewards: -10535.3                     Violations: 0                    Mean Train Rewards: -11920.6\n",
            "Episode: 620 |                     Train Rewards: -13411.6                     Violations: 33.725242614746094                    Mean Train Rewards: -11961.2\n",
            "Episode: 630 |                     Train Rewards: -12670.2                     Violations: 24.09602165222168                    Mean Train Rewards: -11965.5\n",
            "Episode: 640 |                     Train Rewards: -12437.7                     Violations: 24.002705812454224                    Mean Train Rewards: -12182.5\n",
            "Episode: 650 |                     Train Rewards: -13077.3                     Violations: 31.050819158554077                    Mean Train Rewards: -12139.2\n",
            "Episode: 660 |                     Train Rewards: -12140.2                     Violations: 16.206982135772705                    Mean Train Rewards: -12257.8\n",
            "Episode: 670 |                     Train Rewards: -13964.3                     Violations: 39.307923316955566                    Mean Train Rewards: -12313.3\n",
            "Episode: 680 |                     Train Rewards: -11133.6                     Violations: 9.995307922363281                    Mean Train Rewards: -12409.0\n",
            "Episode: 690 |                     Train Rewards: -10615.4                     Violations: 3.5668277740478516                    Mean Train Rewards: -12508.8\n",
            "Episode: 700 |                     Train Rewards: -14631.1                     Violations: 45.05679368972778                    Mean Train Rewards: -12537.7\n",
            "Episode: 710 |                     Train Rewards: -10577.8                     Violations: 0                    Mean Train Rewards: -12502.0\n",
            "Episode: 720 |                     Train Rewards: -10587.5                     Violations: 0                    Mean Train Rewards: -12426.2\n",
            "Episode: 730 |                     Train Rewards: -12907.7                     Violations: 30.098524093627915                    Mean Train Rewards: -12585.3\n",
            "Episode: 740 |                     Train Rewards: -13353.2                     Violations: 34.99111533164978                    Mean Train Rewards: -12467.9\n",
            "Episode: 750 |                     Train Rewards: -15084.4                     Violations: 48.188505172729506                    Mean Train Rewards: -12510.0\n",
            "Episode: 760 |                     Train Rewards: -18111.2                     Violations: 83.89333248138428                    Mean Train Rewards: -12514.8\n",
            "Episode: 770 |                     Train Rewards: -15662.8                     Violations: 53.99632215499878                    Mean Train Rewards: -12610.1\n",
            "Episode: 780 |                     Train Rewards: -10298.7                     Violations: 0                    Mean Train Rewards: -12512.1\n",
            "Episode: 790 |                     Train Rewards: -11982.3                     Violations: 14.317920207977295                    Mean Train Rewards: -12653.8\n",
            "Episode: 800 |                     Train Rewards: -11726.4                     Violations: 17.528032064437866                    Mean Train Rewards: -12643.1\n",
            "Episode: 810 |                     Train Rewards: -12599.8                     Violations: 20.496711730957017                    Mean Train Rewards: -12768.6\n",
            "Episode: 820 |                     Train Rewards: -13039.6                     Violations: 30.03406286239624                    Mean Train Rewards: -12887.4\n",
            "Episode: 830 |                     Train Rewards: -14623.2                     Violations: 47.89531469345093                    Mean Train Rewards: -12750.5\n",
            "Episode: 840 |                     Train Rewards: -12514.2                     Violations: 22.90965914726258                    Mean Train Rewards: -12714.2\n",
            "Episode: 850 |                     Train Rewards: -13208.2                     Violations: 28.80128502845764                    Mean Train Rewards: -12968.3\n",
            "Episode: 860 |                     Train Rewards: -12790.9                     Violations: 26.658964157104506                    Mean Train Rewards: -12868.5\n",
            "Episode: 870 |                     Train Rewards: -14245.0                     Violations: 39.10876274108887                    Mean Train Rewards: -12801.9\n",
            "Episode: 880 |                     Train Rewards: -13149.3                     Violations: 28.915319442749023                    Mean Train Rewards: -12752.7\n",
            "Episode: 890 |                     Train Rewards: -11179.4                     Violations: 10.58086633682251                    Mean Train Rewards: -12732.8\n",
            "Episode: 900 |                     Train Rewards: -10194.2                     Violations: 0                    Mean Train Rewards: -12748.6\n",
            "Episode: 910 |                     Train Rewards: -15285.2                     Violations: 51.9062614440918                    Mean Train Rewards: -12571.4\n",
            "Episode: 920 |                     Train Rewards: -13521.8                     Violations: 33.90124320983887                    Mean Train Rewards: -12658.1\n",
            "Episode: 930 |                     Train Rewards: -10738.4                     Violations: 2.232893705368042                    Mean Train Rewards: -12689.2\n",
            "Episode: 940 |                     Train Rewards: -12027.3                     Violations: 20.845823287963867                    Mean Train Rewards: -12711.4\n",
            "Episode: 950 |                     Train Rewards: -15938.4                     Violations: 62.31033205986023                    Mean Train Rewards: -12507.5\n",
            "Episode: 960 |                     Train Rewards: -14673.0                     Violations: 43.336079120636                    Mean Train Rewards: -12483.9\n",
            "Episode: 970 |                     Train Rewards: -12843.7                     Violations: 26.3352370262146                    Mean Train Rewards: -12517.0\n",
            "Episode: 980 |                     Train Rewards: -10675.4                     Violations: 3.2113993167877126                    Mean Train Rewards: -12577.9\n",
            "Episode: 990 |                     Train Rewards: -15511.9                     Violations: 54.03425455093384                    Mean Train Rewards: -12554.8\n",
            "Episode: 1000 |                     Train Rewards: -12916.2                     Violations: 29.527230262756348                    Mean Train Rewards: -12428.9\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 6 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-44/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-45\n",
            "\n",
            "==================================================\n",
            "Starting run 6/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0003, 'EPSILON': 0.2, 'ENTROPY_COEFFICIENT': 0.05, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -10255.8                     Violations: 1.7635071277618337                    Mean Train Rewards: -12358.4\n",
            "Episode:  20 |                     Train Rewards: -10386.8                     Violations: 0                    Mean Train Rewards: -11461.4\n",
            "Episode:  30 |                     Train Rewards: -10323.1                     Violations: 0                    Mean Train Rewards: -11109.0\n",
            "Episode:  40 |                     Train Rewards: -10224.6                     Violations: 0                    Mean Train Rewards: -10924.0\n",
            "Episode:  50 |                     Train Rewards: -10391.5                     Violations: 0                    Mean Train Rewards: -10820.6\n",
            "Episode:  60 |                     Train Rewards: -10307.0                     Violations: 0                    Mean Train Rewards: -10741.3\n",
            "Episode:  70 |                     Train Rewards: -10368.6                     Violations: 0                    Mean Train Rewards: -10674.1\n",
            "Episode:  80 |                     Train Rewards: -10346.1                     Violations: 0                    Mean Train Rewards: -10629.3\n",
            "Episode:  90 |                     Train Rewards: -10413.6                     Violations: 3.534998893737793                    Mean Train Rewards: -10594.0\n",
            "Episode: 100 |                     Train Rewards: -11562.5                     Violations: 15.995295047760017                    Mean Train Rewards: -10691.7\n",
            "Episode: 110 |                     Train Rewards: -10094.4                     Violations: 0                    Mean Train Rewards: -10750.6\n",
            "Episode: 120 |                     Train Rewards: -10683.3                     Violations: 6.33986234664917                    Mean Train Rewards: -10798.3\n",
            "Episode: 130 |                     Train Rewards: -10388.4                     Violations: 3.12485933303833                    Mean Train Rewards: -10814.2\n",
            "Episode: 140 |                     Train Rewards: -10213.2                     Violations: 0                    Mean Train Rewards: -10796.5\n",
            "Episode: 150 |                     Train Rewards: -10273.0                     Violations: 0                    Mean Train Rewards: -10782.2\n",
            "Episode: 160 |                     Train Rewards: -10144.5                     Violations: 0                    Mean Train Rewards: -10776.8\n",
            "Episode: 170 |                     Train Rewards: -10294.6                     Violations: 0                    Mean Train Rewards: -10769.8\n",
            "Episode: 180 |                     Train Rewards: -10206.4                     Violations: 0                    Mean Train Rewards: -10759.5\n",
            "Episode: 190 |                     Train Rewards: -10254.7                     Violations: 0                    Mean Train Rewards: -10763.5\n",
            "Episode: 200 |                     Train Rewards: -10152.4                     Violations: 0.0806891918182373                    Mean Train Rewards: -10646.2\n",
            "Episode: 210 |                     Train Rewards: -14762.0                     Violations: 50.12672305107117                    Mean Train Rewards: -10493.9\n",
            "Episode: 220 |                     Train Rewards: -14030.1                     Violations: 42.421791553497314                    Mean Train Rewards: -10786.2\n",
            "Episode: 230 |                     Train Rewards: -12657.1                     Violations: 27.968982458114624                    Mean Train Rewards: -11070.9\n",
            "Episode: 240 |                     Train Rewards: -10122.5                     Violations: 0                    Mean Train Rewards: -11095.5\n",
            "Episode: 250 |                     Train Rewards: -10188.5                     Violations: 0                    Mean Train Rewards: -11095.8\n",
            "Episode: 260 |                     Train Rewards: -10310.4                     Violations: 0                    Mean Train Rewards: -11086.8\n",
            "Episode: 270 |                     Train Rewards: -10278.0                     Violations: 0                    Mean Train Rewards: -11094.1\n",
            "Episode: 280 |                     Train Rewards: -10114.8                     Violations: 0                    Mean Train Rewards: -11093.3\n",
            "Episode: 290 |                     Train Rewards: -10383.9                     Violations: 0                    Mean Train Rewards: -11089.5\n",
            "Episode: 300 |                     Train Rewards: -10584.0                     Violations: 0                    Mean Train Rewards: -11092.7\n",
            "Episode: 310 |                     Train Rewards: -10728.1                     Violations: 0                    Mean Train Rewards: -11010.8\n",
            "Episode: 320 |                     Train Rewards: -10666.6                     Violations: 0                    Mean Train Rewards: -10679.2\n",
            "Episode: 330 |                     Train Rewards: -10773.7                     Violations: 0                    Mean Train Rewards: -10404.7\n",
            "Episode: 340 |                     Train Rewards: -10764.8                     Violations: 0                    Mean Train Rewards: -10430.8\n",
            "Episode: 350 |                     Train Rewards: -10898.6                     Violations: 0                    Mean Train Rewards: -10489.2\n",
            "Episode: 360 |                     Train Rewards: -10777.2                     Violations: 0                    Mean Train Rewards: -10554.5\n",
            "Episode: 370 |                     Train Rewards: -10637.2                     Violations: 0                    Mean Train Rewards: -10592.3\n",
            "Episode: 380 |                     Train Rewards: -10475.5                     Violations: 0                    Mean Train Rewards: -10630.9\n",
            "Episode: 390 |                     Train Rewards: -10425.4                     Violations: 0                    Mean Train Rewards: -10646.1\n",
            "Episode: 400 |                     Train Rewards: -10454.1                     Violations: 0                    Mean Train Rewards: -10641.4\n",
            "Episode: 410 |                     Train Rewards: -10586.0                     Violations: 0                    Mean Train Rewards: -10638.8\n",
            "Episode: 420 |                     Train Rewards: -10640.0                     Violations: 0                    Mean Train Rewards: -10636.4\n",
            "Episode: 430 |                     Train Rewards: -10374.5                     Violations: 0                    Mean Train Rewards: -10618.6\n",
            "Episode: 440 |                     Train Rewards: -10624.8                     Violations: 0                    Mean Train Rewards: -10598.7\n",
            "Episode: 450 |                     Train Rewards: -10439.9                     Violations: 0                    Mean Train Rewards: -10562.9\n",
            "Episode: 460 |                     Train Rewards: -10478.3                     Violations: 0                    Mean Train Rewards: -10527.5\n",
            "Episode: 470 |                     Train Rewards: -10653.1                     Violations: 0                    Mean Train Rewards: -10520.4\n",
            "Episode: 480 |                     Train Rewards: -10590.6                     Violations: 0                    Mean Train Rewards: -10524.7\n",
            "Episode: 490 |                     Train Rewards: -10605.5                     Violations: 0                    Mean Train Rewards: -10538.2\n",
            "Episode: 500 |                     Train Rewards: -10544.3                     Violations: 0                    Mean Train Rewards: -10563.8\n",
            "Episode: 510 |                     Train Rewards: -10534.1                     Violations: 0                    Mean Train Rewards: -10557.5\n",
            "Episode: 520 |                     Train Rewards: -10552.8                     Violations: 0                    Mean Train Rewards: -10545.4\n",
            "Episode: 530 |                     Train Rewards: -10703.0                     Violations: 0                    Mean Train Rewards: -10556.7\n",
            "Episode: 540 |                     Train Rewards: -10664.9                     Violations: 0                    Mean Train Rewards: -10571.6\n",
            "Episode: 550 |                     Train Rewards: -10640.9                     Violations: 0                    Mean Train Rewards: -10582.5\n",
            "Episode: 560 |                     Train Rewards: -10623.4                     Violations: 0                    Mean Train Rewards: -10588.3\n",
            "Episode: 570 |                     Train Rewards: -10657.6                     Violations: 0                    Mean Train Rewards: -10596.0\n",
            "Episode: 580 |                     Train Rewards: -10566.6                     Violations: 0                    Mean Train Rewards: -10593.0\n",
            "Episode: 590 |                     Train Rewards: -10521.1                     Violations: 0                    Mean Train Rewards: -10584.7\n",
            "Episode: 600 |                     Train Rewards: -10573.2                     Violations: 0                    Mean Train Rewards: -10577.5\n",
            "Episode: 610 |                     Train Rewards: -10522.9                     Violations: 0                    Mean Train Rewards: -10574.0\n",
            "Episode: 620 |                     Train Rewards: -10490.6                     Violations: 0                    Mean Train Rewards: -10568.7\n",
            "Episode: 630 |                     Train Rewards: -10465.9                     Violations: 0                    Mean Train Rewards: -10560.0\n",
            "Episode: 640 |                     Train Rewards: -10275.4                     Violations: 0                    Mean Train Rewards: -10534.0\n",
            "Episode: 650 |                     Train Rewards: -10327.9                     Violations: 0                    Mean Train Rewards: -10510.8\n",
            "Episode: 660 |                     Train Rewards: -10313.9                     Violations: 0                    Mean Train Rewards: -10493.7\n",
            "Episode: 670 |                     Train Rewards: -10198.1                     Violations: 0                    Mean Train Rewards: -10458.3\n",
            "Episode: 680 |                     Train Rewards: -10106.3                     Violations: 0.18215417861937766                    Mean Train Rewards: -10432.6\n",
            "Episode: 690 |                     Train Rewards: -10200.2                     Violations: 0                    Mean Train Rewards: -10401.8\n",
            "Episode: 700 |                     Train Rewards: -10462.8                     Violations: 2.839186191558838                    Mean Train Rewards: -10388.1\n",
            "Episode: 710 |                     Train Rewards: -10271.2                     Violations: 0                    Mean Train Rewards: -10365.3\n",
            "Episode: 720 |                     Train Rewards: -10294.3                     Violations: 0                    Mean Train Rewards: -10346.9\n",
            "Episode: 730 |                     Train Rewards: -10209.6                     Violations: 1.5483462810516357                    Mean Train Rewards: -10332.1\n",
            "Episode: 740 |                     Train Rewards: -11634.7                     Violations: 17.20769762992859                    Mean Train Rewards: -10342.4\n",
            "Episode: 750 |                     Train Rewards: -10975.8                     Violations: 8.835097551345825                    Mean Train Rewards: -10352.3\n",
            "Episode: 760 |                     Train Rewards: -13067.4                     Violations: 32.28807806968689                    Mean Train Rewards: -10435.1\n",
            "Episode: 770 |                     Train Rewards: -11171.0                     Violations: 11.423643827438354                    Mean Train Rewards: -10523.9\n",
            "Episode: 780 |                     Train Rewards: -10438.7                     Violations: 4.322253465652466                    Mean Train Rewards: -10606.5\n",
            "Episode: 790 |                     Train Rewards: -10724.0                     Violations: 7.072993516921997                    Mean Train Rewards: -10720.4\n",
            "Episode: 800 |                     Train Rewards: -11889.9                     Violations: 19.89385843276977                    Mean Train Rewards: -10879.5\n",
            "Episode: 810 |                     Train Rewards: -10622.4                     Violations: 5.209639072418213                    Mean Train Rewards: -10966.6\n",
            "Episode: 820 |                     Train Rewards: -10642.0                     Violations: 6.548824310302734                    Mean Train Rewards: -11028.3\n",
            "Episode: 830 |                     Train Rewards: -10069.9                     Violations: 0                    Mean Train Rewards: -11032.0\n",
            "Episode: 840 |                     Train Rewards: -10254.7                     Violations: 1.0001683235168386                    Mean Train Rewards: -11007.6\n",
            "Episode: 850 |                     Train Rewards: -10308.2                     Violations: 0                    Mean Train Rewards: -11016.3\n",
            "Episode: 860 |                     Train Rewards: -10220.8                     Violations: 0                    Mean Train Rewards: -10919.4\n",
            "Episode: 870 |                     Train Rewards: -11830.0                     Violations: 16.661258935928345                    Mean Train Rewards: -10855.0\n",
            "Episode: 880 |                     Train Rewards: -10975.6                     Violations: 8.988680839538574                    Mean Train Rewards: -10783.7\n",
            "Episode: 890 |                     Train Rewards: -10863.2                     Violations: 8.908967971801758                    Mean Train Rewards: -10838.7\n",
            "Episode: 900 |                     Train Rewards: -10139.7                     Violations: 0                    Mean Train Rewards: -10774.0\n",
            "Episode: 910 |                     Train Rewards: -10788.8                     Violations: 7.268812656402588                    Mean Train Rewards: -10698.6\n",
            "Episode: 920 |                     Train Rewards: -10237.0                     Violations: 1.094510555267334                    Mean Train Rewards: -10670.8\n",
            "Episode: 930 |                     Train Rewards: -10453.1                     Violations: 2.4222397804260254                    Mean Train Rewards: -10682.0\n",
            "Episode: 940 |                     Train Rewards: -11660.5                     Violations: 17.47922658920288                    Mean Train Rewards: -10715.6\n",
            "Episode: 950 |                     Train Rewards: -14277.5                     Violations: 45.02662181854248                    Mean Train Rewards: -10976.9\n",
            "Episode: 960 |                     Train Rewards: -11467.5                     Violations: 15.087168216705315                    Mean Train Rewards: -11121.5\n",
            "Episode: 970 |                     Train Rewards: -10629.6                     Violations: 5.874665975570679                    Mean Train Rewards: -11264.7\n",
            "Episode: 980 |                     Train Rewards: -10147.8                     Violations: 0                    Mean Train Rewards: -11265.2\n",
            "Episode: 990 |                     Train Rewards: -10276.9                     Violations: 0.5634510517120361                    Mean Train Rewards: -11102.5\n",
            "Episode: 1000 |                     Train Rewards: -10187.7                     Violations: 1.6860198974609304                    Mean Train Rewards: -10990.8\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 8 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 8 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-45/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-46\n",
            "\n",
            "==================================================\n",
            "Starting run 7/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 128, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -10898.1                     Violations: 0                    Mean Train Rewards: -10934.5\n",
            "Episode:  20 |                     Train Rewards: -11140.7                     Violations: 0                    Mean Train Rewards: -11020.6\n",
            "Episode:  30 |                     Train Rewards: -11175.4                     Violations: 0                    Mean Train Rewards: -11064.4\n",
            "Episode:  40 |                     Train Rewards: -11173.9                     Violations: 0                    Mean Train Rewards: -11088.4\n",
            "Episode:  50 |                     Train Rewards: -11180.3                     Violations: 0                    Mean Train Rewards: -11104.1\n",
            "Episode:  60 |                     Train Rewards: -11183.1                     Violations: 0                    Mean Train Rewards: -11115.9\n",
            "Episode:  70 |                     Train Rewards: -11182.9                     Violations: 0                    Mean Train Rewards: -11123.4\n",
            "Episode:  80 |                     Train Rewards: -11177.4                     Violations: 0                    Mean Train Rewards: -11129.3\n",
            "Episode:  90 |                     Train Rewards: -11178.6                     Violations: 0                    Mean Train Rewards: -11134.5\n",
            "Episode: 100 |                     Train Rewards: -11194.2                     Violations: 0                    Mean Train Rewards: -11138.8\n",
            "Episode: 110 |                     Train Rewards: -11183.0                     Violations: 0                    Mean Train Rewards: -11162.7\n",
            "Episode: 120 |                     Train Rewards: -11175.0                     Violations: 0                    Mean Train Rewards: -11170.2\n",
            "Episode: 130 |                     Train Rewards: -11172.7                     Violations: 0                    Mean Train Rewards: -11172.4\n",
            "Episode: 140 |                     Train Rewards: -11191.9                     Violations: 0                    Mean Train Rewards: -11174.9\n",
            "Episode: 150 |                     Train Rewards: -11191.2                     Violations: 0                    Mean Train Rewards: -11177.1\n",
            "Episode: 160 |                     Train Rewards: -11183.0                     Violations: 0                    Mean Train Rewards: -11178.4\n",
            "Episode: 170 |                     Train Rewards: -11194.2                     Violations: 0                    Mean Train Rewards: -11180.2\n",
            "Episode: 180 |                     Train Rewards: -11195.0                     Violations: 0                    Mean Train Rewards: -11181.7\n",
            "Episode: 190 |                     Train Rewards: -11194.4                     Violations: 0                    Mean Train Rewards: -11183.1\n",
            "Episode: 200 |                     Train Rewards: -11190.1                     Violations: 0                    Mean Train Rewards: -11184.6\n",
            "Episode: 210 |                     Train Rewards: -11185.4                     Violations: 0                    Mean Train Rewards: -11186.4\n",
            "Episode: 220 |                     Train Rewards: -11189.6                     Violations: 0                    Mean Train Rewards: -11186.9\n",
            "Episode: 230 |                     Train Rewards: -11190.7                     Violations: 0                    Mean Train Rewards: -11188.8\n",
            "Episode: 240 |                     Train Rewards: -11195.6                     Violations: 0                    Mean Train Rewards: -11189.6\n",
            "Episode: 250 |                     Train Rewards: -11194.8                     Violations: 0                    Mean Train Rewards: -11189.9\n",
            "Episode: 260 |                     Train Rewards: -11198.7                     Violations: 0                    Mean Train Rewards: -11190.3\n",
            "Episode: 270 |                     Train Rewards: -11197.0                     Violations: 0                    Mean Train Rewards: -11190.7\n",
            "Episode: 280 |                     Train Rewards: -11191.4                     Violations: 0                    Mean Train Rewards: -11191.2\n",
            "Episode: 290 |                     Train Rewards: -11195.8                     Violations: 0                    Mean Train Rewards: -11191.3\n",
            "Episode: 300 |                     Train Rewards: -11196.8                     Violations: 0                    Mean Train Rewards: -11191.5\n",
            "Episode: 310 |                     Train Rewards: -11197.0                     Violations: 0                    Mean Train Rewards: -11191.8\n",
            "Episode: 320 |                     Train Rewards: -11190.9                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 330 |                     Train Rewards: -11196.0                     Violations: 0                    Mean Train Rewards: -11192.6\n",
            "Episode: 340 |                     Train Rewards: -11193.2                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 350 |                     Train Rewards: -11198.0                     Violations: 0                    Mean Train Rewards: -11193.1\n",
            "Episode: 360 |                     Train Rewards: -11193.4                     Violations: 0                    Mean Train Rewards: -11193.4\n",
            "Episode: 370 |                     Train Rewards: -11192.1                     Violations: 0                    Mean Train Rewards: -11193.2\n",
            "Episode: 380 |                     Train Rewards: -11190.8                     Violations: 0                    Mean Train Rewards: -11193.2\n",
            "Episode: 390 |                     Train Rewards: -11192.5                     Violations: 0                    Mean Train Rewards: -11193.3\n",
            "Episode: 400 |                     Train Rewards: -11193.4                     Violations: 0                    Mean Train Rewards: -11192.9\n",
            "Episode: 410 |                     Train Rewards: -11190.0                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 420 |                     Train Rewards: -11196.9                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 430 |                     Train Rewards: -11193.7                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 440 |                     Train Rewards: -11193.5                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 450 |                     Train Rewards: -11196.5                     Violations: 0                    Mean Train Rewards: -11192.2\n",
            "Episode: 460 |                     Train Rewards: -11196.1                     Violations: 0                    Mean Train Rewards: -11192.1\n",
            "Episode: 470 |                     Train Rewards: -11197.6                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 480 |                     Train Rewards: -11197.5                     Violations: 0                    Mean Train Rewards: -11193.2\n",
            "Episode: 490 |                     Train Rewards: -11194.4                     Violations: 0                    Mean Train Rewards: -11193.7\n",
            "Episode: 500 |                     Train Rewards: -11193.0                     Violations: 0                    Mean Train Rewards: -11194.1\n",
            "Episode: 510 |                     Train Rewards: -11196.5                     Violations: 0                    Mean Train Rewards: -11194.4\n",
            "Episode: 520 |                     Train Rewards: -11196.4                     Violations: 0                    Mean Train Rewards: -11194.6\n",
            "Episode: 530 |                     Train Rewards: -11193.9                     Violations: 0                    Mean Train Rewards: -11194.7\n",
            "Episode: 540 |                     Train Rewards: -11193.7                     Violations: 0                    Mean Train Rewards: -11194.7\n",
            "Episode: 550 |                     Train Rewards: -11196.4                     Violations: 0                    Mean Train Rewards: -11194.6\n",
            "Episode: 560 |                     Train Rewards: -11196.0                     Violations: 0                    Mean Train Rewards: -11194.6\n",
            "Episode: 570 |                     Train Rewards: -11196.3                     Violations: 0                    Mean Train Rewards: -11194.6\n",
            "Episode: 580 |                     Train Rewards: -11194.3                     Violations: 0                    Mean Train Rewards: -11194.3\n",
            "Episode: 590 |                     Train Rewards: -11191.8                     Violations: 0                    Mean Train Rewards: -11194.0\n",
            "Episode: 600 |                     Train Rewards: -11192.5                     Violations: 0                    Mean Train Rewards: -11193.7\n",
            "Episode: 610 |                     Train Rewards: -11195.2                     Violations: 0                    Mean Train Rewards: -11193.1\n",
            "Episode: 620 |                     Train Rewards: -11195.0                     Violations: 0                    Mean Train Rewards: -11192.8\n",
            "Episode: 630 |                     Train Rewards: -11186.2                     Violations: 0                    Mean Train Rewards: -11192.7\n",
            "Episode: 640 |                     Train Rewards: -11185.6                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 650 |                     Train Rewards: -11194.9                     Violations: 0                    Mean Train Rewards: -11192.1\n",
            "Episode: 660 |                     Train Rewards: -11192.1                     Violations: 0                    Mean Train Rewards: -11191.1\n",
            "Episode: 670 |                     Train Rewards: -11193.8                     Violations: 0                    Mean Train Rewards: -11190.8\n",
            "Episode: 680 |                     Train Rewards: -11185.6                     Violations: 0                    Mean Train Rewards: -11190.2\n",
            "Episode: 690 |                     Train Rewards: -11193.9                     Violations: 0                    Mean Train Rewards: -11190.2\n",
            "Episode: 700 |                     Train Rewards: -11191.0                     Violations: 0                    Mean Train Rewards: -11190.2\n",
            "Episode: 710 |                     Train Rewards: -11194.8                     Violations: 0                    Mean Train Rewards: -11190.6\n",
            "Episode: 720 |                     Train Rewards: -11197.9                     Violations: 0                    Mean Train Rewards: -11190.9\n",
            "Episode: 730 |                     Train Rewards: -11190.8                     Violations: 0                    Mean Train Rewards: -11191.2\n",
            "Episode: 740 |                     Train Rewards: -11188.5                     Violations: 0                    Mean Train Rewards: -11191.5\n",
            "Episode: 750 |                     Train Rewards: -11189.6                     Violations: 0                    Mean Train Rewards: -11191.6\n",
            "Episode: 760 |                     Train Rewards: -11189.8                     Violations: 0                    Mean Train Rewards: -11192.6\n",
            "Episode: 770 |                     Train Rewards: -11193.6                     Violations: 0                    Mean Train Rewards: -11192.9\n",
            "Episode: 780 |                     Train Rewards: -11194.1                     Violations: 0                    Mean Train Rewards: -11193.7\n",
            "Episode: 790 |                     Train Rewards: -11194.5                     Violations: 0                    Mean Train Rewards: -11193.8\n",
            "Episode: 800 |                     Train Rewards: -11195.2                     Violations: 0                    Mean Train Rewards: -11194.0\n",
            "Episode: 810 |                     Train Rewards: -11197.3                     Violations: 0                    Mean Train Rewards: -11194.0\n",
            "Episode: 820 |                     Train Rewards: -11194.8                     Violations: 0                    Mean Train Rewards: -11193.8\n",
            "Episode: 830 |                     Train Rewards: -11189.8                     Violations: 0                    Mean Train Rewards: -11193.7\n",
            "Episode: 840 |                     Train Rewards: -11184.8                     Violations: 0                    Mean Train Rewards: -11193.4\n",
            "Episode: 850 |                     Train Rewards: -11194.9                     Violations: 0                    Mean Train Rewards: -11193.3\n",
            "Episode: 860 |                     Train Rewards: -11179.5                     Violations: 0                    Mean Train Rewards: -11192.9\n",
            "Episode: 870 |                     Train Rewards: -11188.2                     Violations: 0                    Mean Train Rewards: -11192.4\n",
            "Episode: 880 |                     Train Rewards: -11143.8                     Violations: 0                    Mean Train Rewards: -11190.0\n",
            "Episode: 890 |                     Train Rewards: -11137.7                     Violations: 0                    Mean Train Rewards: -11185.5\n",
            "Episode: 900 |                     Train Rewards: -11172.5                     Violations: 0                    Mean Train Rewards: -11183.6\n",
            "Episode: 910 |                     Train Rewards: -11177.3                     Violations: 0                    Mean Train Rewards: -11182.7\n",
            "Episode: 920 |                     Train Rewards: -11171.2                     Violations: 0                    Mean Train Rewards: -11180.2\n",
            "Episode: 930 |                     Train Rewards: -11187.3                     Violations: 0                    Mean Train Rewards: -11178.6\n",
            "Episode: 940 |                     Train Rewards: -11165.9                     Violations: 0                    Mean Train Rewards: -11178.0\n",
            "Episode: 950 |                     Train Rewards: -11162.9                     Violations: 0                    Mean Train Rewards: -11175.4\n",
            "Episode: 960 |                     Train Rewards: -11179.2                     Violations: 0                    Mean Train Rewards: -11174.3\n",
            "Episode: 970 |                     Train Rewards: -11179.3                     Violations: 0                    Mean Train Rewards: -11171.4\n",
            "Episode: 980 |                     Train Rewards: -11119.9                     Violations: 0                    Mean Train Rewards: -11170.6\n",
            "Episode: 990 |                     Train Rewards: -11159.6                     Violations: 0                    Mean Train Rewards: -11173.5\n",
            "Episode: 1000 |                     Train Rewards: -11156.5                     Violations: 0                    Mean Train Rewards: -11173.6\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 8 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 8 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-46/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-47\n",
            "\n",
            "==================================================\n",
            "Starting run 8/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.003, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 32, 'PPO_STEPS': 8, 'BATCH_SIZE': 128, 'DISCOUNT_FACTOR': 0.95, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -10754.7                     Violations: 0                    Mean Train Rewards: -10918.8\n",
            "Episode:  20 |                     Train Rewards: -11144.9                     Violations: 0                    Mean Train Rewards: -10971.9\n",
            "Episode:  30 |                     Train Rewards: -11171.4                     Violations: 0                    Mean Train Rewards: -11028.4\n",
            "Episode:  40 |                     Train Rewards: -11138.3                     Violations: 0                    Mean Train Rewards: -11051.0\n",
            "Episode:  50 |                     Train Rewards: -11085.6                     Violations: 0                    Mean Train Rewards: -11052.7\n",
            "Episode:  60 |                     Train Rewards: -10859.4                     Violations: 0                    Mean Train Rewards: -11045.9\n",
            "Episode:  70 |                     Train Rewards: -10691.3                     Violations: 0                    Mean Train Rewards: -11316.6\n",
            "Episode:  80 |                     Train Rewards: -16071.9                     Violations: 58.58161449432373                    Mean Train Rewards: -11769.9\n",
            "Episode:  90 |                     Train Rewards: -16113.5                     Violations: 61.817979812622056                    Mean Train Rewards: -11984.8\n",
            "Episode: 100 |                     Train Rewards: -10784.1                     Violations: 0                    Mean Train Rewards: -12350.8\n",
            "Episode: 110 |                     Train Rewards: -12891.9                     Violations: 24.085853099822998                    Mean Train Rewards: -12570.4\n",
            "Episode: 120 |                     Train Rewards: -15670.2                     Violations: 54.56245899200438                    Mean Train Rewards: -12864.3\n",
            "Episode: 130 |                     Train Rewards: -18234.2                     Violations: 83.72526884078978                    Mean Train Rewards: -13173.8\n",
            "Episode: 140 |                     Train Rewards: -16168.1                     Violations: 59.54398632049559                    Mean Train Rewards: -13466.7\n",
            "Episode: 150 |                     Train Rewards: -13640.9                     Violations: 34.38753843307494                    Mean Train Rewards: -13780.9\n",
            "Episode: 160 |                     Train Rewards: -13642.9                     Violations: 35.40538549423218                    Mean Train Rewards: -13993.8\n",
            "Episode: 170 |                     Train Rewards: -10370.9                     Violations: 0.63576340675354                    Mean Train Rewards: -14366.0\n",
            "Episode: 180 |                     Train Rewards: -10735.9                     Violations: 0                    Mean Train Rewards: -14540.5\n",
            "Episode: 190 |                     Train Rewards: -15632.9                     Violations: 54.55186128616333                    Mean Train Rewards: -14565.5\n",
            "Episode: 200 |                     Train Rewards: -16680.0                     Violations: 67.52110481262206                    Mean Train Rewards: -14615.7\n",
            "Episode: 210 |                     Train Rewards: -17121.0                     Violations: 72.70048499107361                    Mean Train Rewards: -14744.3\n",
            "Episode: 220 |                     Train Rewards: -17983.3                     Violations: 80.91122627258301                    Mean Train Rewards: -15012.6\n",
            "Episode: 230 |                     Train Rewards: -13131.0                     Violations: 30.83044409751892                    Mean Train Rewards: -15022.1\n",
            "Episode: 240 |                     Train Rewards: -10456.1                     Violations: 0                    Mean Train Rewards: -14941.4\n",
            "Episode: 250 |                     Train Rewards: -20982.5                     Violations: 111.3090193271637                    Mean Train Rewards: -15055.1\n",
            "Episode: 260 |                     Train Rewards: -11056.5                     Violations: 4.860280752182014                    Mean Train Rewards: -15200.8\n",
            "Episode: 270 |                     Train Rewards: -10683.1                     Violations: 0                    Mean Train Rewards: -14994.3\n",
            "Episode: 280 |                     Train Rewards: -23376.7                     Violations: 138.90060186386108                    Mean Train Rewards: -14944.5\n",
            "Episode: 290 |                     Train Rewards: -13884.6                     Violations: 34.87959861755371                    Mean Train Rewards: -15085.5\n",
            "Episode: 300 |                     Train Rewards: -11764.5                     Violations: 11.283972263336182                    Mean Train Rewards: -15007.4\n",
            "Episode: 310 |                     Train Rewards: -11082.9                     Violations: 4.063501358032227                    Mean Train Rewards: -14944.1\n",
            "Episode: 320 |                     Train Rewards: -12325.5                     Violations: 20.915040969848633                    Mean Train Rewards: -14712.9\n",
            "Episode: 330 |                     Train Rewards: -11908.1                     Violations: 15.047922134399414                    Mean Train Rewards: -14922.8\n",
            "Episode: 340 |                     Train Rewards: -16219.9                     Violations: 60.223658084869356                    Mean Train Rewards: -14932.1\n",
            "Episode: 350 |                     Train Rewards: -15477.5                     Violations: 49.771997928619385                    Mean Train Rewards: -14573.0\n",
            "Episode: 360 |                     Train Rewards: -17819.5                     Violations: 80.47303676605225                    Mean Train Rewards: -14681.6\n",
            "Episode: 370 |                     Train Rewards: -11913.5                     Violations: 15.510426759719849                    Mean Train Rewards: -14726.6\n",
            "Episode: 380 |                     Train Rewards: -14875.1                     Violations: 48.30733299255371                    Mean Train Rewards: -14499.0\n",
            "Episode: 390 |                     Train Rewards: -10576.4                     Violations: 1.607372760772705                    Mean Train Rewards: -14331.0\n",
            "Episode: 400 |                     Train Rewards: -21127.1                     Violations: 111.65499210357666                    Mean Train Rewards: -14283.6\n",
            "Episode: 410 |                     Train Rewards: -16289.4                     Violations: 63.47552537918091                    Mean Train Rewards: -14298.1\n",
            "Episode: 420 |                     Train Rewards: -11610.7                     Violations: 11.03528380393982                    Mean Train Rewards: -14370.5\n",
            "Episode: 430 |                     Train Rewards: -15604.2                     Violations: 58.11398863792421                    Mean Train Rewards: -14141.3\n",
            "Episode: 440 |                     Train Rewards: -15935.9                     Violations: 54.34789419174193                    Mean Train Rewards: -14249.4\n",
            "Episode: 450 |                     Train Rewards: -16180.7                     Violations: 58.97686243057251                    Mean Train Rewards: -14635.9\n",
            "Episode: 460 |                     Train Rewards: -16451.2                     Violations: 65.44887065887451                    Mean Train Rewards: -14605.4\n",
            "Episode: 470 |                     Train Rewards: -15881.5                     Violations: 54.840848445892334                    Mean Train Rewards: -14601.9\n",
            "Episode: 480 |                     Train Rewards: -11207.0                     Violations: 8.13247799873352                    Mean Train Rewards: -14608.4\n",
            "Episode: 490 |                     Train Rewards: -12574.7                     Violations: 24.311034679412842                    Mean Train Rewards: -14677.4\n",
            "Episode: 500 |                     Train Rewards: -11975.7                     Violations: 17.82116174697876                    Mean Train Rewards: -14528.0\n",
            "Episode: 510 |                     Train Rewards: -10714.5                     Violations: 0                    Mean Train Rewards: -14417.7\n",
            "Episode: 520 |                     Train Rewards: -12304.3                     Violations: 17.355992794036865                    Mean Train Rewards: -14172.4\n",
            "Episode: 530 |                     Train Rewards: -16365.3                     Violations: 60.87213277816774                    Mean Train Rewards: -14276.6\n",
            "Episode: 540 |                     Train Rewards: -11187.6                     Violations: 9.818973541259766                    Mean Train Rewards: -14090.0\n",
            "Episode: 550 |                     Train Rewards: -10596.4                     Violations: 0                    Mean Train Rewards: -13976.6\n",
            "Episode: 560 |                     Train Rewards: -10431.3                     Violations: 0                    Mean Train Rewards: -13859.3\n",
            "Episode: 570 |                     Train Rewards: -12206.1                     Violations: 17.467060089111328                    Mean Train Rewards: -13689.1\n",
            "Episode: 580 |                     Train Rewards: -11522.1                     Violations: 12.861039638519287                    Mean Train Rewards: -13652.1\n",
            "Episode: 590 |                     Train Rewards: -11814.5                     Violations: 13.039937019348145                    Mean Train Rewards: -13430.4\n",
            "Episode: 600 |                     Train Rewards: -10602.4                     Violations: 0                    Mean Train Rewards: -13443.9\n",
            "Episode: 610 |                     Train Rewards: -10625.4                     Violations: 0                    Mean Train Rewards: -13617.2\n",
            "Episode: 620 |                     Train Rewards: -18816.8                     Violations: 89.5493221282959                    Mean Train Rewards: -13741.4\n",
            "Episode: 630 |                     Train Rewards: -16874.3                     Violations: 71.39753460884093                    Mean Train Rewards: -13693.1\n",
            "Episode: 640 |                     Train Rewards: -14256.6                     Violations: 42.836958169937134                    Mean Train Rewards: -13951.2\n",
            "Episode: 650 |                     Train Rewards: -16551.8                     Violations: 66.72442197799683                    Mean Train Rewards: -13797.6\n",
            "Episode: 660 |                     Train Rewards: -13278.8                     Violations: 26.21387004852295                    Mean Train Rewards: -13848.2\n",
            "Episode: 670 |                     Train Rewards: -18628.0                     Violations: 87.02942490577699                    Mean Train Rewards: -13975.0\n",
            "Episode: 680 |                     Train Rewards: -11723.8                     Violations: 15.653821229934692                    Mean Train Rewards: -14116.1\n",
            "Episode: 690 |                     Train Rewards: -11140.2                     Violations: 7.97148585319519                    Mean Train Rewards: -14169.3\n",
            "Episode: 700 |                     Train Rewards: -16039.0                     Violations: 59.098062515258775                    Mean Train Rewards: -14179.1\n",
            "Episode: 710 |                     Train Rewards: -10656.7                     Violations: 0                    Mean Train Rewards: -14127.1\n",
            "Episode: 720 |                     Train Rewards: -11431.4                     Violations: 8.749970197677612                    Mean Train Rewards: -14079.3\n",
            "Episode: 730 |                     Train Rewards: -17441.4                     Violations: 77.49344944953918                    Mean Train Rewards: -14137.6\n",
            "Episode: 740 |                     Train Rewards: -18092.7                     Violations: 84.12585020065308                    Mean Train Rewards: -13994.5\n",
            "Episode: 750 |                     Train Rewards: -16001.5                     Violations: 57.25613594055176                    Mean Train Rewards: -14054.5\n",
            "Episode: 760 |                     Train Rewards: -20930.3                     Violations: 112.72055268287659                    Mean Train Rewards: -14069.8\n",
            "Episode: 770 |                     Train Rewards: -10588.8                     Violations: 0                    Mean Train Rewards: -13941.4\n",
            "Episode: 780 |                     Train Rewards: -10315.6                     Violations: 0                    Mean Train Rewards: -13799.6\n",
            "Episode: 790 |                     Train Rewards: -16521.4                     Violations: 65.16760110855105                    Mean Train Rewards: -13926.6\n",
            "Episode: 800 |                     Train Rewards: -13212.4                     Violations: 33.165985345840454                    Mean Train Rewards: -13982.2\n",
            "Episode: 810 |                     Train Rewards: -14654.2                     Violations: 39.93290424346924                    Mean Train Rewards: -14160.2\n",
            "Episode: 820 |                     Train Rewards: -10246.8                     Violations: 0                    Mean Train Rewards: -14167.8\n",
            "Episode: 830 |                     Train Rewards: -20352.5                     Violations: 107.31558084487914                    Mean Train Rewards: -14063.9\n",
            "Episode: 840 |                     Train Rewards: -16547.2                     Violations: 67.15780854225159                    Mean Train Rewards: -14028.4\n",
            "Episode: 850 |                     Train Rewards: -14366.7                     Violations: 40.03831744194031                    Mean Train Rewards: -14268.5\n",
            "Episode: 860 |                     Train Rewards: -14678.0                     Violations: 45.601242780685425                    Mean Train Rewards: -14116.1\n",
            "Episode: 870 |                     Train Rewards: -16022.7                     Violations: 57.16744422912599                    Mean Train Rewards: -14199.5\n",
            "Episode: 880 |                     Train Rewards: -14642.0                     Violations: 43.53844881057739                    Mean Train Rewards: -14175.9\n",
            "Episode: 890 |                     Train Rewards: -12415.7                     Violations: 23.24902892112732                    Mean Train Rewards: -14216.0\n",
            "Episode: 900 |                     Train Rewards: -10141.4                     Violations: 0                    Mean Train Rewards: -14169.9\n",
            "Episode: 910 |                     Train Rewards: -10308.8                     Violations: 0                    Mean Train Rewards: -13813.3\n",
            "Episode: 920 |                     Train Rewards: -16925.5                     Violations: 68.35617542266846                    Mean Train Rewards: -13887.4\n",
            "Episode: 930 |                     Train Rewards: -12287.9                     Violations: 18.12657594680786                    Mean Train Rewards: -13912.0\n",
            "Episode: 940 |                     Train Rewards: -13235.4                     Violations: 31.155904531478882                    Mean Train Rewards: -14038.2\n",
            "Episode: 950 |                     Train Rewards: -21864.3                     Violations: 123.48852872848511                    Mean Train Rewards: -13893.0\n",
            "Episode: 960 |                     Train Rewards: -16168.5                     Violations: 57.33557701110841                    Mean Train Rewards: -13915.9\n",
            "Episode: 970 |                     Train Rewards: -15219.5                     Violations: 50.17770290374756                    Mean Train Rewards: -13945.1\n",
            "Episode: 980 |                     Train Rewards: -11126.6                     Violations: 8.808627128601074                    Mean Train Rewards: -13925.6\n",
            "Episode: 990 |                     Train Rewards: -14150.5                     Violations: 40.467534065246596                    Mean Train Rewards: -13976.9\n",
            "Episode: 1000 |                     Train Rewards: -17292.8                     Violations: 75.02817392349242                    Mean Train Rewards: -13973.8\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 6 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-47/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-48\n",
            "\n",
            "==================================================\n",
            "Starting run 9/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4950.2                     Violations: 9.955905675888054                    Mean Train Rewards: -4891.2\n",
            "Episode:  20 |                     Train Rewards: -5110.6                     Violations: 0                    Mean Train Rewards: -4963.1\n",
            "Episode:  30 |                     Train Rewards: -5274.4                     Violations: 0                    Mean Train Rewards: -5032.3\n",
            "Episode:  40 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5067.3\n",
            "Episode:  50 |                     Train Rewards: -5280.3                     Violations: 0                    Mean Train Rewards: -5102.5\n",
            "Episode:  60 |                     Train Rewards: -5257.5                     Violations: 0                    Mean Train Rewards: -5142.0\n",
            "Episode:  70 |                     Train Rewards: -5334.0                     Violations: 0                    Mean Train Rewards: -5165.2\n",
            "Episode:  80 |                     Train Rewards: -5354.8                     Violations: 0                    Mean Train Rewards: -5179.5\n",
            "Episode:  90 |                     Train Rewards: -5246.9                     Violations: 0                    Mean Train Rewards: -5195.0\n",
            "Episode: 100 |                     Train Rewards: -5270.4                     Violations: 0                    Mean Train Rewards: -5204.7\n",
            "Episode: 110 |                     Train Rewards: -5296.6                     Violations: 0                    Mean Train Rewards: -5240.6\n",
            "Episode: 120 |                     Train Rewards: -5425.7                     Violations: 0                    Mean Train Rewards: -5279.3\n",
            "Episode: 130 |                     Train Rewards: -5490.7                     Violations: 0                    Mean Train Rewards: -5302.4\n",
            "Episode: 140 |                     Train Rewards: -5572.1                     Violations: 0                    Mean Train Rewards: -5336.5\n",
            "Episode: 150 |                     Train Rewards: -5590.3                     Violations: 0                    Mean Train Rewards: -5367.6\n",
            "Episode: 160 |                     Train Rewards: -5574.6                     Violations: 0                    Mean Train Rewards: -5388.7\n",
            "Episode: 170 |                     Train Rewards: -5582.5                     Violations: 0                    Mean Train Rewards: -5414.9\n",
            "Episode: 180 |                     Train Rewards: -5489.3                     Violations: 0                    Mean Train Rewards: -5441.9\n",
            "Episode: 190 |                     Train Rewards: -5511.8                     Violations: 0                    Mean Train Rewards: -5458.3\n",
            "Episode: 200 |                     Train Rewards: -5393.9                     Violations: 0                    Mean Train Rewards: -5470.6\n",
            "Episode: 210 |                     Train Rewards: -5230.0                     Violations: 0                    Mean Train Rewards: -5478.1\n",
            "Episode: 220 |                     Train Rewards: -5457.9                     Violations: 0                    Mean Train Rewards: -5471.8\n",
            "Episode: 230 |                     Train Rewards: -5379.2                     Violations: 0                    Mean Train Rewards: -5469.6\n",
            "Episode: 240 |                     Train Rewards: -5267.2                     Violations: 0                    Mean Train Rewards: -5450.9\n",
            "Episode: 250 |                     Train Rewards: -5393.1                     Violations: 0                    Mean Train Rewards: -5425.8\n",
            "Episode: 260 |                     Train Rewards: -5395.1                     Violations: 0                    Mean Train Rewards: -5405.9\n",
            "Episode: 270 |                     Train Rewards: -5338.7                     Violations: 0                    Mean Train Rewards: -5385.3\n",
            "Episode: 280 |                     Train Rewards: -5363.0                     Violations: 0                    Mean Train Rewards: -5370.6\n",
            "Episode: 290 |                     Train Rewards: -5320.7                     Violations: 0                    Mean Train Rewards: -5359.8\n",
            "Episode: 300 |                     Train Rewards: -5272.7                     Violations: 0                    Mean Train Rewards: -5350.0\n",
            "Episode: 310 |                     Train Rewards: -5255.4                     Violations: 0                    Mean Train Rewards: -5342.6\n",
            "Episode: 320 |                     Train Rewards: -5248.7                     Violations: 0                    Mean Train Rewards: -5331.0\n",
            "Episode: 330 |                     Train Rewards: -5314.5                     Violations: 0                    Mean Train Rewards: -5319.3\n",
            "Episode: 340 |                     Train Rewards: -5328.7                     Violations: 0                    Mean Train Rewards: -5316.6\n",
            "Episode: 350 |                     Train Rewards: -5214.8                     Violations: 0                    Mean Train Rewards: -5314.0\n",
            "Episode: 360 |                     Train Rewards: -5263.1                     Violations: 0                    Mean Train Rewards: -5308.2\n",
            "Episode: 370 |                     Train Rewards: -5179.4                     Violations: 0                    Mean Train Rewards: -5296.6\n",
            "Episode: 380 |                     Train Rewards: -5292.7                     Violations: 0                    Mean Train Rewards: -5288.4\n",
            "Episode: 390 |                     Train Rewards: -5250.7                     Violations: 0                    Mean Train Rewards: -5279.8\n",
            "Episode: 400 |                     Train Rewards: -5195.3                     Violations: 0                    Mean Train Rewards: -5275.8\n",
            "Episode: 410 |                     Train Rewards: -5317.8                     Violations: 0                    Mean Train Rewards: -5276.4\n",
            "Episode: 420 |                     Train Rewards: -5135.8                     Violations: 0                    Mean Train Rewards: -5272.0\n",
            "Episode: 430 |                     Train Rewards: -5175.9                     Violations: 0                    Mean Train Rewards: -5261.7\n",
            "Episode: 440 |                     Train Rewards: -5197.4                     Violations: 0                    Mean Train Rewards: -5251.9\n",
            "Episode: 450 |                     Train Rewards: -5186.2                     Violations: 0                    Mean Train Rewards: -5245.5\n",
            "Episode: 460 |                     Train Rewards: -5213.6                     Violations: 0                    Mean Train Rewards: -5235.4\n",
            "Episode: 470 |                     Train Rewards: -5289.1                     Violations: 0                    Mean Train Rewards: -5232.3\n",
            "Episode: 480 |                     Train Rewards: -5218.8                     Violations: 0                    Mean Train Rewards: -5222.4\n",
            "Episode: 490 |                     Train Rewards: -5187.5                     Violations: 0                    Mean Train Rewards: -5210.3\n",
            "Episode: 500 |                     Train Rewards: -5234.0                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 510 |                     Train Rewards: -5273.6                     Violations: 0                    Mean Train Rewards: -5202.6\n",
            "Episode: 520 |                     Train Rewards: -5204.2                     Violations: 0                    Mean Train Rewards: -5202.7\n",
            "Episode: 530 |                     Train Rewards: -5170.9                     Violations: 0                    Mean Train Rewards: -5208.9\n",
            "Episode: 540 |                     Train Rewards: -5213.7                     Violations: 0                    Mean Train Rewards: -5208.7\n",
            "Episode: 550 |                     Train Rewards: -5222.6                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 560 |                     Train Rewards: -5130.2                     Violations: 0                    Mean Train Rewards: -5203.0\n",
            "Episode: 570 |                     Train Rewards: -5211.5                     Violations: 0                    Mean Train Rewards: -5202.9\n",
            "Episode: 580 |                     Train Rewards: -5263.8                     Violations: 0                    Mean Train Rewards: -5200.0\n",
            "Episode: 590 |                     Train Rewards: -5154.4                     Violations: 0                    Mean Train Rewards: -5206.8\n",
            "Episode: 600 |                     Train Rewards: -5311.8                     Violations: 0                    Mean Train Rewards: -5207.1\n",
            "Episode: 610 |                     Train Rewards: -5309.1                     Violations: 0                    Mean Train Rewards: -5214.6\n",
            "Episode: 620 |                     Train Rewards: -5349.2                     Violations: 0                    Mean Train Rewards: -5225.0\n",
            "Episode: 630 |                     Train Rewards: -5241.3                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 640 |                     Train Rewards: -5262.9                     Violations: 0                    Mean Train Rewards: -5234.5\n",
            "Episode: 650 |                     Train Rewards: -5280.9                     Violations: 0                    Mean Train Rewards: -5242.6\n",
            "Episode: 660 |                     Train Rewards: -5350.9                     Violations: 0                    Mean Train Rewards: -5259.0\n",
            "Episode: 670 |                     Train Rewards: -5321.0                     Violations: 0                    Mean Train Rewards: -5271.2\n",
            "Episode: 680 |                     Train Rewards: -5306.9                     Violations: 0                    Mean Train Rewards: -5283.6\n",
            "Episode: 690 |                     Train Rewards: -5339.1                     Violations: 0                    Mean Train Rewards: -5291.7\n",
            "Episode: 700 |                     Train Rewards: -5343.5                     Violations: 0                    Mean Train Rewards: -5302.1\n",
            "Episode: 710 |                     Train Rewards: -5293.2                     Violations: 0                    Mean Train Rewards: -5300.5\n",
            "Episode: 720 |                     Train Rewards: -5226.9                     Violations: 0                    Mean Train Rewards: -5297.0\n",
            "Episode: 730 |                     Train Rewards: -5204.6                     Violations: 0                    Mean Train Rewards: -5287.4\n",
            "Episode: 740 |                     Train Rewards: -5190.1                     Violations: 0                    Mean Train Rewards: -5281.3\n",
            "Episode: 750 |                     Train Rewards: -5206.3                     Violations: 0                    Mean Train Rewards: -5275.4\n",
            "Episode: 760 |                     Train Rewards: -5203.5                     Violations: 0                    Mean Train Rewards: -5266.8\n",
            "Episode: 770 |                     Train Rewards: -5282.9                     Violations: 0                    Mean Train Rewards: -5258.2\n",
            "Episode: 780 |                     Train Rewards: -5194.5                     Violations: 0                    Mean Train Rewards: -5249.6\n",
            "Episode: 790 |                     Train Rewards: -5207.9                     Violations: 0                    Mean Train Rewards: -5238.3\n",
            "Episode: 800 |                     Train Rewards: -5259.1                     Violations: 0                    Mean Train Rewards: -5223.1\n",
            "Episode: 810 |                     Train Rewards: -5291.2                     Violations: 0                    Mean Train Rewards: -5217.5\n",
            "Episode: 820 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5213.7\n",
            "Episode: 830 |                     Train Rewards: -5231.7                     Violations: 0                    Mean Train Rewards: -5218.1\n",
            "Episode: 840 |                     Train Rewards: -5215.7                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 850 |                     Train Rewards: -5193.7                     Violations: 0                    Mean Train Rewards: -5236.9\n",
            "Episode: 860 |                     Train Rewards: -5234.2                     Violations: 0                    Mean Train Rewards: -5236.2\n",
            "Episode: 870 |                     Train Rewards: -5209.0                     Violations: 0                    Mean Train Rewards: -5234.3\n",
            "Episode: 880 |                     Train Rewards: -5233.0                     Violations: 0                    Mean Train Rewards: -5234.6\n",
            "Episode: 890 |                     Train Rewards: -5159.3                     Violations: 0                    Mean Train Rewards: -5230.3\n",
            "Episode: 900 |                     Train Rewards: -5123.4                     Violations: 0                    Mean Train Rewards: -5223.7\n",
            "Episode: 910 |                     Train Rewards: -5057.0                     Violations: 0                    Mean Train Rewards: -5209.0\n",
            "Episode: 920 |                     Train Rewards: -5041.1                     Violations: 4.0547990798950195                    Mean Train Rewards: -5194.3\n",
            "Episode: 930 |                     Train Rewards: -5166.7                     Violations: 0                    Mean Train Rewards: -5180.0\n",
            "Episode: 940 |                     Train Rewards: -5199.8                     Violations: 0                    Mean Train Rewards: -5165.5\n",
            "Episode: 950 |                     Train Rewards: -5176.2                     Violations: 0                    Mean Train Rewards: -5156.8\n",
            "Episode: 960 |                     Train Rewards: -5179.1                     Violations: 0                    Mean Train Rewards: -5149.5\n",
            "Episode: 970 |                     Train Rewards: -5091.3                     Violations: 0                    Mean Train Rewards: -5142.8\n",
            "Episode: 980 |                     Train Rewards: -5161.8                     Violations: 0                    Mean Train Rewards: -5136.4\n",
            "Episode: 990 |                     Train Rewards: -5110.2                     Violations: 0                    Mean Train Rewards: -5137.9\n",
            "Episode: 1000 |                     Train Rewards: -5133.0                     Violations: 0                    Mean Train Rewards: -5142.2\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 6 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-48/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-49\n",
            "\n",
            "==================================================\n",
            "Starting run 10/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 2, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -5945.8                     Violations: 9.955905675888054                    Mean Train Rewards: -7357.2\n",
            "Episode:  20 |                     Train Rewards: -5110.6                     Violations: 0                    Mean Train Rewards: -6401.0\n",
            "Episode:  30 |                     Train Rewards: -5274.4                     Violations: 0                    Mean Train Rewards: -5991.0\n",
            "Episode:  40 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5786.3\n",
            "Episode:  50 |                     Train Rewards: -5280.3                     Violations: 0                    Mean Train Rewards: -5677.7\n",
            "Episode:  60 |                     Train Rewards: -5257.5                     Violations: 0                    Mean Train Rewards: -5621.3\n",
            "Episode:  70 |                     Train Rewards: -5334.0                     Violations: 0                    Mean Train Rewards: -5576.1\n",
            "Episode:  80 |                     Train Rewards: -5354.8                     Violations: 0                    Mean Train Rewards: -5539.0\n",
            "Episode:  90 |                     Train Rewards: -5246.9                     Violations: 0                    Mean Train Rewards: -5514.6\n",
            "Episode: 100 |                     Train Rewards: -5270.4                     Violations: 0                    Mean Train Rewards: -5492.3\n",
            "Episode: 110 |                     Train Rewards: -5296.6                     Violations: 0                    Mean Train Rewards: -5281.5\n",
            "Episode: 120 |                     Train Rewards: -5425.7                     Violations: 0                    Mean Train Rewards: -5279.3\n",
            "Episode: 130 |                     Train Rewards: -5490.7                     Violations: 0                    Mean Train Rewards: -5302.4\n",
            "Episode: 140 |                     Train Rewards: -5572.1                     Violations: 0                    Mean Train Rewards: -5336.5\n",
            "Episode: 150 |                     Train Rewards: -5590.3                     Violations: 0                    Mean Train Rewards: -5367.6\n",
            "Episode: 160 |                     Train Rewards: -5574.6                     Violations: 0                    Mean Train Rewards: -5388.7\n",
            "Episode: 170 |                     Train Rewards: -5582.5                     Violations: 0                    Mean Train Rewards: -5414.9\n",
            "Episode: 180 |                     Train Rewards: -5489.3                     Violations: 0                    Mean Train Rewards: -5441.9\n",
            "Episode: 190 |                     Train Rewards: -5511.8                     Violations: 0                    Mean Train Rewards: -5458.3\n",
            "Episode: 200 |                     Train Rewards: -5393.9                     Violations: 0                    Mean Train Rewards: -5470.6\n",
            "Episode: 210 |                     Train Rewards: -5230.0                     Violations: 0                    Mean Train Rewards: -5478.1\n",
            "Episode: 220 |                     Train Rewards: -5457.9                     Violations: 0                    Mean Train Rewards: -5471.8\n",
            "Episode: 230 |                     Train Rewards: -5379.2                     Violations: 0                    Mean Train Rewards: -5469.6\n",
            "Episode: 240 |                     Train Rewards: -5267.2                     Violations: 0                    Mean Train Rewards: -5450.9\n",
            "Episode: 250 |                     Train Rewards: -5393.1                     Violations: 0                    Mean Train Rewards: -5425.8\n",
            "Episode: 260 |                     Train Rewards: -5395.1                     Violations: 0                    Mean Train Rewards: -5405.9\n",
            "Episode: 270 |                     Train Rewards: -5338.7                     Violations: 0                    Mean Train Rewards: -5385.3\n",
            "Episode: 280 |                     Train Rewards: -5363.0                     Violations: 0                    Mean Train Rewards: -5370.6\n",
            "Episode: 290 |                     Train Rewards: -5320.7                     Violations: 0                    Mean Train Rewards: -5359.8\n",
            "Episode: 300 |                     Train Rewards: -5272.7                     Violations: 0                    Mean Train Rewards: -5350.0\n",
            "Episode: 310 |                     Train Rewards: -5255.4                     Violations: 0                    Mean Train Rewards: -5342.6\n",
            "Episode: 320 |                     Train Rewards: -5248.7                     Violations: 0                    Mean Train Rewards: -5331.0\n",
            "Episode: 330 |                     Train Rewards: -5314.5                     Violations: 0                    Mean Train Rewards: -5319.3\n",
            "Episode: 340 |                     Train Rewards: -5328.7                     Violations: 0                    Mean Train Rewards: -5316.6\n",
            "Episode: 350 |                     Train Rewards: -5214.8                     Violations: 0                    Mean Train Rewards: -5314.0\n",
            "Episode: 360 |                     Train Rewards: -5263.1                     Violations: 0                    Mean Train Rewards: -5308.2\n",
            "Episode: 370 |                     Train Rewards: -5179.4                     Violations: 0                    Mean Train Rewards: -5296.6\n",
            "Episode: 380 |                     Train Rewards: -5292.7                     Violations: 0                    Mean Train Rewards: -5288.4\n",
            "Episode: 390 |                     Train Rewards: -5250.7                     Violations: 0                    Mean Train Rewards: -5279.8\n",
            "Episode: 400 |                     Train Rewards: -5195.3                     Violations: 0                    Mean Train Rewards: -5275.8\n",
            "Episode: 410 |                     Train Rewards: -5317.8                     Violations: 0                    Mean Train Rewards: -5276.4\n",
            "Episode: 420 |                     Train Rewards: -5135.8                     Violations: 0                    Mean Train Rewards: -5272.0\n",
            "Episode: 430 |                     Train Rewards: -5175.9                     Violations: 0                    Mean Train Rewards: -5261.7\n",
            "Episode: 440 |                     Train Rewards: -5197.4                     Violations: 0                    Mean Train Rewards: -5251.9\n",
            "Episode: 450 |                     Train Rewards: -5186.2                     Violations: 0                    Mean Train Rewards: -5245.5\n",
            "Episode: 460 |                     Train Rewards: -5213.6                     Violations: 0                    Mean Train Rewards: -5235.4\n",
            "Episode: 470 |                     Train Rewards: -5289.1                     Violations: 0                    Mean Train Rewards: -5232.3\n",
            "Episode: 480 |                     Train Rewards: -5218.8                     Violations: 0                    Mean Train Rewards: -5222.4\n",
            "Episode: 490 |                     Train Rewards: -5187.5                     Violations: 0                    Mean Train Rewards: -5210.3\n",
            "Episode: 500 |                     Train Rewards: -5234.0                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 510 |                     Train Rewards: -5273.6                     Violations: 0                    Mean Train Rewards: -5202.6\n",
            "Episode: 520 |                     Train Rewards: -5204.2                     Violations: 0                    Mean Train Rewards: -5202.7\n",
            "Episode: 530 |                     Train Rewards: -5170.9                     Violations: 0                    Mean Train Rewards: -5208.9\n",
            "Episode: 540 |                     Train Rewards: -5213.7                     Violations: 0                    Mean Train Rewards: -5208.7\n",
            "Episode: 550 |                     Train Rewards: -5222.6                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 560 |                     Train Rewards: -5130.2                     Violations: 0                    Mean Train Rewards: -5203.0\n",
            "Episode: 570 |                     Train Rewards: -5211.5                     Violations: 0                    Mean Train Rewards: -5202.9\n",
            "Episode: 580 |                     Train Rewards: -5263.8                     Violations: 0                    Mean Train Rewards: -5200.0\n",
            "Episode: 590 |                     Train Rewards: -5154.4                     Violations: 0                    Mean Train Rewards: -5206.8\n",
            "Episode: 600 |                     Train Rewards: -5311.8                     Violations: 0                    Mean Train Rewards: -5207.1\n",
            "Episode: 610 |                     Train Rewards: -5309.1                     Violations: 0                    Mean Train Rewards: -5214.6\n",
            "Episode: 620 |                     Train Rewards: -5349.2                     Violations: 0                    Mean Train Rewards: -5225.0\n",
            "Episode: 630 |                     Train Rewards: -5241.3                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 640 |                     Train Rewards: -5262.9                     Violations: 0                    Mean Train Rewards: -5234.5\n",
            "Episode: 650 |                     Train Rewards: -5280.9                     Violations: 0                    Mean Train Rewards: -5242.6\n",
            "Episode: 660 |                     Train Rewards: -5350.9                     Violations: 0                    Mean Train Rewards: -5259.0\n",
            "Episode: 670 |                     Train Rewards: -5321.0                     Violations: 0                    Mean Train Rewards: -5271.2\n",
            "Episode: 680 |                     Train Rewards: -5306.9                     Violations: 0                    Mean Train Rewards: -5283.6\n",
            "Episode: 690 |                     Train Rewards: -5339.1                     Violations: 0                    Mean Train Rewards: -5291.7\n",
            "Episode: 700 |                     Train Rewards: -5343.5                     Violations: 0                    Mean Train Rewards: -5302.1\n",
            "Episode: 710 |                     Train Rewards: -5293.2                     Violations: 0                    Mean Train Rewards: -5300.5\n",
            "Episode: 720 |                     Train Rewards: -5226.9                     Violations: 0                    Mean Train Rewards: -5297.0\n",
            "Episode: 730 |                     Train Rewards: -5204.6                     Violations: 0                    Mean Train Rewards: -5287.4\n",
            "Episode: 740 |                     Train Rewards: -5190.1                     Violations: 0                    Mean Train Rewards: -5281.3\n",
            "Episode: 750 |                     Train Rewards: -5206.3                     Violations: 0                    Mean Train Rewards: -5275.4\n",
            "Episode: 760 |                     Train Rewards: -5203.5                     Violations: 0                    Mean Train Rewards: -5266.8\n",
            "Episode: 770 |                     Train Rewards: -5282.9                     Violations: 0                    Mean Train Rewards: -5258.2\n",
            "Episode: 780 |                     Train Rewards: -5194.5                     Violations: 0                    Mean Train Rewards: -5249.6\n",
            "Episode: 790 |                     Train Rewards: -5207.9                     Violations: 0                    Mean Train Rewards: -5238.3\n",
            "Episode: 800 |                     Train Rewards: -5259.1                     Violations: 0                    Mean Train Rewards: -5223.1\n",
            "Episode: 810 |                     Train Rewards: -5291.2                     Violations: 0                    Mean Train Rewards: -5217.5\n",
            "Episode: 820 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5213.7\n",
            "Episode: 830 |                     Train Rewards: -5231.7                     Violations: 0                    Mean Train Rewards: -5218.1\n",
            "Episode: 840 |                     Train Rewards: -5215.7                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 850 |                     Train Rewards: -5193.7                     Violations: 0                    Mean Train Rewards: -5236.9\n",
            "Episode: 860 |                     Train Rewards: -5234.2                     Violations: 0                    Mean Train Rewards: -5236.2\n",
            "Episode: 870 |                     Train Rewards: -5209.0                     Violations: 0                    Mean Train Rewards: -5234.3\n",
            "Episode: 880 |                     Train Rewards: -5233.0                     Violations: 0                    Mean Train Rewards: -5234.6\n",
            "Episode: 890 |                     Train Rewards: -5159.3                     Violations: 0                    Mean Train Rewards: -5230.3\n",
            "Episode: 900 |                     Train Rewards: -5123.4                     Violations: 0                    Mean Train Rewards: -5223.7\n",
            "Episode: 910 |                     Train Rewards: -5057.0                     Violations: 0                    Mean Train Rewards: -5210.4\n",
            "Episode: 920 |                     Train Rewards: -5446.5                     Violations: 4.0547990798950195                    Mean Train Rewards: -5199.7\n",
            "Episode: 930 |                     Train Rewards: -5166.7                     Violations: 0                    Mean Train Rewards: -5188.9\n",
            "Episode: 940 |                     Train Rewards: -5199.8                     Violations: 0                    Mean Train Rewards: -5174.4\n",
            "Episode: 950 |                     Train Rewards: -5176.2                     Violations: 0                    Mean Train Rewards: -5165.7\n",
            "Episode: 960 |                     Train Rewards: -5179.1                     Violations: 0                    Mean Train Rewards: -5158.4\n",
            "Episode: 970 |                     Train Rewards: -5091.3                     Violations: 0                    Mean Train Rewards: -5151.7\n",
            "Episode: 980 |                     Train Rewards: -5161.8                     Violations: 0                    Mean Train Rewards: -5145.3\n",
            "Episode: 990 |                     Train Rewards: -5110.2                     Violations: 0                    Mean Train Rewards: -5146.8\n",
            "Episode: 1000 |                     Train Rewards: -5133.0                     Violations: 0                    Mean Train Rewards: -5151.1\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-49/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-50\n",
            "\n",
            "==================================================\n",
            "Starting run 11/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4950.2                     Violations: 9.955905675888054                    Mean Train Rewards: -4891.2\n",
            "Episode:  20 |                     Train Rewards: -5110.6                     Violations: 0                    Mean Train Rewards: -4963.1\n",
            "Episode:  30 |                     Train Rewards: -5274.4                     Violations: 0                    Mean Train Rewards: -5032.3\n",
            "Episode:  40 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5067.3\n",
            "Episode:  50 |                     Train Rewards: -5280.3                     Violations: 0                    Mean Train Rewards: -5102.5\n",
            "Episode:  60 |                     Train Rewards: -5257.5                     Violations: 0                    Mean Train Rewards: -5142.0\n",
            "Episode:  70 |                     Train Rewards: -5334.0                     Violations: 0                    Mean Train Rewards: -5165.2\n",
            "Episode:  80 |                     Train Rewards: -5354.8                     Violations: 0                    Mean Train Rewards: -5179.5\n",
            "Episode:  90 |                     Train Rewards: -5246.9                     Violations: 0                    Mean Train Rewards: -5195.0\n",
            "Episode: 100 |                     Train Rewards: -5270.4                     Violations: 0                    Mean Train Rewards: -5204.7\n",
            "Episode: 110 |                     Train Rewards: -5296.6                     Violations: 0                    Mean Train Rewards: -5240.6\n",
            "Episode: 120 |                     Train Rewards: -5425.7                     Violations: 0                    Mean Train Rewards: -5279.3\n",
            "Episode: 130 |                     Train Rewards: -5490.7                     Violations: 0                    Mean Train Rewards: -5302.4\n",
            "Episode: 140 |                     Train Rewards: -5572.1                     Violations: 0                    Mean Train Rewards: -5336.5\n",
            "Episode: 150 |                     Train Rewards: -5590.3                     Violations: 0                    Mean Train Rewards: -5367.6\n",
            "Episode: 160 |                     Train Rewards: -5574.6                     Violations: 0                    Mean Train Rewards: -5388.7\n",
            "Episode: 170 |                     Train Rewards: -5582.5                     Violations: 0                    Mean Train Rewards: -5414.9\n",
            "Episode: 180 |                     Train Rewards: -5489.3                     Violations: 0                    Mean Train Rewards: -5441.9\n",
            "Episode: 190 |                     Train Rewards: -5511.8                     Violations: 0                    Mean Train Rewards: -5458.3\n",
            "Episode: 200 |                     Train Rewards: -5393.9                     Violations: 0                    Mean Train Rewards: -5470.6\n",
            "Episode: 210 |                     Train Rewards: -5230.0                     Violations: 0                    Mean Train Rewards: -5478.1\n",
            "Episode: 220 |                     Train Rewards: -5457.9                     Violations: 0                    Mean Train Rewards: -5471.8\n",
            "Episode: 230 |                     Train Rewards: -5379.2                     Violations: 0                    Mean Train Rewards: -5469.6\n",
            "Episode: 240 |                     Train Rewards: -5267.2                     Violations: 0                    Mean Train Rewards: -5450.9\n",
            "Episode: 250 |                     Train Rewards: -5393.1                     Violations: 0                    Mean Train Rewards: -5425.8\n",
            "Episode: 260 |                     Train Rewards: -5395.1                     Violations: 0                    Mean Train Rewards: -5405.9\n",
            "Episode: 270 |                     Train Rewards: -5338.7                     Violations: 0                    Mean Train Rewards: -5385.3\n",
            "Episode: 280 |                     Train Rewards: -5363.0                     Violations: 0                    Mean Train Rewards: -5370.6\n",
            "Episode: 290 |                     Train Rewards: -5320.7                     Violations: 0                    Mean Train Rewards: -5359.8\n",
            "Episode: 300 |                     Train Rewards: -5272.7                     Violations: 0                    Mean Train Rewards: -5350.0\n",
            "Episode: 310 |                     Train Rewards: -5255.4                     Violations: 0                    Mean Train Rewards: -5342.6\n",
            "Episode: 320 |                     Train Rewards: -5248.7                     Violations: 0                    Mean Train Rewards: -5331.0\n",
            "Episode: 330 |                     Train Rewards: -5314.5                     Violations: 0                    Mean Train Rewards: -5319.3\n",
            "Episode: 340 |                     Train Rewards: -5328.7                     Violations: 0                    Mean Train Rewards: -5316.6\n",
            "Episode: 350 |                     Train Rewards: -5214.8                     Violations: 0                    Mean Train Rewards: -5314.0\n",
            "Episode: 360 |                     Train Rewards: -5263.1                     Violations: 0                    Mean Train Rewards: -5308.2\n",
            "Episode: 370 |                     Train Rewards: -5179.4                     Violations: 0                    Mean Train Rewards: -5296.6\n",
            "Episode: 380 |                     Train Rewards: -5292.7                     Violations: 0                    Mean Train Rewards: -5288.4\n",
            "Episode: 390 |                     Train Rewards: -5250.7                     Violations: 0                    Mean Train Rewards: -5279.8\n",
            "Episode: 400 |                     Train Rewards: -5195.3                     Violations: 0                    Mean Train Rewards: -5275.8\n",
            "Episode: 410 |                     Train Rewards: -5317.8                     Violations: 0                    Mean Train Rewards: -5276.4\n",
            "Episode: 420 |                     Train Rewards: -5135.8                     Violations: 0                    Mean Train Rewards: -5272.0\n",
            "Episode: 430 |                     Train Rewards: -5175.9                     Violations: 0                    Mean Train Rewards: -5261.7\n",
            "Episode: 440 |                     Train Rewards: -5197.4                     Violations: 0                    Mean Train Rewards: -5251.9\n",
            "Episode: 450 |                     Train Rewards: -5186.2                     Violations: 0                    Mean Train Rewards: -5245.5\n",
            "Episode: 460 |                     Train Rewards: -5213.6                     Violations: 0                    Mean Train Rewards: -5235.4\n",
            "Episode: 470 |                     Train Rewards: -5289.1                     Violations: 0                    Mean Train Rewards: -5232.3\n",
            "Episode: 480 |                     Train Rewards: -5218.8                     Violations: 0                    Mean Train Rewards: -5222.4\n",
            "Episode: 490 |                     Train Rewards: -5187.5                     Violations: 0                    Mean Train Rewards: -5210.3\n",
            "Episode: 500 |                     Train Rewards: -5234.0                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 510 |                     Train Rewards: -5273.6                     Violations: 0                    Mean Train Rewards: -5202.6\n",
            "Episode: 520 |                     Train Rewards: -5204.2                     Violations: 0                    Mean Train Rewards: -5202.7\n",
            "Episode: 530 |                     Train Rewards: -5170.9                     Violations: 0                    Mean Train Rewards: -5208.9\n",
            "Episode: 540 |                     Train Rewards: -5213.7                     Violations: 0                    Mean Train Rewards: -5208.7\n",
            "Episode: 550 |                     Train Rewards: -5222.6                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 560 |                     Train Rewards: -5130.2                     Violations: 0                    Mean Train Rewards: -5203.0\n",
            "Episode: 570 |                     Train Rewards: -5211.5                     Violations: 0                    Mean Train Rewards: -5202.9\n",
            "Episode: 580 |                     Train Rewards: -5263.8                     Violations: 0                    Mean Train Rewards: -5200.0\n",
            "Episode: 590 |                     Train Rewards: -5154.4                     Violations: 0                    Mean Train Rewards: -5206.8\n",
            "Episode: 600 |                     Train Rewards: -5311.8                     Violations: 0                    Mean Train Rewards: -5207.1\n",
            "Episode: 610 |                     Train Rewards: -5309.1                     Violations: 0                    Mean Train Rewards: -5214.6\n",
            "Episode: 620 |                     Train Rewards: -5349.2                     Violations: 0                    Mean Train Rewards: -5225.0\n",
            "Episode: 630 |                     Train Rewards: -5241.3                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 640 |                     Train Rewards: -5262.9                     Violations: 0                    Mean Train Rewards: -5234.5\n",
            "Episode: 650 |                     Train Rewards: -5280.9                     Violations: 0                    Mean Train Rewards: -5242.6\n",
            "Episode: 660 |                     Train Rewards: -5350.9                     Violations: 0                    Mean Train Rewards: -5259.0\n",
            "Episode: 670 |                     Train Rewards: -5321.0                     Violations: 0                    Mean Train Rewards: -5271.2\n",
            "Episode: 680 |                     Train Rewards: -5306.9                     Violations: 0                    Mean Train Rewards: -5283.6\n",
            "Episode: 690 |                     Train Rewards: -5339.1                     Violations: 0                    Mean Train Rewards: -5291.7\n",
            "Episode: 700 |                     Train Rewards: -5343.5                     Violations: 0                    Mean Train Rewards: -5302.1\n",
            "Episode: 710 |                     Train Rewards: -5293.2                     Violations: 0                    Mean Train Rewards: -5300.5\n",
            "Episode: 720 |                     Train Rewards: -5226.9                     Violations: 0                    Mean Train Rewards: -5297.0\n",
            "Episode: 730 |                     Train Rewards: -5204.6                     Violations: 0                    Mean Train Rewards: -5287.4\n",
            "Episode: 740 |                     Train Rewards: -5190.1                     Violations: 0                    Mean Train Rewards: -5281.3\n",
            "Episode: 750 |                     Train Rewards: -5206.3                     Violations: 0                    Mean Train Rewards: -5275.4\n",
            "Episode: 760 |                     Train Rewards: -5203.5                     Violations: 0                    Mean Train Rewards: -5266.8\n",
            "Episode: 770 |                     Train Rewards: -5282.9                     Violations: 0                    Mean Train Rewards: -5258.2\n",
            "Episode: 780 |                     Train Rewards: -5194.5                     Violations: 0                    Mean Train Rewards: -5249.6\n",
            "Episode: 790 |                     Train Rewards: -5207.9                     Violations: 0                    Mean Train Rewards: -5238.3\n",
            "Episode: 800 |                     Train Rewards: -5259.1                     Violations: 0                    Mean Train Rewards: -5223.1\n",
            "Episode: 810 |                     Train Rewards: -5291.2                     Violations: 0                    Mean Train Rewards: -5217.5\n",
            "Episode: 820 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5213.7\n",
            "Episode: 830 |                     Train Rewards: -5231.7                     Violations: 0                    Mean Train Rewards: -5218.1\n",
            "Episode: 840 |                     Train Rewards: -5215.7                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 850 |                     Train Rewards: -5193.7                     Violations: 0                    Mean Train Rewards: -5236.9\n",
            "Episode: 860 |                     Train Rewards: -5234.2                     Violations: 0                    Mean Train Rewards: -5236.2\n",
            "Episode: 870 |                     Train Rewards: -5209.0                     Violations: 0                    Mean Train Rewards: -5234.3\n",
            "Episode: 880 |                     Train Rewards: -5233.0                     Violations: 0                    Mean Train Rewards: -5234.6\n",
            "Episode: 890 |                     Train Rewards: -5159.3                     Violations: 0                    Mean Train Rewards: -5230.3\n",
            "Episode: 900 |                     Train Rewards: -5123.4                     Violations: 0                    Mean Train Rewards: -5223.7\n",
            "Episode: 910 |                     Train Rewards: -5057.0                     Violations: 0                    Mean Train Rewards: -5209.0\n",
            "Episode: 920 |                     Train Rewards: -5041.1                     Violations: 4.0547990798950195                    Mean Train Rewards: -5194.3\n",
            "Episode: 930 |                     Train Rewards: -5166.7                     Violations: 0                    Mean Train Rewards: -5180.0\n",
            "Episode: 940 |                     Train Rewards: -5199.8                     Violations: 0                    Mean Train Rewards: -5165.5\n",
            "Episode: 950 |                     Train Rewards: -5176.2                     Violations: 0                    Mean Train Rewards: -5156.8\n",
            "Episode: 960 |                     Train Rewards: -5179.1                     Violations: 0                    Mean Train Rewards: -5149.5\n",
            "Episode: 970 |                     Train Rewards: -5091.3                     Violations: 0                    Mean Train Rewards: -5142.8\n",
            "Episode: 980 |                     Train Rewards: -5161.8                     Violations: 0                    Mean Train Rewards: -5136.4\n",
            "Episode: 990 |                     Train Rewards: -5110.2                     Violations: 0                    Mean Train Rewards: -5137.9\n",
            "Episode: 1000 |                     Train Rewards: -5133.0                     Violations: 0                    Mean Train Rewards: -5142.2\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-50/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-51\n",
            "\n",
            "==================================================\n",
            "Starting run 12/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 2, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -5945.8                     Violations: 9.955905675888054                    Mean Train Rewards: -7357.2\n",
            "Episode:  20 |                     Train Rewards: -5110.6                     Violations: 0                    Mean Train Rewards: -6401.0\n",
            "Episode:  30 |                     Train Rewards: -5274.4                     Violations: 0                    Mean Train Rewards: -5991.0\n",
            "Episode:  40 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5786.3\n",
            "Episode:  50 |                     Train Rewards: -5280.3                     Violations: 0                    Mean Train Rewards: -5677.7\n",
            "Episode:  60 |                     Train Rewards: -5257.5                     Violations: 0                    Mean Train Rewards: -5621.3\n",
            "Episode:  70 |                     Train Rewards: -5334.0                     Violations: 0                    Mean Train Rewards: -5576.1\n",
            "Episode:  80 |                     Train Rewards: -5354.8                     Violations: 0                    Mean Train Rewards: -5539.0\n",
            "Episode:  90 |                     Train Rewards: -5246.9                     Violations: 0                    Mean Train Rewards: -5514.6\n",
            "Episode: 100 |                     Train Rewards: -5270.4                     Violations: 0                    Mean Train Rewards: -5492.3\n",
            "Episode: 110 |                     Train Rewards: -5296.6                     Violations: 0                    Mean Train Rewards: -5281.5\n",
            "Episode: 120 |                     Train Rewards: -5425.7                     Violations: 0                    Mean Train Rewards: -5279.3\n",
            "Episode: 130 |                     Train Rewards: -5490.7                     Violations: 0                    Mean Train Rewards: -5302.4\n",
            "Episode: 140 |                     Train Rewards: -5572.1                     Violations: 0                    Mean Train Rewards: -5336.5\n",
            "Episode: 150 |                     Train Rewards: -5590.3                     Violations: 0                    Mean Train Rewards: -5367.6\n",
            "Episode: 160 |                     Train Rewards: -5574.6                     Violations: 0                    Mean Train Rewards: -5388.7\n",
            "Episode: 170 |                     Train Rewards: -5582.5                     Violations: 0                    Mean Train Rewards: -5414.9\n",
            "Episode: 180 |                     Train Rewards: -5489.3                     Violations: 0                    Mean Train Rewards: -5441.9\n",
            "Episode: 190 |                     Train Rewards: -5511.8                     Violations: 0                    Mean Train Rewards: -5458.3\n",
            "Episode: 200 |                     Train Rewards: -5393.9                     Violations: 0                    Mean Train Rewards: -5470.6\n",
            "Episode: 210 |                     Train Rewards: -5230.0                     Violations: 0                    Mean Train Rewards: -5478.1\n",
            "Episode: 220 |                     Train Rewards: -5457.9                     Violations: 0                    Mean Train Rewards: -5471.8\n",
            "Episode: 230 |                     Train Rewards: -5379.2                     Violations: 0                    Mean Train Rewards: -5469.6\n",
            "Episode: 240 |                     Train Rewards: -5267.2                     Violations: 0                    Mean Train Rewards: -5450.9\n",
            "Episode: 250 |                     Train Rewards: -5393.1                     Violations: 0                    Mean Train Rewards: -5425.8\n",
            "Episode: 260 |                     Train Rewards: -5395.1                     Violations: 0                    Mean Train Rewards: -5405.9\n",
            "Episode: 270 |                     Train Rewards: -5338.7                     Violations: 0                    Mean Train Rewards: -5385.3\n",
            "Episode: 280 |                     Train Rewards: -5363.0                     Violations: 0                    Mean Train Rewards: -5370.6\n",
            "Episode: 290 |                     Train Rewards: -5320.7                     Violations: 0                    Mean Train Rewards: -5359.8\n",
            "Episode: 300 |                     Train Rewards: -5272.7                     Violations: 0                    Mean Train Rewards: -5350.0\n",
            "Episode: 310 |                     Train Rewards: -5255.4                     Violations: 0                    Mean Train Rewards: -5342.6\n",
            "Episode: 320 |                     Train Rewards: -5248.7                     Violations: 0                    Mean Train Rewards: -5331.0\n",
            "Episode: 330 |                     Train Rewards: -5314.5                     Violations: 0                    Mean Train Rewards: -5319.3\n",
            "Episode: 340 |                     Train Rewards: -5328.7                     Violations: 0                    Mean Train Rewards: -5316.6\n",
            "Episode: 350 |                     Train Rewards: -5214.8                     Violations: 0                    Mean Train Rewards: -5314.0\n",
            "Episode: 360 |                     Train Rewards: -5263.1                     Violations: 0                    Mean Train Rewards: -5308.2\n",
            "Episode: 370 |                     Train Rewards: -5179.4                     Violations: 0                    Mean Train Rewards: -5296.6\n",
            "Episode: 380 |                     Train Rewards: -5292.7                     Violations: 0                    Mean Train Rewards: -5288.4\n",
            "Episode: 390 |                     Train Rewards: -5250.7                     Violations: 0                    Mean Train Rewards: -5279.8\n",
            "Episode: 400 |                     Train Rewards: -5195.3                     Violations: 0                    Mean Train Rewards: -5275.8\n",
            "Episode: 410 |                     Train Rewards: -5317.8                     Violations: 0                    Mean Train Rewards: -5276.4\n",
            "Episode: 420 |                     Train Rewards: -5135.8                     Violations: 0                    Mean Train Rewards: -5272.0\n",
            "Episode: 430 |                     Train Rewards: -5175.9                     Violations: 0                    Mean Train Rewards: -5261.7\n",
            "Episode: 440 |                     Train Rewards: -5197.4                     Violations: 0                    Mean Train Rewards: -5251.9\n",
            "Episode: 450 |                     Train Rewards: -5186.2                     Violations: 0                    Mean Train Rewards: -5245.5\n",
            "Episode: 460 |                     Train Rewards: -5213.6                     Violations: 0                    Mean Train Rewards: -5235.4\n",
            "Episode: 470 |                     Train Rewards: -5289.1                     Violations: 0                    Mean Train Rewards: -5232.3\n",
            "Episode: 480 |                     Train Rewards: -5218.8                     Violations: 0                    Mean Train Rewards: -5222.4\n",
            "Episode: 490 |                     Train Rewards: -5187.5                     Violations: 0                    Mean Train Rewards: -5210.3\n",
            "Episode: 500 |                     Train Rewards: -5234.0                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 510 |                     Train Rewards: -5273.6                     Violations: 0                    Mean Train Rewards: -5202.6\n",
            "Episode: 520 |                     Train Rewards: -5204.2                     Violations: 0                    Mean Train Rewards: -5202.7\n",
            "Episode: 530 |                     Train Rewards: -5170.9                     Violations: 0                    Mean Train Rewards: -5208.9\n",
            "Episode: 540 |                     Train Rewards: -5213.7                     Violations: 0                    Mean Train Rewards: -5208.7\n",
            "Episode: 550 |                     Train Rewards: -5222.6                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 560 |                     Train Rewards: -5130.2                     Violations: 0                    Mean Train Rewards: -5203.0\n",
            "Episode: 570 |                     Train Rewards: -5211.5                     Violations: 0                    Mean Train Rewards: -5202.9\n",
            "Episode: 580 |                     Train Rewards: -5263.8                     Violations: 0                    Mean Train Rewards: -5200.0\n",
            "Episode: 590 |                     Train Rewards: -5154.4                     Violations: 0                    Mean Train Rewards: -5206.8\n",
            "Episode: 600 |                     Train Rewards: -5311.8                     Violations: 0                    Mean Train Rewards: -5207.1\n",
            "Episode: 610 |                     Train Rewards: -5309.1                     Violations: 0                    Mean Train Rewards: -5214.6\n",
            "Episode: 620 |                     Train Rewards: -5349.2                     Violations: 0                    Mean Train Rewards: -5225.0\n",
            "Episode: 630 |                     Train Rewards: -5241.3                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 640 |                     Train Rewards: -5262.9                     Violations: 0                    Mean Train Rewards: -5234.5\n",
            "Episode: 650 |                     Train Rewards: -5280.9                     Violations: 0                    Mean Train Rewards: -5242.6\n",
            "Episode: 660 |                     Train Rewards: -5350.9                     Violations: 0                    Mean Train Rewards: -5259.0\n",
            "Episode: 670 |                     Train Rewards: -5321.0                     Violations: 0                    Mean Train Rewards: -5271.2\n",
            "Episode: 680 |                     Train Rewards: -5306.9                     Violations: 0                    Mean Train Rewards: -5283.6\n",
            "Episode: 690 |                     Train Rewards: -5339.1                     Violations: 0                    Mean Train Rewards: -5291.7\n",
            "Episode: 700 |                     Train Rewards: -5343.5                     Violations: 0                    Mean Train Rewards: -5302.1\n",
            "Episode: 710 |                     Train Rewards: -5293.2                     Violations: 0                    Mean Train Rewards: -5300.5\n",
            "Episode: 720 |                     Train Rewards: -5226.9                     Violations: 0                    Mean Train Rewards: -5297.0\n",
            "Episode: 730 |                     Train Rewards: -5204.6                     Violations: 0                    Mean Train Rewards: -5287.4\n",
            "Episode: 740 |                     Train Rewards: -5190.1                     Violations: 0                    Mean Train Rewards: -5281.3\n",
            "Episode: 750 |                     Train Rewards: -5206.3                     Violations: 0                    Mean Train Rewards: -5275.4\n",
            "Episode: 760 |                     Train Rewards: -5203.5                     Violations: 0                    Mean Train Rewards: -5266.8\n",
            "Episode: 770 |                     Train Rewards: -5282.9                     Violations: 0                    Mean Train Rewards: -5258.2\n",
            "Episode: 780 |                     Train Rewards: -5194.5                     Violations: 0                    Mean Train Rewards: -5249.6\n",
            "Episode: 790 |                     Train Rewards: -5207.9                     Violations: 0                    Mean Train Rewards: -5238.3\n",
            "Episode: 800 |                     Train Rewards: -5259.1                     Violations: 0                    Mean Train Rewards: -5223.1\n",
            "Episode: 810 |                     Train Rewards: -5291.2                     Violations: 0                    Mean Train Rewards: -5217.5\n",
            "Episode: 820 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5213.7\n",
            "Episode: 830 |                     Train Rewards: -5231.7                     Violations: 0                    Mean Train Rewards: -5218.1\n",
            "Episode: 840 |                     Train Rewards: -5215.7                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 850 |                     Train Rewards: -5193.7                     Violations: 0                    Mean Train Rewards: -5236.9\n",
            "Episode: 860 |                     Train Rewards: -5234.2                     Violations: 0                    Mean Train Rewards: -5236.2\n",
            "Episode: 870 |                     Train Rewards: -5209.0                     Violations: 0                    Mean Train Rewards: -5234.3\n",
            "Episode: 880 |                     Train Rewards: -5233.0                     Violations: 0                    Mean Train Rewards: -5234.6\n",
            "Episode: 890 |                     Train Rewards: -5159.3                     Violations: 0                    Mean Train Rewards: -5230.3\n",
            "Episode: 900 |                     Train Rewards: -5123.4                     Violations: 0                    Mean Train Rewards: -5223.7\n",
            "Episode: 910 |                     Train Rewards: -5057.0                     Violations: 0                    Mean Train Rewards: -5210.4\n",
            "Episode: 920 |                     Train Rewards: -5446.5                     Violations: 4.0547990798950195                    Mean Train Rewards: -5199.7\n",
            "Episode: 930 |                     Train Rewards: -5166.7                     Violations: 0                    Mean Train Rewards: -5188.9\n",
            "Episode: 940 |                     Train Rewards: -5199.8                     Violations: 0                    Mean Train Rewards: -5174.4\n",
            "Episode: 950 |                     Train Rewards: -5176.2                     Violations: 0                    Mean Train Rewards: -5165.7\n",
            "Episode: 960 |                     Train Rewards: -5179.1                     Violations: 0                    Mean Train Rewards: -5158.4\n",
            "Episode: 970 |                     Train Rewards: -5091.3                     Violations: 0                    Mean Train Rewards: -5151.7\n",
            "Episode: 980 |                     Train Rewards: -5161.8                     Violations: 0                    Mean Train Rewards: -5145.3\n",
            "Episode: 990 |                     Train Rewards: -5110.2                     Violations: 0                    Mean Train Rewards: -5146.8\n",
            "Episode: 1000 |                     Train Rewards: -5133.0                     Violations: 0                    Mean Train Rewards: -5151.1\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 8 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 8 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-51/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-52\n",
            "\n",
            "==================================================\n",
            "Starting run 13/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4950.2                     Violations: 9.955905675888054                    Mean Train Rewards: -4891.2\n",
            "Episode:  20 |                     Train Rewards: -5110.6                     Violations: 0                    Mean Train Rewards: -4963.1\n",
            "Episode:  30 |                     Train Rewards: -5274.4                     Violations: 0                    Mean Train Rewards: -5032.3\n",
            "Episode:  40 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5067.3\n",
            "Episode:  50 |                     Train Rewards: -5280.3                     Violations: 0                    Mean Train Rewards: -5102.5\n",
            "Episode:  60 |                     Train Rewards: -5257.5                     Violations: 0                    Mean Train Rewards: -5142.0\n",
            "Episode:  70 |                     Train Rewards: -5334.0                     Violations: 0                    Mean Train Rewards: -5165.2\n",
            "Episode:  80 |                     Train Rewards: -5354.8                     Violations: 0                    Mean Train Rewards: -5179.5\n",
            "Episode:  90 |                     Train Rewards: -5246.9                     Violations: 0                    Mean Train Rewards: -5195.0\n",
            "Episode: 100 |                     Train Rewards: -5270.4                     Violations: 0                    Mean Train Rewards: -5204.7\n",
            "Episode: 110 |                     Train Rewards: -5296.6                     Violations: 0                    Mean Train Rewards: -5240.6\n",
            "Episode: 120 |                     Train Rewards: -5425.7                     Violations: 0                    Mean Train Rewards: -5279.3\n",
            "Episode: 130 |                     Train Rewards: -5490.7                     Violations: 0                    Mean Train Rewards: -5302.4\n",
            "Episode: 140 |                     Train Rewards: -5572.1                     Violations: 0                    Mean Train Rewards: -5336.5\n",
            "Episode: 150 |                     Train Rewards: -5590.3                     Violations: 0                    Mean Train Rewards: -5367.6\n",
            "Episode: 160 |                     Train Rewards: -5574.6                     Violations: 0                    Mean Train Rewards: -5388.7\n",
            "Episode: 170 |                     Train Rewards: -5582.5                     Violations: 0                    Mean Train Rewards: -5414.9\n",
            "Episode: 180 |                     Train Rewards: -5489.3                     Violations: 0                    Mean Train Rewards: -5441.9\n",
            "Episode: 190 |                     Train Rewards: -5511.8                     Violations: 0                    Mean Train Rewards: -5458.3\n",
            "Episode: 200 |                     Train Rewards: -5393.9                     Violations: 0                    Mean Train Rewards: -5470.6\n",
            "Episode: 210 |                     Train Rewards: -5230.0                     Violations: 0                    Mean Train Rewards: -5478.1\n",
            "Episode: 220 |                     Train Rewards: -5457.9                     Violations: 0                    Mean Train Rewards: -5471.8\n",
            "Episode: 230 |                     Train Rewards: -5379.2                     Violations: 0                    Mean Train Rewards: -5469.6\n",
            "Episode: 240 |                     Train Rewards: -5267.2                     Violations: 0                    Mean Train Rewards: -5450.9\n",
            "Episode: 250 |                     Train Rewards: -5393.1                     Violations: 0                    Mean Train Rewards: -5425.8\n",
            "Episode: 260 |                     Train Rewards: -5395.1                     Violations: 0                    Mean Train Rewards: -5405.9\n",
            "Episode: 270 |                     Train Rewards: -5338.7                     Violations: 0                    Mean Train Rewards: -5385.3\n",
            "Episode: 280 |                     Train Rewards: -5363.0                     Violations: 0                    Mean Train Rewards: -5370.6\n",
            "Episode: 290 |                     Train Rewards: -5320.7                     Violations: 0                    Mean Train Rewards: -5359.8\n",
            "Episode: 300 |                     Train Rewards: -5272.7                     Violations: 0                    Mean Train Rewards: -5350.0\n",
            "Episode: 310 |                     Train Rewards: -5255.4                     Violations: 0                    Mean Train Rewards: -5342.6\n",
            "Episode: 320 |                     Train Rewards: -5248.7                     Violations: 0                    Mean Train Rewards: -5331.0\n",
            "Episode: 330 |                     Train Rewards: -5314.5                     Violations: 0                    Mean Train Rewards: -5319.3\n",
            "Episode: 340 |                     Train Rewards: -5328.7                     Violations: 0                    Mean Train Rewards: -5316.6\n",
            "Episode: 350 |                     Train Rewards: -5214.8                     Violations: 0                    Mean Train Rewards: -5314.0\n",
            "Episode: 360 |                     Train Rewards: -5263.1                     Violations: 0                    Mean Train Rewards: -5308.2\n",
            "Episode: 370 |                     Train Rewards: -5179.4                     Violations: 0                    Mean Train Rewards: -5296.6\n",
            "Episode: 380 |                     Train Rewards: -5292.7                     Violations: 0                    Mean Train Rewards: -5288.4\n",
            "Episode: 390 |                     Train Rewards: -5250.7                     Violations: 0                    Mean Train Rewards: -5279.8\n",
            "Episode: 400 |                     Train Rewards: -5195.3                     Violations: 0                    Mean Train Rewards: -5275.8\n",
            "Episode: 410 |                     Train Rewards: -5317.8                     Violations: 0                    Mean Train Rewards: -5276.4\n",
            "Episode: 420 |                     Train Rewards: -5135.8                     Violations: 0                    Mean Train Rewards: -5272.0\n",
            "Episode: 430 |                     Train Rewards: -5175.9                     Violations: 0                    Mean Train Rewards: -5261.7\n",
            "Episode: 440 |                     Train Rewards: -5197.4                     Violations: 0                    Mean Train Rewards: -5251.9\n",
            "Episode: 450 |                     Train Rewards: -5186.2                     Violations: 0                    Mean Train Rewards: -5245.5\n",
            "Episode: 460 |                     Train Rewards: -5213.6                     Violations: 0                    Mean Train Rewards: -5235.4\n",
            "Episode: 470 |                     Train Rewards: -5289.1                     Violations: 0                    Mean Train Rewards: -5232.3\n",
            "Episode: 480 |                     Train Rewards: -5218.8                     Violations: 0                    Mean Train Rewards: -5222.4\n",
            "Episode: 490 |                     Train Rewards: -5187.5                     Violations: 0                    Mean Train Rewards: -5210.3\n",
            "Episode: 500 |                     Train Rewards: -5234.0                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 510 |                     Train Rewards: -5273.6                     Violations: 0                    Mean Train Rewards: -5202.6\n",
            "Episode: 520 |                     Train Rewards: -5204.2                     Violations: 0                    Mean Train Rewards: -5202.7\n",
            "Episode: 530 |                     Train Rewards: -5170.9                     Violations: 0                    Mean Train Rewards: -5208.9\n",
            "Episode: 540 |                     Train Rewards: -5213.7                     Violations: 0                    Mean Train Rewards: -5208.7\n",
            "Episode: 550 |                     Train Rewards: -5222.6                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 560 |                     Train Rewards: -5130.2                     Violations: 0                    Mean Train Rewards: -5203.0\n",
            "Episode: 570 |                     Train Rewards: -5211.5                     Violations: 0                    Mean Train Rewards: -5202.9\n",
            "Episode: 580 |                     Train Rewards: -5263.8                     Violations: 0                    Mean Train Rewards: -5200.0\n",
            "Episode: 590 |                     Train Rewards: -5154.4                     Violations: 0                    Mean Train Rewards: -5206.8\n",
            "Episode: 600 |                     Train Rewards: -5311.8                     Violations: 0                    Mean Train Rewards: -5207.1\n",
            "Episode: 610 |                     Train Rewards: -5309.1                     Violations: 0                    Mean Train Rewards: -5214.6\n",
            "Episode: 620 |                     Train Rewards: -5349.2                     Violations: 0                    Mean Train Rewards: -5225.0\n",
            "Episode: 630 |                     Train Rewards: -5241.3                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 640 |                     Train Rewards: -5262.9                     Violations: 0                    Mean Train Rewards: -5234.5\n",
            "Episode: 650 |                     Train Rewards: -5280.9                     Violations: 0                    Mean Train Rewards: -5242.6\n",
            "Episode: 660 |                     Train Rewards: -5350.9                     Violations: 0                    Mean Train Rewards: -5259.0\n",
            "Episode: 670 |                     Train Rewards: -5321.0                     Violations: 0                    Mean Train Rewards: -5271.2\n",
            "Episode: 680 |                     Train Rewards: -5306.9                     Violations: 0                    Mean Train Rewards: -5283.6\n",
            "Episode: 690 |                     Train Rewards: -5339.1                     Violations: 0                    Mean Train Rewards: -5291.7\n",
            "Episode: 700 |                     Train Rewards: -5343.5                     Violations: 0                    Mean Train Rewards: -5302.1\n",
            "Episode: 710 |                     Train Rewards: -5293.2                     Violations: 0                    Mean Train Rewards: -5300.5\n",
            "Episode: 720 |                     Train Rewards: -5226.9                     Violations: 0                    Mean Train Rewards: -5297.0\n",
            "Episode: 730 |                     Train Rewards: -5204.6                     Violations: 0                    Mean Train Rewards: -5287.4\n",
            "Episode: 740 |                     Train Rewards: -5190.1                     Violations: 0                    Mean Train Rewards: -5281.3\n",
            "Episode: 750 |                     Train Rewards: -5206.3                     Violations: 0                    Mean Train Rewards: -5275.4\n",
            "Episode: 760 |                     Train Rewards: -5203.5                     Violations: 0                    Mean Train Rewards: -5266.8\n",
            "Episode: 770 |                     Train Rewards: -5282.9                     Violations: 0                    Mean Train Rewards: -5258.2\n",
            "Episode: 780 |                     Train Rewards: -5194.5                     Violations: 0                    Mean Train Rewards: -5249.6\n",
            "Episode: 790 |                     Train Rewards: -5207.9                     Violations: 0                    Mean Train Rewards: -5238.3\n",
            "Episode: 800 |                     Train Rewards: -5259.1                     Violations: 0                    Mean Train Rewards: -5223.1\n",
            "Episode: 810 |                     Train Rewards: -5291.2                     Violations: 0                    Mean Train Rewards: -5217.5\n",
            "Episode: 820 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5213.7\n",
            "Episode: 830 |                     Train Rewards: -5231.7                     Violations: 0                    Mean Train Rewards: -5218.1\n",
            "Episode: 840 |                     Train Rewards: -5215.7                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 850 |                     Train Rewards: -5193.7                     Violations: 0                    Mean Train Rewards: -5236.9\n",
            "Episode: 860 |                     Train Rewards: -5234.2                     Violations: 0                    Mean Train Rewards: -5236.2\n",
            "Episode: 870 |                     Train Rewards: -5209.0                     Violations: 0                    Mean Train Rewards: -5234.3\n",
            "Episode: 880 |                     Train Rewards: -5233.0                     Violations: 0                    Mean Train Rewards: -5234.6\n",
            "Episode: 890 |                     Train Rewards: -5159.3                     Violations: 0                    Mean Train Rewards: -5230.3\n",
            "Episode: 900 |                     Train Rewards: -5123.4                     Violations: 0                    Mean Train Rewards: -5223.7\n",
            "Episode: 910 |                     Train Rewards: -5057.0                     Violations: 0                    Mean Train Rewards: -5209.0\n",
            "Episode: 920 |                     Train Rewards: -5041.1                     Violations: 4.0547990798950195                    Mean Train Rewards: -5194.3\n",
            "Episode: 930 |                     Train Rewards: -5166.7                     Violations: 0                    Mean Train Rewards: -5180.0\n",
            "Episode: 940 |                     Train Rewards: -5199.8                     Violations: 0                    Mean Train Rewards: -5165.5\n",
            "Episode: 950 |                     Train Rewards: -5176.2                     Violations: 0                    Mean Train Rewards: -5156.8\n",
            "Episode: 960 |                     Train Rewards: -5179.1                     Violations: 0                    Mean Train Rewards: -5149.5\n",
            "Episode: 970 |                     Train Rewards: -5091.3                     Violations: 0                    Mean Train Rewards: -5142.8\n",
            "Episode: 980 |                     Train Rewards: -5161.8                     Violations: 0                    Mean Train Rewards: -5136.4\n",
            "Episode: 990 |                     Train Rewards: -5110.2                     Violations: 0                    Mean Train Rewards: -5137.9\n",
            "Episode: 1000 |                     Train Rewards: -5133.0                     Violations: 0                    Mean Train Rewards: -5142.2\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 8 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 8 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-52/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-53\n",
            "\n",
            "==================================================\n",
            "Starting run 14/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 2, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -5945.8                     Violations: 9.955905675888054                    Mean Train Rewards: -7357.2\n",
            "Episode:  20 |                     Train Rewards: -5110.6                     Violations: 0                    Mean Train Rewards: -6401.0\n",
            "Episode:  30 |                     Train Rewards: -5274.4                     Violations: 0                    Mean Train Rewards: -5991.0\n",
            "Episode:  40 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5786.3\n",
            "Episode:  50 |                     Train Rewards: -5280.3                     Violations: 0                    Mean Train Rewards: -5677.7\n",
            "Episode:  60 |                     Train Rewards: -5257.5                     Violations: 0                    Mean Train Rewards: -5621.3\n",
            "Episode:  70 |                     Train Rewards: -5334.0                     Violations: 0                    Mean Train Rewards: -5576.1\n",
            "Episode:  80 |                     Train Rewards: -5354.8                     Violations: 0                    Mean Train Rewards: -5539.0\n",
            "Episode:  90 |                     Train Rewards: -5246.9                     Violations: 0                    Mean Train Rewards: -5514.6\n",
            "Episode: 100 |                     Train Rewards: -5270.4                     Violations: 0                    Mean Train Rewards: -5492.3\n",
            "Episode: 110 |                     Train Rewards: -5296.6                     Violations: 0                    Mean Train Rewards: -5281.5\n",
            "Episode: 120 |                     Train Rewards: -5425.7                     Violations: 0                    Mean Train Rewards: -5279.3\n",
            "Episode: 130 |                     Train Rewards: -5490.7                     Violations: 0                    Mean Train Rewards: -5302.4\n",
            "Episode: 140 |                     Train Rewards: -5572.1                     Violations: 0                    Mean Train Rewards: -5336.5\n",
            "Episode: 150 |                     Train Rewards: -5590.3                     Violations: 0                    Mean Train Rewards: -5367.6\n",
            "Episode: 160 |                     Train Rewards: -5574.6                     Violations: 0                    Mean Train Rewards: -5388.7\n",
            "Episode: 170 |                     Train Rewards: -5582.5                     Violations: 0                    Mean Train Rewards: -5414.9\n",
            "Episode: 180 |                     Train Rewards: -5489.3                     Violations: 0                    Mean Train Rewards: -5441.9\n",
            "Episode: 190 |                     Train Rewards: -5511.8                     Violations: 0                    Mean Train Rewards: -5458.3\n",
            "Episode: 200 |                     Train Rewards: -5393.9                     Violations: 0                    Mean Train Rewards: -5470.6\n",
            "Episode: 210 |                     Train Rewards: -5230.0                     Violations: 0                    Mean Train Rewards: -5478.1\n",
            "Episode: 220 |                     Train Rewards: -5457.9                     Violations: 0                    Mean Train Rewards: -5471.8\n",
            "Episode: 230 |                     Train Rewards: -5379.2                     Violations: 0                    Mean Train Rewards: -5469.6\n",
            "Episode: 240 |                     Train Rewards: -5267.2                     Violations: 0                    Mean Train Rewards: -5450.9\n",
            "Episode: 250 |                     Train Rewards: -5393.1                     Violations: 0                    Mean Train Rewards: -5425.8\n",
            "Episode: 260 |                     Train Rewards: -5395.1                     Violations: 0                    Mean Train Rewards: -5405.9\n",
            "Episode: 270 |                     Train Rewards: -5338.7                     Violations: 0                    Mean Train Rewards: -5385.3\n",
            "Episode: 280 |                     Train Rewards: -5363.0                     Violations: 0                    Mean Train Rewards: -5370.6\n",
            "Episode: 290 |                     Train Rewards: -5320.7                     Violations: 0                    Mean Train Rewards: -5359.8\n",
            "Episode: 300 |                     Train Rewards: -5272.7                     Violations: 0                    Mean Train Rewards: -5350.0\n",
            "Episode: 310 |                     Train Rewards: -5255.4                     Violations: 0                    Mean Train Rewards: -5342.6\n",
            "Episode: 320 |                     Train Rewards: -5248.7                     Violations: 0                    Mean Train Rewards: -5331.0\n",
            "Episode: 330 |                     Train Rewards: -5314.5                     Violations: 0                    Mean Train Rewards: -5319.3\n",
            "Episode: 340 |                     Train Rewards: -5328.7                     Violations: 0                    Mean Train Rewards: -5316.6\n",
            "Episode: 350 |                     Train Rewards: -5214.8                     Violations: 0                    Mean Train Rewards: -5314.0\n",
            "Episode: 360 |                     Train Rewards: -5263.1                     Violations: 0                    Mean Train Rewards: -5308.2\n",
            "Episode: 370 |                     Train Rewards: -5179.4                     Violations: 0                    Mean Train Rewards: -5296.6\n",
            "Episode: 380 |                     Train Rewards: -5292.7                     Violations: 0                    Mean Train Rewards: -5288.4\n",
            "Episode: 390 |                     Train Rewards: -5250.7                     Violations: 0                    Mean Train Rewards: -5279.8\n",
            "Episode: 400 |                     Train Rewards: -5195.3                     Violations: 0                    Mean Train Rewards: -5275.8\n",
            "Episode: 410 |                     Train Rewards: -5317.8                     Violations: 0                    Mean Train Rewards: -5276.4\n",
            "Episode: 420 |                     Train Rewards: -5135.8                     Violations: 0                    Mean Train Rewards: -5272.0\n",
            "Episode: 430 |                     Train Rewards: -5175.9                     Violations: 0                    Mean Train Rewards: -5261.7\n",
            "Episode: 440 |                     Train Rewards: -5197.4                     Violations: 0                    Mean Train Rewards: -5251.9\n",
            "Episode: 450 |                     Train Rewards: -5186.2                     Violations: 0                    Mean Train Rewards: -5245.5\n",
            "Episode: 460 |                     Train Rewards: -5213.6                     Violations: 0                    Mean Train Rewards: -5235.4\n",
            "Episode: 470 |                     Train Rewards: -5289.1                     Violations: 0                    Mean Train Rewards: -5232.3\n",
            "Episode: 480 |                     Train Rewards: -5218.8                     Violations: 0                    Mean Train Rewards: -5222.4\n",
            "Episode: 490 |                     Train Rewards: -5187.5                     Violations: 0                    Mean Train Rewards: -5210.3\n",
            "Episode: 500 |                     Train Rewards: -5234.0                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 510 |                     Train Rewards: -5273.6                     Violations: 0                    Mean Train Rewards: -5202.6\n",
            "Episode: 520 |                     Train Rewards: -5204.2                     Violations: 0                    Mean Train Rewards: -5202.7\n",
            "Episode: 530 |                     Train Rewards: -5170.9                     Violations: 0                    Mean Train Rewards: -5208.9\n",
            "Episode: 540 |                     Train Rewards: -5213.7                     Violations: 0                    Mean Train Rewards: -5208.7\n",
            "Episode: 550 |                     Train Rewards: -5222.6                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 560 |                     Train Rewards: -5130.2                     Violations: 0                    Mean Train Rewards: -5203.0\n",
            "Episode: 570 |                     Train Rewards: -5211.5                     Violations: 0                    Mean Train Rewards: -5202.9\n",
            "Episode: 580 |                     Train Rewards: -5263.8                     Violations: 0                    Mean Train Rewards: -5200.0\n",
            "Episode: 590 |                     Train Rewards: -5154.4                     Violations: 0                    Mean Train Rewards: -5206.8\n",
            "Episode: 600 |                     Train Rewards: -5311.8                     Violations: 0                    Mean Train Rewards: -5207.1\n",
            "Episode: 610 |                     Train Rewards: -5309.1                     Violations: 0                    Mean Train Rewards: -5214.6\n",
            "Episode: 620 |                     Train Rewards: -5349.2                     Violations: 0                    Mean Train Rewards: -5225.0\n",
            "Episode: 630 |                     Train Rewards: -5241.3                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 640 |                     Train Rewards: -5262.9                     Violations: 0                    Mean Train Rewards: -5234.5\n",
            "Episode: 650 |                     Train Rewards: -5280.9                     Violations: 0                    Mean Train Rewards: -5242.6\n",
            "Episode: 660 |                     Train Rewards: -5350.9                     Violations: 0                    Mean Train Rewards: -5259.0\n",
            "Episode: 670 |                     Train Rewards: -5321.0                     Violations: 0                    Mean Train Rewards: -5271.2\n",
            "Episode: 680 |                     Train Rewards: -5306.9                     Violations: 0                    Mean Train Rewards: -5283.6\n",
            "Episode: 690 |                     Train Rewards: -5339.1                     Violations: 0                    Mean Train Rewards: -5291.7\n",
            "Episode: 700 |                     Train Rewards: -5343.5                     Violations: 0                    Mean Train Rewards: -5302.1\n",
            "Episode: 710 |                     Train Rewards: -5293.2                     Violations: 0                    Mean Train Rewards: -5300.5\n",
            "Episode: 720 |                     Train Rewards: -5226.9                     Violations: 0                    Mean Train Rewards: -5297.0\n",
            "Episode: 730 |                     Train Rewards: -5204.6                     Violations: 0                    Mean Train Rewards: -5287.4\n",
            "Episode: 740 |                     Train Rewards: -5190.1                     Violations: 0                    Mean Train Rewards: -5281.3\n",
            "Episode: 750 |                     Train Rewards: -5206.3                     Violations: 0                    Mean Train Rewards: -5275.4\n",
            "Episode: 760 |                     Train Rewards: -5203.5                     Violations: 0                    Mean Train Rewards: -5266.8\n",
            "Episode: 770 |                     Train Rewards: -5282.9                     Violations: 0                    Mean Train Rewards: -5258.2\n",
            "Episode: 780 |                     Train Rewards: -5194.5                     Violations: 0                    Mean Train Rewards: -5249.6\n",
            "Episode: 790 |                     Train Rewards: -5207.9                     Violations: 0                    Mean Train Rewards: -5238.3\n",
            "Episode: 800 |                     Train Rewards: -5259.1                     Violations: 0                    Mean Train Rewards: -5223.1\n",
            "Episode: 810 |                     Train Rewards: -5291.2                     Violations: 0                    Mean Train Rewards: -5217.5\n",
            "Episode: 820 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5213.7\n",
            "Episode: 830 |                     Train Rewards: -5231.7                     Violations: 0                    Mean Train Rewards: -5218.1\n",
            "Episode: 840 |                     Train Rewards: -5215.7                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 850 |                     Train Rewards: -5193.7                     Violations: 0                    Mean Train Rewards: -5236.9\n",
            "Episode: 860 |                     Train Rewards: -5234.2                     Violations: 0                    Mean Train Rewards: -5236.2\n",
            "Episode: 870 |                     Train Rewards: -5209.0                     Violations: 0                    Mean Train Rewards: -5234.3\n",
            "Episode: 880 |                     Train Rewards: -5233.0                     Violations: 0                    Mean Train Rewards: -5234.6\n",
            "Episode: 890 |                     Train Rewards: -5159.3                     Violations: 0                    Mean Train Rewards: -5230.3\n",
            "Episode: 900 |                     Train Rewards: -5123.4                     Violations: 0                    Mean Train Rewards: -5223.7\n",
            "Episode: 910 |                     Train Rewards: -5057.0                     Violations: 0                    Mean Train Rewards: -5210.4\n",
            "Episode: 920 |                     Train Rewards: -5446.5                     Violations: 4.0547990798950195                    Mean Train Rewards: -5199.7\n",
            "Episode: 930 |                     Train Rewards: -5166.7                     Violations: 0                    Mean Train Rewards: -5188.9\n",
            "Episode: 940 |                     Train Rewards: -5199.8                     Violations: 0                    Mean Train Rewards: -5174.4\n",
            "Episode: 950 |                     Train Rewards: -5176.2                     Violations: 0                    Mean Train Rewards: -5165.7\n",
            "Episode: 960 |                     Train Rewards: -5179.1                     Violations: 0                    Mean Train Rewards: -5158.4\n",
            "Episode: 970 |                     Train Rewards: -5091.3                     Violations: 0                    Mean Train Rewards: -5151.7\n",
            "Episode: 980 |                     Train Rewards: -5161.8                     Violations: 0                    Mean Train Rewards: -5145.3\n",
            "Episode: 990 |                     Train Rewards: -5110.2                     Violations: 0                    Mean Train Rewards: -5146.8\n",
            "Episode: 1000 |                     Train Rewards: -5133.0                     Violations: 0                    Mean Train Rewards: -5151.1\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 20 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 20 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-53/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-54\n",
            "\n",
            "==================================================\n",
            "Starting run 15/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4950.2                     Violations: 9.955905675888054                    Mean Train Rewards: -4891.2\n",
            "Episode:  20 |                     Train Rewards: -5110.6                     Violations: 0                    Mean Train Rewards: -4963.1\n",
            "Episode:  30 |                     Train Rewards: -5274.4                     Violations: 0                    Mean Train Rewards: -5032.3\n",
            "Episode:  40 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5067.3\n",
            "Episode:  50 |                     Train Rewards: -5280.3                     Violations: 0                    Mean Train Rewards: -5102.5\n",
            "Episode:  60 |                     Train Rewards: -5257.5                     Violations: 0                    Mean Train Rewards: -5142.0\n",
            "Episode:  70 |                     Train Rewards: -5334.0                     Violations: 0                    Mean Train Rewards: -5165.2\n",
            "Episode:  80 |                     Train Rewards: -5354.8                     Violations: 0                    Mean Train Rewards: -5179.5\n",
            "Episode:  90 |                     Train Rewards: -5246.9                     Violations: 0                    Mean Train Rewards: -5195.0\n",
            "Episode: 100 |                     Train Rewards: -5270.4                     Violations: 0                    Mean Train Rewards: -5204.7\n",
            "Episode: 110 |                     Train Rewards: -5296.6                     Violations: 0                    Mean Train Rewards: -5240.6\n",
            "Episode: 120 |                     Train Rewards: -5425.7                     Violations: 0                    Mean Train Rewards: -5279.3\n",
            "Episode: 130 |                     Train Rewards: -5490.7                     Violations: 0                    Mean Train Rewards: -5302.4\n",
            "Episode: 140 |                     Train Rewards: -5572.1                     Violations: 0                    Mean Train Rewards: -5336.5\n",
            "Episode: 150 |                     Train Rewards: -5590.3                     Violations: 0                    Mean Train Rewards: -5367.6\n",
            "Episode: 160 |                     Train Rewards: -5574.6                     Violations: 0                    Mean Train Rewards: -5388.7\n",
            "Episode: 170 |                     Train Rewards: -5582.5                     Violations: 0                    Mean Train Rewards: -5414.9\n",
            "Episode: 180 |                     Train Rewards: -5489.3                     Violations: 0                    Mean Train Rewards: -5441.9\n",
            "Episode: 190 |                     Train Rewards: -5511.8                     Violations: 0                    Mean Train Rewards: -5458.3\n",
            "Episode: 200 |                     Train Rewards: -5393.9                     Violations: 0                    Mean Train Rewards: -5470.6\n",
            "Episode: 210 |                     Train Rewards: -5230.0                     Violations: 0                    Mean Train Rewards: -5478.1\n",
            "Episode: 220 |                     Train Rewards: -5457.9                     Violations: 0                    Mean Train Rewards: -5471.8\n",
            "Episode: 230 |                     Train Rewards: -5379.2                     Violations: 0                    Mean Train Rewards: -5469.6\n",
            "Episode: 240 |                     Train Rewards: -5267.2                     Violations: 0                    Mean Train Rewards: -5450.9\n",
            "Episode: 250 |                     Train Rewards: -5393.1                     Violations: 0                    Mean Train Rewards: -5425.8\n",
            "Episode: 260 |                     Train Rewards: -5395.1                     Violations: 0                    Mean Train Rewards: -5405.9\n",
            "Episode: 270 |                     Train Rewards: -5338.7                     Violations: 0                    Mean Train Rewards: -5385.3\n",
            "Episode: 280 |                     Train Rewards: -5363.0                     Violations: 0                    Mean Train Rewards: -5370.6\n",
            "Episode: 290 |                     Train Rewards: -5320.7                     Violations: 0                    Mean Train Rewards: -5359.8\n",
            "Episode: 300 |                     Train Rewards: -5272.7                     Violations: 0                    Mean Train Rewards: -5350.0\n",
            "Episode: 310 |                     Train Rewards: -5255.4                     Violations: 0                    Mean Train Rewards: -5342.6\n",
            "Episode: 320 |                     Train Rewards: -5248.7                     Violations: 0                    Mean Train Rewards: -5331.0\n",
            "Episode: 330 |                     Train Rewards: -5314.5                     Violations: 0                    Mean Train Rewards: -5319.3\n",
            "Episode: 340 |                     Train Rewards: -5328.7                     Violations: 0                    Mean Train Rewards: -5316.6\n",
            "Episode: 350 |                     Train Rewards: -5214.8                     Violations: 0                    Mean Train Rewards: -5314.0\n",
            "Episode: 360 |                     Train Rewards: -5263.1                     Violations: 0                    Mean Train Rewards: -5308.2\n",
            "Episode: 370 |                     Train Rewards: -5179.4                     Violations: 0                    Mean Train Rewards: -5296.6\n",
            "Episode: 380 |                     Train Rewards: -5292.7                     Violations: 0                    Mean Train Rewards: -5288.4\n",
            "Episode: 390 |                     Train Rewards: -5250.7                     Violations: 0                    Mean Train Rewards: -5279.8\n",
            "Episode: 400 |                     Train Rewards: -5195.3                     Violations: 0                    Mean Train Rewards: -5275.8\n",
            "Episode: 410 |                     Train Rewards: -5317.8                     Violations: 0                    Mean Train Rewards: -5276.4\n",
            "Episode: 420 |                     Train Rewards: -5135.8                     Violations: 0                    Mean Train Rewards: -5272.0\n",
            "Episode: 430 |                     Train Rewards: -5175.9                     Violations: 0                    Mean Train Rewards: -5261.7\n",
            "Episode: 440 |                     Train Rewards: -5197.4                     Violations: 0                    Mean Train Rewards: -5251.9\n",
            "Episode: 450 |                     Train Rewards: -5186.2                     Violations: 0                    Mean Train Rewards: -5245.5\n",
            "Episode: 460 |                     Train Rewards: -5213.6                     Violations: 0                    Mean Train Rewards: -5235.4\n",
            "Episode: 470 |                     Train Rewards: -5289.1                     Violations: 0                    Mean Train Rewards: -5232.3\n",
            "Episode: 480 |                     Train Rewards: -5218.8                     Violations: 0                    Mean Train Rewards: -5222.4\n",
            "Episode: 490 |                     Train Rewards: -5187.5                     Violations: 0                    Mean Train Rewards: -5210.3\n",
            "Episode: 500 |                     Train Rewards: -5234.0                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 510 |                     Train Rewards: -5273.6                     Violations: 0                    Mean Train Rewards: -5202.6\n",
            "Episode: 520 |                     Train Rewards: -5204.2                     Violations: 0                    Mean Train Rewards: -5202.7\n",
            "Episode: 530 |                     Train Rewards: -5170.9                     Violations: 0                    Mean Train Rewards: -5208.9\n",
            "Episode: 540 |                     Train Rewards: -5213.7                     Violations: 0                    Mean Train Rewards: -5208.7\n",
            "Episode: 550 |                     Train Rewards: -5222.6                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 560 |                     Train Rewards: -5130.2                     Violations: 0                    Mean Train Rewards: -5203.0\n",
            "Episode: 570 |                     Train Rewards: -5211.5                     Violations: 0                    Mean Train Rewards: -5202.9\n",
            "Episode: 580 |                     Train Rewards: -5263.8                     Violations: 0                    Mean Train Rewards: -5200.0\n",
            "Episode: 590 |                     Train Rewards: -5154.4                     Violations: 0                    Mean Train Rewards: -5206.8\n",
            "Episode: 600 |                     Train Rewards: -5311.8                     Violations: 0                    Mean Train Rewards: -5207.1\n",
            "Episode: 610 |                     Train Rewards: -5309.1                     Violations: 0                    Mean Train Rewards: -5214.6\n",
            "Episode: 620 |                     Train Rewards: -5349.2                     Violations: 0                    Mean Train Rewards: -5225.0\n",
            "Episode: 630 |                     Train Rewards: -5241.3                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 640 |                     Train Rewards: -5262.9                     Violations: 0                    Mean Train Rewards: -5234.5\n",
            "Episode: 650 |                     Train Rewards: -5280.9                     Violations: 0                    Mean Train Rewards: -5242.6\n",
            "Episode: 660 |                     Train Rewards: -5350.9                     Violations: 0                    Mean Train Rewards: -5259.0\n",
            "Episode: 670 |                     Train Rewards: -5321.0                     Violations: 0                    Mean Train Rewards: -5271.2\n",
            "Episode: 680 |                     Train Rewards: -5306.9                     Violations: 0                    Mean Train Rewards: -5283.6\n",
            "Episode: 690 |                     Train Rewards: -5339.1                     Violations: 0                    Mean Train Rewards: -5291.7\n",
            "Episode: 700 |                     Train Rewards: -5343.5                     Violations: 0                    Mean Train Rewards: -5302.1\n",
            "Episode: 710 |                     Train Rewards: -5293.2                     Violations: 0                    Mean Train Rewards: -5300.5\n",
            "Episode: 720 |                     Train Rewards: -5226.9                     Violations: 0                    Mean Train Rewards: -5297.0\n",
            "Episode: 730 |                     Train Rewards: -5204.6                     Violations: 0                    Mean Train Rewards: -5287.4\n",
            "Episode: 740 |                     Train Rewards: -5190.1                     Violations: 0                    Mean Train Rewards: -5281.3\n",
            "Episode: 750 |                     Train Rewards: -5206.3                     Violations: 0                    Mean Train Rewards: -5275.4\n",
            "Episode: 760 |                     Train Rewards: -5203.5                     Violations: 0                    Mean Train Rewards: -5266.8\n",
            "Episode: 770 |                     Train Rewards: -5282.9                     Violations: 0                    Mean Train Rewards: -5258.2\n",
            "Episode: 780 |                     Train Rewards: -5194.5                     Violations: 0                    Mean Train Rewards: -5249.6\n",
            "Episode: 790 |                     Train Rewards: -5207.9                     Violations: 0                    Mean Train Rewards: -5238.3\n",
            "Episode: 800 |                     Train Rewards: -5259.1                     Violations: 0                    Mean Train Rewards: -5223.1\n",
            "Episode: 810 |                     Train Rewards: -5291.2                     Violations: 0                    Mean Train Rewards: -5217.5\n",
            "Episode: 820 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5213.7\n",
            "Episode: 830 |                     Train Rewards: -5231.7                     Violations: 0                    Mean Train Rewards: -5218.1\n",
            "Episode: 840 |                     Train Rewards: -5215.7                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 850 |                     Train Rewards: -5193.7                     Violations: 0                    Mean Train Rewards: -5236.9\n",
            "Episode: 860 |                     Train Rewards: -5234.2                     Violations: 0                    Mean Train Rewards: -5236.2\n",
            "Episode: 870 |                     Train Rewards: -5209.0                     Violations: 0                    Mean Train Rewards: -5234.3\n",
            "Episode: 880 |                     Train Rewards: -5233.0                     Violations: 0                    Mean Train Rewards: -5234.6\n",
            "Episode: 890 |                     Train Rewards: -5159.3                     Violations: 0                    Mean Train Rewards: -5230.3\n",
            "Episode: 900 |                     Train Rewards: -5123.4                     Violations: 0                    Mean Train Rewards: -5223.7\n",
            "Episode: 910 |                     Train Rewards: -5057.0                     Violations: 0                    Mean Train Rewards: -5209.0\n",
            "Episode: 920 |                     Train Rewards: -5041.1                     Violations: 4.0547990798950195                    Mean Train Rewards: -5194.3\n",
            "Episode: 930 |                     Train Rewards: -5166.7                     Violations: 0                    Mean Train Rewards: -5180.0\n",
            "Episode: 940 |                     Train Rewards: -5199.8                     Violations: 0                    Mean Train Rewards: -5165.5\n",
            "Episode: 950 |                     Train Rewards: -5176.2                     Violations: 0                    Mean Train Rewards: -5156.8\n",
            "Episode: 960 |                     Train Rewards: -5179.1                     Violations: 0                    Mean Train Rewards: -5149.5\n",
            "Episode: 970 |                     Train Rewards: -5091.3                     Violations: 0                    Mean Train Rewards: -5142.8\n",
            "Episode: 980 |                     Train Rewards: -5161.8                     Violations: 0                    Mean Train Rewards: -5136.4\n",
            "Episode: 990 |                     Train Rewards: -5110.2                     Violations: 0                    Mean Train Rewards: -5137.9\n",
            "Episode: 1000 |                     Train Rewards: -5133.0                     Violations: 0                    Mean Train Rewards: -5142.2\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-54/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-55\n",
            "\n",
            "==================================================\n",
            "Starting run 16/16, seed 123\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 123}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4950.2                     Violations: 9.955905675888054                    Mean Train Rewards: -4891.2\n",
            "Episode:  20 |                     Train Rewards: -5110.6                     Violations: 0                    Mean Train Rewards: -4963.1\n",
            "Episode:  30 |                     Train Rewards: -5274.4                     Violations: 0                    Mean Train Rewards: -5032.3\n",
            "Episode:  40 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5067.3\n",
            "Episode:  50 |                     Train Rewards: -5280.3                     Violations: 0                    Mean Train Rewards: -5102.5\n",
            "Episode:  60 |                     Train Rewards: -5257.5                     Violations: 0                    Mean Train Rewards: -5142.0\n",
            "Episode:  70 |                     Train Rewards: -5334.0                     Violations: 0                    Mean Train Rewards: -5165.2\n",
            "Episode:  80 |                     Train Rewards: -5354.8                     Violations: 0                    Mean Train Rewards: -5179.5\n",
            "Episode:  90 |                     Train Rewards: -5246.9                     Violations: 0                    Mean Train Rewards: -5195.0\n",
            "Episode: 100 |                     Train Rewards: -5270.4                     Violations: 0                    Mean Train Rewards: -5204.7\n",
            "Episode: 110 |                     Train Rewards: -5296.6                     Violations: 0                    Mean Train Rewards: -5240.6\n",
            "Episode: 120 |                     Train Rewards: -5425.7                     Violations: 0                    Mean Train Rewards: -5279.3\n",
            "Episode: 130 |                     Train Rewards: -5490.7                     Violations: 0                    Mean Train Rewards: -5302.4\n",
            "Episode: 140 |                     Train Rewards: -5572.1                     Violations: 0                    Mean Train Rewards: -5336.5\n",
            "Episode: 150 |                     Train Rewards: -5590.3                     Violations: 0                    Mean Train Rewards: -5367.6\n",
            "Episode: 160 |                     Train Rewards: -5574.6                     Violations: 0                    Mean Train Rewards: -5388.7\n",
            "Episode: 170 |                     Train Rewards: -5582.5                     Violations: 0                    Mean Train Rewards: -5414.9\n",
            "Episode: 180 |                     Train Rewards: -5489.3                     Violations: 0                    Mean Train Rewards: -5441.9\n",
            "Episode: 190 |                     Train Rewards: -5511.8                     Violations: 0                    Mean Train Rewards: -5458.3\n",
            "Episode: 200 |                     Train Rewards: -5393.9                     Violations: 0                    Mean Train Rewards: -5470.6\n",
            "Episode: 210 |                     Train Rewards: -5230.0                     Violations: 0                    Mean Train Rewards: -5478.1\n",
            "Episode: 220 |                     Train Rewards: -5457.9                     Violations: 0                    Mean Train Rewards: -5471.8\n",
            "Episode: 230 |                     Train Rewards: -5379.2                     Violations: 0                    Mean Train Rewards: -5469.6\n",
            "Episode: 240 |                     Train Rewards: -5267.2                     Violations: 0                    Mean Train Rewards: -5450.9\n",
            "Episode: 250 |                     Train Rewards: -5393.1                     Violations: 0                    Mean Train Rewards: -5425.8\n",
            "Episode: 260 |                     Train Rewards: -5395.1                     Violations: 0                    Mean Train Rewards: -5405.9\n",
            "Episode: 270 |                     Train Rewards: -5338.7                     Violations: 0                    Mean Train Rewards: -5385.3\n",
            "Episode: 280 |                     Train Rewards: -5363.0                     Violations: 0                    Mean Train Rewards: -5370.6\n",
            "Episode: 290 |                     Train Rewards: -5320.7                     Violations: 0                    Mean Train Rewards: -5359.8\n",
            "Episode: 300 |                     Train Rewards: -5272.7                     Violations: 0                    Mean Train Rewards: -5350.0\n",
            "Episode: 310 |                     Train Rewards: -5255.4                     Violations: 0                    Mean Train Rewards: -5342.6\n",
            "Episode: 320 |                     Train Rewards: -5248.7                     Violations: 0                    Mean Train Rewards: -5331.0\n",
            "Episode: 330 |                     Train Rewards: -5314.5                     Violations: 0                    Mean Train Rewards: -5319.3\n",
            "Episode: 340 |                     Train Rewards: -5328.7                     Violations: 0                    Mean Train Rewards: -5316.6\n",
            "Episode: 350 |                     Train Rewards: -5214.8                     Violations: 0                    Mean Train Rewards: -5314.0\n",
            "Episode: 360 |                     Train Rewards: -5263.1                     Violations: 0                    Mean Train Rewards: -5308.2\n",
            "Episode: 370 |                     Train Rewards: -5179.4                     Violations: 0                    Mean Train Rewards: -5296.6\n",
            "Episode: 380 |                     Train Rewards: -5292.7                     Violations: 0                    Mean Train Rewards: -5288.4\n",
            "Episode: 390 |                     Train Rewards: -5250.7                     Violations: 0                    Mean Train Rewards: -5279.8\n",
            "Episode: 400 |                     Train Rewards: -5195.3                     Violations: 0                    Mean Train Rewards: -5275.8\n",
            "Episode: 410 |                     Train Rewards: -5317.8                     Violations: 0                    Mean Train Rewards: -5276.4\n",
            "Episode: 420 |                     Train Rewards: -5135.8                     Violations: 0                    Mean Train Rewards: -5272.0\n",
            "Episode: 430 |                     Train Rewards: -5175.9                     Violations: 0                    Mean Train Rewards: -5261.7\n",
            "Episode: 440 |                     Train Rewards: -5197.4                     Violations: 0                    Mean Train Rewards: -5251.9\n",
            "Episode: 450 |                     Train Rewards: -5186.2                     Violations: 0                    Mean Train Rewards: -5245.5\n",
            "Episode: 460 |                     Train Rewards: -5213.6                     Violations: 0                    Mean Train Rewards: -5235.4\n",
            "Episode: 470 |                     Train Rewards: -5289.1                     Violations: 0                    Mean Train Rewards: -5232.3\n",
            "Episode: 480 |                     Train Rewards: -5218.8                     Violations: 0                    Mean Train Rewards: -5222.4\n",
            "Episode: 490 |                     Train Rewards: -5187.5                     Violations: 0                    Mean Train Rewards: -5210.3\n",
            "Episode: 500 |                     Train Rewards: -5234.0                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 510 |                     Train Rewards: -5273.6                     Violations: 0                    Mean Train Rewards: -5202.6\n",
            "Episode: 520 |                     Train Rewards: -5204.2                     Violations: 0                    Mean Train Rewards: -5202.7\n",
            "Episode: 530 |                     Train Rewards: -5170.9                     Violations: 0                    Mean Train Rewards: -5208.9\n",
            "Episode: 540 |                     Train Rewards: -5213.7                     Violations: 0                    Mean Train Rewards: -5208.7\n",
            "Episode: 550 |                     Train Rewards: -5222.6                     Violations: 0                    Mean Train Rewards: -5206.1\n",
            "Episode: 560 |                     Train Rewards: -5130.2                     Violations: 0                    Mean Train Rewards: -5203.0\n",
            "Episode: 570 |                     Train Rewards: -5211.5                     Violations: 0                    Mean Train Rewards: -5202.9\n",
            "Episode: 580 |                     Train Rewards: -5263.8                     Violations: 0                    Mean Train Rewards: -5200.0\n",
            "Episode: 590 |                     Train Rewards: -5154.4                     Violations: 0                    Mean Train Rewards: -5206.8\n",
            "Episode: 600 |                     Train Rewards: -5311.8                     Violations: 0                    Mean Train Rewards: -5207.1\n",
            "Episode: 610 |                     Train Rewards: -5309.1                     Violations: 0                    Mean Train Rewards: -5214.6\n",
            "Episode: 620 |                     Train Rewards: -5349.2                     Violations: 0                    Mean Train Rewards: -5225.0\n",
            "Episode: 630 |                     Train Rewards: -5241.3                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 640 |                     Train Rewards: -5262.9                     Violations: 0                    Mean Train Rewards: -5234.5\n",
            "Episode: 650 |                     Train Rewards: -5280.9                     Violations: 0                    Mean Train Rewards: -5242.6\n",
            "Episode: 660 |                     Train Rewards: -5350.9                     Violations: 0                    Mean Train Rewards: -5259.0\n",
            "Episode: 670 |                     Train Rewards: -5321.0                     Violations: 0                    Mean Train Rewards: -5271.2\n",
            "Episode: 680 |                     Train Rewards: -5306.9                     Violations: 0                    Mean Train Rewards: -5283.6\n",
            "Episode: 690 |                     Train Rewards: -5339.1                     Violations: 0                    Mean Train Rewards: -5291.7\n",
            "Episode: 700 |                     Train Rewards: -5343.5                     Violations: 0                    Mean Train Rewards: -5302.1\n",
            "Episode: 710 |                     Train Rewards: -5293.2                     Violations: 0                    Mean Train Rewards: -5300.5\n",
            "Episode: 720 |                     Train Rewards: -5226.9                     Violations: 0                    Mean Train Rewards: -5297.0\n",
            "Episode: 730 |                     Train Rewards: -5204.6                     Violations: 0                    Mean Train Rewards: -5287.4\n",
            "Episode: 740 |                     Train Rewards: -5190.1                     Violations: 0                    Mean Train Rewards: -5281.3\n",
            "Episode: 750 |                     Train Rewards: -5206.3                     Violations: 0                    Mean Train Rewards: -5275.4\n",
            "Episode: 760 |                     Train Rewards: -5203.5                     Violations: 0                    Mean Train Rewards: -5266.8\n",
            "Episode: 770 |                     Train Rewards: -5282.9                     Violations: 0                    Mean Train Rewards: -5258.2\n",
            "Episode: 780 |                     Train Rewards: -5194.5                     Violations: 0                    Mean Train Rewards: -5249.6\n",
            "Episode: 790 |                     Train Rewards: -5207.9                     Violations: 0                    Mean Train Rewards: -5238.3\n",
            "Episode: 800 |                     Train Rewards: -5259.1                     Violations: 0                    Mean Train Rewards: -5223.1\n",
            "Episode: 810 |                     Train Rewards: -5291.2                     Violations: 0                    Mean Train Rewards: -5217.5\n",
            "Episode: 820 |                     Train Rewards: -5189.9                     Violations: 0                    Mean Train Rewards: -5213.7\n",
            "Episode: 830 |                     Train Rewards: -5231.7                     Violations: 0                    Mean Train Rewards: -5218.1\n",
            "Episode: 840 |                     Train Rewards: -5215.7                     Violations: 0                    Mean Train Rewards: -5231.2\n",
            "Episode: 850 |                     Train Rewards: -5193.7                     Violations: 0                    Mean Train Rewards: -5236.9\n",
            "Episode: 860 |                     Train Rewards: -5234.2                     Violations: 0                    Mean Train Rewards: -5236.2\n",
            "Episode: 870 |                     Train Rewards: -5209.0                     Violations: 0                    Mean Train Rewards: -5234.3\n",
            "Episode: 880 |                     Train Rewards: -5233.0                     Violations: 0                    Mean Train Rewards: -5234.6\n",
            "Episode: 890 |                     Train Rewards: -5159.3                     Violations: 0                    Mean Train Rewards: -5230.3\n",
            "Episode: 900 |                     Train Rewards: -5123.4                     Violations: 0                    Mean Train Rewards: -5223.7\n",
            "Episode: 910 |                     Train Rewards: -5057.0                     Violations: 0                    Mean Train Rewards: -5209.0\n",
            "Episode: 920 |                     Train Rewards: -5041.1                     Violations: 4.0547990798950195                    Mean Train Rewards: -5194.3\n",
            "Episode: 930 |                     Train Rewards: -5166.7                     Violations: 0                    Mean Train Rewards: -5180.0\n",
            "Episode: 940 |                     Train Rewards: -5199.8                     Violations: 0                    Mean Train Rewards: -5165.5\n",
            "Episode: 950 |                     Train Rewards: -5176.2                     Violations: 0                    Mean Train Rewards: -5156.8\n",
            "Episode: 960 |                     Train Rewards: -5179.1                     Violations: 0                    Mean Train Rewards: -5149.5\n",
            "Episode: 970 |                     Train Rewards: -5091.3                     Violations: 0                    Mean Train Rewards: -5142.8\n",
            "Episode: 980 |                     Train Rewards: -5161.8                     Violations: 0                    Mean Train Rewards: -5136.4\n",
            "Episode: 990 |                     Train Rewards: -5110.2                     Violations: 0                    Mean Train Rewards: -5137.9\n",
            "Episode: 1000 |                     Train Rewards: -5133.0                     Violations: 0                    Mean Train Rewards: -5142.2\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 18 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 18 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-55/metadata\n",
            "Sampling 1000 random states to calculate offset k...\n",
            "  Completed 200/1000 samples...\n",
            "  Completed 400/1000 samples...\n",
            "  Completed 600/1000 samples...\n",
            "  Completed 800/1000 samples...\n",
            "  Completed 1000/1000 samples...\n",
            "  Using mean method: k = |2545.57| = 2545.57\n",
            "  Successfully sampled 1000/1000 states\n",
            "  Objective value range: [2300.13, 2800.00]\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-56\n",
            "\n",
            "==================================================\n",
            "Starting run 1/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.001, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -9508.8                     Violations: 116.49408578872684                    Mean Train Rewards: -9575.7\n",
            "Episode:  20 |                     Train Rewards: -9857.6                     Violations: 28.474197387695305                    Mean Train Rewards: -9592.0\n",
            "Episode:  30 |                     Train Rewards: -10123.2                     Violations: 0                    Mean Train Rewards: -9786.9\n",
            "Episode:  40 |                     Train Rewards: -9908.6                     Violations: 19.642733335494995                    Mean Train Rewards: -9829.3\n",
            "Episode:  50 |                     Train Rewards: -9615.8                     Violations: 82.98959732055663                    Mean Train Rewards: -9777.4\n",
            "Episode:  60 |                     Train Rewards: -9388.7                     Violations: 164.52977895736694                    Mean Train Rewards: -9726.0\n",
            "Episode:  70 |                     Train Rewards: -9732.6                     Violations: 53.47100853919983                    Mean Train Rewards: -9712.5\n",
            "Episode:  80 |                     Train Rewards: -9775.1                     Violations: 44.98049974441528                    Mean Train Rewards: -9713.5\n",
            "Episode:  90 |                     Train Rewards: -10082.9                     Violations: 0.03589034080505371                    Mean Train Rewards: -9739.7\n",
            "Episode: 100 |                     Train Rewards: -10259.7                     Violations: 0                    Mean Train Rewards: -9789.8\n",
            "Episode: 110 |                     Train Rewards: -10831.0                     Violations: 0                    Mean Train Rewards: -9887.4\n",
            "Episode: 120 |                     Train Rewards: -11050.1                     Violations: 0                    Mean Train Rewards: -10016.5\n",
            "Episode: 130 |                     Train Rewards: -11116.8                     Violations: 0                    Mean Train Rewards: -10100.8\n",
            "Episode: 140 |                     Train Rewards: -10913.9                     Violations: 0                    Mean Train Rewards: -10198.0\n",
            "Episode: 150 |                     Train Rewards: -10745.6                     Violations: 0                    Mean Train Rewards: -10317.7\n",
            "Episode: 160 |                     Train Rewards: -11187.6                     Violations: 0                    Mean Train Rewards: -10479.1\n",
            "Episode: 170 |                     Train Rewards: -11168.7                     Violations: 0                    Mean Train Rewards: -10633.6\n",
            "Episode: 180 |                     Train Rewards: -10623.9                     Violations: 15.149589776992798                    Mean Train Rewards: -10766.5\n",
            "Episode: 190 |                     Train Rewards: -10278.5                     Violations: 36.53284311294556                    Mean Train Rewards: -10802.1\n",
            "Episode: 200 |                     Train Rewards: -10561.9                     Violations: 33.72766733169556                    Mean Train Rewards: -10807.6\n",
            "Episode: 210 |                     Train Rewards: -10267.8                     Violations: 34.267412424087524                    Mean Train Rewards: -10782.6\n",
            "Episode: 220 |                     Train Rewards: -9923.6                     Violations: 80.20718812942505                    Mean Train Rewards: -10723.9\n",
            "Episode: 230 |                     Train Rewards: -9777.5                     Violations: 89.55219507217409                    Mean Train Rewards: -10633.2\n",
            "Episode: 240 |                     Train Rewards: -10408.9                     Violations: 0                    Mean Train Rewards: -10548.3\n",
            "Episode: 250 |                     Train Rewards: -10191.1                     Violations: 33.1157660484314                    Mean Train Rewards: -10486.8\n",
            "Episode: 260 |                     Train Rewards: -10143.2                     Violations: 32.89117574691771                    Mean Train Rewards: -10387.0\n",
            "Episode: 270 |                     Train Rewards: -10648.5                     Violations: 19.864037036895766                    Mean Train Rewards: -10302.8\n",
            "Episode: 280 |                     Train Rewards: -10428.3                     Violations: 19.60869073867798                    Mean Train Rewards: -10223.0\n",
            "Episode: 290 |                     Train Rewards: -10228.7                     Violations: 8.737250566482544                    Mean Train Rewards: -10216.4\n",
            "Episode: 300 |                     Train Rewards: -9644.2                     Violations: 87.51787900924683                    Mean Train Rewards: -10192.0\n",
            "Episode: 310 |                     Train Rewards: -10288.0                     Violations: 51.62531733512877                    Mean Train Rewards: -10201.0\n",
            "Episode: 320 |                     Train Rewards: -10545.5                     Violations: 0                    Mean Train Rewards: -10189.4\n",
            "Episode: 330 |                     Train Rewards: -9742.4                     Violations: 96.79029703140259                    Mean Train Rewards: -10199.7\n",
            "Episode: 340 |                     Train Rewards: -9801.3                     Violations: 109.40705060958864                    Mean Train Rewards: -10203.0\n",
            "Episode: 350 |                     Train Rewards: -10219.2                     Violations: 13.806250095367432                    Mean Train Rewards: -10222.2\n",
            "Episode: 360 |                     Train Rewards: -9960.4                     Violations: 30.64293384552002                    Mean Train Rewards: -10235.5\n",
            "Episode: 370 |                     Train Rewards: -9652.5                     Violations: 123.70263814926147                    Mean Train Rewards: -10208.4\n",
            "Episode: 380 |                     Train Rewards: -9925.0                     Violations: 55.227283239364624                    Mean Train Rewards: -10195.7\n",
            "Episode: 390 |                     Train Rewards: -10674.1                     Violations: 0                    Mean Train Rewards: -10198.9\n",
            "Episode: 400 |                     Train Rewards: -10559.7                     Violations: 2.538886070251465                    Mean Train Rewards: -10222.4\n",
            "Episode: 410 |                     Train Rewards: -9709.4                     Violations: 96.27889156341554                    Mean Train Rewards: -10191.9\n",
            "Episode: 420 |                     Train Rewards: -10104.2                     Violations: 58.902091979980455                    Mean Train Rewards: -10193.7\n",
            "Episode: 430 |                     Train Rewards: -10367.4                     Violations: 43.13482999801636                    Mean Train Rewards: -10192.7\n",
            "Episode: 440 |                     Train Rewards: -9780.9                     Violations: 59.604387283325195                    Mean Train Rewards: -10194.8\n",
            "Episode: 450 |                     Train Rewards: -9455.1                     Violations: 157.34226822853088                    Mean Train Rewards: -10178.4\n",
            "Episode: 460 |                     Train Rewards: -10210.4                     Violations: 46.01890444755555                    Mean Train Rewards: -10182.1\n",
            "Episode: 470 |                     Train Rewards: -10217.8                     Violations: 7.232551574707017                    Mean Train Rewards: -10186.2\n",
            "Episode: 480 |                     Train Rewards: -10282.6                     Violations: 57.86957144737244                    Mean Train Rewards: -10192.9\n",
            "Episode: 490 |                     Train Rewards: -10505.6                     Violations: 8.106579780578613                    Mean Train Rewards: -10196.1\n",
            "Episode: 500 |                     Train Rewards: -10069.6                     Violations: 53.90399217605591                    Mean Train Rewards: -10188.7\n",
            "Episode: 510 |                     Train Rewards: -9973.0                     Violations: 33.44224810600281                    Mean Train Rewards: -10210.1\n",
            "Episode: 520 |                     Train Rewards: -10604.7                     Violations: 0                    Mean Train Rewards: -10220.7\n",
            "Episode: 530 |                     Train Rewards: -10112.2                     Violations: 26.973729133605957                    Mean Train Rewards: -10214.8\n",
            "Episode: 540 |                     Train Rewards: -9702.6                     Violations: 74.14316296577454                    Mean Train Rewards: -10216.6\n",
            "Episode: 550 |                     Train Rewards: -10190.6                     Violations: 27.613459825515747                    Mean Train Rewards: -10208.5\n",
            "Episode: 560 |                     Train Rewards: -9649.6                     Violations: 88.13814878463745                    Mean Train Rewards: -10200.5\n",
            "Episode: 570 |                     Train Rewards: -9645.7                     Violations: 75.91635584831238                    Mean Train Rewards: -10208.5\n",
            "Episode: 580 |                     Train Rewards: -9511.0                     Violations: 119.47749972343446                    Mean Train Rewards: -10206.3\n",
            "Episode: 590 |                     Train Rewards: -9709.2                     Violations: 65.38883686065674                    Mean Train Rewards: -10156.5\n",
            "Episode: 600 |                     Train Rewards: -10327.8                     Violations: 14.710583686828613                    Mean Train Rewards: -10113.9\n",
            "Episode: 610 |                     Train Rewards: -10447.3                     Violations: 0                    Mean Train Rewards: -10079.6\n",
            "Episode: 620 |                     Train Rewards: -10360.1                     Violations: 51.34377002716063                    Mean Train Rewards: -10083.5\n",
            "Episode: 630 |                     Train Rewards: -9980.2                     Violations: 67.38049626350403                    Mean Train Rewards: -10086.9\n",
            "Episode: 640 |                     Train Rewards: -10257.8                     Violations: 24.635753631591783                    Mean Train Rewards: -10094.7\n",
            "Episode: 650 |                     Train Rewards: -10535.1                     Violations: 14.574649333953857                    Mean Train Rewards: -10124.4\n",
            "Episode: 660 |                     Train Rewards: -10224.8                     Violations: 39.32844400405885                    Mean Train Rewards: -10115.9\n",
            "Episode: 670 |                     Train Rewards: -10191.5                     Violations: 56.87858819961548                    Mean Train Rewards: -10125.9\n",
            "Episode: 680 |                     Train Rewards: -10390.5                     Violations: 7.447322607040405                    Mean Train Rewards: -10131.4\n",
            "Episode: 690 |                     Train Rewards: -10218.1                     Violations: 43.81946325302123                    Mean Train Rewards: -10158.8\n",
            "Episode: 700 |                     Train Rewards: -10099.9                     Violations: 52.48521327972411                    Mean Train Rewards: -10192.9\n",
            "Episode: 710 |                     Train Rewards: -10479.6                     Violations: 54.069457054138184                    Mean Train Rewards: -10215.7\n",
            "Episode: 720 |                     Train Rewards: -10230.6                     Violations: 42.29477405548096                    Mean Train Rewards: -10205.6\n",
            "Episode: 730 |                     Train Rewards: -10200.5                     Violations: 31.621239185333252                    Mean Train Rewards: -10206.5\n",
            "Episode: 740 |                     Train Rewards: -9701.2                     Violations: 91.4271330833435                    Mean Train Rewards: -10190.2\n",
            "Episode: 750 |                     Train Rewards: -10395.8                     Violations: 1.738497018814087                    Mean Train Rewards: -10183.0\n",
            "Episode: 760 |                     Train Rewards: -10576.1                     Violations: 28.78573894500734                    Mean Train Rewards: -10210.0\n",
            "Episode: 770 |                     Train Rewards: -10136.6                     Violations: 53.042612075805664                    Mean Train Rewards: -10194.8\n",
            "Episode: 780 |                     Train Rewards: -10412.6                     Violations: 9.16835904121399                    Mean Train Rewards: -10187.9\n",
            "Episode: 790 |                     Train Rewards: -10163.3                     Violations: 17.437597513198853                    Mean Train Rewards: -10185.5\n",
            "Episode: 800 |                     Train Rewards: -10418.9                     Violations: 12.729390859603882                    Mean Train Rewards: -10190.3\n",
            "Episode: 810 |                     Train Rewards: -10828.9                     Violations: 4.162427186965928                    Mean Train Rewards: -10195.6\n",
            "Episode: 820 |                     Train Rewards: -9832.9                     Violations: 50.9835147857666                    Mean Train Rewards: -10179.4\n",
            "Episode: 830 |                     Train Rewards: -9810.8                     Violations: 112.73541212081909                    Mean Train Rewards: -10158.5\n",
            "Episode: 840 |                     Train Rewards: -10303.7                     Violations: 0                    Mean Train Rewards: -10138.6\n",
            "Episode: 850 |                     Train Rewards: -9974.7                     Violations: 26.077373027801514                    Mean Train Rewards: -10109.0\n",
            "Episode: 860 |                     Train Rewards: -9535.7                     Violations: 131.24239921569824                    Mean Train Rewards: -10049.2\n",
            "Episode: 870 |                     Train Rewards: -10458.4                     Violations: 0                    Mean Train Rewards: -10051.5\n",
            "Episode: 880 |                     Train Rewards: -9746.4                     Violations: 108.26475143432616                    Mean Train Rewards: -10045.7\n",
            "Episode: 890 |                     Train Rewards: -9777.5                     Violations: 48.87334227561951                    Mean Train Rewards: -10028.6\n",
            "Episode: 900 |                     Train Rewards: -10093.9                     Violations: 59.85717296600343                    Mean Train Rewards: -10017.2\n",
            "Episode: 910 |                     Train Rewards: -9830.8                     Violations: 84.73119258880615                    Mean Train Rewards: -9970.1\n",
            "Episode: 920 |                     Train Rewards: -9992.9                     Violations: 27.781413793563843                    Mean Train Rewards: -9928.5\n",
            "Episode: 930 |                     Train Rewards: -10314.7                     Violations: 12.941547632217407                    Mean Train Rewards: -9903.3\n",
            "Episode: 940 |                     Train Rewards: -9739.0                     Violations: 71.20706677436829                    Mean Train Rewards: -9897.2\n",
            "Episode: 950 |                     Train Rewards: -9616.6                     Violations: 94.00152564048769                    Mean Train Rewards: -9873.0\n",
            "Episode: 960 |                     Train Rewards: -9977.1                     Violations: 34.09366846084593                    Mean Train Rewards: -9897.0\n",
            "Episode: 970 |                     Train Rewards: -9744.0                     Violations: 72.6449990272522                    Mean Train Rewards: -9873.9\n",
            "Episode: 980 |                     Train Rewards: -9874.4                     Violations: 27.515090703964226                    Mean Train Rewards: -9847.6\n",
            "Episode: 990 |                     Train Rewards: -9781.1                     Violations: 96.61758303642273                    Mean Train Rewards: -9852.3\n",
            "Episode: 1000 |                     Train Rewards: -9915.2                     Violations: 56.425490379333496                    Mean Train Rewards: -9847.0\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 6 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-56/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-57\n",
            "\n",
            "==================================================\n",
            "Starting run 2/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0003, 'EPSILON': 0.2, 'ENTROPY_COEFFICIENT': 0.05, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -9820.8                     Violations: 35.83910822868347                    Mean Train Rewards: -9668.4\n",
            "Episode:  20 |                     Train Rewards: -10010.9                     Violations: 8.504359722137444                    Mean Train Rewards: -9799.7\n",
            "Episode:  30 |                     Train Rewards: -10242.9                     Violations: 0                    Mean Train Rewards: -9952.2\n",
            "Episode:  40 |                     Train Rewards: -10098.6                     Violations: 4.468863010406494                    Mean Train Rewards: -9987.1\n",
            "Episode:  50 |                     Train Rewards: -9875.8                     Violations: 28.991020917892456                    Mean Train Rewards: -9961.5\n",
            "Episode:  60 |                     Train Rewards: -9675.1                     Violations: 64.97438907623291                    Mean Train Rewards: -9917.6\n",
            "Episode:  70 |                     Train Rewards: -9977.6                     Violations: 6.925027370452888                    Mean Train Rewards: -9927.2\n",
            "Episode:  80 |                     Train Rewards: -10170.6                     Violations: 0                    Mean Train Rewards: -9936.1\n",
            "Episode:  90 |                     Train Rewards: -10378.9                     Violations: 0                    Mean Train Rewards: -9971.3\n",
            "Episode: 100 |                     Train Rewards: -10511.8                     Violations: 0                    Mean Train Rewards: -10028.4\n",
            "Episode: 110 |                     Train Rewards: -10778.3                     Violations: 0                    Mean Train Rewards: -10125.9\n",
            "Episode: 120 |                     Train Rewards: -11003.0                     Violations: 0                    Mean Train Rewards: -10222.5\n",
            "Episode: 130 |                     Train Rewards: -11121.4                     Violations: 0                    Mean Train Rewards: -10298.5\n",
            "Episode: 140 |                     Train Rewards: -10973.7                     Violations: 0                    Mean Train Rewards: -10386.8\n",
            "Episode: 150 |                     Train Rewards: -10815.8                     Violations: 0                    Mean Train Rewards: -10487.6\n",
            "Episode: 160 |                     Train Rewards: -11187.2                     Violations: 0                    Mean Train Rewards: -10625.9\n",
            "Episode: 170 |                     Train Rewards: -11176.9                     Violations: 0                    Mean Train Rewards: -10745.2\n",
            "Episode: 180 |                     Train Rewards: -11163.2                     Violations: 0                    Mean Train Rewards: -10861.1\n",
            "Episode: 190 |                     Train Rewards: -11146.8                     Violations: 0                    Mean Train Rewards: -10951.0\n",
            "Episode: 200 |                     Train Rewards: -11155.6                     Violations: 0                    Mean Train Rewards: -11009.9\n",
            "Episode: 210 |                     Train Rewards: -11138.8                     Violations: 0                    Mean Train Rewards: -11061.4\n",
            "Episode: 220 |                     Train Rewards: -10841.2                     Violations: 0                    Mean Train Rewards: -11076.3\n",
            "Episode: 230 |                     Train Rewards: -11001.8                     Violations: 0                    Mean Train Rewards: -11067.9\n",
            "Episode: 240 |                     Train Rewards: -11152.1                     Violations: 0                    Mean Train Rewards: -11076.7\n",
            "Episode: 250 |                     Train Rewards: -11140.5                     Violations: 0                    Mean Train Rewards: -11104.9\n",
            "Episode: 260 |                     Train Rewards: -11159.1                     Violations: 0                    Mean Train Rewards: -11108.5\n",
            "Episode: 270 |                     Train Rewards: -11137.2                     Violations: 0                    Mean Train Rewards: -11103.4\n",
            "Episode: 280 |                     Train Rewards: -11087.6                     Violations: 0                    Mean Train Rewards: -11090.1\n",
            "Episode: 290 |                     Train Rewards: -11111.7                     Violations: 0                    Mean Train Rewards: -11082.2\n",
            "Episode: 300 |                     Train Rewards: -10778.4                     Violations: 0                    Mean Train Rewards: -11061.5\n",
            "Episode: 310 |                     Train Rewards: -10947.7                     Violations: 0                    Mean Train Rewards: -11032.4\n",
            "Episode: 320 |                     Train Rewards: -11154.5                     Violations: 0                    Mean Train Rewards: -11030.7\n",
            "Episode: 330 |                     Train Rewards: -11106.3                     Violations: 0                    Mean Train Rewards: -11049.8\n",
            "Episode: 340 |                     Train Rewards: -11059.8                     Violations: 0                    Mean Train Rewards: -11054.8\n",
            "Episode: 350 |                     Train Rewards: -11123.5                     Violations: 0                    Mean Train Rewards: -11053.7\n",
            "Episode: 360 |                     Train Rewards: -11107.5                     Violations: 0                    Mean Train Rewards: -11053.5\n",
            "Episode: 370 |                     Train Rewards: -11111.3                     Violations: 0                    Mean Train Rewards: -11051.4\n",
            "Episode: 380 |                     Train Rewards: -11022.4                     Violations: 0                    Mean Train Rewards: -11057.6\n",
            "Episode: 390 |                     Train Rewards: -11162.4                     Violations: 0                    Mean Train Rewards: -11058.2\n",
            "Episode: 400 |                     Train Rewards: -11170.5                     Violations: 0                    Mean Train Rewards: -11076.2\n",
            "Episode: 410 |                     Train Rewards: -11038.4                     Violations: 0                    Mean Train Rewards: -11101.7\n",
            "Episode: 420 |                     Train Rewards: -11125.3                     Violations: 0                    Mean Train Rewards: -11111.4\n",
            "Episode: 430 |                     Train Rewards: -11087.9                     Violations: 0                    Mean Train Rewards: -11107.5\n",
            "Episode: 440 |                     Train Rewards: -10627.6                     Violations: 0                    Mean Train Rewards: -11096.5\n",
            "Episode: 450 |                     Train Rewards: -10774.9                     Violations: 0                    Mean Train Rewards: -11077.0\n",
            "Episode: 460 |                     Train Rewards: -10960.9                     Violations: 0                    Mean Train Rewards: -11068.4\n",
            "Episode: 470 |                     Train Rewards: -10731.8                     Violations: 0                    Mean Train Rewards: -11033.4\n",
            "Episode: 480 |                     Train Rewards: -10737.0                     Violations: 0                    Mean Train Rewards: -11007.2\n",
            "Episode: 490 |                     Train Rewards: -10907.1                     Violations: 0                    Mean Train Rewards: -10996.4\n",
            "Episode: 500 |                     Train Rewards: -10658.5                     Violations: 0                    Mean Train Rewards: -10972.7\n",
            "Episode: 510 |                     Train Rewards: -10262.5                     Violations: 0                    Mean Train Rewards: -10937.0\n",
            "Episode: 520 |                     Train Rewards: -10855.1                     Violations: 0                    Mean Train Rewards: -10877.9\n",
            "Episode: 530 |                     Train Rewards: -10906.1                     Violations: 0                    Mean Train Rewards: -10844.5\n",
            "Episode: 540 |                     Train Rewards: -10642.4                     Violations: 0                    Mean Train Rewards: -10817.1\n",
            "Episode: 550 |                     Train Rewards: -10788.2                     Violations: 0                    Mean Train Rewards: -10799.6\n",
            "Episode: 560 |                     Train Rewards: -10323.6                     Violations: 3.274872303009033                    Mean Train Rewards: -10767.1\n",
            "Episode: 570 |                     Train Rewards: -10401.9                     Violations: 0                    Mean Train Rewards: -10767.1\n",
            "Episode: 580 |                     Train Rewards: -10584.3                     Violations: 0                    Mean Train Rewards: -10756.9\n",
            "Episode: 590 |                     Train Rewards: -10589.0                     Violations: 0                    Mean Train Rewards: -10705.8\n",
            "Episode: 600 |                     Train Rewards: -10675.1                     Violations: 0                    Mean Train Rewards: -10664.5\n",
            "Episode: 610 |                     Train Rewards: -10620.6                     Violations: 0                    Mean Train Rewards: -10614.6\n",
            "Episode: 620 |                     Train Rewards: -10426.0                     Violations: 21.904360055923462                    Mean Train Rewards: -10600.1\n",
            "Episode: 630 |                     Train Rewards: -10049.5                     Violations: 33.2680606842041                    Mean Train Rewards: -10547.0\n",
            "Episode: 640 |                     Train Rewards: -10251.1                     Violations: 13.508667945861816                    Mean Train Rewards: -10500.7\n",
            "Episode: 650 |                     Train Rewards: -10454.1                     Violations: 7.831939458847032                    Mean Train Rewards: -10460.7\n",
            "Episode: 660 |                     Train Rewards: -10249.5                     Violations: 19.539557695388794                    Mean Train Rewards: -10406.9\n",
            "Episode: 670 |                     Train Rewards: -10171.2                     Violations: 45.75721979141235                    Mean Train Rewards: -10353.5\n",
            "Episode: 680 |                     Train Rewards: -10360.5                     Violations: 2.1704459190368652                    Mean Train Rewards: -10299.1\n",
            "Episode: 690 |                     Train Rewards: -10217.3                     Violations: 31.22129201889038                    Mean Train Rewards: -10263.8\n",
            "Episode: 700 |                     Train Rewards: -10103.0                     Violations: 38.98259162902832                    Mean Train Rewards: -10235.4\n",
            "Episode: 710 |                     Train Rewards: -10544.3                     Violations: 42.293164730072036                    Mean Train Rewards: -10236.5\n",
            "Episode: 720 |                     Train Rewards: -10240.3                     Violations: 26.299033164978027                    Mean Train Rewards: -10220.2\n",
            "Episode: 730 |                     Train Rewards: -10187.0                     Violations: 17.585506439208984                    Mean Train Rewards: -10217.3\n",
            "Episode: 740 |                     Train Rewards: -9796.8                     Violations: 59.21020030975342                    Mean Train Rewards: -10203.0\n",
            "Episode: 750 |                     Train Rewards: -10384.3                     Violations: 0                    Mean Train Rewards: -10195.9\n",
            "Episode: 760 |                     Train Rewards: -10498.0                     Violations: 16.38527750968933                    Mean Train Rewards: -10211.9\n",
            "Episode: 770 |                     Train Rewards: -10482.3                     Violations: 0                    Mean Train Rewards: -10205.2\n",
            "Episode: 780 |                     Train Rewards: -10191.6                     Violations: 30.311119556427002                    Mean Train Rewards: -10206.2\n",
            "Episode: 790 |                     Train Rewards: -9772.8                     Violations: 107.57632970809938                    Mean Train Rewards: -10198.2\n",
            "Episode: 800 |                     Train Rewards: -10373.4                     Violations: 6.472691297531128                    Mean Train Rewards: -10199.6\n",
            "Episode: 810 |                     Train Rewards: -10411.9                     Violations: 17.643063068389893                    Mean Train Rewards: -10188.6\n",
            "Episode: 820 |                     Train Rewards: -9969.1                     Violations: 31.945035457611084                    Mean Train Rewards: -10178.1\n",
            "Episode: 830 |                     Train Rewards: -9972.8                     Violations: 69.52891707420349                    Mean Train Rewards: -10170.4\n",
            "Episode: 840 |                     Train Rewards: -10502.3                     Violations: 0                    Mean Train Rewards: -10177.3\n",
            "Episode: 850 |                     Train Rewards: -10526.2                     Violations: 0                    Mean Train Rewards: -10183.6\n",
            "Episode: 860 |                     Train Rewards: -9895.0                     Violations: 60.298564434051514                    Mean Train Rewards: -10169.8\n",
            "Episode: 870 |                     Train Rewards: -10414.3                     Violations: 0                    Mean Train Rewards: -10174.5\n",
            "Episode: 880 |                     Train Rewards: -9853.3                     Violations: 76.76167011260986                    Mean Train Rewards: -10167.8\n",
            "Episode: 890 |                     Train Rewards: -10001.2                     Violations: 19.253612756729126                    Mean Train Rewards: -10171.4\n",
            "Episode: 900 |                     Train Rewards: -10272.1                     Violations: 30.037693977355957                    Mean Train Rewards: -10179.3\n",
            "Episode: 910 |                     Train Rewards: -10214.7                     Violations: 39.348769187927246                    Mean Train Rewards: -10173.2\n",
            "Episode: 920 |                     Train Rewards: -10405.4                     Violations: 0                    Mean Train Rewards: -10167.8\n",
            "Episode: 930 |                     Train Rewards: -10628.5                     Violations: 0                    Mean Train Rewards: -10169.8\n",
            "Episode: 940 |                     Train Rewards: -10028.7                     Violations: 47.10713386535646                    Mean Train Rewards: -10165.8\n",
            "Episode: 950 |                     Train Rewards: -9749.2                     Violations: 82.89302349090576                    Mean Train Rewards: -10134.7\n",
            "Episode: 960 |                     Train Rewards: -10406.5                     Violations: 3.724285364151001                    Mean Train Rewards: -10140.8\n",
            "Episode: 970 |                     Train Rewards: -9975.1                     Violations: 40.78419208526613                    Mean Train Rewards: -10139.8\n",
            "Episode: 980 |                     Train Rewards: -10195.0                     Violations: 0.5123460292816091                    Mean Train Rewards: -10138.4\n",
            "Episode: 990 |                     Train Rewards: -9915.1                     Violations: 66.13362193107605                    Mean Train Rewards: -10143.9\n",
            "Episode: 1000 |                     Train Rewards: -10053.3                     Violations: 27.982213497161858                    Mean Train Rewards: -10134.6\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 16 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 16 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-57/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-58\n",
            "\n",
            "==================================================\n",
            "Starting run 3/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 128, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -9984.0                     Violations: 7.377136945724487                    Mean Train Rewards: -9898.2\n",
            "Episode:  20 |                     Train Rewards: -10092.3                     Violations: 1.5970134735107493                    Mean Train Rewards: -9985.2\n",
            "Episode:  30 |                     Train Rewards: -10208.3                     Violations: 0                    Mean Train Rewards: -10070.1\n",
            "Episode:  40 |                     Train Rewards: -10091.3                     Violations: 3.626798391342156                    Mean Train Rewards: -10076.2\n",
            "Episode:  50 |                     Train Rewards: -9962.9                     Violations: 15.114699602127075                    Mean Train Rewards: -10057.5\n",
            "Episode:  60 |                     Train Rewards: -9843.0                     Violations: 31.40665054321289                    Mean Train Rewards: -10026.0\n",
            "Episode:  70 |                     Train Rewards: -10004.4                     Violations: 4.747428894042969                    Mean Train Rewards: -10028.4\n",
            "Episode:  80 |                     Train Rewards: -10181.2                     Violations: 0                    Mean Train Rewards: -10032.8\n",
            "Episode:  90 |                     Train Rewards: -10260.0                     Violations: 0                    Mean Train Rewards: -10050.8\n",
            "Episode: 100 |                     Train Rewards: -10308.9                     Violations: 0                    Mean Train Rewards: -10081.7\n",
            "Episode: 110 |                     Train Rewards: -10447.0                     Violations: 0                    Mean Train Rewards: -10133.6\n",
            "Episode: 120 |                     Train Rewards: -10582.8                     Violations: 0                    Mean Train Rewards: -10177.7\n",
            "Episode: 130 |                     Train Rewards: -10958.8                     Violations: 0                    Mean Train Rewards: -10228.6\n",
            "Episode: 140 |                     Train Rewards: -10820.9                     Violations: 0                    Mean Train Rewards: -10299.1\n",
            "Episode: 150 |                     Train Rewards: -10767.7                     Violations: 0                    Mean Train Rewards: -10376.6\n",
            "Episode: 160 |                     Train Rewards: -11187.4                     Violations: 0                    Mean Train Rewards: -10493.5\n",
            "Episode: 170 |                     Train Rewards: -11178.4                     Violations: 0                    Mean Train Rewards: -10607.0\n",
            "Episode: 180 |                     Train Rewards: -11170.1                     Violations: 0                    Mean Train Rewards: -10717.0\n",
            "Episode: 190 |                     Train Rewards: -11165.3                     Violations: 0                    Mean Train Rewards: -10813.9\n",
            "Episode: 200 |                     Train Rewards: -11169.5                     Violations: 0                    Mean Train Rewards: -10893.5\n",
            "Episode: 210 |                     Train Rewards: -11148.4                     Violations: 0                    Mean Train Rewards: -10968.7\n",
            "Episode: 220 |                     Train Rewards: -11072.7                     Violations: 0                    Mean Train Rewards: -11031.0\n",
            "Episode: 230 |                     Train Rewards: -11152.2                     Violations: 0                    Mean Train Rewards: -11068.4\n",
            "Episode: 240 |                     Train Rewards: -11166.2                     Violations: 0                    Mean Train Rewards: -11103.9\n",
            "Episode: 250 |                     Train Rewards: -11162.9                     Violations: 0                    Mean Train Rewards: -11144.6\n",
            "Episode: 260 |                     Train Rewards: -11175.8                     Violations: 0                    Mean Train Rewards: -11156.1\n",
            "Episode: 270 |                     Train Rewards: -11169.6                     Violations: 0                    Mean Train Rewards: -11154.0\n",
            "Episode: 280 |                     Train Rewards: -11159.3                     Violations: 0                    Mean Train Rewards: -11151.4\n",
            "Episode: 290 |                     Train Rewards: -11179.6                     Violations: 0                    Mean Train Rewards: -11151.4\n",
            "Episode: 300 |                     Train Rewards: -11079.3                     Violations: 0                    Mean Train Rewards: -11148.8\n",
            "Episode: 310 |                     Train Rewards: -11146.7                     Violations: 0                    Mean Train Rewards: -11145.9\n",
            "Episode: 320 |                     Train Rewards: -11183.8                     Violations: 0                    Mean Train Rewards: -11147.5\n",
            "Episode: 330 |                     Train Rewards: -11163.6                     Violations: 0                    Mean Train Rewards: -11152.4\n",
            "Episode: 340 |                     Train Rewards: -11154.5                     Violations: 0                    Mean Train Rewards: -11153.7\n",
            "Episode: 350 |                     Train Rewards: -11172.6                     Violations: 0                    Mean Train Rewards: -11155.2\n",
            "Episode: 360 |                     Train Rewards: -11168.1                     Violations: 0                    Mean Train Rewards: -11157.0\n",
            "Episode: 370 |                     Train Rewards: -11173.0                     Violations: 0                    Mean Train Rewards: -11158.3\n",
            "Episode: 380 |                     Train Rewards: -11163.4                     Violations: 0                    Mean Train Rewards: -11161.5\n",
            "Episode: 390 |                     Train Rewards: -11190.6                     Violations: 0                    Mean Train Rewards: -11162.7\n",
            "Episode: 400 |                     Train Rewards: -11190.6                     Violations: 0                    Mean Train Rewards: -11167.1\n",
            "Episode: 410 |                     Train Rewards: -11160.7                     Violations: 0                    Mean Train Rewards: -11171.0\n",
            "Episode: 420 |                     Train Rewards: -11186.6                     Violations: 0                    Mean Train Rewards: -11174.0\n",
            "Episode: 430 |                     Train Rewards: -11180.2                     Violations: 0                    Mean Train Rewards: -11174.5\n",
            "Episode: 440 |                     Train Rewards: -11164.9                     Violations: 0                    Mean Train Rewards: -11175.6\n",
            "Episode: 450 |                     Train Rewards: -11161.7                     Violations: 0                    Mean Train Rewards: -11175.5\n",
            "Episode: 460 |                     Train Rewards: -11180.5                     Violations: 0                    Mean Train Rewards: -11176.5\n",
            "Episode: 470 |                     Train Rewards: -11175.0                     Violations: 0                    Mean Train Rewards: -11176.9\n",
            "Episode: 480 |                     Train Rewards: -11166.1                     Violations: 0                    Mean Train Rewards: -11177.9\n",
            "Episode: 490 |                     Train Rewards: -11178.8                     Violations: 0                    Mean Train Rewards: -11178.5\n",
            "Episode: 500 |                     Train Rewards: -11165.7                     Violations: 0                    Mean Train Rewards: -11179.4\n",
            "Episode: 510 |                     Train Rewards: -11182.7                     Violations: 0                    Mean Train Rewards: -11180.2\n",
            "Episode: 520 |                     Train Rewards: -11187.6                     Violations: 0                    Mean Train Rewards: -11180.2\n",
            "Episode: 530 |                     Train Rewards: -11190.4                     Violations: 0                    Mean Train Rewards: -11181.2\n",
            "Episode: 540 |                     Train Rewards: -11186.4                     Violations: 0                    Mean Train Rewards: -11182.2\n",
            "Episode: 550 |                     Train Rewards: -11189.8                     Violations: 0                    Mean Train Rewards: -11183.4\n",
            "Episode: 560 |                     Train Rewards: -11177.7                     Violations: 0                    Mean Train Rewards: -11184.1\n",
            "Episode: 570 |                     Train Rewards: -11179.1                     Violations: 0                    Mean Train Rewards: -11185.5\n",
            "Episode: 580 |                     Train Rewards: -11182.7                     Violations: 0                    Mean Train Rewards: -11186.5\n",
            "Episode: 590 |                     Train Rewards: -11188.4                     Violations: 0                    Mean Train Rewards: -11186.8\n",
            "Episode: 600 |                     Train Rewards: -11181.5                     Violations: 0                    Mean Train Rewards: -11187.3\n",
            "Episode: 610 |                     Train Rewards: -11192.9                     Violations: 0                    Mean Train Rewards: -11187.2\n",
            "Episode: 620 |                     Train Rewards: -11197.0                     Violations: 0                    Mean Train Rewards: -11187.7\n",
            "Episode: 630 |                     Train Rewards: -11192.3                     Violations: 0                    Mean Train Rewards: -11187.8\n",
            "Episode: 640 |                     Train Rewards: -11192.1                     Violations: 0                    Mean Train Rewards: -11188.0\n",
            "Episode: 650 |                     Train Rewards: -11193.4                     Violations: 0                    Mean Train Rewards: -11188.2\n",
            "Episode: 660 |                     Train Rewards: -11193.5                     Violations: 0                    Mean Train Rewards: -11188.4\n",
            "Episode: 670 |                     Train Rewards: -11191.8                     Violations: 0                    Mean Train Rewards: -11188.2\n",
            "Episode: 680 |                     Train Rewards: -11193.8                     Violations: 0                    Mean Train Rewards: -11188.0\n",
            "Episode: 690 |                     Train Rewards: -11180.1                     Violations: 0                    Mean Train Rewards: -11188.1\n",
            "Episode: 700 |                     Train Rewards: -11179.4                     Violations: 0                    Mean Train Rewards: -11187.6\n",
            "Episode: 710 |                     Train Rewards: -11186.8                     Violations: 0                    Mean Train Rewards: -11187.3\n",
            "Episode: 720 |                     Train Rewards: -11188.7                     Violations: 0                    Mean Train Rewards: -11187.0\n",
            "Episode: 730 |                     Train Rewards: -11188.1                     Violations: 0                    Mean Train Rewards: -11186.8\n",
            "Episode: 740 |                     Train Rewards: -11172.5                     Violations: 0                    Mean Train Rewards: -11186.3\n",
            "Episode: 750 |                     Train Rewards: -11192.9                     Violations: 0                    Mean Train Rewards: -11186.4\n",
            "Episode: 760 |                     Train Rewards: -11194.2                     Violations: 0                    Mean Train Rewards: -11186.0\n",
            "Episode: 770 |                     Train Rewards: -11183.5                     Violations: 0                    Mean Train Rewards: -11185.6\n",
            "Episode: 780 |                     Train Rewards: -11190.6                     Violations: 0                    Mean Train Rewards: -11185.7\n",
            "Episode: 790 |                     Train Rewards: -11190.7                     Violations: 0                    Mean Train Rewards: -11185.6\n",
            "Episode: 800 |                     Train Rewards: -11192.3                     Violations: 0                    Mean Train Rewards: -11186.1\n",
            "Episode: 810 |                     Train Rewards: -11193.9                     Violations: 0                    Mean Train Rewards: -11185.5\n",
            "Episode: 820 |                     Train Rewards: -11127.0                     Violations: 0                    Mean Train Rewards: -11182.9\n",
            "Episode: 830 |                     Train Rewards: -11120.9                     Violations: 0                    Mean Train Rewards: -11178.9\n",
            "Episode: 840 |                     Train Rewards: -11169.2                     Violations: 0                    Mean Train Rewards: -11173.2\n",
            "Episode: 850 |                     Train Rewards: -11191.0                     Violations: 0                    Mean Train Rewards: -11171.8\n",
            "Episode: 860 |                     Train Rewards: -11129.6                     Violations: 0                    Mean Train Rewards: -11169.0\n",
            "Episode: 870 |                     Train Rewards: -11180.5                     Violations: 0                    Mean Train Rewards: -11167.3\n",
            "Episode: 880 |                     Train Rewards: -11161.6                     Violations: 0                    Mean Train Rewards: -11164.7\n",
            "Episode: 890 |                     Train Rewards: -11123.0                     Violations: 0                    Mean Train Rewards: -11160.3\n",
            "Episode: 900 |                     Train Rewards: -11157.2                     Violations: 0                    Mean Train Rewards: -11156.8\n",
            "Episode: 910 |                     Train Rewards: -11163.9                     Violations: 0                    Mean Train Rewards: -11154.3\n",
            "Episode: 920 |                     Train Rewards: -11169.9                     Violations: 0                    Mean Train Rewards: -11154.0\n",
            "Episode: 930 |                     Train Rewards: -11187.9                     Violations: 0                    Mean Train Rewards: -11155.6\n",
            "Episode: 940 |                     Train Rewards: -11136.4                     Violations: 0                    Mean Train Rewards: -11159.8\n",
            "Episode: 950 |                     Train Rewards: -11148.3                     Violations: 0                    Mean Train Rewards: -11159.1\n",
            "Episode: 960 |                     Train Rewards: -11190.5                     Violations: 0                    Mean Train Rewards: -11161.0\n",
            "Episode: 970 |                     Train Rewards: -11157.1                     Violations: 0                    Mean Train Rewards: -11161.1\n",
            "Episode: 980 |                     Train Rewards: -11174.7                     Violations: 0                    Mean Train Rewards: -11161.5\n",
            "Episode: 990 |                     Train Rewards: -11178.5                     Violations: 0                    Mean Train Rewards: -11165.4\n",
            "Episode: 1000 |                     Train Rewards: -11147.0                     Violations: 0                    Mean Train Rewards: -11166.9\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 12 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 12 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-58/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-59\n",
            "\n",
            "==================================================\n",
            "Starting run 4/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.003, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 32, 'PPO_STEPS': 8, 'BATCH_SIZE': 128, 'DISCOUNT_FACTOR': 0.95, 'constraint_penalty_factor': 0, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -9745.5                     Violations: 50.904492139816284                    Mean Train Rewards: -9772.1\n",
            "Episode:  20 |                     Train Rewards: -9837.6                     Violations: 32.481292486190796                    Mean Train Rewards: -9771.1\n",
            "Episode:  30 |                     Train Rewards: -9940.2                     Violations: 13.496739864349358                    Mean Train Rewards: -9856.4\n",
            "Episode:  40 |                     Train Rewards: -9924.8                     Violations: 15.900136232376092                    Mean Train Rewards: -9877.3\n",
            "Episode:  50 |                     Train Rewards: -9635.0                     Violations: 77.2461235523224                    Mean Train Rewards: -9823.6\n",
            "Episode:  60 |                     Train Rewards: -9481.3                     Violations: 127.46825456619263                    Mean Train Rewards: -9775.9\n",
            "Episode:  70 |                     Train Rewards: -9862.7                     Violations: 27.465513944625854                    Mean Train Rewards: -9779.2\n",
            "Episode:  80 |                     Train Rewards: -10031.5                     Violations: 0.8514666557312083                    Mean Train Rewards: -9792.7\n",
            "Episode:  90 |                     Train Rewards: -10182.5                     Violations: 0                    Mean Train Rewards: -9830.8\n",
            "Episode: 100 |                     Train Rewards: -10437.1                     Violations: 0                    Mean Train Rewards: -9890.8\n",
            "Episode: 110 |                     Train Rewards: -10814.3                     Violations: 0                    Mean Train Rewards: -9979.0\n",
            "Episode: 120 |                     Train Rewards: -11098.8                     Violations: 0                    Mean Train Rewards: -10094.9\n",
            "Episode: 130 |                     Train Rewards: -11179.6                     Violations: 0                    Mean Train Rewards: -10205.7\n",
            "Episode: 140 |                     Train Rewards: -11116.2                     Violations: 0                    Mean Train Rewards: -10323.4\n",
            "Episode: 150 |                     Train Rewards: -10483.3                     Violations: 0                    Mean Train Rewards: -10424.7\n",
            "Episode: 160 |                     Train Rewards: -11191.5                     Violations: 0                    Mean Train Rewards: -10572.8\n",
            "Episode: 170 |                     Train Rewards: -11178.1                     Violations: 0                    Mean Train Rewards: -10711.4\n",
            "Episode: 180 |                     Train Rewards: -10970.4                     Violations: 0                    Mean Train Rewards: -10832.5\n",
            "Episode: 190 |                     Train Rewards: -10440.2                     Violations: 15.61522126197815                    Mean Train Rewards: -10889.1\n",
            "Episode: 200 |                     Train Rewards: -10817.4                     Violations: 0                    Mean Train Rewards: -10904.3\n",
            "Episode: 210 |                     Train Rewards: -10590.8                     Violations: 0                    Mean Train Rewards: -10920.7\n",
            "Episode: 220 |                     Train Rewards: -9896.5                     Violations: 70.98233103752136                    Mean Train Rewards: -10863.5\n",
            "Episode: 230 |                     Train Rewards: -10033.6                     Violations: 28.344463109970093                    Mean Train Rewards: -10762.0\n",
            "Episode: 240 |                     Train Rewards: -10546.1                     Violations: 0                    Mean Train Rewards: -10674.9\n",
            "Episode: 250 |                     Train Rewards: -10539.2                     Violations: 0                    Mean Train Rewards: -10660.5\n",
            "Episode: 260 |                     Train Rewards: -10629.4                     Violations: 0                    Mean Train Rewards: -10606.3\n",
            "Episode: 270 |                     Train Rewards: -10740.7                     Violations: 0                    Mean Train Rewards: -10544.2\n",
            "Episode: 280 |                     Train Rewards: -10425.4                     Violations: 7.05169677734375                    Mean Train Rewards: -10468.4\n",
            "Episode: 290 |                     Train Rewards: -10277.0                     Violations: 0                    Mean Train Rewards: -10425.9\n",
            "Episode: 300 |                     Train Rewards: -9865.7                     Violations: 33.99322152137756                    Mean Train Rewards: -10378.3\n",
            "Episode: 310 |                     Train Rewards: -10386.3                     Violations: 15.52344799041748                    Mean Train Rewards: -10334.6\n",
            "Episode: 320 |                     Train Rewards: -10764.7                     Violations: 0                    Mean Train Rewards: -10339.0\n",
            "Episode: 330 |                     Train Rewards: -10311.0                     Violations: 0                    Mean Train Rewards: -10393.2\n",
            "Episode: 340 |                     Train Rewards: -10327.1                     Violations: 11.05837702751159                    Mean Train Rewards: -10430.9\n",
            "Episode: 350 |                     Train Rewards: -10894.1                     Violations: 0                    Mean Train Rewards: -10462.2\n",
            "Episode: 360 |                     Train Rewards: -10519.6                     Violations: 0                    Mean Train Rewards: -10474.5\n",
            "Episode: 370 |                     Train Rewards: -10087.2                     Violations: 29.068683385849                    Mean Train Rewards: -10453.1\n",
            "Episode: 380 |                     Train Rewards: -10073.2                     Violations: 20.84929227828978                    Mean Train Rewards: -10453.9\n",
            "Episode: 390 |                     Train Rewards: -10735.2                     Violations: 0                    Mean Train Rewards: -10462.4\n",
            "Episode: 400 |                     Train Rewards: -10840.5                     Violations: 0                    Mean Train Rewards: -10503.1\n",
            "Episode: 410 |                     Train Rewards: -9991.0                     Violations: 36.48807406425475                    Mean Train Rewards: -10511.2\n",
            "Episode: 420 |                     Train Rewards: -10613.6                     Violations: 6.500014066696167                    Mean Train Rewards: -10509.2\n",
            "Episode: 430 |                     Train Rewards: -10477.4                     Violations: 18.673958778381348                    Mean Train Rewards: -10483.1\n",
            "Episode: 440 |                     Train Rewards: -9941.7                     Violations: 33.54472875595093                    Mean Train Rewards: -10450.3\n",
            "Episode: 450 |                     Train Rewards: -9625.6                     Violations: 101.04039192199707                    Mean Train Rewards: -10400.9\n",
            "Episode: 460 |                     Train Rewards: -10252.9                     Violations: 26.79326295852661                    Mean Train Rewards: -10369.9\n",
            "Episode: 470 |                     Train Rewards: -10053.4                     Violations: 57.901940345764174                    Mean Train Rewards: -10350.8\n",
            "Episode: 480 |                     Train Rewards: -10301.4                     Violations: 34.038764238357544                    Mean Train Rewards: -10337.1\n",
            "Episode: 490 |                     Train Rewards: -10508.7                     Violations: 2.1796071529388357                    Mean Train Rewards: -10329.3\n",
            "Episode: 500 |                     Train Rewards: -10114.2                     Violations: 31.43337845802307                    Mean Train Rewards: -10304.3\n",
            "Episode: 510 |                     Train Rewards: -10069.1                     Violations: 10.220683813095093                    Mean Train Rewards: -10289.7\n",
            "Episode: 520 |                     Train Rewards: -10516.8                     Violations: 0                    Mean Train Rewards: -10280.1\n",
            "Episode: 530 |                     Train Rewards: -10217.6                     Violations: 5.360947847366333                    Mean Train Rewards: -10263.2\n",
            "Episode: 540 |                     Train Rewards: -9911.7                     Violations: 27.672005891799927                    Mean Train Rewards: -10250.5\n",
            "Episode: 550 |                     Train Rewards: -10274.7                     Violations: 8.844618797302246                    Mean Train Rewards: -10239.1\n",
            "Episode: 560 |                     Train Rewards: -9832.3                     Violations: 46.492793560028076                    Mean Train Rewards: -10233.0\n",
            "Episode: 570 |                     Train Rewards: -9874.5                     Violations: 31.918312311172485                    Mean Train Rewards: -10243.7\n",
            "Episode: 580 |                     Train Rewards: -10318.5                     Violations: 10.147287845611572                    Mean Train Rewards: -10254.5\n",
            "Episode: 590 |                     Train Rewards: -10044.6                     Violations: 24.80749011039733                    Mean Train Rewards: -10237.5\n",
            "Episode: 600 |                     Train Rewards: -10519.2                     Violations: 3.9616668224334717                    Mean Train Rewards: -10235.4\n",
            "Episode: 610 |                     Train Rewards: -10394.9                     Violations: 0                    Mean Train Rewards: -10212.7\n",
            "Episode: 620 |                     Train Rewards: -10426.1                     Violations: 21.376954317092896                    Mean Train Rewards: -10220.6\n",
            "Episode: 630 |                     Train Rewards: -10079.5                     Violations: 27.068842649459825                    Mean Train Rewards: -10221.2\n",
            "Episode: 640 |                     Train Rewards: -10281.8                     Violations: 11.969711780548096                    Mean Train Rewards: -10233.9\n",
            "Episode: 650 |                     Train Rewards: -10495.0                     Violations: 5.991133451461792                    Mean Train Rewards: -10253.5\n",
            "Episode: 660 |                     Train Rewards: -10273.4                     Violations: 17.058532238006592                    Mean Train Rewards: -10250.6\n",
            "Episode: 670 |                     Train Rewards: -10211.1                     Violations: 43.037757873535156                    Mean Train Rewards: -10248.9\n",
            "Episode: 680 |                     Train Rewards: -10405.0                     Violations: 0.007250308990478516                    Mean Train Rewards: -10239.0\n",
            "Episode: 690 |                     Train Rewards: -10233.8                     Violations: 30.615577697753892                    Mean Train Rewards: -10241.6\n",
            "Episode: 700 |                     Train Rewards: -10122.8                     Violations: 38.43900918960571                    Mean Train Rewards: -10235.8\n",
            "Episode: 710 |                     Train Rewards: -10555.1                     Violations: 42.762789726257324                    Mean Train Rewards: -10256.1\n",
            "Episode: 720 |                     Train Rewards: -10264.5                     Violations: 25.366780757904067                    Mean Train Rewards: -10244.1\n",
            "Episode: 730 |                     Train Rewards: -10213.7                     Violations: 17.102649211883545                    Mean Train Rewards: -10242.3\n",
            "Episode: 740 |                     Train Rewards: -9792.4                     Violations: 61.19292497634888                    Mean Train Rewards: -10226.0\n",
            "Episode: 750 |                     Train Rewards: -10397.6                     Violations: 0                    Mean Train Rewards: -10219.2\n",
            "Episode: 760 |                     Train Rewards: -10500.6                     Violations: 17.083998918533325                    Mean Train Rewards: -10232.7\n",
            "Episode: 770 |                     Train Rewards: -10472.0                     Violations: 0                    Mean Train Rewards: -10222.2\n",
            "Episode: 780 |                     Train Rewards: -10166.1                     Violations: 34.917229413986206                    Mean Train Rewards: -10216.8\n",
            "Episode: 790 |                     Train Rewards: -9739.6                     Violations: 111.15629196166992                    Mean Train Rewards: -10202.9\n",
            "Episode: 800 |                     Train Rewards: -10345.9                     Violations: 8.560713529586792                    Mean Train Rewards: -10199.8\n",
            "Episode: 810 |                     Train Rewards: -10390.5                     Violations: 20.917879343032844                    Mean Train Rewards: -10184.5\n",
            "Episode: 820 |                     Train Rewards: -9898.7                     Violations: 37.71288394927978                    Mean Train Rewards: -10166.8\n",
            "Episode: 830 |                     Train Rewards: -9911.8                     Violations: 85.36171078681944                    Mean Train Rewards: -10148.4\n",
            "Episode: 840 |                     Train Rewards: -10421.7                     Violations: 0                    Mean Train Rewards: -10144.8\n",
            "Episode: 850 |                     Train Rewards: -10416.7                     Violations: 0                    Mean Train Rewards: -10141.5\n",
            "Episode: 860 |                     Train Rewards: -9812.3                     Violations: 77.47088432312012                    Mean Train Rewards: -10117.8\n",
            "Episode: 870 |                     Train Rewards: -10334.5                     Violations: 0                    Mean Train Rewards: -10115.0\n",
            "Episode: 880 |                     Train Rewards: -9730.5                     Violations: 110.10816812515257                    Mean Train Rewards: -10101.6\n",
            "Episode: 890 |                     Train Rewards: -9867.1                     Violations: 37.21102595329285                    Mean Train Rewards: -10096.9\n",
            "Episode: 900 |                     Train Rewards: -10186.0                     Violations: 41.56375646591185                    Mean Train Rewards: -10096.9\n",
            "Episode: 910 |                     Train Rewards: -10096.5                     Violations: 55.64725399017334                    Mean Train Rewards: -10080.4\n",
            "Episode: 920 |                     Train Rewards: -10284.7                     Violations: 0.987401008605957                    Mean Train Rewards: -10067.5\n",
            "Episode: 930 |                     Train Rewards: -10519.8                     Violations: 0                    Mean Train Rewards: -10063.0\n",
            "Episode: 940 |                     Train Rewards: -9909.3                     Violations: 57.33518600463867                    Mean Train Rewards: -10057.1\n",
            "Episode: 950 |                     Train Rewards: -9731.6                     Violations: 69.68450903892517                    Mean Train Rewards: -10024.6\n",
            "Episode: 960 |                     Train Rewards: -10252.2                     Violations: 13.632049560546875                    Mean Train Rewards: -10028.4\n",
            "Episode: 970 |                     Train Rewards: -9863.6                     Violations: 55.74182510375976                    Mean Train Rewards: -10024.3\n",
            "Episode: 980 |                     Train Rewards: -10050.0                     Violations: 8.838181495666504                    Mean Train Rewards: -10020.6\n",
            "Episode: 990 |                     Train Rewards: -9822.7                     Violations: 87.78180837631226                    Mean Train Rewards: -10025.9\n",
            "Episode: 1000 |                     Train Rewards: -9971.5                     Violations: 45.43555021286011                    Mean Train Rewards: -10017.8\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-59/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-60\n",
            "\n",
            "==================================================\n",
            "Starting run 5/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.001, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -16345.4                     Violations: 66.75970435142517                    Mean Train Rewards: -17954.2\n",
            "Episode:  20 |                     Train Rewards: -10196.3                     Violations: 0                    Mean Train Rewards: -15604.5\n",
            "Episode:  30 |                     Train Rewards: -10700.3                     Violations: 0                    Mean Train Rewards: -13923.8\n",
            "Episode:  40 |                     Train Rewards: -10527.5                     Violations: 0                    Mean Train Rewards: -13069.4\n",
            "Episode:  50 |                     Train Rewards: -10274.2                     Violations: 0                    Mean Train Rewards: -12584.8\n",
            "Episode:  60 |                     Train Rewards: -10527.0                     Violations: 5.331294536590576                    Mean Train Rewards: -12250.7\n",
            "Episode:  70 |                     Train Rewards: -10401.2                     Violations: 0                    Mean Train Rewards: -11983.6\n",
            "Episode:  80 |                     Train Rewards: -10598.6                     Violations: 0                    Mean Train Rewards: -11791.7\n",
            "Episode:  90 |                     Train Rewards: -10806.0                     Violations: 0                    Mean Train Rewards: -11667.9\n",
            "Episode: 100 |                     Train Rewards: -10782.1                     Violations: 0                    Mean Train Rewards: -11581.7\n",
            "Episode: 110 |                     Train Rewards: -11116.5                     Violations: 0                    Mean Train Rewards: -10878.0\n",
            "Episode: 120 |                     Train Rewards: -11161.6                     Violations: 0                    Mean Train Rewards: -10666.8\n",
            "Episode: 130 |                     Train Rewards: -11184.5                     Violations: 0                    Mean Train Rewards: -10726.7\n",
            "Episode: 140 |                     Train Rewards: -11153.7                     Violations: 0                    Mean Train Rewards: -10790.8\n",
            "Episode: 150 |                     Train Rewards: -11072.0                     Violations: 6.508764028549194                    Mean Train Rewards: -10836.9\n",
            "Episode: 160 |                     Train Rewards: -11184.3                     Violations: 0                    Mean Train Rewards: -10890.2\n",
            "Episode: 170 |                     Train Rewards: -11154.4                     Violations: 0                    Mean Train Rewards: -10969.0\n",
            "Episode: 180 |                     Train Rewards: -11961.7                     Violations: 13.276150226593018                    Mean Train Rewards: -11037.0\n",
            "Episode: 190 |                     Train Rewards: -11317.6                     Violations: 8.219858407974243                    Mean Train Rewards: -11044.4\n",
            "Episode: 200 |                     Train Rewards: -10792.6                     Violations: 0                    Mean Train Rewards: -11121.3\n",
            "Episode: 210 |                     Train Rewards: -11631.4                     Violations: 14.259706735610962                    Mean Train Rewards: -11131.1\n",
            "Episode: 220 |                     Train Rewards: -15361.0                     Violations: 56.040101051330566                    Mean Train Rewards: -11310.0\n",
            "Episode: 230 |                     Train Rewards: -10796.5                     Violations: 6.8524980545043945                    Mean Train Rewards: -11616.6\n",
            "Episode: 240 |                     Train Rewards: -10448.0                     Violations: 0                    Mean Train Rewards: -11560.0\n",
            "Episode: 250 |                     Train Rewards: -10701.4                     Violations: 0                    Mean Train Rewards: -11512.1\n",
            "Episode: 260 |                     Train Rewards: -10907.1                     Violations: 0                    Mean Train Rewards: -11468.9\n",
            "Episode: 270 |                     Train Rewards: -10762.6                     Violations: 0                    Mean Train Rewards: -11423.8\n",
            "Episode: 280 |                     Train Rewards: -10434.6                     Violations: 0                    Mean Train Rewards: -11407.1\n",
            "Episode: 290 |                     Train Rewards: -10648.6                     Violations: 0                    Mean Train Rewards: -11417.7\n",
            "Episode: 300 |                     Train Rewards: -10649.2                     Violations: 5.790951251983643                    Mean Train Rewards: -11369.0\n",
            "Episode: 310 |                     Train Rewards: -10915.5                     Violations: 0                    Mean Train Rewards: -11426.7\n",
            "Episode: 320 |                     Train Rewards: -11181.4                     Violations: 0                    Mean Train Rewards: -11240.5\n",
            "Episode: 330 |                     Train Rewards: -11168.8                     Violations: 0                    Mean Train Rewards: -10934.7\n",
            "Episode: 340 |                     Train Rewards: -11113.6                     Violations: 0                    Mean Train Rewards: -10992.3\n",
            "Episode: 350 |                     Train Rewards: -11139.6                     Violations: 0                    Mean Train Rewards: -11045.3\n",
            "Episode: 360 |                     Train Rewards: -11087.7                     Violations: 0                    Mean Train Rewards: -11088.0\n",
            "Episode: 370 |                     Train Rewards: -11047.1                     Violations: 0                    Mean Train Rewards: -11123.3\n",
            "Episode: 380 |                     Train Rewards: -12764.7                     Violations: 27.638404369354248                    Mean Train Rewards: -11148.6\n",
            "Episode: 390 |                     Train Rewards: -11073.0                     Violations: 0                    Mean Train Rewards: -11260.6\n",
            "Episode: 400 |                     Train Rewards: -11159.7                     Violations: 0                    Mean Train Rewards: -11248.9\n",
            "Episode: 410 |                     Train Rewards: -10761.9                     Violations: 0                    Mean Train Rewards: -11192.3\n",
            "Episode: 420 |                     Train Rewards: -11955.5                     Violations: 14.600261449813843                    Mean Train Rewards: -11208.5\n",
            "Episode: 430 |                     Train Rewards: -12891.6                     Violations: 25.18408060073851                    Mean Train Rewards: -11246.3\n",
            "Episode: 440 |                     Train Rewards: -14308.9                     Violations: 44.804474115371704                    Mean Train Rewards: -11473.2\n",
            "Episode: 450 |                     Train Rewards: -20757.8                     Violations: 111.77924156188965                    Mean Train Rewards: -11673.0\n",
            "Episode: 460 |                     Train Rewards: -13005.0                     Violations: 27.785990238189697                    Mean Train Rewards: -11823.0\n",
            "Episode: 470 |                     Train Rewards: -15800.8                     Violations: 57.511863708496094                    Mean Train Rewards: -12039.6\n",
            "Episode: 480 |                     Train Rewards: -16506.4                     Violations: 62.766581773757935                    Mean Train Rewards: -12310.2\n",
            "Episode: 490 |                     Train Rewards: -10614.4                     Violations: 0.9002888202667307                    Mean Train Rewards: -12344.7\n",
            "Episode: 500 |                     Train Rewards: -12988.7                     Violations: 28.508620262145996                    Mean Train Rewards: -12384.4\n",
            "Episode: 510 |                     Train Rewards: -10570.1                     Violations: 4.570512771606438                    Mean Train Rewards: -12472.5\n",
            "Episode: 520 |                     Train Rewards: -10564.6                     Violations: 0                    Mean Train Rewards: -12560.9\n",
            "Episode: 530 |                     Train Rewards: -10321.4                     Violations: 0                    Mean Train Rewards: -12593.3\n",
            "Episode: 540 |                     Train Rewards: -10733.6                     Violations: 6.799592971801758                    Mean Train Rewards: -12490.6\n",
            "Episode: 550 |                     Train Rewards: -10402.1                     Violations: 0                    Mean Train Rewards: -12342.2\n",
            "Episode: 560 |                     Train Rewards: -12145.8                     Violations: 21.79994702339173                    Mean Train Rewards: -12231.6\n",
            "Episode: 570 |                     Train Rewards: -11112.2                     Violations: 10.670559406280518                    Mean Train Rewards: -12046.1\n",
            "Episode: 580 |                     Train Rewards: -10669.3                     Violations: 2.2817277908325195                    Mean Train Rewards: -11756.3\n",
            "Episode: 590 |                     Train Rewards: -10665.2                     Violations: 4.276033639907837                    Mean Train Rewards: -11740.0\n",
            "Episode: 600 |                     Train Rewards: -10605.5                     Violations: 0                    Mean Train Rewards: -11823.2\n",
            "Episode: 610 |                     Train Rewards: -10521.6                     Violations: 0                    Mean Train Rewards: -11834.2\n",
            "Episode: 620 |                     Train Rewards: -11086.7                     Violations: 5.535694360733032                    Mean Train Rewards: -11745.5\n",
            "Episode: 630 |                     Train Rewards: -11026.4                     Violations: 7.6911890506744385                    Mean Train Rewards: -11714.6\n",
            "Episode: 640 |                     Train Rewards: -10691.4                     Violations: 2.4234020709991455                    Mean Train Rewards: -11605.5\n",
            "Episode: 650 |                     Train Rewards: -10637.6                     Violations: 0                    Mean Train Rewards: -11574.1\n",
            "Episode: 660 |                     Train Rewards: -10458.2                     Violations: 0.45250892639160867                    Mean Train Rewards: -11529.7\n",
            "Episode: 670 |                     Train Rewards: -12216.0                     Violations: 18.22282314300537                    Mean Train Rewards: -11573.7\n",
            "Episode: 680 |                     Train Rewards: -10573.9                     Violations: 0                    Mean Train Rewards: -11592.2\n",
            "Episode: 690 |                     Train Rewards: -12297.8                     Violations: 19.456764459609985                    Mean Train Rewards: -11545.8\n",
            "Episode: 700 |                     Train Rewards: -12663.5                     Violations: 23.93510103225708                    Mean Train Rewards: -11517.8\n",
            "Episode: 710 |                     Train Rewards: -13915.6                     Violations: 32.96246290206909                    Mean Train Rewards: -11472.3\n",
            "Episode: 720 |                     Train Rewards: -11801.9                     Violations: 13.84297251701355                    Mean Train Rewards: -11471.2\n",
            "Episode: 730 |                     Train Rewards: -11124.7                     Violations: 7.455995082855225                    Mean Train Rewards: -11484.4\n",
            "Episode: 740 |                     Train Rewards: -13796.6                     Violations: 38.445168733596816                    Mean Train Rewards: -11590.5\n",
            "Episode: 750 |                     Train Rewards: -10556.5                     Violations: 0                    Mean Train Rewards: -11528.7\n",
            "Episode: 760 |                     Train Rewards: -11349.7                     Violations: 7.1861231327056885                    Mean Train Rewards: -11601.1\n",
            "Episode: 770 |                     Train Rewards: -10627.6                     Violations: 0                    Mean Train Rewards: -11633.3\n",
            "Episode: 780 |                     Train Rewards: -12047.5                     Violations: 17.342182397842407                    Mean Train Rewards: -11781.6\n",
            "Episode: 790 |                     Train Rewards: -19178.2                     Violations: 92.89078235626222                    Mean Train Rewards: -11959.0\n",
            "Episode: 800 |                     Train Rewards: -10506.8                     Violations: 0                    Mean Train Rewards: -11942.0\n",
            "Episode: 810 |                     Train Rewards: -11459.4                     Violations: 9.566410779953003                    Mean Train Rewards: -12002.6\n",
            "Episode: 820 |                     Train Rewards: -12834.4                     Violations: 28.20502281188965                    Mean Train Rewards: -12176.6\n",
            "Episode: 830 |                     Train Rewards: -16589.6                     Violations: 66.12271428108214                    Mean Train Rewards: -12330.4\n",
            "Episode: 840 |                     Train Rewards: -10513.2                     Violations: 0                    Mean Train Rewards: -12343.4\n",
            "Episode: 850 |                     Train Rewards: -10558.8                     Violations: 0                    Mean Train Rewards: -12393.8\n",
            "Episode: 860 |                     Train Rewards: -15175.1                     Violations: 52.40150332450867                    Mean Train Rewards: -12496.3\n",
            "Episode: 870 |                     Train Rewards: -10491.2                     Violations: 0                    Mean Train Rewards: -12486.0\n",
            "Episode: 880 |                     Train Rewards: -16397.2                     Violations: 64.92881298065187                    Mean Train Rewards: -12473.3\n",
            "Episode: 890 |                     Train Rewards: -11601.6                     Violations: 15.765107870101922                    Mean Train Rewards: -12422.8\n",
            "Episode: 900 |                     Train Rewards: -13075.4                     Violations: 27.922974824905396                    Mean Train Rewards: -12510.6\n",
            "Episode: 910 |                     Train Rewards: -13954.7                     Violations: 37.45550513267517                    Mean Train Rewards: -12671.0\n",
            "Episode: 920 |                     Train Rewards: -10393.7                     Violations: 0                    Mean Train Rewards: -12775.4\n",
            "Episode: 930 |                     Train Rewards: -10631.5                     Violations: 0                    Mean Train Rewards: -12756.4\n",
            "Episode: 940 |                     Train Rewards: -14534.1                     Violations: 44.849524497985854                    Mean Train Rewards: -12849.8\n",
            "Episode: 950 |                     Train Rewards: -17554.6                     Violations: 77.6726722717285                    Mean Train Rewards: -13051.1\n",
            "Episode: 960 |                     Train Rewards: -10449.6                     Violations: 0.008007287979125977                    Mean Train Rewards: -13015.5\n",
            "Episode: 970 |                     Train Rewards: -13307.6                     Violations: 32.809340953826904                    Mean Train Rewards: -13070.1\n",
            "Episode: 980 |                     Train Rewards: -10260.8                     Violations: 0                    Mean Train Rewards: -13075.8\n",
            "Episode: 990 |                     Train Rewards: -15109.5                     Violations: 51.23680353164673                    Mean Train Rewards: -13050.4\n",
            "Episode: 1000 |                     Train Rewards: -11934.9                     Violations: 18.30729722976684                    Mean Train Rewards: -13015.8\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-60/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-61\n",
            "\n",
            "==================================================\n",
            "Starting run 6/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0003, 'EPSILON': 0.2, 'ENTROPY_COEFFICIENT': 0.05, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -14035.9                     Violations: 42.48266577720642                    Mean Train Rewards: -17172.8\n",
            "Episode:  20 |                     Train Rewards: -10388.2                     Violations: 3.108009099960327                    Mean Train Rewards: -14740.1\n",
            "Episode:  30 |                     Train Rewards: -10359.9                     Violations: 0                    Mean Train Rewards: -13278.3\n",
            "Episode:  40 |                     Train Rewards: -10270.7                     Violations: 1.1510813236236572                    Mean Train Rewards: -12565.5\n",
            "Episode:  50 |                     Train Rewards: -11317.0                     Violations: 13.175158500671373                    Mean Train Rewards: -12360.2\n",
            "Episode:  60 |                     Train Rewards: -12085.5                     Violations: 21.952245235443115                    Mean Train Rewards: -12397.1\n",
            "Episode:  70 |                     Train Rewards: -10229.2                     Violations: 0                    Mean Train Rewards: -12128.1\n",
            "Episode:  80 |                     Train Rewards: -10447.4                     Violations: 0                    Mean Train Rewards: -11907.9\n",
            "Episode:  90 |                     Train Rewards: -10710.5                     Violations: 0                    Mean Train Rewards: -11755.5\n",
            "Episode: 100 |                     Train Rewards: -10846.5                     Violations: 0                    Mean Train Rewards: -11664.4\n",
            "Episode: 110 |                     Train Rewards: -11033.0                     Violations: 0                    Mean Train Rewards: -11039.6\n",
            "Episode: 120 |                     Train Rewards: -11160.0                     Violations: 0                    Mean Train Rewards: -10915.8\n",
            "Episode: 130 |                     Train Rewards: -11179.1                     Violations: 0                    Mean Train Rewards: -10995.8\n",
            "Episode: 140 |                     Train Rewards: -11173.7                     Violations: 0                    Mean Train Rewards: -11069.0\n",
            "Episode: 150 |                     Train Rewards: -11146.6                     Violations: 0                    Mean Train Rewards: -11030.4\n",
            "Episode: 160 |                     Train Rewards: -11187.7                     Violations: 0                    Mean Train Rewards: -10888.8\n",
            "Episode: 170 |                     Train Rewards: -11177.8                     Violations: 0                    Mean Train Rewards: -10955.2\n",
            "Episode: 180 |                     Train Rewards: -11162.6                     Violations: 0                    Mean Train Rewards: -11034.5\n",
            "Episode: 190 |                     Train Rewards: -11139.9                     Violations: 0                    Mean Train Rewards: -11095.7\n",
            "Episode: 200 |                     Train Rewards: -11150.6                     Violations: 0                    Mean Train Rewards: -11123.3\n",
            "Episode: 210 |                     Train Rewards: -11126.6                     Violations: 0                    Mean Train Rewards: -11146.2\n",
            "Episode: 220 |                     Train Rewards: -10881.9                     Violations: 0                    Mean Train Rewards: -11147.8\n",
            "Episode: 230 |                     Train Rewards: -10782.8                     Violations: 0                    Mean Train Rewards: -11115.0\n",
            "Episode: 240 |                     Train Rewards: -10883.3                     Violations: 0                    Mean Train Rewards: -11060.6\n",
            "Episode: 250 |                     Train Rewards: -10869.8                     Violations: 0                    Mean Train Rewards: -11038.9\n",
            "Episode: 260 |                     Train Rewards: -11047.7                     Violations: 0                    Mean Train Rewards: -11014.0\n",
            "Episode: 270 |                     Train Rewards: -10988.5                     Violations: 0                    Mean Train Rewards: -10990.9\n",
            "Episode: 280 |                     Train Rewards: -10935.0                     Violations: 0                    Mean Train Rewards: -10958.8\n",
            "Episode: 290 |                     Train Rewards: -11017.6                     Violations: 0                    Mean Train Rewards: -10937.0\n",
            "Episode: 300 |                     Train Rewards: -10914.8                     Violations: 0                    Mean Train Rewards: -10922.1\n",
            "Episode: 310 |                     Train Rewards: -11084.6                     Violations: 0                    Mean Train Rewards: -10905.7\n",
            "Episode: 320 |                     Train Rewards: -11177.7                     Violations: 0                    Mean Train Rewards: -10909.0\n",
            "Episode: 330 |                     Train Rewards: -11153.9                     Violations: 0                    Mean Train Rewards: -10942.6\n",
            "Episode: 340 |                     Train Rewards: -11133.8                     Violations: 0                    Mean Train Rewards: -10996.7\n",
            "Episode: 350 |                     Train Rewards: -11172.9                     Violations: 0                    Mean Train Rewards: -11020.2\n",
            "Episode: 360 |                     Train Rewards: -11151.0                     Violations: 0                    Mean Train Rewards: -11044.0\n",
            "Episode: 370 |                     Train Rewards: -11157.4                     Violations: 0                    Mean Train Rewards: -11064.5\n",
            "Episode: 380 |                     Train Rewards: -11099.2                     Violations: 0                    Mean Train Rewards: -11094.5\n",
            "Episode: 390 |                     Train Rewards: -11182.1                     Violations: 0                    Mean Train Rewards: -11116.0\n",
            "Episode: 400 |                     Train Rewards: -11185.9                     Violations: 0                    Mean Train Rewards: -11134.4\n",
            "Episode: 410 |                     Train Rewards: -11127.8                     Violations: 0                    Mean Train Rewards: -11151.8\n",
            "Episode: 420 |                     Train Rewards: -11170.5                     Violations: 0                    Mean Train Rewards: -11156.7\n",
            "Episode: 430 |                     Train Rewards: -11153.5                     Violations: 0                    Mean Train Rewards: -11155.5\n",
            "Episode: 440 |                     Train Rewards: -11037.7                     Violations: 0                    Mean Train Rewards: -11152.9\n",
            "Episode: 450 |                     Train Rewards: -11081.0                     Violations: 0                    Mean Train Rewards: -11147.8\n",
            "Episode: 460 |                     Train Rewards: -11118.8                     Violations: 0                    Mean Train Rewards: -11146.3\n",
            "Episode: 470 |                     Train Rewards: -11087.0                     Violations: 0                    Mean Train Rewards: -11139.5\n",
            "Episode: 480 |                     Train Rewards: -11040.8                     Violations: 0                    Mean Train Rewards: -11134.7\n",
            "Episode: 490 |                     Train Rewards: -11101.5                     Violations: 0                    Mean Train Rewards: -11132.9\n",
            "Episode: 500 |                     Train Rewards: -11040.3                     Violations: 0                    Mean Train Rewards: -11129.2\n",
            "Episode: 510 |                     Train Rewards: -10894.8                     Violations: 0                    Mean Train Rewards: -11120.4\n",
            "Episode: 520 |                     Train Rewards: -11096.9                     Violations: 0                    Mean Train Rewards: -11125.0\n",
            "Episode: 530 |                     Train Rewards: -11142.5                     Violations: 0                    Mean Train Rewards: -11119.5\n",
            "Episode: 540 |                     Train Rewards: -11094.2                     Violations: 0                    Mean Train Rewards: -11117.3\n",
            "Episode: 550 |                     Train Rewards: -11123.1                     Violations: 0                    Mean Train Rewards: -11117.3\n",
            "Episode: 560 |                     Train Rewards: -10993.1                     Violations: 0                    Mean Train Rewards: -11112.7\n",
            "Episode: 570 |                     Train Rewards: -11005.0                     Violations: 0                    Mean Train Rewards: -11114.8\n",
            "Episode: 580 |                     Train Rewards: -11107.1                     Violations: 0                    Mean Train Rewards: -11115.6\n",
            "Episode: 590 |                     Train Rewards: -11056.1                     Violations: 0                    Mean Train Rewards: -11103.8\n",
            "Episode: 600 |                     Train Rewards: -10925.9                     Violations: 0                    Mean Train Rewards: -11092.8\n",
            "Episode: 610 |                     Train Rewards: -10606.3                     Violations: 0                    Mean Train Rewards: -11111.3\n",
            "Episode: 620 |                     Train Rewards: -25393.6                     Violations: 159.93467807769775                    Mean Train Rewards: -12147.9\n",
            "Episode: 630 |                     Train Rewards: -10864.9                     Violations: 5.6753599643707275                    Mean Train Rewards: -12561.4\n",
            "Episode: 640 |                     Train Rewards: -11385.2                     Violations: 10.881915092468262                    Mean Train Rewards: -12592.0\n",
            "Episode: 650 |                     Train Rewards: -11191.2                     Violations: 7.251753807067871                    Mean Train Rewards: -12673.4\n",
            "Episode: 660 |                     Train Rewards: -12088.2                     Violations: 18.274365663528428                    Mean Train Rewards: -12822.0\n",
            "Episode: 670 |                     Train Rewards: -14648.7                     Violations: 44.62949991226196                    Mean Train Rewards: -13039.5\n",
            "Episode: 680 |                     Train Rewards: -10493.2                     Violations: 1.127316951751709                    Mean Train Rewards: -13156.8\n",
            "Episode: 690 |                     Train Rewards: -13259.3                     Violations: 30.276999473571777                    Mean Train Rewards: -13366.1\n",
            "Episode: 700 |                     Train Rewards: -13902.5                     Violations: 37.81311273574828                    Mean Train Rewards: -13574.7\n",
            "Episode: 710 |                     Train Rewards: -14686.9                     Violations: 41.291890144348145                    Mean Train Rewards: -13680.5\n",
            "Episode: 720 |                     Train Rewards: -12720.8                     Violations: 24.59468603134154                    Mean Train Rewards: -12732.9\n",
            "Episode: 730 |                     Train Rewards: -11860.8                     Violations: 16.47274136543274                    Mean Train Rewards: -12460.9\n",
            "Episode: 740 |                     Train Rewards: -15332.1                     Violations: 55.10859012603761                    Mean Train Rewards: -12686.3\n",
            "Episode: 750 |                     Train Rewards: -10413.6                     Violations: 0                    Mean Train Rewards: -12597.0\n",
            "Episode: 760 |                     Train Rewards: -12013.4                     Violations: 14.879056215286255                    Mean Train Rewards: -12590.6\n",
            "Episode: 770 |                     Train Rewards: -10521.2                     Violations: 0                    Mean Train Rewards: -12563.3\n",
            "Episode: 780 |                     Train Rewards: -12817.4                     Violations: 25.91480016708374                    Mean Train Rewards: -12696.5\n",
            "Episode: 790 |                     Train Rewards: -20287.3                     Violations: 104.813392162323                    Mean Train Rewards: -12852.3\n",
            "Episode: 800 |                     Train Rewards: -10817.6                     Violations: 4.065128564834595                    Mean Train Rewards: -12767.9\n",
            "Episode: 810 |                     Train Rewards: -11885.0                     Violations: 14.455636739730835                    Mean Train Rewards: -12847.1\n",
            "Episode: 820 |                     Train Rewards: -13018.9                     Violations: 30.149481296539307                    Mean Train Rewards: -12970.7\n",
            "Episode: 830 |                     Train Rewards: -16325.5                     Violations: 63.28686237335204                    Mean Train Rewards: -13045.2\n",
            "Episode: 840 |                     Train Rewards: -10536.3                     Violations: 0                    Mean Train Rewards: -12919.3\n",
            "Episode: 850 |                     Train Rewards: -10575.3                     Violations: 0                    Mean Train Rewards: -12944.5\n",
            "Episode: 860 |                     Train Rewards: -15276.7                     Violations: 53.4312868118286                    Mean Train Rewards: -12981.1\n",
            "Episode: 870 |                     Train Rewards: -10462.4                     Violations: 0                    Mean Train Rewards: -12897.3\n",
            "Episode: 880 |                     Train Rewards: -16755.8                     Violations: 68.62267971038816                    Mean Train Rewards: -12815.3\n",
            "Episode: 890 |                     Train Rewards: -11388.9                     Violations: 13.355587720870972                    Mean Train Rewards: -12638.4\n",
            "Episode: 900 |                     Train Rewards: -12899.8                     Violations: 25.940595865249634                    Mean Train Rewards: -12663.2\n",
            "Episode: 910 |                     Train Rewards: -13598.2                     Violations: 33.43136310577394                    Mean Train Rewards: -12699.3\n",
            "Episode: 920 |                     Train Rewards: -10445.4                     Violations: 0                    Mean Train Rewards: -12737.8\n",
            "Episode: 930 |                     Train Rewards: -10666.4                     Violations: 0                    Mean Train Rewards: -12688.3\n",
            "Episode: 940 |                     Train Rewards: -14616.7                     Violations: 45.44189929962158                    Mean Train Rewards: -12778.8\n",
            "Episode: 950 |                     Train Rewards: -17637.1                     Violations: 78.53276133537292                    Mean Train Rewards: -12980.4\n",
            "Episode: 960 |                     Train Rewards: -10472.5                     Violations: 0                    Mean Train Rewards: -12943.5\n",
            "Episode: 970 |                     Train Rewards: -13439.3                     Violations: 34.12292599678039                    Mean Train Rewards: -12988.7\n",
            "Episode: 980 |                     Train Rewards: -10261.1                     Violations: 0                    Mean Train Rewards: -12977.6\n",
            "Episode: 990 |                     Train Rewards: -15662.3                     Violations: 56.9792342185974                    Mean Train Rewards: -12982.3\n",
            "Episode: 1000 |                     Train Rewards: -12081.0                     Violations: 19.85877275466919                    Mean Train Rewards: -12976.5\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 16 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 16 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-61/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-62\n",
            "\n",
            "==================================================\n",
            "Starting run 7/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 128, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -10219.9                     Violations: 1.6534590721130442                    Mean Train Rewards: -12234.1\n",
            "Episode:  20 |                     Train Rewards: -10163.2                     Violations: 0                    Mean Train Rewards: -11373.1\n",
            "Episode:  30 |                     Train Rewards: -10277.7                     Violations: 0                    Mean Train Rewards: -11015.4\n",
            "Episode:  40 |                     Train Rewards: -10154.8                     Violations: 0                    Mean Train Rewards: -10839.1\n",
            "Episode:  50 |                     Train Rewards: -10379.2                     Violations: 2.8126144409179616                    Mean Train Rewards: -10751.5\n",
            "Episode:  60 |                     Train Rewards: -10469.9                     Violations: 4.672877788543701                    Mean Train Rewards: -10737.3\n",
            "Episode:  70 |                     Train Rewards: -10150.8                     Violations: 0                    Mean Train Rewards: -10674.5\n",
            "Episode:  80 |                     Train Rewards: -10334.4                     Violations: 0                    Mean Train Rewards: -10619.1\n",
            "Episode:  90 |                     Train Rewards: -10405.8                     Violations: 0                    Mean Train Rewards: -10588.0\n",
            "Episode: 100 |                     Train Rewards: -10450.2                     Violations: 0                    Mean Train Rewards: -10578.5\n",
            "Episode: 110 |                     Train Rewards: -10578.8                     Violations: 0                    Mean Train Rewards: -10409.1\n",
            "Episode: 120 |                     Train Rewards: -10734.9                     Violations: 0                    Mean Train Rewards: -10422.8\n",
            "Episode: 130 |                     Train Rewards: -11026.8                     Violations: 0                    Mean Train Rewards: -10479.0\n",
            "Episode: 140 |                     Train Rewards: -10907.5                     Violations: 0                    Mean Train Rewards: -10536.9\n",
            "Episode: 150 |                     Train Rewards: -10838.1                     Violations: 0                    Mean Train Rewards: -10581.4\n",
            "Episode: 160 |                     Train Rewards: -11188.8                     Violations: 0                    Mean Train Rewards: -10621.6\n",
            "Episode: 170 |                     Train Rewards: -11180.6                     Violations: 0                    Mean Train Rewards: -10709.8\n",
            "Episode: 180 |                     Train Rewards: -11173.4                     Violations: 0                    Mean Train Rewards: -10803.4\n",
            "Episode: 190 |                     Train Rewards: -11169.6                     Violations: 0                    Mean Train Rewards: -10886.3\n",
            "Episode: 200 |                     Train Rewards: -11173.0                     Violations: 0                    Mean Train Rewards: -10953.2\n",
            "Episode: 210 |                     Train Rewards: -11156.1                     Violations: 0                    Mean Train Rewards: -11016.4\n",
            "Episode: 220 |                     Train Rewards: -11091.3                     Violations: 0                    Mean Train Rewards: -11066.4\n",
            "Episode: 230 |                     Train Rewards: -11112.4                     Violations: 0                    Mean Train Rewards: -11091.5\n",
            "Episode: 240 |                     Train Rewards: -11112.8                     Violations: 0                    Mean Train Rewards: -11108.0\n",
            "Episode: 250 |                     Train Rewards: -11116.5                     Violations: 0                    Mean Train Rewards: -11134.7\n",
            "Episode: 260 |                     Train Rewards: -11174.9                     Violations: 0                    Mean Train Rewards: -11141.0\n",
            "Episode: 270 |                     Train Rewards: -11171.8                     Violations: 0                    Mean Train Rewards: -11138.9\n",
            "Episode: 280 |                     Train Rewards: -11162.7                     Violations: 0                    Mean Train Rewards: -11137.1\n",
            "Episode: 290 |                     Train Rewards: -11185.0                     Violations: 0                    Mean Train Rewards: -11137.3\n",
            "Episode: 300 |                     Train Rewards: -11116.4                     Violations: 0                    Mean Train Rewards: -11136.2\n",
            "Episode: 310 |                     Train Rewards: -11161.4                     Violations: 0                    Mean Train Rewards: -11135.0\n",
            "Episode: 320 |                     Train Rewards: -11186.4                     Violations: 0                    Mean Train Rewards: -11136.4\n",
            "Episode: 330 |                     Train Rewards: -11168.5                     Violations: 0                    Mean Train Rewards: -11142.7\n",
            "Episode: 340 |                     Train Rewards: -11161.3                     Violations: 0                    Mean Train Rewards: -11154.5\n",
            "Episode: 350 |                     Train Rewards: -11176.1                     Violations: 0                    Mean Train Rewards: -11161.3\n",
            "Episode: 360 |                     Train Rewards: -11172.2                     Violations: 0                    Mean Train Rewards: -11165.7\n",
            "Episode: 370 |                     Train Rewards: -11176.2                     Violations: 0                    Mean Train Rewards: -11167.1\n",
            "Episode: 380 |                     Train Rewards: -11168.7                     Violations: 0                    Mean Train Rewards: -11169.5\n",
            "Episode: 390 |                     Train Rewards: -11191.8                     Violations: 0                    Mean Train Rewards: -11170.4\n",
            "Episode: 400 |                     Train Rewards: -11191.6                     Violations: 0                    Mean Train Rewards: -11173.1\n",
            "Episode: 410 |                     Train Rewards: -11165.3                     Violations: 0                    Mean Train Rewards: -11175.1\n",
            "Episode: 420 |                     Train Rewards: -11188.3                     Violations: 0                    Mean Train Rewards: -11177.4\n",
            "Episode: 430 |                     Train Rewards: -11182.7                     Violations: 0                    Mean Train Rewards: -11177.8\n",
            "Episode: 440 |                     Train Rewards: -11169.9                     Violations: 0                    Mean Train Rewards: -11178.7\n",
            "Episode: 450 |                     Train Rewards: -11166.1                     Violations: 0                    Mean Train Rewards: -11178.6\n",
            "Episode: 460 |                     Train Rewards: -11183.2                     Violations: 0                    Mean Train Rewards: -11179.4\n",
            "Episode: 470 |                     Train Rewards: -11178.0                     Violations: 0                    Mean Train Rewards: -11179.8\n",
            "Episode: 480 |                     Train Rewards: -11169.8                     Violations: 0                    Mean Train Rewards: -11180.7\n",
            "Episode: 490 |                     Train Rewards: -11180.5                     Violations: 0                    Mean Train Rewards: -11181.1\n",
            "Episode: 500 |                     Train Rewards: -11169.2                     Violations: 0                    Mean Train Rewards: -11181.8\n",
            "Episode: 510 |                     Train Rewards: -11184.9                     Violations: 0                    Mean Train Rewards: -11182.5\n",
            "Episode: 520 |                     Train Rewards: -11188.9                     Violations: 0                    Mean Train Rewards: -11182.5\n",
            "Episode: 530 |                     Train Rewards: -11191.0                     Violations: 0                    Mean Train Rewards: -11183.4\n",
            "Episode: 540 |                     Train Rewards: -11187.3                     Violations: 0                    Mean Train Rewards: -11184.2\n",
            "Episode: 550 |                     Train Rewards: -11190.4                     Violations: 0                    Mean Train Rewards: -11185.2\n",
            "Episode: 560 |                     Train Rewards: -11179.1                     Violations: 0                    Mean Train Rewards: -11185.6\n",
            "Episode: 570 |                     Train Rewards: -11180.3                     Violations: 0                    Mean Train Rewards: -11186.9\n",
            "Episode: 580 |                     Train Rewards: -11189.0                     Violations: 0                    Mean Train Rewards: -11187.7\n",
            "Episode: 590 |                     Train Rewards: -11189.4                     Violations: 0                    Mean Train Rewards: -11187.9\n",
            "Episode: 600 |                     Train Rewards: -11183.0                     Violations: 0                    Mean Train Rewards: -11188.4\n",
            "Episode: 610 |                     Train Rewards: -11193.4                     Violations: 0                    Mean Train Rewards: -11188.3\n",
            "Episode: 620 |                     Train Rewards: -11197.2                     Violations: 0                    Mean Train Rewards: -11188.3\n",
            "Episode: 630 |                     Train Rewards: -11192.0                     Violations: 0                    Mean Train Rewards: -11188.4\n",
            "Episode: 640 |                     Train Rewards: -11192.2                     Violations: 0                    Mean Train Rewards: -11188.5\n",
            "Episode: 650 |                     Train Rewards: -11193.3                     Violations: 0                    Mean Train Rewards: -11188.6\n",
            "Episode: 660 |                     Train Rewards: -11193.8                     Violations: 0                    Mean Train Rewards: -11188.7\n",
            "Episode: 670 |                     Train Rewards: -11192.1                     Violations: 0                    Mean Train Rewards: -11188.5\n",
            "Episode: 680 |                     Train Rewards: -11194.1                     Violations: 0                    Mean Train Rewards: -11188.3\n",
            "Episode: 690 |                     Train Rewards: -11180.5                     Violations: 0                    Mean Train Rewards: -11188.2\n",
            "Episode: 700 |                     Train Rewards: -11180.8                     Violations: 0                    Mean Train Rewards: -11187.7\n",
            "Episode: 710 |                     Train Rewards: -11188.0                     Violations: 0                    Mean Train Rewards: -11187.4\n",
            "Episode: 720 |                     Train Rewards: -11189.4                     Violations: 0                    Mean Train Rewards: -11187.5\n",
            "Episode: 730 |                     Train Rewards: -11188.7                     Violations: 0                    Mean Train Rewards: -11187.4\n",
            "Episode: 740 |                     Train Rewards: -11174.0                     Violations: 0                    Mean Train Rewards: -11187.0\n",
            "Episode: 750 |                     Train Rewards: -11193.4                     Violations: 0                    Mean Train Rewards: -11187.1\n",
            "Episode: 760 |                     Train Rewards: -11194.5                     Violations: 0                    Mean Train Rewards: -11186.8\n",
            "Episode: 770 |                     Train Rewards: -11184.6                     Violations: 0                    Mean Train Rewards: -11186.4\n",
            "Episode: 780 |                     Train Rewards: -11190.9                     Violations: 0                    Mean Train Rewards: -11186.5\n",
            "Episode: 790 |                     Train Rewards: -11191.3                     Violations: 0                    Mean Train Rewards: -11186.4\n",
            "Episode: 800 |                     Train Rewards: -11192.9                     Violations: 0                    Mean Train Rewards: -11186.9\n",
            "Episode: 810 |                     Train Rewards: -11194.5                     Violations: 0                    Mean Train Rewards: -11186.4\n",
            "Episode: 820 |                     Train Rewards: -11139.7                     Violations: 0                    Mean Train Rewards: -11184.4\n",
            "Episode: 830 |                     Train Rewards: -11136.0                     Violations: 0                    Mean Train Rewards: -11181.5\n",
            "Episode: 840 |                     Train Rewards: -11176.0                     Violations: 0                    Mean Train Rewards: -11177.7\n",
            "Episode: 850 |                     Train Rewards: -11192.9                     Violations: 0                    Mean Train Rewards: -11176.7\n",
            "Episode: 860 |                     Train Rewards: -11150.5                     Violations: 0                    Mean Train Rewards: -11174.9\n",
            "Episode: 870 |                     Train Rewards: -11184.2                     Violations: 0                    Mean Train Rewards: -11173.9\n",
            "Episode: 880 |                     Train Rewards: -11171.0                     Violations: 0                    Mean Train Rewards: -11172.0\n",
            "Episode: 890 |                     Train Rewards: -11146.6                     Violations: 0                    Mean Train Rewards: -11169.3\n",
            "Episode: 900 |                     Train Rewards: -11166.7                     Violations: 0                    Mean Train Rewards: -11167.0\n",
            "Episode: 910 |                     Train Rewards: -11171.5                     Violations: 0                    Mean Train Rewards: -11165.3\n",
            "Episode: 920 |                     Train Rewards: -11175.9                     Violations: 0                    Mean Train Rewards: -11165.4\n",
            "Episode: 930 |                     Train Rewards: -11190.1                     Violations: 0                    Mean Train Rewards: -11166.5\n",
            "Episode: 940 |                     Train Rewards: -11149.5                     Violations: 0                    Mean Train Rewards: -11169.3\n",
            "Episode: 950 |                     Train Rewards: -11159.2                     Violations: 0                    Mean Train Rewards: -11168.8\n",
            "Episode: 960 |                     Train Rewards: -11192.4                     Violations: 0                    Mean Train Rewards: -11170.1\n",
            "Episode: 970 |                     Train Rewards: -11166.0                     Violations: 0                    Mean Train Rewards: -11170.1\n",
            "Episode: 980 |                     Train Rewards: -11179.5                     Violations: 0                    Mean Train Rewards: -11170.4\n",
            "Episode: 990 |                     Train Rewards: -11182.3                     Violations: 0                    Mean Train Rewards: -11172.9\n",
            "Episode: 1000 |                     Train Rewards: -11156.5                     Violations: 0                    Mean Train Rewards: -11173.7\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 12 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 12 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-62/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-63\n",
            "\n",
            "==================================================\n",
            "Starting run 8/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.003, 'EPSILON': 0.3, 'ENTROPY_COEFFICIENT': 0.1, 'HIDDEN_DIMENSIONS': 32, 'PPO_STEPS': 8, 'BATCH_SIZE': 128, 'DISCOUNT_FACTOR': 0.95, 'constraint_penalty_factor': 100, 'episode_length': 4, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -12833.3                     Violations: 29.824260473251343                    Mean Train Rewards: -13809.2\n",
            "Episode:  20 |                     Train Rewards: -10337.9                     Violations: 3.078024387359612                    Mean Train Rewards: -12920.3\n",
            "Episode:  30 |                     Train Rewards: -10131.4                     Violations: 0                    Mean Train Rewards: -12008.5\n",
            "Episode:  40 |                     Train Rewards: -10120.8                     Violations: 0                    Mean Train Rewards: -11569.2\n",
            "Episode:  50 |                     Train Rewards: -11289.6                     Violations: 13.218926191329956                    Mean Train Rewards: -11721.0\n",
            "Episode:  60 |                     Train Rewards: -13445.7                     Violations: 36.27042531967163                    Mean Train Rewards: -11848.8\n",
            "Episode:  70 |                     Train Rewards: -10157.2                     Violations: 0                    Mean Train Rewards: -11664.1\n",
            "Episode:  80 |                     Train Rewards: -10300.6                     Violations: 0                    Mean Train Rewards: -11500.1\n",
            "Episode:  90 |                     Train Rewards: -10418.6                     Violations: 0                    Mean Train Rewards: -11372.9\n",
            "Episode: 100 |                     Train Rewards: -10615.9                     Violations: 0                    Mean Train Rewards: -11296.3\n",
            "Episode: 110 |                     Train Rewards: -10936.8                     Violations: 0                    Mean Train Rewards: -10994.0\n",
            "Episode: 120 |                     Train Rewards: -11141.6                     Violations: 0                    Mean Train Rewards: -10897.0\n",
            "Episode: 130 |                     Train Rewards: -11184.6                     Violations: 0                    Mean Train Rewards: -10994.1\n",
            "Episode: 140 |                     Train Rewards: -11140.6                     Violations: 0                    Mean Train Rewards: -11083.3\n",
            "Episode: 150 |                     Train Rewards: -10677.5                     Violations: 0                    Mean Train Rewards: -10940.4\n",
            "Episode: 160 |                     Train Rewards: -11189.2                     Violations: 0                    Mean Train Rewards: -10797.4\n",
            "Episode: 170 |                     Train Rewards: -11172.7                     Violations: 0                    Mean Train Rewards: -10859.9\n",
            "Episode: 180 |                     Train Rewards: -11045.4                     Violations: 0                    Mean Train Rewards: -10935.6\n",
            "Episode: 190 |                     Train Rewards: -12099.1                     Violations: 17.083832025527954                    Mean Train Rewards: -11031.6\n",
            "Episode: 200 |                     Train Rewards: -11415.5                     Violations: 7.114245891571045                    Mean Train Rewards: -11108.9\n",
            "Episode: 210 |                     Train Rewards: -11865.1                     Violations: 15.111021995544434                    Mean Train Rewards: -11169.9\n",
            "Episode: 220 |                     Train Rewards: -17680.8                     Violations: 78.27544927597046                    Mean Train Rewards: -11347.8\n",
            "Episode: 230 |                     Train Rewards: -13517.0                     Violations: 35.31519055366515                    Mean Train Rewards: -11547.0\n",
            "Episode: 240 |                     Train Rewards: -10558.0                     Violations: 0                    Mean Train Rewards: -11633.1\n",
            "Episode: 250 |                     Train Rewards: -10515.6                     Violations: 0                    Mean Train Rewards: -11684.5\n",
            "Episode: 260 |                     Train Rewards: -10632.5                     Violations: 0                    Mean Train Rewards: -11699.9\n",
            "Episode: 270 |                     Train Rewards: -10788.5                     Violations: 0                    Mean Train Rewards: -11702.4\n",
            "Episode: 280 |                     Train Rewards: -10624.7                     Violations: 0.6121778488159251                    Mean Train Rewards: -11781.4\n",
            "Episode: 290 |                     Train Rewards: -10495.0                     Violations: 0                    Mean Train Rewards: -11783.2\n",
            "Episode: 300 |                     Train Rewards: -11064.4                     Violations: 10.48820495605468                    Mean Train Rewards: -11768.1\n",
            "Episode: 310 |                     Train Rewards: -11387.3                     Violations: 8.454378843307495                    Mean Train Rewards: -11812.7\n",
            "Episode: 320 |                     Train Rewards: -10896.2                     Violations: 0                    Mean Train Rewards: -11633.7\n",
            "Episode: 330 |                     Train Rewards: -10457.0                     Violations: 0                    Mean Train Rewards: -11396.7\n",
            "Episode: 340 |                     Train Rewards: -10471.9                     Violations: 0                    Mean Train Rewards: -11300.3\n",
            "Episode: 350 |                     Train Rewards: -10948.7                     Violations: 0                    Mean Train Rewards: -11246.0\n",
            "Episode: 360 |                     Train Rewards: -10669.4                     Violations: 0                    Mean Train Rewards: -11199.1\n",
            "Episode: 370 |                     Train Rewards: -10873.7                     Violations: 5.150296688079834                    Mean Train Rewards: -11185.4\n",
            "Episode: 380 |                     Train Rewards: -10465.6                     Violations: 2.1835052967071533                    Mean Train Rewards: -11120.0\n",
            "Episode: 390 |                     Train Rewards: -10879.8                     Violations: 0                    Mean Train Rewards: -11148.4\n",
            "Episode: 400 |                     Train Rewards: -10943.0                     Violations: 0                    Mean Train Rewards: -11132.1\n",
            "Episode: 410 |                     Train Rewards: -11596.0                     Violations: 13.564738035202026                    Mean Train Rewards: -11049.3\n",
            "Episode: 420 |                     Train Rewards: -10603.2                     Violations: 0                    Mean Train Rewards: -11007.0\n",
            "Episode: 430 |                     Train Rewards: -11398.9                     Violations: 7.2599852085113525                    Mean Train Rewards: -11012.2\n",
            "Episode: 440 |                     Train Rewards: -11960.3                     Violations: 18.039491176605225                    Mean Train Rewards: -11063.8\n",
            "Episode: 450 |                     Train Rewards: -15244.2                     Violations: 54.20415043830873                    Mean Train Rewards: -11125.2\n",
            "Episode: 460 |                     Train Rewards: -11853.9                     Violations: 14.163609743118286                    Mean Train Rewards: -11196.6\n",
            "Episode: 470 |                     Train Rewards: -15288.0                     Violations: 50.862917900085435                    Mean Train Rewards: -11293.7\n",
            "Episode: 480 |                     Train Rewards: -14870.9                     Violations: 45.22216916084291                    Mean Train Rewards: -11420.2\n",
            "Episode: 490 |                     Train Rewards: -10661.8                     Violations: 0                    Mean Train Rewards: -11367.0\n",
            "Episode: 500 |                     Train Rewards: -11710.8                     Violations: 14.292161464691162                    Mean Train Rewards: -11337.7\n",
            "Episode: 510 |                     Train Rewards: -10291.7                     Violations: 0                    Mean Train Rewards: -11359.8\n",
            "Episode: 520 |                     Train Rewards: -10709.2                     Violations: 0                    Mean Train Rewards: -11437.7\n",
            "Episode: 530 |                     Train Rewards: -10526.2                     Violations: 0                    Mean Train Rewards: -11479.3\n",
            "Episode: 540 |                     Train Rewards: -10294.9                     Violations: 0                    Mean Train Rewards: -11490.3\n",
            "Episode: 550 |                     Train Rewards: -10582.8                     Violations: 0                    Mean Train Rewards: -11450.6\n",
            "Episode: 560 |                     Train Rewards: -11213.9                     Violations: 10.658904314041138                    Mean Train Rewards: -11396.7\n",
            "Episode: 570 |                     Train Rewards: -10512.3                     Violations: 2.7931952476501465                    Mean Train Rewards: -11284.4\n",
            "Episode: 580 |                     Train Rewards: -10606.3                     Violations: 0                    Mean Train Rewards: -11122.9\n",
            "Episode: 590 |                     Train Rewards: -10375.5                     Violations: 0                    Mean Train Rewards: -11138.2\n",
            "Episode: 600 |                     Train Rewards: -10684.0                     Violations: 0                    Mean Train Rewards: -11211.0\n",
            "Episode: 610 |                     Train Rewards: -10617.6                     Violations: 0                    Mean Train Rewards: -11246.1\n",
            "Episode: 620 |                     Train Rewards: -10624.1                     Violations: 0.15072464942931418                    Mean Train Rewards: -11206.4\n",
            "Episode: 630 |                     Train Rewards: -10431.3                     Violations: 0.7061922550201416                    Mean Train Rewards: -11209.9\n",
            "Episode: 640 |                     Train Rewards: -10536.3                     Violations: 0                    Mean Train Rewards: -11151.2\n",
            "Episode: 650 |                     Train Rewards: -10707.5                     Violations: 0                    Mean Train Rewards: -11166.3\n",
            "Episode: 660 |                     Train Rewards: -10500.8                     Violations: 0                    Mean Train Rewards: -11162.3\n",
            "Episode: 670 |                     Train Rewards: -11797.3                     Violations: 13.376929759979248                    Mean Train Rewards: -11224.5\n",
            "Episode: 680 |                     Train Rewards: -10653.4                     Violations: 0                    Mean Train Rewards: -11240.9\n",
            "Episode: 690 |                     Train Rewards: -15534.9                     Violations: 52.214131355285645                    Mean Train Rewards: -11288.8\n",
            "Episode: 700 |                     Train Rewards: -12611.2                     Violations: 23.239550590515137                    Mean Train Rewards: -11320.2\n",
            "Episode: 710 |                     Train Rewards: -13733.1                     Violations: 30.808804035186753                    Mean Train Rewards: -11304.2\n",
            "Episode: 720 |                     Train Rewards: -11685.2                     Violations: 12.290289402008057                    Mean Train Rewards: -11313.3\n",
            "Episode: 730 |                     Train Rewards: -10962.2                     Violations: 5.3850138187408305                    Mean Train Rewards: -11341.6\n",
            "Episode: 740 |                     Train Rewards: -13416.0                     Violations: 34.21484231948851                    Mean Train Rewards: -11446.9\n",
            "Episode: 750 |                     Train Rewards: -10607.9                     Violations: 0                    Mean Train Rewards: -11395.7\n",
            "Episode: 760 |                     Train Rewards: -11164.7                     Violations: 4.909619092941284                    Mean Train Rewards: -11475.9\n",
            "Episode: 770 |                     Train Rewards: -13237.8                     Violations: 29.584619998931885                    Mean Train Rewards: -11547.2\n",
            "Episode: 780 |                     Train Rewards: -11796.2                     Violations: 13.931097984313965                    Mean Train Rewards: -11667.0\n",
            "Episode: 790 |                     Train Rewards: -18417.7                     Violations: 84.48827981948851                    Mean Train Rewards: -11779.7\n",
            "Episode: 800 |                     Train Rewards: -10586.1                     Violations: 0                    Mean Train Rewards: -11758.8\n",
            "Episode: 810 |                     Train Rewards: -11233.7                     Violations: 6.789817810058594                    Mean Train Rewards: -11794.0\n",
            "Episode: 820 |                     Train Rewards: -12723.2                     Violations: 26.645216941833496                    Mean Train Rewards: -11955.6\n",
            "Episode: 830 |                     Train Rewards: -15943.5                     Violations: 59.339383840560906                    Mean Train Rewards: -12089.4\n",
            "Episode: 840 |                     Train Rewards: -10559.5                     Violations: 0                    Mean Train Rewards: -12100.8\n",
            "Episode: 850 |                     Train Rewards: -10624.1                     Violations: 0                    Mean Train Rewards: -12144.0\n",
            "Episode: 860 |                     Train Rewards: -14682.4                     Violations: 47.10415840148925                    Mean Train Rewards: -12236.8\n",
            "Episode: 870 |                     Train Rewards: -10544.8                     Violations: 0                    Mean Train Rewards: -12204.2\n",
            "Episode: 880 |                     Train Rewards: -15919.4                     Violations: 59.8100972175598                    Mean Train Rewards: -12213.6\n",
            "Episode: 890 |                     Train Rewards: -11277.0                     Violations: 12.052791118621826                    Mean Train Rewards: -12195.5\n",
            "Episode: 900 |                     Train Rewards: -12837.8                     Violations: 25.22576332092285                    Mean Train Rewards: -12279.2\n",
            "Episode: 910 |                     Train Rewards: -13563.9                     Violations: 33.07412266731261                    Mean Train Rewards: -12447.4\n",
            "Episode: 920 |                     Train Rewards: -10440.6                     Violations: 0                    Mean Train Rewards: -12545.0\n",
            "Episode: 930 |                     Train Rewards: -10668.6                     Violations: 0                    Mean Train Rewards: -12532.3\n",
            "Episode: 940 |                     Train Rewards: -14538.7                     Violations: 44.55965518951416                    Mean Train Rewards: -12630.9\n",
            "Episode: 950 |                     Train Rewards: -17555.4                     Violations: 77.60469913482666                    Mean Train Rewards: -12825.7\n",
            "Episode: 960 |                     Train Rewards: -10472.7                     Violations: 0                    Mean Train Rewards: -12810.4\n",
            "Episode: 970 |                     Train Rewards: -13266.2                     Violations: 32.29154348373412                    Mean Train Rewards: -12876.6\n",
            "Episode: 980 |                     Train Rewards: -10275.3                     Violations: 0                    Mean Train Rewards: -12900.5\n",
            "Episode: 990 |                     Train Rewards: -15076.7                     Violations: 50.81947565078735                    Mean Train Rewards: -12902.3\n",
            "Episode: 1000 |                     Train Rewards: -11924.3                     Violations: 18.117889165878296                    Mean Train Rewards: -12883.6\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 16 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 16 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-63/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-64\n",
            "\n",
            "==================================================\n",
            "Starting run 9/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4736.1                     Violations: 70.57235836982728                    Mean Train Rewards: -4789.5\n",
            "Episode:  20 |                     Train Rewards: -4700.8                     Violations: 79.69679355621338                    Mean Train Rewards: -4756.4\n",
            "Episode:  30 |                     Train Rewards: -4673.4                     Violations: 90.6486701965332                    Mean Train Rewards: -4725.8\n",
            "Episode:  40 |                     Train Rewards: -4766.2                     Violations: 53.500337600707994                    Mean Train Rewards: -4730.5\n",
            "Episode:  50 |                     Train Rewards: -4717.8                     Violations: 72.89018154144287                    Mean Train Rewards: -4748.6\n",
            "Episode:  60 |                     Train Rewards: -4960.7                     Violations: 14.311411380767822                    Mean Train Rewards: -4772.0\n",
            "Episode:  70 |                     Train Rewards: -4658.7                     Violations: 96.52316093444824                    Mean Train Rewards: -4767.7\n",
            "Episode:  80 |                     Train Rewards: -4602.2                     Violations: 119.10668134689332                    Mean Train Rewards: -4751.4\n",
            "Episode:  90 |                     Train Rewards: -4636.8                     Violations: 105.29204130172732                    Mean Train Rewards: -4742.0\n",
            "Episode: 100 |                     Train Rewards: -4794.2                     Violations: 55.734848976135254                    Mean Train Rewards: -4739.1\n",
            "Episode: 110 |                     Train Rewards: -4628.3                     Violations: 108.68116140365599                    Mean Train Rewards: -4725.2\n",
            "Episode: 120 |                     Train Rewards: -4625.0                     Violations: 110.01508951187134                    Mean Train Rewards: -4717.0\n",
            "Episode: 130 |                     Train Rewards: -4703.7                     Violations: 78.7666141986847                    Mean Train Rewards: -4716.2\n",
            "Episode: 140 |                     Train Rewards: -4656.7                     Violations: 97.31820344924927                    Mean Train Rewards: -4710.0\n",
            "Episode: 150 |                     Train Rewards: -4610.5                     Violations: 115.79125642776489                    Mean Train Rewards: -4705.7\n",
            "Episode: 160 |                     Train Rewards: -4828.5                     Violations: 37.61382699012756                    Mean Train Rewards: -4689.2\n",
            "Episode: 170 |                     Train Rewards: -5016.6                     Violations: 15.038659572601318                    Mean Train Rewards: -4713.3\n",
            "Episode: 180 |                     Train Rewards: -5324.6                     Violations: 0                    Mean Train Rewards: -4760.4\n",
            "Episode: 190 |                     Train Rewards: -5018.8                     Violations: 16.11035704612732                    Mean Train Rewards: -4796.3\n",
            "Episode: 200 |                     Train Rewards: -5118.5                     Violations: 0                    Mean Train Rewards: -4827.2\n",
            "Episode: 210 |                     Train Rewards: -5210.2                     Violations: 15.250357389450073                    Mean Train Rewards: -4876.7\n",
            "Episode: 220 |                     Train Rewards: -5029.9                     Violations: 11.641093492507935                    Mean Train Rewards: -4920.7\n",
            "Episode: 230 |                     Train Rewards: -5035.9                     Violations: 41.90182447433472                    Mean Train Rewards: -4959.7\n",
            "Episode: 240 |                     Train Rewards: -4690.2                     Violations: 83.91851902008057                    Mean Train Rewards: -4995.6\n",
            "Episode: 250 |                     Train Rewards: -5447.0                     Violations: 0                    Mean Train Rewards: -5026.0\n",
            "Episode: 260 |                     Train Rewards: -5543.7                     Violations: 0                    Mean Train Rewards: -5062.5\n",
            "Episode: 270 |                     Train Rewards: -4929.7                     Violations: 15.594639778137207                    Mean Train Rewards: -5069.7\n",
            "Episode: 280 |                     Train Rewards: -5378.4                     Violations: 0                    Mean Train Rewards: -5064.8\n",
            "Episode: 290 |                     Train Rewards: -4797.0                     Violations: 54.37930226325989                    Mean Train Rewards: -5077.0\n",
            "Episode: 300 |                     Train Rewards: -5132.2                     Violations: 14.0245521068573                    Mean Train Rewards: -5091.1\n",
            "Episode: 310 |                     Train Rewards: -5409.5                     Violations: 0                    Mean Train Rewards: -5090.1\n",
            "Episode: 320 |                     Train Rewards: -5526.2                     Violations: 0                    Mean Train Rewards: -5103.2\n",
            "Episode: 330 |                     Train Rewards: -4851.2                     Violations: 49.22570943832399                    Mean Train Rewards: -5117.6\n",
            "Episode: 340 |                     Train Rewards: -5126.5                     Violations: 0                    Mean Train Rewards: -5139.5\n",
            "Episode: 350 |                     Train Rewards: -5246.6                     Violations: 9.109654426574707                    Mean Train Rewards: -5140.1\n",
            "Episode: 360 |                     Train Rewards: -4916.8                     Violations: 59.528288841247544                    Mean Train Rewards: -5137.4\n",
            "Episode: 370 |                     Train Rewards: -5077.0                     Violations: 46.33016347885132                    Mean Train Rewards: -5148.2\n",
            "Episode: 380 |                     Train Rewards: -4782.7                     Violations: 57.08435773849487                    Mean Train Rewards: -5147.0\n",
            "Episode: 390 |                     Train Rewards: -5519.5                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 400 |                     Train Rewards: -5418.0                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 410 |                     Train Rewards: -4776.9                     Violations: 58.96626114845276                    Mean Train Rewards: -5141.4\n",
            "Episode: 420 |                     Train Rewards: -5040.3                     Violations: 16.395481824874878                    Mean Train Rewards: -5140.2\n",
            "Episode: 430 |                     Train Rewards: -4685.5                     Violations: 85.81982374191284                    Mean Train Rewards: -5098.0\n",
            "Episode: 440 |                     Train Rewards: -4616.0                     Violations: 113.58714818954469                    Mean Train Rewards: -5041.7\n",
            "Episode: 450 |                     Train Rewards: -4636.5                     Violations: 105.40186882019044                    Mean Train Rewards: -4997.4\n",
            "Episode: 460 |                     Train Rewards: -4669.4                     Violations: 92.2599983215332                    Mean Train Rewards: -4957.2\n",
            "Episode: 470 |                     Train Rewards: -4703.4                     Violations: 78.62668752670288                    Mean Train Rewards: -4912.7\n",
            "Episode: 480 |                     Train Rewards: -4691.6                     Violations: 83.36882114410399                    Mean Train Rewards: -4877.6\n",
            "Episode: 490 |                     Train Rewards: -4737.6                     Violations: 64.9736714363098                    Mean Train Rewards: -4837.2\n",
            "Episode: 500 |                     Train Rewards: -4846.2                     Violations: 30.760644674301147                    Mean Train Rewards: -4800.0\n",
            "Episode: 510 |                     Train Rewards: -4878.6                     Violations: 58.28530550003052                    Mean Train Rewards: -4771.4\n",
            "Episode: 520 |                     Train Rewards: -4914.5                     Violations: 38.99128198623657                    Mean Train Rewards: -4740.2\n",
            "Episode: 530 |                     Train Rewards: -4847.2                     Violations: 34.017336368560805                    Mean Train Rewards: -4755.9\n",
            "Episode: 540 |                     Train Rewards: -5046.1                     Violations: 38.36244106292723                    Mean Train Rewards: -4780.5\n",
            "Episode: 550 |                     Train Rewards: -4862.0                     Violations: 55.49348354339598                    Mean Train Rewards: -4803.7\n",
            "Episode: 560 |                     Train Rewards: -5094.2                     Violations: 0                    Mean Train Rewards: -4837.8\n",
            "Episode: 570 |                     Train Rewards: -4765.9                     Violations: 66.43972992897035                    Mean Train Rewards: -4861.8\n",
            "Episode: 580 |                     Train Rewards: -4651.8                     Violations: 99.2690873146057                    Mean Train Rewards: -4868.0\n",
            "Episode: 590 |                     Train Rewards: -4776.8                     Violations: 59.12743806838989                    Mean Train Rewards: -4871.2\n",
            "Episode: 600 |                     Train Rewards: -4757.3                     Violations: 57.090396881103516                    Mean Train Rewards: -4872.7\n",
            "Episode: 610 |                     Train Rewards: -4693.4                     Violations: 82.6213550567627                    Mean Train Rewards: -4871.3\n",
            "Episode: 620 |                     Train Rewards: -4759.0                     Violations: 64.68918919563293                    Mean Train Rewards: -4864.7\n",
            "Episode: 630 |                     Train Rewards: -4784.9                     Violations: 60.62675714492798                    Mean Train Rewards: -4849.2\n",
            "Episode: 640 |                     Train Rewards: -4968.2                     Violations: 11.152561902999878                    Mean Train Rewards: -4841.2\n",
            "Episode: 650 |                     Train Rewards: -5287.8                     Violations: 0                    Mean Train Rewards: -4855.1\n",
            "Episode: 660 |                     Train Rewards: -4656.0                     Violations: 97.58322954177855                    Mean Train Rewards: -4866.4\n",
            "Episode: 670 |                     Train Rewards: -4916.8                     Violations: 33.18828105926514                    Mean Train Rewards: -4873.5\n",
            "Episode: 680 |                     Train Rewards: -5168.1                     Violations: 0                    Mean Train Rewards: -4904.9\n",
            "Episode: 690 |                     Train Rewards: -4956.9                     Violations: 10.634698867797852                    Mean Train Rewards: -4938.0\n",
            "Episode: 700 |                     Train Rewards: -5160.2                     Violations: 0                    Mean Train Rewards: -4985.1\n",
            "Episode: 710 |                     Train Rewards: -5285.8                     Violations: 0                    Mean Train Rewards: -5017.0\n",
            "Episode: 720 |                     Train Rewards: -4943.9                     Violations: 11.228935718536377                    Mean Train Rewards: -5044.8\n",
            "Episode: 730 |                     Train Rewards: -4956.0                     Violations: 14.285036325454712                    Mean Train Rewards: -5059.0\n",
            "Episode: 740 |                     Train Rewards: -4729.5                     Violations: 68.19272756576537                    Mean Train Rewards: -5087.5\n",
            "Episode: 750 |                     Train Rewards: -5302.3                     Violations: 0                    Mean Train Rewards: -5093.9\n",
            "Episode: 760 |                     Train Rewards: -4879.6                     Violations: 25.190228223800645                    Mean Train Rewards: -5086.9\n",
            "Episode: 770 |                     Train Rewards: -5067.4                     Violations: 34.49713945388794                    Mean Train Rewards: -5096.5\n",
            "Episode: 780 |                     Train Rewards: -5215.3                     Violations: 0                    Mean Train Rewards: -5104.1\n",
            "Episode: 790 |                     Train Rewards: -5396.2                     Violations: 0                    Mean Train Rewards: -5114.5\n",
            "Episode: 800 |                     Train Rewards: -5111.9                     Violations: 5.124744176864624                    Mean Train Rewards: -5097.4\n",
            "Episode: 810 |                     Train Rewards: -4673.8                     Violations: 90.48516273498535                    Mean Train Rewards: -5083.6\n",
            "Episode: 820 |                     Train Rewards: -5027.3                     Violations: 8.884021043777466                    Mean Train Rewards: -5084.4\n",
            "Episode: 830 |                     Train Rewards: -4992.1                     Violations: 13.484432697296143                    Mean Train Rewards: -5107.7\n",
            "Episode: 840 |                     Train Rewards: -5060.7                     Violations: 28.209457397460938                    Mean Train Rewards: -5099.5\n",
            "Episode: 850 |                     Train Rewards: -5077.5                     Violations: 10.43190598487854                    Mean Train Rewards: -5094.4\n",
            "Episode: 860 |                     Train Rewards: -5110.7                     Violations: 43.15834999084473                    Mean Train Rewards: -5107.7\n",
            "Episode: 870 |                     Train Rewards: -5360.6                     Violations: 0                    Mean Train Rewards: -5102.4\n",
            "Episode: 880 |                     Train Rewards: -4930.8                     Violations: 13.848464488983154                    Mean Train Rewards: -5090.4\n",
            "Episode: 890 |                     Train Rewards: -5239.8                     Violations: 10.418298244476318                    Mean Train Rewards: -5086.4\n",
            "Episode: 900 |                     Train Rewards: -4644.6                     Violations: 102.1556210517883                    Mean Train Rewards: -5073.6\n",
            "Episode: 910 |                     Train Rewards: -5075.5                     Violations: 0.9277546405792236                    Mean Train Rewards: -5087.9\n",
            "Episode: 920 |                     Train Rewards: -5095.6                     Violations: 1.4103615283965993                    Mean Train Rewards: -5089.6\n",
            "Episode: 930 |                     Train Rewards: -5152.4                     Violations: 37.0959734916687                    Mean Train Rewards: -5089.6\n",
            "Episode: 940 |                     Train Rewards: -5226.8                     Violations: 3.022887706756592                    Mean Train Rewards: -5089.8\n",
            "Episode: 950 |                     Train Rewards: -4760.2                     Violations: 55.92338562011717                    Mean Train Rewards: -5084.2\n",
            "Episode: 960 |                     Train Rewards: -5167.0                     Violations: 19.515361785888672                    Mean Train Rewards: -5086.7\n",
            "Episode: 970 |                     Train Rewards: -5019.2                     Violations: 36.360952854156494                    Mean Train Rewards: -5082.8\n",
            "Episode: 980 |                     Train Rewards: -5248.6                     Violations: 0                    Mean Train Rewards: -5099.2\n",
            "Episode: 990 |                     Train Rewards: -5073.3                     Violations: 7.821264266967773                    Mean Train Rewards: -5092.9\n",
            "Episode: 1000 |                     Train Rewards: -5040.9                     Violations: 25.249216556549072                    Mean Train Rewards: -5107.0\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 26 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 26 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-64/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-65\n",
            "\n",
            "==================================================\n",
            "Starting run 10/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -11793.4                     Violations: 70.57235836982728                    Mean Train Rewards: -10020.9\n",
            "Episode:  20 |                     Train Rewards: -12670.4                     Violations: 79.69679355621338                    Mean Train Rewards: -11015.5\n",
            "Episode:  30 |                     Train Rewards: -13738.2                     Violations: 90.6486701965332                    Mean Train Rewards: -12037.1\n",
            "Episode:  40 |                     Train Rewards: -10116.3                     Violations: 53.500337600707994                    Mean Train Rewards: -11866.6\n",
            "Episode:  50 |                     Train Rewards: -12006.8                     Violations: 72.89018154144287                    Mean Train Rewards: -11341.8\n",
            "Episode:  60 |                     Train Rewards: -6391.8                     Violations: 14.311411380767822                    Mean Train Rewards: -10676.9\n",
            "Episode:  70 |                     Train Rewards: -14311.0                     Violations: 96.52316093444824                    Mean Train Rewards: -10820.5\n",
            "Episode:  80 |                     Train Rewards: -16512.9                     Violations: 119.10668134689332                    Mean Train Rewards: -11363.1\n",
            "Episode:  90 |                     Train Rewards: -15166.0                     Violations: 105.29204130172732                    Mean Train Rewards: -11658.1\n",
            "Episode: 100 |                     Train Rewards: -10367.7                     Violations: 55.734848976135254                    Mean Train Rewards: -11733.5\n",
            "Episode: 110 |                     Train Rewards: -15496.4                     Violations: 108.68116140365599                    Mean Train Rewards: -12196.7\n",
            "Episode: 120 |                     Train Rewards: -15626.5                     Violations: 110.01508951187134                    Mean Train Rewards: -12494.3\n",
            "Episode: 130 |                     Train Rewards: -12580.3                     Violations: 78.7666141986847                    Mean Train Rewards: -12523.6\n",
            "Episode: 140 |                     Train Rewards: -14388.5                     Violations: 97.31820344924927                    Mean Train Rewards: -12737.0\n",
            "Episode: 150 |                     Train Rewards: -16189.6                     Violations: 115.79125642776489                    Mean Train Rewards: -12895.0\n",
            "Episode: 160 |                     Train Rewards: -8589.9                     Violations: 37.61382699012756                    Mean Train Rewards: -13355.1\n",
            "Episode: 170 |                     Train Rewards: -6520.4                     Violations: 15.038659572601318                    Mean Train Rewards: -13000.8\n",
            "Episode: 180 |                     Train Rewards: -5324.6                     Violations: 0                    Mean Train Rewards: -12256.3\n",
            "Episode: 190 |                     Train Rewards: -6629.9                     Violations: 16.11035704612732                    Mean Train Rewards: -11609.1\n",
            "Episode: 200 |                     Train Rewards: -5118.5                     Violations: 0                    Mean Train Rewards: -11096.2\n",
            "Episode: 210 |                     Train Rewards: -6735.2                     Violations: 15.250357389450073                    Mean Train Rewards: -10287.7\n",
            "Episode: 220 |                     Train Rewards: -6194.0                     Violations: 11.641093492507935                    Mean Train Rewards: -9551.7\n",
            "Episode: 230 |                     Train Rewards: -9226.1                     Violations: 41.90182447433472                    Mean Train Rewards: -8847.3\n",
            "Episode: 240 |                     Train Rewards: -13082.1                     Violations: 83.91851902008057                    Mean Train Rewards: -8248.1\n",
            "Episode: 250 |                     Train Rewards: -5447.0                     Violations: 0                    Mean Train Rewards: -7972.7\n",
            "Episode: 260 |                     Train Rewards: -5543.7                     Violations: 0                    Mean Train Rewards: -7466.1\n",
            "Episode: 270 |                     Train Rewards: -6489.2                     Violations: 15.594639778137207                    Mean Train Rewards: -7393.0\n",
            "Episode: 280 |                     Train Rewards: -5378.4                     Violations: 0                    Mean Train Rewards: -7372.0\n",
            "Episode: 290 |                     Train Rewards: -10234.9                     Violations: 54.37930226325989                    Mean Train Rewards: -7296.0\n",
            "Episode: 300 |                     Train Rewards: -6534.6                     Violations: 14.0245521068573                    Mean Train Rewards: -7151.6\n",
            "Episode: 310 |                     Train Rewards: -5409.5                     Violations: 0                    Mean Train Rewards: -7265.3\n",
            "Episode: 320 |                     Train Rewards: -5526.2                     Violations: 0                    Mean Train Rewards: -7151.9\n",
            "Episode: 330 |                     Train Rewards: -9773.8                     Violations: 49.22570943832399                    Mean Train Rewards: -7104.7\n",
            "Episode: 340 |                     Train Rewards: -5126.5                     Violations: 0                    Mean Train Rewards: -6934.9\n",
            "Episode: 350 |                     Train Rewards: -6157.6                     Violations: 9.109654426574707                    Mean Train Rewards: -6818.8\n",
            "Episode: 360 |                     Train Rewards: -10869.7                     Violations: 59.528288841247544                    Mean Train Rewards: -6850.7\n",
            "Episode: 370 |                     Train Rewards: -9710.0                     Violations: 46.33016347885132                    Mean Train Rewards: -6756.8\n",
            "Episode: 380 |                     Train Rewards: -10491.1                     Violations: 57.08435773849487                    Mean Train Rewards: -6749.3\n",
            "Episode: 390 |                     Train Rewards: -5519.5                     Violations: 0                    Mean Train Rewards: -6769.2\n",
            "Episode: 400 |                     Train Rewards: -5418.0                     Violations: 0                    Mean Train Rewards: -6814.8\n",
            "Episode: 410 |                     Train Rewards: -10673.5                     Violations: 58.96626114845276                    Mean Train Rewards: -6712.9\n",
            "Episode: 420 |                     Train Rewards: -6679.8                     Violations: 16.395481824874878                    Mean Train Rewards: -6696.1\n",
            "Episode: 430 |                     Train Rewards: -13267.4                     Violations: 85.81982374191284                    Mean Train Rewards: -7099.0\n",
            "Episode: 440 |                     Train Rewards: -15974.7                     Violations: 113.58714818954469                    Mean Train Rewards: -7815.2\n",
            "Episode: 450 |                     Train Rewards: -15176.7                     Violations: 105.40186882019044                    Mean Train Rewards: -8612.1\n",
            "Episode: 460 |                     Train Rewards: -13895.3                     Violations: 92.2599983215332                    Mean Train Rewards: -9316.1\n",
            "Episode: 470 |                     Train Rewards: -12566.1                     Violations: 78.62668752670288                    Mean Train Rewards: -9943.9\n",
            "Episode: 480 |                     Train Rewards: -13028.5                     Violations: 83.36882114410399                    Mean Train Rewards: -10502.7\n",
            "Episode: 490 |                     Train Rewards: -11234.9                     Violations: 64.9736714363098                    Mean Train Rewards: -11035.3\n",
            "Episode: 500 |                     Train Rewards: -7922.3                     Violations: 30.760644674301147                    Mean Train Rewards: -11510.9\n",
            "Episode: 510 |                     Train Rewards: -10707.2                     Violations: 58.28530550003052                    Mean Train Rewards: -11900.6\n",
            "Episode: 520 |                     Train Rewards: -8813.6                     Violations: 38.99128198623657                    Mean Train Rewards: -12201.0\n",
            "Episode: 530 |                     Train Rewards: -8249.0                     Violations: 34.017336368560805                    Mean Train Rewards: -12013.9\n",
            "Episode: 540 |                     Train Rewards: -8882.3                     Violations: 38.36244106292723                    Mean Train Rewards: -11521.2\n",
            "Episode: 550 |                     Train Rewards: -10411.4                     Violations: 55.49348354339598                    Mean Train Rewards: -10949.3\n",
            "Episode: 560 |                     Train Rewards: -5094.2                     Violations: 0                    Mean Train Rewards: -10333.6\n",
            "Episode: 570 |                     Train Rewards: -11409.9                     Violations: 66.43972992897035                    Mean Train Rewards: -9865.3\n",
            "Episode: 580 |                     Train Rewards: -14578.7                     Violations: 99.2690873146057                    Mean Train Rewards: -9711.3\n",
            "Episode: 590 |                     Train Rewards: -10689.6                     Violations: 59.12743806838989                    Mean Train Rewards: -9607.4\n",
            "Episode: 600 |                     Train Rewards: -10466.3                     Violations: 57.090396881103516                    Mean Train Rewards: -9559.2\n",
            "Episode: 610 |                     Train Rewards: -12955.6                     Violations: 82.6213550567627                    Mean Train Rewards: -9534.8\n",
            "Episode: 620 |                     Train Rewards: -11227.9                     Violations: 64.68918919563293                    Mean Train Rewards: -9609.0\n",
            "Episode: 630 |                     Train Rewards: -10847.6                     Violations: 60.62675714492798                    Mean Train Rewards: -9794.3\n",
            "Episode: 640 |                     Train Rewards: -6083.4                     Violations: 11.152561902999878                    Mean Train Rewards: -9867.7\n",
            "Episode: 650 |                     Train Rewards: -5287.8                     Violations: 0                    Mean Train Rewards: -9723.6\n",
            "Episode: 660 |                     Train Rewards: -14414.4                     Violations: 97.58322954177855                    Mean Train Rewards: -9649.7\n",
            "Episode: 670 |                     Train Rewards: -8235.7                     Violations: 33.18828105926514                    Mean Train Rewards: -9613.3\n",
            "Episode: 680 |                     Train Rewards: -5168.1                     Violations: 0                    Mean Train Rewards: -9268.0\n",
            "Episode: 690 |                     Train Rewards: -6020.4                     Violations: 10.634698867797852                    Mean Train Rewards: -8842.4\n",
            "Episode: 700 |                     Train Rewards: -5160.2                     Violations: 0                    Mean Train Rewards: -8380.2\n",
            "Episode: 710 |                     Train Rewards: -5285.8                     Violations: 0                    Mean Train Rewards: -8000.0\n",
            "Episode: 720 |                     Train Rewards: -6066.7                     Violations: 11.228935718536377                    Mean Train Rewards: -7677.4\n",
            "Episode: 730 |                     Train Rewards: -6384.5                     Violations: 14.285036325454712                    Mean Train Rewards: -7499.5\n",
            "Episode: 740 |                     Train Rewards: -11548.8                     Violations: 68.19272756576537                    Mean Train Rewards: -7314.7\n",
            "Episode: 750 |                     Train Rewards: -5302.3                     Violations: 0                    Mean Train Rewards: -7244.0\n",
            "Episode: 760 |                     Train Rewards: -7398.6                     Violations: 25.190228223800645                    Mean Train Rewards: -7294.2\n",
            "Episode: 770 |                     Train Rewards: -8517.1                     Violations: 34.49713945388794                    Mean Train Rewards: -7304.9\n",
            "Episode: 780 |                     Train Rewards: -5215.3                     Violations: 0                    Mean Train Rewards: -7150.4\n",
            "Episode: 790 |                     Train Rewards: -5396.2                     Violations: 0                    Mean Train Rewards: -7060.1\n",
            "Episode: 800 |                     Train Rewards: -5624.4                     Violations: 5.124744176864624                    Mean Train Rewards: -7127.8\n",
            "Episode: 810 |                     Train Rewards: -13722.3                     Violations: 90.48516273498535                    Mean Train Rewards: -7329.3\n",
            "Episode: 820 |                     Train Rewards: -5915.7                     Violations: 8.884021043777466                    Mean Train Rewards: -7353.4\n",
            "Episode: 830 |                     Train Rewards: -6340.5                     Violations: 13.484432697296143                    Mean Train Rewards: -7109.5\n",
            "Episode: 840 |                     Train Rewards: -7881.6                     Violations: 28.209457397460938                    Mean Train Rewards: -7121.5\n",
            "Episode: 850 |                     Train Rewards: -6120.7                     Violations: 10.43190598487854                    Mean Train Rewards: -7120.7\n",
            "Episode: 860 |                     Train Rewards: -9426.5                     Violations: 43.15834999084473                    Mean Train Rewards: -6933.3\n",
            "Episode: 870 |                     Train Rewards: -5360.6                     Violations: 0                    Mean Train Rewards: -6925.2\n",
            "Episode: 880 |                     Train Rewards: -6315.6                     Violations: 13.848464488983154                    Mean Train Rewards: -7038.1\n",
            "Episode: 890 |                     Train Rewards: -6281.6                     Violations: 10.418298244476318                    Mean Train Rewards: -7078.5\n",
            "Episode: 900 |                     Train Rewards: -14860.2                     Violations: 102.1556210517883                    Mean Train Rewards: -7313.6\n",
            "Episode: 910 |                     Train Rewards: -5168.3                     Violations: 0.9277546405792236                    Mean Train Rewards: -7144.4\n",
            "Episode: 920 |                     Train Rewards: -5236.6                     Violations: 1.4103615283965993                    Mean Train Rewards: -7174.1\n",
            "Episode: 930 |                     Train Rewards: -8862.0                     Violations: 37.0959734916687                    Mean Train Rewards: -7169.3\n",
            "Episode: 940 |                     Train Rewards: -5529.1                     Violations: 3.022887706756592                    Mean Train Rewards: -7141.2\n",
            "Episode: 950 |                     Train Rewards: -10352.5                     Violations: 55.92338562011717                    Mean Train Rewards: -7269.6\n",
            "Episode: 960 |                     Train Rewards: -7118.6                     Violations: 19.515361785888672                    Mean Train Rewards: -7340.4\n",
            "Episode: 970 |                     Train Rewards: -8655.3                     Violations: 36.360952854156494                    Mean Train Rewards: -7391.7\n",
            "Episode: 980 |                     Train Rewards: -5248.6                     Violations: 0                    Mean Train Rewards: -7247.0\n",
            "Episode: 990 |                     Train Rewards: -5855.4                     Violations: 7.821264266967773                    Mean Train Rewards: -7259.7\n",
            "Episode: 1000 |                     Train Rewards: -7565.8                     Violations: 25.249216556549072                    Mean Train Rewards: -7045.3\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-65/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-66\n",
            "\n",
            "==================================================\n",
            "Starting run 11/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4736.1                     Violations: 70.57235836982728                    Mean Train Rewards: -4789.5\n",
            "Episode:  20 |                     Train Rewards: -4700.8                     Violations: 79.69679355621338                    Mean Train Rewards: -4756.4\n",
            "Episode:  30 |                     Train Rewards: -4673.4                     Violations: 90.6486701965332                    Mean Train Rewards: -4725.8\n",
            "Episode:  40 |                     Train Rewards: -4766.2                     Violations: 53.500337600707994                    Mean Train Rewards: -4730.5\n",
            "Episode:  50 |                     Train Rewards: -4717.8                     Violations: 72.89018154144287                    Mean Train Rewards: -4748.6\n",
            "Episode:  60 |                     Train Rewards: -4960.7                     Violations: 14.311411380767822                    Mean Train Rewards: -4772.0\n",
            "Episode:  70 |                     Train Rewards: -4658.7                     Violations: 96.52316093444824                    Mean Train Rewards: -4767.7\n",
            "Episode:  80 |                     Train Rewards: -4602.2                     Violations: 119.10668134689332                    Mean Train Rewards: -4751.4\n",
            "Episode:  90 |                     Train Rewards: -4636.8                     Violations: 105.29204130172732                    Mean Train Rewards: -4742.0\n",
            "Episode: 100 |                     Train Rewards: -4794.2                     Violations: 55.734848976135254                    Mean Train Rewards: -4739.1\n",
            "Episode: 110 |                     Train Rewards: -4628.3                     Violations: 108.68116140365599                    Mean Train Rewards: -4725.2\n",
            "Episode: 120 |                     Train Rewards: -4625.0                     Violations: 110.01508951187134                    Mean Train Rewards: -4717.0\n",
            "Episode: 130 |                     Train Rewards: -4703.7                     Violations: 78.7666141986847                    Mean Train Rewards: -4716.2\n",
            "Episode: 140 |                     Train Rewards: -4656.7                     Violations: 97.31820344924927                    Mean Train Rewards: -4710.0\n",
            "Episode: 150 |                     Train Rewards: -4610.5                     Violations: 115.79125642776489                    Mean Train Rewards: -4705.7\n",
            "Episode: 160 |                     Train Rewards: -4828.5                     Violations: 37.61382699012756                    Mean Train Rewards: -4689.2\n",
            "Episode: 170 |                     Train Rewards: -5016.6                     Violations: 15.038659572601318                    Mean Train Rewards: -4713.3\n",
            "Episode: 180 |                     Train Rewards: -5324.6                     Violations: 0                    Mean Train Rewards: -4760.4\n",
            "Episode: 190 |                     Train Rewards: -5018.8                     Violations: 16.11035704612732                    Mean Train Rewards: -4796.3\n",
            "Episode: 200 |                     Train Rewards: -5118.5                     Violations: 0                    Mean Train Rewards: -4827.2\n",
            "Episode: 210 |                     Train Rewards: -5210.2                     Violations: 15.250357389450073                    Mean Train Rewards: -4876.7\n",
            "Episode: 220 |                     Train Rewards: -5029.9                     Violations: 11.641093492507935                    Mean Train Rewards: -4920.7\n",
            "Episode: 230 |                     Train Rewards: -5035.9                     Violations: 41.90182447433472                    Mean Train Rewards: -4959.7\n",
            "Episode: 240 |                     Train Rewards: -4690.2                     Violations: 83.91851902008057                    Mean Train Rewards: -4995.6\n",
            "Episode: 250 |                     Train Rewards: -5447.0                     Violations: 0                    Mean Train Rewards: -5026.0\n",
            "Episode: 260 |                     Train Rewards: -5543.7                     Violations: 0                    Mean Train Rewards: -5062.5\n",
            "Episode: 270 |                     Train Rewards: -4929.7                     Violations: 15.594639778137207                    Mean Train Rewards: -5069.7\n",
            "Episode: 280 |                     Train Rewards: -5378.4                     Violations: 0                    Mean Train Rewards: -5064.8\n",
            "Episode: 290 |                     Train Rewards: -4797.0                     Violations: 54.37930226325989                    Mean Train Rewards: -5077.0\n",
            "Episode: 300 |                     Train Rewards: -5132.2                     Violations: 14.0245521068573                    Mean Train Rewards: -5091.1\n",
            "Episode: 310 |                     Train Rewards: -5409.5                     Violations: 0                    Mean Train Rewards: -5090.1\n",
            "Episode: 320 |                     Train Rewards: -5526.2                     Violations: 0                    Mean Train Rewards: -5103.2\n",
            "Episode: 330 |                     Train Rewards: -4851.2                     Violations: 49.22570943832399                    Mean Train Rewards: -5117.6\n",
            "Episode: 340 |                     Train Rewards: -5126.5                     Violations: 0                    Mean Train Rewards: -5139.5\n",
            "Episode: 350 |                     Train Rewards: -5246.6                     Violations: 9.109654426574707                    Mean Train Rewards: -5140.1\n",
            "Episode: 360 |                     Train Rewards: -4916.8                     Violations: 59.528288841247544                    Mean Train Rewards: -5137.4\n",
            "Episode: 370 |                     Train Rewards: -5077.0                     Violations: 46.33016347885132                    Mean Train Rewards: -5148.2\n",
            "Episode: 380 |                     Train Rewards: -4782.7                     Violations: 57.08435773849487                    Mean Train Rewards: -5147.0\n",
            "Episode: 390 |                     Train Rewards: -5519.5                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 400 |                     Train Rewards: -5418.0                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 410 |                     Train Rewards: -4776.9                     Violations: 58.96626114845276                    Mean Train Rewards: -5141.4\n",
            "Episode: 420 |                     Train Rewards: -5040.3                     Violations: 16.395481824874878                    Mean Train Rewards: -5140.2\n",
            "Episode: 430 |                     Train Rewards: -4685.5                     Violations: 85.81982374191284                    Mean Train Rewards: -5098.0\n",
            "Episode: 440 |                     Train Rewards: -4616.0                     Violations: 113.58714818954469                    Mean Train Rewards: -5041.7\n",
            "Episode: 450 |                     Train Rewards: -4636.5                     Violations: 105.40186882019044                    Mean Train Rewards: -4997.4\n",
            "Episode: 460 |                     Train Rewards: -4669.4                     Violations: 92.2599983215332                    Mean Train Rewards: -4957.2\n",
            "Episode: 470 |                     Train Rewards: -4703.4                     Violations: 78.62668752670288                    Mean Train Rewards: -4912.7\n",
            "Episode: 480 |                     Train Rewards: -4691.6                     Violations: 83.36882114410399                    Mean Train Rewards: -4877.6\n",
            "Episode: 490 |                     Train Rewards: -4737.6                     Violations: 64.9736714363098                    Mean Train Rewards: -4837.2\n",
            "Episode: 500 |                     Train Rewards: -4846.2                     Violations: 30.760644674301147                    Mean Train Rewards: -4800.0\n",
            "Episode: 510 |                     Train Rewards: -4878.6                     Violations: 58.28530550003052                    Mean Train Rewards: -4771.4\n",
            "Episode: 520 |                     Train Rewards: -4914.5                     Violations: 38.99128198623657                    Mean Train Rewards: -4740.2\n",
            "Episode: 530 |                     Train Rewards: -4847.2                     Violations: 34.017336368560805                    Mean Train Rewards: -4755.9\n",
            "Episode: 540 |                     Train Rewards: -5046.1                     Violations: 38.36244106292723                    Mean Train Rewards: -4780.5\n",
            "Episode: 550 |                     Train Rewards: -4862.0                     Violations: 55.49348354339598                    Mean Train Rewards: -4803.7\n",
            "Episode: 560 |                     Train Rewards: -5094.2                     Violations: 0                    Mean Train Rewards: -4837.8\n",
            "Episode: 570 |                     Train Rewards: -4765.9                     Violations: 66.43972992897035                    Mean Train Rewards: -4861.8\n",
            "Episode: 580 |                     Train Rewards: -4651.8                     Violations: 99.2690873146057                    Mean Train Rewards: -4868.0\n",
            "Episode: 590 |                     Train Rewards: -4776.8                     Violations: 59.12743806838989                    Mean Train Rewards: -4871.2\n",
            "Episode: 600 |                     Train Rewards: -4757.3                     Violations: 57.090396881103516                    Mean Train Rewards: -4872.7\n",
            "Episode: 610 |                     Train Rewards: -4693.4                     Violations: 82.6213550567627                    Mean Train Rewards: -4871.3\n",
            "Episode: 620 |                     Train Rewards: -4759.0                     Violations: 64.68918919563293                    Mean Train Rewards: -4864.7\n",
            "Episode: 630 |                     Train Rewards: -4784.9                     Violations: 60.62675714492798                    Mean Train Rewards: -4849.2\n",
            "Episode: 640 |                     Train Rewards: -4968.2                     Violations: 11.152561902999878                    Mean Train Rewards: -4841.2\n",
            "Episode: 650 |                     Train Rewards: -5287.8                     Violations: 0                    Mean Train Rewards: -4855.1\n",
            "Episode: 660 |                     Train Rewards: -4656.0                     Violations: 97.58322954177855                    Mean Train Rewards: -4866.4\n",
            "Episode: 670 |                     Train Rewards: -4916.8                     Violations: 33.18828105926514                    Mean Train Rewards: -4873.5\n",
            "Episode: 680 |                     Train Rewards: -5168.1                     Violations: 0                    Mean Train Rewards: -4904.9\n",
            "Episode: 690 |                     Train Rewards: -4956.9                     Violations: 10.634698867797852                    Mean Train Rewards: -4938.0\n",
            "Episode: 700 |                     Train Rewards: -5160.2                     Violations: 0                    Mean Train Rewards: -4985.1\n",
            "Episode: 710 |                     Train Rewards: -5285.8                     Violations: 0                    Mean Train Rewards: -5017.0\n",
            "Episode: 720 |                     Train Rewards: -4943.9                     Violations: 11.228935718536377                    Mean Train Rewards: -5044.8\n",
            "Episode: 730 |                     Train Rewards: -4956.0                     Violations: 14.285036325454712                    Mean Train Rewards: -5059.0\n",
            "Episode: 740 |                     Train Rewards: -4729.5                     Violations: 68.19272756576537                    Mean Train Rewards: -5087.5\n",
            "Episode: 750 |                     Train Rewards: -5302.3                     Violations: 0                    Mean Train Rewards: -5093.9\n",
            "Episode: 760 |                     Train Rewards: -4879.6                     Violations: 25.190228223800645                    Mean Train Rewards: -5086.9\n",
            "Episode: 770 |                     Train Rewards: -5067.4                     Violations: 34.49713945388794                    Mean Train Rewards: -5096.5\n",
            "Episode: 780 |                     Train Rewards: -5215.3                     Violations: 0                    Mean Train Rewards: -5104.1\n",
            "Episode: 790 |                     Train Rewards: -5396.2                     Violations: 0                    Mean Train Rewards: -5114.5\n",
            "Episode: 800 |                     Train Rewards: -5111.9                     Violations: 5.124744176864624                    Mean Train Rewards: -5097.4\n",
            "Episode: 810 |                     Train Rewards: -4673.8                     Violations: 90.48516273498535                    Mean Train Rewards: -5083.6\n",
            "Episode: 820 |                     Train Rewards: -5027.3                     Violations: 8.884021043777466                    Mean Train Rewards: -5084.4\n",
            "Episode: 830 |                     Train Rewards: -4992.1                     Violations: 13.484432697296143                    Mean Train Rewards: -5107.7\n",
            "Episode: 840 |                     Train Rewards: -5060.7                     Violations: 28.209457397460938                    Mean Train Rewards: -5099.5\n",
            "Episode: 850 |                     Train Rewards: -5077.5                     Violations: 10.43190598487854                    Mean Train Rewards: -5094.4\n",
            "Episode: 860 |                     Train Rewards: -5110.7                     Violations: 43.15834999084473                    Mean Train Rewards: -5107.7\n",
            "Episode: 870 |                     Train Rewards: -5360.6                     Violations: 0                    Mean Train Rewards: -5102.4\n",
            "Episode: 880 |                     Train Rewards: -4930.8                     Violations: 13.848464488983154                    Mean Train Rewards: -5090.4\n",
            "Episode: 890 |                     Train Rewards: -5239.8                     Violations: 10.418298244476318                    Mean Train Rewards: -5086.4\n",
            "Episode: 900 |                     Train Rewards: -4644.6                     Violations: 102.1556210517883                    Mean Train Rewards: -5073.6\n",
            "Episode: 910 |                     Train Rewards: -5075.5                     Violations: 0.9277546405792236                    Mean Train Rewards: -5087.9\n",
            "Episode: 920 |                     Train Rewards: -5095.6                     Violations: 1.4103615283965993                    Mean Train Rewards: -5089.6\n",
            "Episode: 930 |                     Train Rewards: -5152.4                     Violations: 37.0959734916687                    Mean Train Rewards: -5089.6\n",
            "Episode: 940 |                     Train Rewards: -5226.8                     Violations: 3.022887706756592                    Mean Train Rewards: -5089.8\n",
            "Episode: 950 |                     Train Rewards: -4760.2                     Violations: 55.92338562011717                    Mean Train Rewards: -5084.2\n",
            "Episode: 960 |                     Train Rewards: -5167.0                     Violations: 19.515361785888672                    Mean Train Rewards: -5086.7\n",
            "Episode: 970 |                     Train Rewards: -5019.2                     Violations: 36.360952854156494                    Mean Train Rewards: -5082.8\n",
            "Episode: 980 |                     Train Rewards: -5248.6                     Violations: 0                    Mean Train Rewards: -5099.2\n",
            "Episode: 990 |                     Train Rewards: -5073.3                     Violations: 7.821264266967773                    Mean Train Rewards: -5092.9\n",
            "Episode: 1000 |                     Train Rewards: -5040.9                     Violations: 25.249216556549072                    Mean Train Rewards: -5107.0\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 20 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 20 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-66/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-67\n",
            "\n",
            "==================================================\n",
            "Starting run 12/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -11793.4                     Violations: 70.57235836982728                    Mean Train Rewards: -10020.9\n",
            "Episode:  20 |                     Train Rewards: -12670.4                     Violations: 79.69679355621338                    Mean Train Rewards: -11015.5\n",
            "Episode:  30 |                     Train Rewards: -13738.2                     Violations: 90.6486701965332                    Mean Train Rewards: -12037.1\n",
            "Episode:  40 |                     Train Rewards: -10116.3                     Violations: 53.500337600707994                    Mean Train Rewards: -11866.6\n",
            "Episode:  50 |                     Train Rewards: -12006.8                     Violations: 72.89018154144287                    Mean Train Rewards: -11341.8\n",
            "Episode:  60 |                     Train Rewards: -6391.8                     Violations: 14.311411380767822                    Mean Train Rewards: -10676.9\n",
            "Episode:  70 |                     Train Rewards: -14311.0                     Violations: 96.52316093444824                    Mean Train Rewards: -10820.5\n",
            "Episode:  80 |                     Train Rewards: -16512.9                     Violations: 119.10668134689332                    Mean Train Rewards: -11363.1\n",
            "Episode:  90 |                     Train Rewards: -15166.0                     Violations: 105.29204130172732                    Mean Train Rewards: -11658.1\n",
            "Episode: 100 |                     Train Rewards: -10367.7                     Violations: 55.734848976135254                    Mean Train Rewards: -11733.5\n",
            "Episode: 110 |                     Train Rewards: -15496.4                     Violations: 108.68116140365599                    Mean Train Rewards: -12196.7\n",
            "Episode: 120 |                     Train Rewards: -15626.5                     Violations: 110.01508951187134                    Mean Train Rewards: -12494.3\n",
            "Episode: 130 |                     Train Rewards: -12580.3                     Violations: 78.7666141986847                    Mean Train Rewards: -12523.6\n",
            "Episode: 140 |                     Train Rewards: -14388.5                     Violations: 97.31820344924927                    Mean Train Rewards: -12737.0\n",
            "Episode: 150 |                     Train Rewards: -16189.6                     Violations: 115.79125642776489                    Mean Train Rewards: -12895.0\n",
            "Episode: 160 |                     Train Rewards: -8589.9                     Violations: 37.61382699012756                    Mean Train Rewards: -13355.1\n",
            "Episode: 170 |                     Train Rewards: -6520.4                     Violations: 15.038659572601318                    Mean Train Rewards: -13000.8\n",
            "Episode: 180 |                     Train Rewards: -5324.6                     Violations: 0                    Mean Train Rewards: -12256.3\n",
            "Episode: 190 |                     Train Rewards: -6629.9                     Violations: 16.11035704612732                    Mean Train Rewards: -11609.1\n",
            "Episode: 200 |                     Train Rewards: -5118.5                     Violations: 0                    Mean Train Rewards: -11096.2\n",
            "Episode: 210 |                     Train Rewards: -6735.2                     Violations: 15.250357389450073                    Mean Train Rewards: -10287.7\n",
            "Episode: 220 |                     Train Rewards: -6194.0                     Violations: 11.641093492507935                    Mean Train Rewards: -9551.7\n",
            "Episode: 230 |                     Train Rewards: -9226.1                     Violations: 41.90182447433472                    Mean Train Rewards: -8847.3\n",
            "Episode: 240 |                     Train Rewards: -13082.1                     Violations: 83.91851902008057                    Mean Train Rewards: -8248.1\n",
            "Episode: 250 |                     Train Rewards: -5447.0                     Violations: 0                    Mean Train Rewards: -7972.7\n",
            "Episode: 260 |                     Train Rewards: -5543.7                     Violations: 0                    Mean Train Rewards: -7466.1\n",
            "Episode: 270 |                     Train Rewards: -6489.2                     Violations: 15.594639778137207                    Mean Train Rewards: -7393.0\n",
            "Episode: 280 |                     Train Rewards: -5378.4                     Violations: 0                    Mean Train Rewards: -7372.0\n",
            "Episode: 290 |                     Train Rewards: -10234.9                     Violations: 54.37930226325989                    Mean Train Rewards: -7296.0\n",
            "Episode: 300 |                     Train Rewards: -6534.6                     Violations: 14.0245521068573                    Mean Train Rewards: -7151.6\n",
            "Episode: 310 |                     Train Rewards: -5409.5                     Violations: 0                    Mean Train Rewards: -7265.3\n",
            "Episode: 320 |                     Train Rewards: -5526.2                     Violations: 0                    Mean Train Rewards: -7151.9\n",
            "Episode: 330 |                     Train Rewards: -9773.8                     Violations: 49.22570943832399                    Mean Train Rewards: -7104.7\n",
            "Episode: 340 |                     Train Rewards: -5126.5                     Violations: 0                    Mean Train Rewards: -6934.9\n",
            "Episode: 350 |                     Train Rewards: -6157.6                     Violations: 9.109654426574707                    Mean Train Rewards: -6818.8\n",
            "Episode: 360 |                     Train Rewards: -10869.7                     Violations: 59.528288841247544                    Mean Train Rewards: -6850.7\n",
            "Episode: 370 |                     Train Rewards: -9710.0                     Violations: 46.33016347885132                    Mean Train Rewards: -6756.8\n",
            "Episode: 380 |                     Train Rewards: -10491.1                     Violations: 57.08435773849487                    Mean Train Rewards: -6749.3\n",
            "Episode: 390 |                     Train Rewards: -5519.5                     Violations: 0                    Mean Train Rewards: -6769.2\n",
            "Episode: 400 |                     Train Rewards: -5418.0                     Violations: 0                    Mean Train Rewards: -6814.8\n",
            "Episode: 410 |                     Train Rewards: -10673.5                     Violations: 58.96626114845276                    Mean Train Rewards: -6712.9\n",
            "Episode: 420 |                     Train Rewards: -6679.8                     Violations: 16.395481824874878                    Mean Train Rewards: -6696.1\n",
            "Episode: 430 |                     Train Rewards: -13267.4                     Violations: 85.81982374191284                    Mean Train Rewards: -7099.0\n",
            "Episode: 440 |                     Train Rewards: -15974.7                     Violations: 113.58714818954469                    Mean Train Rewards: -7815.2\n",
            "Episode: 450 |                     Train Rewards: -15176.7                     Violations: 105.40186882019044                    Mean Train Rewards: -8612.1\n",
            "Episode: 460 |                     Train Rewards: -13895.3                     Violations: 92.2599983215332                    Mean Train Rewards: -9316.1\n",
            "Episode: 470 |                     Train Rewards: -12566.1                     Violations: 78.62668752670288                    Mean Train Rewards: -9943.9\n",
            "Episode: 480 |                     Train Rewards: -13028.5                     Violations: 83.36882114410399                    Mean Train Rewards: -10502.7\n",
            "Episode: 490 |                     Train Rewards: -11234.9                     Violations: 64.9736714363098                    Mean Train Rewards: -11035.3\n",
            "Episode: 500 |                     Train Rewards: -7922.3                     Violations: 30.760644674301147                    Mean Train Rewards: -11510.9\n",
            "Episode: 510 |                     Train Rewards: -10707.2                     Violations: 58.28530550003052                    Mean Train Rewards: -11900.6\n",
            "Episode: 520 |                     Train Rewards: -8813.6                     Violations: 38.99128198623657                    Mean Train Rewards: -12201.0\n",
            "Episode: 530 |                     Train Rewards: -8249.0                     Violations: 34.017336368560805                    Mean Train Rewards: -12013.9\n",
            "Episode: 540 |                     Train Rewards: -8882.3                     Violations: 38.36244106292723                    Mean Train Rewards: -11521.2\n",
            "Episode: 550 |                     Train Rewards: -10411.4                     Violations: 55.49348354339598                    Mean Train Rewards: -10949.3\n",
            "Episode: 560 |                     Train Rewards: -5094.2                     Violations: 0                    Mean Train Rewards: -10333.6\n",
            "Episode: 570 |                     Train Rewards: -11409.9                     Violations: 66.43972992897035                    Mean Train Rewards: -9865.3\n",
            "Episode: 580 |                     Train Rewards: -14578.7                     Violations: 99.2690873146057                    Mean Train Rewards: -9711.3\n",
            "Episode: 590 |                     Train Rewards: -10689.6                     Violations: 59.12743806838989                    Mean Train Rewards: -9607.4\n",
            "Episode: 600 |                     Train Rewards: -10466.3                     Violations: 57.090396881103516                    Mean Train Rewards: -9559.2\n",
            "Episode: 610 |                     Train Rewards: -12955.6                     Violations: 82.6213550567627                    Mean Train Rewards: -9534.8\n",
            "Episode: 620 |                     Train Rewards: -11227.9                     Violations: 64.68918919563293                    Mean Train Rewards: -9609.0\n",
            "Episode: 630 |                     Train Rewards: -10847.6                     Violations: 60.62675714492798                    Mean Train Rewards: -9794.3\n",
            "Episode: 640 |                     Train Rewards: -6083.4                     Violations: 11.152561902999878                    Mean Train Rewards: -9867.7\n",
            "Episode: 650 |                     Train Rewards: -5287.8                     Violations: 0                    Mean Train Rewards: -9723.6\n",
            "Episode: 660 |                     Train Rewards: -14414.4                     Violations: 97.58322954177855                    Mean Train Rewards: -9649.7\n",
            "Episode: 670 |                     Train Rewards: -8235.7                     Violations: 33.18828105926514                    Mean Train Rewards: -9613.3\n",
            "Episode: 680 |                     Train Rewards: -5168.1                     Violations: 0                    Mean Train Rewards: -9268.0\n",
            "Episode: 690 |                     Train Rewards: -6020.4                     Violations: 10.634698867797852                    Mean Train Rewards: -8842.4\n",
            "Episode: 700 |                     Train Rewards: -5160.2                     Violations: 0                    Mean Train Rewards: -8380.2\n",
            "Episode: 710 |                     Train Rewards: -5285.8                     Violations: 0                    Mean Train Rewards: -8000.0\n",
            "Episode: 720 |                     Train Rewards: -6066.7                     Violations: 11.228935718536377                    Mean Train Rewards: -7677.4\n",
            "Episode: 730 |                     Train Rewards: -6384.5                     Violations: 14.285036325454712                    Mean Train Rewards: -7499.5\n",
            "Episode: 740 |                     Train Rewards: -11548.8                     Violations: 68.19272756576537                    Mean Train Rewards: -7314.7\n",
            "Episode: 750 |                     Train Rewards: -5302.3                     Violations: 0                    Mean Train Rewards: -7244.0\n",
            "Episode: 760 |                     Train Rewards: -7398.6                     Violations: 25.190228223800645                    Mean Train Rewards: -7294.2\n",
            "Episode: 770 |                     Train Rewards: -8517.1                     Violations: 34.49713945388794                    Mean Train Rewards: -7304.9\n",
            "Episode: 780 |                     Train Rewards: -5215.3                     Violations: 0                    Mean Train Rewards: -7150.4\n",
            "Episode: 790 |                     Train Rewards: -5396.2                     Violations: 0                    Mean Train Rewards: -7060.1\n",
            "Episode: 800 |                     Train Rewards: -5624.4                     Violations: 5.124744176864624                    Mean Train Rewards: -7127.8\n",
            "Episode: 810 |                     Train Rewards: -13722.3                     Violations: 90.48516273498535                    Mean Train Rewards: -7329.3\n",
            "Episode: 820 |                     Train Rewards: -5915.7                     Violations: 8.884021043777466                    Mean Train Rewards: -7353.4\n",
            "Episode: 830 |                     Train Rewards: -6340.5                     Violations: 13.484432697296143                    Mean Train Rewards: -7109.5\n",
            "Episode: 840 |                     Train Rewards: -7881.6                     Violations: 28.209457397460938                    Mean Train Rewards: -7121.5\n",
            "Episode: 850 |                     Train Rewards: -6120.7                     Violations: 10.43190598487854                    Mean Train Rewards: -7120.7\n",
            "Episode: 860 |                     Train Rewards: -9426.5                     Violations: 43.15834999084473                    Mean Train Rewards: -6933.3\n",
            "Episode: 870 |                     Train Rewards: -5360.6                     Violations: 0                    Mean Train Rewards: -6925.2\n",
            "Episode: 880 |                     Train Rewards: -6315.6                     Violations: 13.848464488983154                    Mean Train Rewards: -7038.1\n",
            "Episode: 890 |                     Train Rewards: -6281.6                     Violations: 10.418298244476318                    Mean Train Rewards: -7078.5\n",
            "Episode: 900 |                     Train Rewards: -14860.2                     Violations: 102.1556210517883                    Mean Train Rewards: -7313.6\n",
            "Episode: 910 |                     Train Rewards: -5168.3                     Violations: 0.9277546405792236                    Mean Train Rewards: -7144.4\n",
            "Episode: 920 |                     Train Rewards: -5236.6                     Violations: 1.4103615283965993                    Mean Train Rewards: -7174.1\n",
            "Episode: 930 |                     Train Rewards: -8862.0                     Violations: 37.0959734916687                    Mean Train Rewards: -7169.3\n",
            "Episode: 940 |                     Train Rewards: -5529.1                     Violations: 3.022887706756592                    Mean Train Rewards: -7141.2\n",
            "Episode: 950 |                     Train Rewards: -10352.5                     Violations: 55.92338562011717                    Mean Train Rewards: -7269.6\n",
            "Episode: 960 |                     Train Rewards: -7118.6                     Violations: 19.515361785888672                    Mean Train Rewards: -7340.4\n",
            "Episode: 970 |                     Train Rewards: -8655.3                     Violations: 36.360952854156494                    Mean Train Rewards: -7391.7\n",
            "Episode: 980 |                     Train Rewards: -5248.6                     Violations: 0                    Mean Train Rewards: -7247.0\n",
            "Episode: 990 |                     Train Rewards: -5855.4                     Violations: 7.821264266967773                    Mean Train Rewards: -7259.7\n",
            "Episode: 1000 |                     Train Rewards: -7565.8                     Violations: 25.249216556549072                    Mean Train Rewards: -7045.3\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-67/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-68\n",
            "\n",
            "==================================================\n",
            "Starting run 13/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4736.1                     Violations: 70.57235836982728                    Mean Train Rewards: -4789.5\n",
            "Episode:  20 |                     Train Rewards: -4700.8                     Violations: 79.69679355621338                    Mean Train Rewards: -4756.4\n",
            "Episode:  30 |                     Train Rewards: -4673.4                     Violations: 90.6486701965332                    Mean Train Rewards: -4725.8\n",
            "Episode:  40 |                     Train Rewards: -4766.2                     Violations: 53.500337600707994                    Mean Train Rewards: -4730.5\n",
            "Episode:  50 |                     Train Rewards: -4717.8                     Violations: 72.89018154144287                    Mean Train Rewards: -4748.6\n",
            "Episode:  60 |                     Train Rewards: -4960.7                     Violations: 14.311411380767822                    Mean Train Rewards: -4772.0\n",
            "Episode:  70 |                     Train Rewards: -4658.7                     Violations: 96.52316093444824                    Mean Train Rewards: -4767.7\n",
            "Episode:  80 |                     Train Rewards: -4602.2                     Violations: 119.10668134689332                    Mean Train Rewards: -4751.4\n",
            "Episode:  90 |                     Train Rewards: -4636.8                     Violations: 105.29204130172732                    Mean Train Rewards: -4742.0\n",
            "Episode: 100 |                     Train Rewards: -4794.2                     Violations: 55.734848976135254                    Mean Train Rewards: -4739.1\n",
            "Episode: 110 |                     Train Rewards: -4628.3                     Violations: 108.68116140365599                    Mean Train Rewards: -4725.2\n",
            "Episode: 120 |                     Train Rewards: -4625.0                     Violations: 110.01508951187134                    Mean Train Rewards: -4717.0\n",
            "Episode: 130 |                     Train Rewards: -4703.7                     Violations: 78.7666141986847                    Mean Train Rewards: -4716.2\n",
            "Episode: 140 |                     Train Rewards: -4656.7                     Violations: 97.31820344924927                    Mean Train Rewards: -4710.0\n",
            "Episode: 150 |                     Train Rewards: -4610.5                     Violations: 115.79125642776489                    Mean Train Rewards: -4705.7\n",
            "Episode: 160 |                     Train Rewards: -4828.5                     Violations: 37.61382699012756                    Mean Train Rewards: -4689.2\n",
            "Episode: 170 |                     Train Rewards: -5016.6                     Violations: 15.038659572601318                    Mean Train Rewards: -4713.3\n",
            "Episode: 180 |                     Train Rewards: -5324.6                     Violations: 0                    Mean Train Rewards: -4760.4\n",
            "Episode: 190 |                     Train Rewards: -5018.8                     Violations: 16.11035704612732                    Mean Train Rewards: -4796.3\n",
            "Episode: 200 |                     Train Rewards: -5118.5                     Violations: 0                    Mean Train Rewards: -4827.2\n",
            "Episode: 210 |                     Train Rewards: -5210.2                     Violations: 15.250357389450073                    Mean Train Rewards: -4876.7\n",
            "Episode: 220 |                     Train Rewards: -5029.9                     Violations: 11.641093492507935                    Mean Train Rewards: -4920.7\n",
            "Episode: 230 |                     Train Rewards: -5035.9                     Violations: 41.90182447433472                    Mean Train Rewards: -4959.7\n",
            "Episode: 240 |                     Train Rewards: -4690.2                     Violations: 83.91851902008057                    Mean Train Rewards: -4995.6\n",
            "Episode: 250 |                     Train Rewards: -5447.0                     Violations: 0                    Mean Train Rewards: -5026.0\n",
            "Episode: 260 |                     Train Rewards: -5543.7                     Violations: 0                    Mean Train Rewards: -5062.5\n",
            "Episode: 270 |                     Train Rewards: -4929.7                     Violations: 15.594639778137207                    Mean Train Rewards: -5069.7\n",
            "Episode: 280 |                     Train Rewards: -5378.4                     Violations: 0                    Mean Train Rewards: -5064.8\n",
            "Episode: 290 |                     Train Rewards: -4797.0                     Violations: 54.37930226325989                    Mean Train Rewards: -5077.0\n",
            "Episode: 300 |                     Train Rewards: -5132.2                     Violations: 14.0245521068573                    Mean Train Rewards: -5091.1\n",
            "Episode: 310 |                     Train Rewards: -5409.5                     Violations: 0                    Mean Train Rewards: -5090.1\n",
            "Episode: 320 |                     Train Rewards: -5526.2                     Violations: 0                    Mean Train Rewards: -5103.2\n",
            "Episode: 330 |                     Train Rewards: -4851.2                     Violations: 49.22570943832399                    Mean Train Rewards: -5117.6\n",
            "Episode: 340 |                     Train Rewards: -5126.5                     Violations: 0                    Mean Train Rewards: -5139.5\n",
            "Episode: 350 |                     Train Rewards: -5246.6                     Violations: 9.109654426574707                    Mean Train Rewards: -5140.1\n",
            "Episode: 360 |                     Train Rewards: -4916.8                     Violations: 59.528288841247544                    Mean Train Rewards: -5137.4\n",
            "Episode: 370 |                     Train Rewards: -5077.0                     Violations: 46.33016347885132                    Mean Train Rewards: -5148.2\n",
            "Episode: 380 |                     Train Rewards: -4782.7                     Violations: 57.08435773849487                    Mean Train Rewards: -5147.0\n",
            "Episode: 390 |                     Train Rewards: -5519.5                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 400 |                     Train Rewards: -5418.0                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 410 |                     Train Rewards: -4776.9                     Violations: 58.96626114845276                    Mean Train Rewards: -5141.4\n",
            "Episode: 420 |                     Train Rewards: -5040.3                     Violations: 16.395481824874878                    Mean Train Rewards: -5140.2\n",
            "Episode: 430 |                     Train Rewards: -4685.5                     Violations: 85.81982374191284                    Mean Train Rewards: -5098.0\n",
            "Episode: 440 |                     Train Rewards: -4616.0                     Violations: 113.58714818954469                    Mean Train Rewards: -5041.7\n",
            "Episode: 450 |                     Train Rewards: -4636.5                     Violations: 105.40186882019044                    Mean Train Rewards: -4997.4\n",
            "Episode: 460 |                     Train Rewards: -4669.4                     Violations: 92.2599983215332                    Mean Train Rewards: -4957.2\n",
            "Episode: 470 |                     Train Rewards: -4703.4                     Violations: 78.62668752670288                    Mean Train Rewards: -4912.7\n",
            "Episode: 480 |                     Train Rewards: -4691.6                     Violations: 83.36882114410399                    Mean Train Rewards: -4877.6\n",
            "Episode: 490 |                     Train Rewards: -4737.6                     Violations: 64.9736714363098                    Mean Train Rewards: -4837.2\n",
            "Episode: 500 |                     Train Rewards: -4846.2                     Violations: 30.760644674301147                    Mean Train Rewards: -4800.0\n",
            "Episode: 510 |                     Train Rewards: -4878.6                     Violations: 58.28530550003052                    Mean Train Rewards: -4771.4\n",
            "Episode: 520 |                     Train Rewards: -4914.5                     Violations: 38.99128198623657                    Mean Train Rewards: -4740.2\n",
            "Episode: 530 |                     Train Rewards: -4847.2                     Violations: 34.017336368560805                    Mean Train Rewards: -4755.9\n",
            "Episode: 540 |                     Train Rewards: -5046.1                     Violations: 38.36244106292723                    Mean Train Rewards: -4780.5\n",
            "Episode: 550 |                     Train Rewards: -4862.0                     Violations: 55.49348354339598                    Mean Train Rewards: -4803.7\n",
            "Episode: 560 |                     Train Rewards: -5094.2                     Violations: 0                    Mean Train Rewards: -4837.8\n",
            "Episode: 570 |                     Train Rewards: -4765.9                     Violations: 66.43972992897035                    Mean Train Rewards: -4861.8\n",
            "Episode: 580 |                     Train Rewards: -4651.8                     Violations: 99.2690873146057                    Mean Train Rewards: -4868.0\n",
            "Episode: 590 |                     Train Rewards: -4776.8                     Violations: 59.12743806838989                    Mean Train Rewards: -4871.2\n",
            "Episode: 600 |                     Train Rewards: -4757.3                     Violations: 57.090396881103516                    Mean Train Rewards: -4872.7\n",
            "Episode: 610 |                     Train Rewards: -4693.4                     Violations: 82.6213550567627                    Mean Train Rewards: -4871.3\n",
            "Episode: 620 |                     Train Rewards: -4759.0                     Violations: 64.68918919563293                    Mean Train Rewards: -4864.7\n",
            "Episode: 630 |                     Train Rewards: -4784.9                     Violations: 60.62675714492798                    Mean Train Rewards: -4849.2\n",
            "Episode: 640 |                     Train Rewards: -4968.2                     Violations: 11.152561902999878                    Mean Train Rewards: -4841.2\n",
            "Episode: 650 |                     Train Rewards: -5287.8                     Violations: 0                    Mean Train Rewards: -4855.1\n",
            "Episode: 660 |                     Train Rewards: -4656.0                     Violations: 97.58322954177855                    Mean Train Rewards: -4866.4\n",
            "Episode: 670 |                     Train Rewards: -4916.8                     Violations: 33.18828105926514                    Mean Train Rewards: -4873.5\n",
            "Episode: 680 |                     Train Rewards: -5168.1                     Violations: 0                    Mean Train Rewards: -4904.9\n",
            "Episode: 690 |                     Train Rewards: -4956.9                     Violations: 10.634698867797852                    Mean Train Rewards: -4938.0\n",
            "Episode: 700 |                     Train Rewards: -5160.2                     Violations: 0                    Mean Train Rewards: -4985.1\n",
            "Episode: 710 |                     Train Rewards: -5285.8                     Violations: 0                    Mean Train Rewards: -5017.0\n",
            "Episode: 720 |                     Train Rewards: -4943.9                     Violations: 11.228935718536377                    Mean Train Rewards: -5044.8\n",
            "Episode: 730 |                     Train Rewards: -4956.0                     Violations: 14.285036325454712                    Mean Train Rewards: -5059.0\n",
            "Episode: 740 |                     Train Rewards: -4729.5                     Violations: 68.19272756576537                    Mean Train Rewards: -5087.5\n",
            "Episode: 750 |                     Train Rewards: -5302.3                     Violations: 0                    Mean Train Rewards: -5093.9\n",
            "Episode: 760 |                     Train Rewards: -4879.6                     Violations: 25.190228223800645                    Mean Train Rewards: -5086.9\n",
            "Episode: 770 |                     Train Rewards: -5067.4                     Violations: 34.49713945388794                    Mean Train Rewards: -5096.5\n",
            "Episode: 780 |                     Train Rewards: -5215.3                     Violations: 0                    Mean Train Rewards: -5104.1\n",
            "Episode: 790 |                     Train Rewards: -5396.2                     Violations: 0                    Mean Train Rewards: -5114.5\n",
            "Episode: 800 |                     Train Rewards: -5111.9                     Violations: 5.124744176864624                    Mean Train Rewards: -5097.4\n",
            "Episode: 810 |                     Train Rewards: -4673.8                     Violations: 90.48516273498535                    Mean Train Rewards: -5083.6\n",
            "Episode: 820 |                     Train Rewards: -5027.3                     Violations: 8.884021043777466                    Mean Train Rewards: -5084.4\n",
            "Episode: 830 |                     Train Rewards: -4992.1                     Violations: 13.484432697296143                    Mean Train Rewards: -5107.7\n",
            "Episode: 840 |                     Train Rewards: -5060.7                     Violations: 28.209457397460938                    Mean Train Rewards: -5099.5\n",
            "Episode: 850 |                     Train Rewards: -5077.5                     Violations: 10.43190598487854                    Mean Train Rewards: -5094.4\n",
            "Episode: 860 |                     Train Rewards: -5110.7                     Violations: 43.15834999084473                    Mean Train Rewards: -5107.7\n",
            "Episode: 870 |                     Train Rewards: -5360.6                     Violations: 0                    Mean Train Rewards: -5102.4\n",
            "Episode: 880 |                     Train Rewards: -4930.8                     Violations: 13.848464488983154                    Mean Train Rewards: -5090.4\n",
            "Episode: 890 |                     Train Rewards: -5239.8                     Violations: 10.418298244476318                    Mean Train Rewards: -5086.4\n",
            "Episode: 900 |                     Train Rewards: -4644.6                     Violations: 102.1556210517883                    Mean Train Rewards: -5073.6\n",
            "Episode: 910 |                     Train Rewards: -5075.5                     Violations: 0.9277546405792236                    Mean Train Rewards: -5087.9\n",
            "Episode: 920 |                     Train Rewards: -5095.6                     Violations: 1.4103615283965993                    Mean Train Rewards: -5089.6\n",
            "Episode: 930 |                     Train Rewards: -5152.4                     Violations: 37.0959734916687                    Mean Train Rewards: -5089.6\n",
            "Episode: 940 |                     Train Rewards: -5226.8                     Violations: 3.022887706756592                    Mean Train Rewards: -5089.8\n",
            "Episode: 950 |                     Train Rewards: -4760.2                     Violations: 55.92338562011717                    Mean Train Rewards: -5084.2\n",
            "Episode: 960 |                     Train Rewards: -5167.0                     Violations: 19.515361785888672                    Mean Train Rewards: -5086.7\n",
            "Episode: 970 |                     Train Rewards: -5019.2                     Violations: 36.360952854156494                    Mean Train Rewards: -5082.8\n",
            "Episode: 980 |                     Train Rewards: -5248.6                     Violations: 0                    Mean Train Rewards: -5099.2\n",
            "Episode: 990 |                     Train Rewards: -5073.3                     Violations: 7.821264266967773                    Mean Train Rewards: -5092.9\n",
            "Episode: 1000 |                     Train Rewards: -5040.9                     Violations: 25.249216556549072                    Mean Train Rewards: -5107.0\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-68/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-69\n",
            "\n",
            "==================================================\n",
            "Starting run 14/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 100, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -11793.4                     Violations: 70.57235836982728                    Mean Train Rewards: -10020.9\n",
            "Episode:  20 |                     Train Rewards: -12670.4                     Violations: 79.69679355621338                    Mean Train Rewards: -11015.5\n",
            "Episode:  30 |                     Train Rewards: -13738.2                     Violations: 90.6486701965332                    Mean Train Rewards: -12037.1\n",
            "Episode:  40 |                     Train Rewards: -10116.3                     Violations: 53.500337600707994                    Mean Train Rewards: -11866.6\n",
            "Episode:  50 |                     Train Rewards: -12006.8                     Violations: 72.89018154144287                    Mean Train Rewards: -11341.8\n",
            "Episode:  60 |                     Train Rewards: -6391.8                     Violations: 14.311411380767822                    Mean Train Rewards: -10676.9\n",
            "Episode:  70 |                     Train Rewards: -14311.0                     Violations: 96.52316093444824                    Mean Train Rewards: -10820.5\n",
            "Episode:  80 |                     Train Rewards: -16512.9                     Violations: 119.10668134689332                    Mean Train Rewards: -11363.1\n",
            "Episode:  90 |                     Train Rewards: -15166.0                     Violations: 105.29204130172732                    Mean Train Rewards: -11658.1\n",
            "Episode: 100 |                     Train Rewards: -10367.7                     Violations: 55.734848976135254                    Mean Train Rewards: -11733.5\n",
            "Episode: 110 |                     Train Rewards: -15496.4                     Violations: 108.68116140365599                    Mean Train Rewards: -12196.7\n",
            "Episode: 120 |                     Train Rewards: -15626.5                     Violations: 110.01508951187134                    Mean Train Rewards: -12494.3\n",
            "Episode: 130 |                     Train Rewards: -12580.3                     Violations: 78.7666141986847                    Mean Train Rewards: -12523.6\n",
            "Episode: 140 |                     Train Rewards: -14388.5                     Violations: 97.31820344924927                    Mean Train Rewards: -12737.0\n",
            "Episode: 150 |                     Train Rewards: -16189.6                     Violations: 115.79125642776489                    Mean Train Rewards: -12895.0\n",
            "Episode: 160 |                     Train Rewards: -8589.9                     Violations: 37.61382699012756                    Mean Train Rewards: -13355.1\n",
            "Episode: 170 |                     Train Rewards: -6520.4                     Violations: 15.038659572601318                    Mean Train Rewards: -13000.8\n",
            "Episode: 180 |                     Train Rewards: -5324.6                     Violations: 0                    Mean Train Rewards: -12256.3\n",
            "Episode: 190 |                     Train Rewards: -6629.9                     Violations: 16.11035704612732                    Mean Train Rewards: -11609.1\n",
            "Episode: 200 |                     Train Rewards: -5118.5                     Violations: 0                    Mean Train Rewards: -11096.2\n",
            "Episode: 210 |                     Train Rewards: -6735.2                     Violations: 15.250357389450073                    Mean Train Rewards: -10287.7\n",
            "Episode: 220 |                     Train Rewards: -6194.0                     Violations: 11.641093492507935                    Mean Train Rewards: -9551.7\n",
            "Episode: 230 |                     Train Rewards: -9226.1                     Violations: 41.90182447433472                    Mean Train Rewards: -8847.3\n",
            "Episode: 240 |                     Train Rewards: -13082.1                     Violations: 83.91851902008057                    Mean Train Rewards: -8248.1\n",
            "Episode: 250 |                     Train Rewards: -5447.0                     Violations: 0                    Mean Train Rewards: -7972.7\n",
            "Episode: 260 |                     Train Rewards: -5543.7                     Violations: 0                    Mean Train Rewards: -7466.1\n",
            "Episode: 270 |                     Train Rewards: -6489.2                     Violations: 15.594639778137207                    Mean Train Rewards: -7393.0\n",
            "Episode: 280 |                     Train Rewards: -5378.4                     Violations: 0                    Mean Train Rewards: -7372.0\n",
            "Episode: 290 |                     Train Rewards: -10234.9                     Violations: 54.37930226325989                    Mean Train Rewards: -7296.0\n",
            "Episode: 300 |                     Train Rewards: -6534.6                     Violations: 14.0245521068573                    Mean Train Rewards: -7151.6\n",
            "Episode: 310 |                     Train Rewards: -5409.5                     Violations: 0                    Mean Train Rewards: -7265.3\n",
            "Episode: 320 |                     Train Rewards: -5526.2                     Violations: 0                    Mean Train Rewards: -7151.9\n",
            "Episode: 330 |                     Train Rewards: -9773.8                     Violations: 49.22570943832399                    Mean Train Rewards: -7104.7\n",
            "Episode: 340 |                     Train Rewards: -5126.5                     Violations: 0                    Mean Train Rewards: -6934.9\n",
            "Episode: 350 |                     Train Rewards: -6157.6                     Violations: 9.109654426574707                    Mean Train Rewards: -6818.8\n",
            "Episode: 360 |                     Train Rewards: -10869.7                     Violations: 59.528288841247544                    Mean Train Rewards: -6850.7\n",
            "Episode: 370 |                     Train Rewards: -9710.0                     Violations: 46.33016347885132                    Mean Train Rewards: -6756.8\n",
            "Episode: 380 |                     Train Rewards: -10491.1                     Violations: 57.08435773849487                    Mean Train Rewards: -6749.3\n",
            "Episode: 390 |                     Train Rewards: -5519.5                     Violations: 0                    Mean Train Rewards: -6769.2\n",
            "Episode: 400 |                     Train Rewards: -5418.0                     Violations: 0                    Mean Train Rewards: -6814.8\n",
            "Episode: 410 |                     Train Rewards: -10673.5                     Violations: 58.96626114845276                    Mean Train Rewards: -6712.9\n",
            "Episode: 420 |                     Train Rewards: -6679.8                     Violations: 16.395481824874878                    Mean Train Rewards: -6696.1\n",
            "Episode: 430 |                     Train Rewards: -13267.4                     Violations: 85.81982374191284                    Mean Train Rewards: -7099.0\n",
            "Episode: 440 |                     Train Rewards: -15974.7                     Violations: 113.58714818954469                    Mean Train Rewards: -7815.2\n",
            "Episode: 450 |                     Train Rewards: -15176.7                     Violations: 105.40186882019044                    Mean Train Rewards: -8612.1\n",
            "Episode: 460 |                     Train Rewards: -13895.3                     Violations: 92.2599983215332                    Mean Train Rewards: -9316.1\n",
            "Episode: 470 |                     Train Rewards: -12566.1                     Violations: 78.62668752670288                    Mean Train Rewards: -9943.9\n",
            "Episode: 480 |                     Train Rewards: -13028.5                     Violations: 83.36882114410399                    Mean Train Rewards: -10502.7\n",
            "Episode: 490 |                     Train Rewards: -11234.9                     Violations: 64.9736714363098                    Mean Train Rewards: -11035.3\n",
            "Episode: 500 |                     Train Rewards: -7922.3                     Violations: 30.760644674301147                    Mean Train Rewards: -11510.9\n",
            "Episode: 510 |                     Train Rewards: -10707.2                     Violations: 58.28530550003052                    Mean Train Rewards: -11900.6\n",
            "Episode: 520 |                     Train Rewards: -8813.6                     Violations: 38.99128198623657                    Mean Train Rewards: -12201.0\n",
            "Episode: 530 |                     Train Rewards: -8249.0                     Violations: 34.017336368560805                    Mean Train Rewards: -12013.9\n",
            "Episode: 540 |                     Train Rewards: -8882.3                     Violations: 38.36244106292723                    Mean Train Rewards: -11521.2\n",
            "Episode: 550 |                     Train Rewards: -10411.4                     Violations: 55.49348354339598                    Mean Train Rewards: -10949.3\n",
            "Episode: 560 |                     Train Rewards: -5094.2                     Violations: 0                    Mean Train Rewards: -10333.6\n",
            "Episode: 570 |                     Train Rewards: -11409.9                     Violations: 66.43972992897035                    Mean Train Rewards: -9865.3\n",
            "Episode: 580 |                     Train Rewards: -14578.7                     Violations: 99.2690873146057                    Mean Train Rewards: -9711.3\n",
            "Episode: 590 |                     Train Rewards: -10689.6                     Violations: 59.12743806838989                    Mean Train Rewards: -9607.4\n",
            "Episode: 600 |                     Train Rewards: -10466.3                     Violations: 57.090396881103516                    Mean Train Rewards: -9559.2\n",
            "Episode: 610 |                     Train Rewards: -12955.6                     Violations: 82.6213550567627                    Mean Train Rewards: -9534.8\n",
            "Episode: 620 |                     Train Rewards: -11227.9                     Violations: 64.68918919563293                    Mean Train Rewards: -9609.0\n",
            "Episode: 630 |                     Train Rewards: -10847.6                     Violations: 60.62675714492798                    Mean Train Rewards: -9794.3\n",
            "Episode: 640 |                     Train Rewards: -6083.4                     Violations: 11.152561902999878                    Mean Train Rewards: -9867.7\n",
            "Episode: 650 |                     Train Rewards: -5287.8                     Violations: 0                    Mean Train Rewards: -9723.6\n",
            "Episode: 660 |                     Train Rewards: -14414.4                     Violations: 97.58322954177855                    Mean Train Rewards: -9649.7\n",
            "Episode: 670 |                     Train Rewards: -8235.7                     Violations: 33.18828105926514                    Mean Train Rewards: -9613.3\n",
            "Episode: 680 |                     Train Rewards: -5168.1                     Violations: 0                    Mean Train Rewards: -9268.0\n",
            "Episode: 690 |                     Train Rewards: -6020.4                     Violations: 10.634698867797852                    Mean Train Rewards: -8842.4\n",
            "Episode: 700 |                     Train Rewards: -5160.2                     Violations: 0                    Mean Train Rewards: -8380.2\n",
            "Episode: 710 |                     Train Rewards: -5285.8                     Violations: 0                    Mean Train Rewards: -8000.0\n",
            "Episode: 720 |                     Train Rewards: -6066.7                     Violations: 11.228935718536377                    Mean Train Rewards: -7677.4\n",
            "Episode: 730 |                     Train Rewards: -6384.5                     Violations: 14.285036325454712                    Mean Train Rewards: -7499.5\n",
            "Episode: 740 |                     Train Rewards: -11548.8                     Violations: 68.19272756576537                    Mean Train Rewards: -7314.7\n",
            "Episode: 750 |                     Train Rewards: -5302.3                     Violations: 0                    Mean Train Rewards: -7244.0\n",
            "Episode: 760 |                     Train Rewards: -7398.6                     Violations: 25.190228223800645                    Mean Train Rewards: -7294.2\n",
            "Episode: 770 |                     Train Rewards: -8517.1                     Violations: 34.49713945388794                    Mean Train Rewards: -7304.9\n",
            "Episode: 780 |                     Train Rewards: -5215.3                     Violations: 0                    Mean Train Rewards: -7150.4\n",
            "Episode: 790 |                     Train Rewards: -5396.2                     Violations: 0                    Mean Train Rewards: -7060.1\n",
            "Episode: 800 |                     Train Rewards: -5624.4                     Violations: 5.124744176864624                    Mean Train Rewards: -7127.8\n",
            "Episode: 810 |                     Train Rewards: -13722.3                     Violations: 90.48516273498535                    Mean Train Rewards: -7329.3\n",
            "Episode: 820 |                     Train Rewards: -5915.7                     Violations: 8.884021043777466                    Mean Train Rewards: -7353.4\n",
            "Episode: 830 |                     Train Rewards: -6340.5                     Violations: 13.484432697296143                    Mean Train Rewards: -7109.5\n",
            "Episode: 840 |                     Train Rewards: -7881.6                     Violations: 28.209457397460938                    Mean Train Rewards: -7121.5\n",
            "Episode: 850 |                     Train Rewards: -6120.7                     Violations: 10.43190598487854                    Mean Train Rewards: -7120.7\n",
            "Episode: 860 |                     Train Rewards: -9426.5                     Violations: 43.15834999084473                    Mean Train Rewards: -6933.3\n",
            "Episode: 870 |                     Train Rewards: -5360.6                     Violations: 0                    Mean Train Rewards: -6925.2\n",
            "Episode: 880 |                     Train Rewards: -6315.6                     Violations: 13.848464488983154                    Mean Train Rewards: -7038.1\n",
            "Episode: 890 |                     Train Rewards: -6281.6                     Violations: 10.418298244476318                    Mean Train Rewards: -7078.5\n",
            "Episode: 900 |                     Train Rewards: -14860.2                     Violations: 102.1556210517883                    Mean Train Rewards: -7313.6\n",
            "Episode: 910 |                     Train Rewards: -5168.3                     Violations: 0.9277546405792236                    Mean Train Rewards: -7144.4\n",
            "Episode: 920 |                     Train Rewards: -5236.6                     Violations: 1.4103615283965993                    Mean Train Rewards: -7174.1\n",
            "Episode: 930 |                     Train Rewards: -8862.0                     Violations: 37.0959734916687                    Mean Train Rewards: -7169.3\n",
            "Episode: 940 |                     Train Rewards: -5529.1                     Violations: 3.022887706756592                    Mean Train Rewards: -7141.2\n",
            "Episode: 950 |                     Train Rewards: -10352.5                     Violations: 55.92338562011717                    Mean Train Rewards: -7269.6\n",
            "Episode: 960 |                     Train Rewards: -7118.6                     Violations: 19.515361785888672                    Mean Train Rewards: -7340.4\n",
            "Episode: 970 |                     Train Rewards: -8655.3                     Violations: 36.360952854156494                    Mean Train Rewards: -7391.7\n",
            "Episode: 980 |                     Train Rewards: -5248.6                     Violations: 0                    Mean Train Rewards: -7247.0\n",
            "Episode: 990 |                     Train Rewards: -5855.4                     Violations: 7.821264266967773                    Mean Train Rewards: -7259.7\n",
            "Episode: 1000 |                     Train Rewards: -7565.8                     Violations: 25.249216556549072                    Mean Train Rewards: -7045.3\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 14 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 14 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-69/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-70\n",
            "\n",
            "==================================================\n",
            "Starting run 15/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4736.1                     Violations: 70.57235836982728                    Mean Train Rewards: -4789.5\n",
            "Episode:  20 |                     Train Rewards: -4700.8                     Violations: 79.69679355621338                    Mean Train Rewards: -4756.4\n",
            "Episode:  30 |                     Train Rewards: -4673.4                     Violations: 90.6486701965332                    Mean Train Rewards: -4725.8\n",
            "Episode:  40 |                     Train Rewards: -4766.2                     Violations: 53.500337600707994                    Mean Train Rewards: -4730.5\n",
            "Episode:  50 |                     Train Rewards: -4717.8                     Violations: 72.89018154144287                    Mean Train Rewards: -4748.6\n",
            "Episode:  60 |                     Train Rewards: -4960.7                     Violations: 14.311411380767822                    Mean Train Rewards: -4772.0\n",
            "Episode:  70 |                     Train Rewards: -4658.7                     Violations: 96.52316093444824                    Mean Train Rewards: -4767.7\n",
            "Episode:  80 |                     Train Rewards: -4602.2                     Violations: 119.10668134689332                    Mean Train Rewards: -4751.4\n",
            "Episode:  90 |                     Train Rewards: -4636.8                     Violations: 105.29204130172732                    Mean Train Rewards: -4742.0\n",
            "Episode: 100 |                     Train Rewards: -4794.2                     Violations: 55.734848976135254                    Mean Train Rewards: -4739.1\n",
            "Episode: 110 |                     Train Rewards: -4628.3                     Violations: 108.68116140365599                    Mean Train Rewards: -4725.2\n",
            "Episode: 120 |                     Train Rewards: -4625.0                     Violations: 110.01508951187134                    Mean Train Rewards: -4717.0\n",
            "Episode: 130 |                     Train Rewards: -4703.7                     Violations: 78.7666141986847                    Mean Train Rewards: -4716.2\n",
            "Episode: 140 |                     Train Rewards: -4656.7                     Violations: 97.31820344924927                    Mean Train Rewards: -4710.0\n",
            "Episode: 150 |                     Train Rewards: -4610.5                     Violations: 115.79125642776489                    Mean Train Rewards: -4705.7\n",
            "Episode: 160 |                     Train Rewards: -4828.5                     Violations: 37.61382699012756                    Mean Train Rewards: -4689.2\n",
            "Episode: 170 |                     Train Rewards: -5016.6                     Violations: 15.038659572601318                    Mean Train Rewards: -4713.3\n",
            "Episode: 180 |                     Train Rewards: -5324.6                     Violations: 0                    Mean Train Rewards: -4760.4\n",
            "Episode: 190 |                     Train Rewards: -5018.8                     Violations: 16.11035704612732                    Mean Train Rewards: -4796.3\n",
            "Episode: 200 |                     Train Rewards: -5118.5                     Violations: 0                    Mean Train Rewards: -4827.2\n",
            "Episode: 210 |                     Train Rewards: -5210.2                     Violations: 15.250357389450073                    Mean Train Rewards: -4876.7\n",
            "Episode: 220 |                     Train Rewards: -5029.9                     Violations: 11.641093492507935                    Mean Train Rewards: -4920.7\n",
            "Episode: 230 |                     Train Rewards: -5035.9                     Violations: 41.90182447433472                    Mean Train Rewards: -4959.7\n",
            "Episode: 240 |                     Train Rewards: -4690.2                     Violations: 83.91851902008057                    Mean Train Rewards: -4995.6\n",
            "Episode: 250 |                     Train Rewards: -5447.0                     Violations: 0                    Mean Train Rewards: -5026.0\n",
            "Episode: 260 |                     Train Rewards: -5543.7                     Violations: 0                    Mean Train Rewards: -5062.5\n",
            "Episode: 270 |                     Train Rewards: -4929.7                     Violations: 15.594639778137207                    Mean Train Rewards: -5069.7\n",
            "Episode: 280 |                     Train Rewards: -5378.4                     Violations: 0                    Mean Train Rewards: -5064.8\n",
            "Episode: 290 |                     Train Rewards: -4797.0                     Violations: 54.37930226325989                    Mean Train Rewards: -5077.0\n",
            "Episode: 300 |                     Train Rewards: -5132.2                     Violations: 14.0245521068573                    Mean Train Rewards: -5091.1\n",
            "Episode: 310 |                     Train Rewards: -5409.5                     Violations: 0                    Mean Train Rewards: -5090.1\n",
            "Episode: 320 |                     Train Rewards: -5526.2                     Violations: 0                    Mean Train Rewards: -5103.2\n",
            "Episode: 330 |                     Train Rewards: -4851.2                     Violations: 49.22570943832399                    Mean Train Rewards: -5117.6\n",
            "Episode: 340 |                     Train Rewards: -5126.5                     Violations: 0                    Mean Train Rewards: -5139.5\n",
            "Episode: 350 |                     Train Rewards: -5246.6                     Violations: 9.109654426574707                    Mean Train Rewards: -5140.1\n",
            "Episode: 360 |                     Train Rewards: -4916.8                     Violations: 59.528288841247544                    Mean Train Rewards: -5137.4\n",
            "Episode: 370 |                     Train Rewards: -5077.0                     Violations: 46.33016347885132                    Mean Train Rewards: -5148.2\n",
            "Episode: 380 |                     Train Rewards: -4782.7                     Violations: 57.08435773849487                    Mean Train Rewards: -5147.0\n",
            "Episode: 390 |                     Train Rewards: -5519.5                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 400 |                     Train Rewards: -5418.0                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 410 |                     Train Rewards: -4776.9                     Violations: 58.96626114845276                    Mean Train Rewards: -5141.4\n",
            "Episode: 420 |                     Train Rewards: -5040.3                     Violations: 16.395481824874878                    Mean Train Rewards: -5140.2\n",
            "Episode: 430 |                     Train Rewards: -4685.5                     Violations: 85.81982374191284                    Mean Train Rewards: -5098.0\n",
            "Episode: 440 |                     Train Rewards: -4616.0                     Violations: 113.58714818954469                    Mean Train Rewards: -5041.7\n",
            "Episode: 450 |                     Train Rewards: -4636.5                     Violations: 105.40186882019044                    Mean Train Rewards: -4997.4\n",
            "Episode: 460 |                     Train Rewards: -4669.4                     Violations: 92.2599983215332                    Mean Train Rewards: -4957.2\n",
            "Episode: 470 |                     Train Rewards: -4703.4                     Violations: 78.62668752670288                    Mean Train Rewards: -4912.7\n",
            "Episode: 480 |                     Train Rewards: -4691.6                     Violations: 83.36882114410399                    Mean Train Rewards: -4877.6\n",
            "Episode: 490 |                     Train Rewards: -4737.6                     Violations: 64.9736714363098                    Mean Train Rewards: -4837.2\n",
            "Episode: 500 |                     Train Rewards: -4846.2                     Violations: 30.760644674301147                    Mean Train Rewards: -4800.0\n",
            "Episode: 510 |                     Train Rewards: -4878.6                     Violations: 58.28530550003052                    Mean Train Rewards: -4771.4\n",
            "Episode: 520 |                     Train Rewards: -4914.5                     Violations: 38.99128198623657                    Mean Train Rewards: -4740.2\n",
            "Episode: 530 |                     Train Rewards: -4847.2                     Violations: 34.017336368560805                    Mean Train Rewards: -4755.9\n",
            "Episode: 540 |                     Train Rewards: -5046.1                     Violations: 38.36244106292723                    Mean Train Rewards: -4780.5\n",
            "Episode: 550 |                     Train Rewards: -4862.0                     Violations: 55.49348354339598                    Mean Train Rewards: -4803.7\n",
            "Episode: 560 |                     Train Rewards: -5094.2                     Violations: 0                    Mean Train Rewards: -4837.8\n",
            "Episode: 570 |                     Train Rewards: -4765.9                     Violations: 66.43972992897035                    Mean Train Rewards: -4861.8\n",
            "Episode: 580 |                     Train Rewards: -4651.8                     Violations: 99.2690873146057                    Mean Train Rewards: -4868.0\n",
            "Episode: 590 |                     Train Rewards: -4776.8                     Violations: 59.12743806838989                    Mean Train Rewards: -4871.2\n",
            "Episode: 600 |                     Train Rewards: -4757.3                     Violations: 57.090396881103516                    Mean Train Rewards: -4872.7\n",
            "Episode: 610 |                     Train Rewards: -4693.4                     Violations: 82.6213550567627                    Mean Train Rewards: -4871.3\n",
            "Episode: 620 |                     Train Rewards: -4759.0                     Violations: 64.68918919563293                    Mean Train Rewards: -4864.7\n",
            "Episode: 630 |                     Train Rewards: -4784.9                     Violations: 60.62675714492798                    Mean Train Rewards: -4849.2\n",
            "Episode: 640 |                     Train Rewards: -4968.2                     Violations: 11.152561902999878                    Mean Train Rewards: -4841.2\n",
            "Episode: 650 |                     Train Rewards: -5287.8                     Violations: 0                    Mean Train Rewards: -4855.1\n",
            "Episode: 660 |                     Train Rewards: -4656.0                     Violations: 97.58322954177855                    Mean Train Rewards: -4866.4\n",
            "Episode: 670 |                     Train Rewards: -4916.8                     Violations: 33.18828105926514                    Mean Train Rewards: -4873.5\n",
            "Episode: 680 |                     Train Rewards: -5168.1                     Violations: 0                    Mean Train Rewards: -4904.9\n",
            "Episode: 690 |                     Train Rewards: -4956.9                     Violations: 10.634698867797852                    Mean Train Rewards: -4938.0\n",
            "Episode: 700 |                     Train Rewards: -5160.2                     Violations: 0                    Mean Train Rewards: -4985.1\n",
            "Episode: 710 |                     Train Rewards: -5285.8                     Violations: 0                    Mean Train Rewards: -5017.0\n",
            "Episode: 720 |                     Train Rewards: -4943.9                     Violations: 11.228935718536377                    Mean Train Rewards: -5044.8\n",
            "Episode: 730 |                     Train Rewards: -4956.0                     Violations: 14.285036325454712                    Mean Train Rewards: -5059.0\n",
            "Episode: 740 |                     Train Rewards: -4729.5                     Violations: 68.19272756576537                    Mean Train Rewards: -5087.5\n",
            "Episode: 750 |                     Train Rewards: -5302.3                     Violations: 0                    Mean Train Rewards: -5093.9\n",
            "Episode: 760 |                     Train Rewards: -4879.6                     Violations: 25.190228223800645                    Mean Train Rewards: -5086.9\n",
            "Episode: 770 |                     Train Rewards: -5067.4                     Violations: 34.49713945388794                    Mean Train Rewards: -5096.5\n",
            "Episode: 780 |                     Train Rewards: -5215.3                     Violations: 0                    Mean Train Rewards: -5104.1\n",
            "Episode: 790 |                     Train Rewards: -5396.2                     Violations: 0                    Mean Train Rewards: -5114.5\n",
            "Episode: 800 |                     Train Rewards: -5111.9                     Violations: 5.124744176864624                    Mean Train Rewards: -5097.4\n",
            "Episode: 810 |                     Train Rewards: -4673.8                     Violations: 90.48516273498535                    Mean Train Rewards: -5083.6\n",
            "Episode: 820 |                     Train Rewards: -5027.3                     Violations: 8.884021043777466                    Mean Train Rewards: -5084.4\n",
            "Episode: 830 |                     Train Rewards: -4992.1                     Violations: 13.484432697296143                    Mean Train Rewards: -5107.7\n",
            "Episode: 840 |                     Train Rewards: -5060.7                     Violations: 28.209457397460938                    Mean Train Rewards: -5099.5\n",
            "Episode: 850 |                     Train Rewards: -5077.5                     Violations: 10.43190598487854                    Mean Train Rewards: -5094.4\n",
            "Episode: 860 |                     Train Rewards: -5110.7                     Violations: 43.15834999084473                    Mean Train Rewards: -5107.7\n",
            "Episode: 870 |                     Train Rewards: -5360.6                     Violations: 0                    Mean Train Rewards: -5102.4\n",
            "Episode: 880 |                     Train Rewards: -4930.8                     Violations: 13.848464488983154                    Mean Train Rewards: -5090.4\n",
            "Episode: 890 |                     Train Rewards: -5239.8                     Violations: 10.418298244476318                    Mean Train Rewards: -5086.4\n",
            "Episode: 900 |                     Train Rewards: -4644.6                     Violations: 102.1556210517883                    Mean Train Rewards: -5073.6\n",
            "Episode: 910 |                     Train Rewards: -5075.5                     Violations: 0.9277546405792236                    Mean Train Rewards: -5087.9\n",
            "Episode: 920 |                     Train Rewards: -5095.6                     Violations: 1.4103615283965993                    Mean Train Rewards: -5089.6\n",
            "Episode: 930 |                     Train Rewards: -5152.4                     Violations: 37.0959734916687                    Mean Train Rewards: -5089.6\n",
            "Episode: 940 |                     Train Rewards: -5226.8                     Violations: 3.022887706756592                    Mean Train Rewards: -5089.8\n",
            "Episode: 950 |                     Train Rewards: -4760.2                     Violations: 55.92338562011717                    Mean Train Rewards: -5084.2\n",
            "Episode: 960 |                     Train Rewards: -5167.0                     Violations: 19.515361785888672                    Mean Train Rewards: -5086.7\n",
            "Episode: 970 |                     Train Rewards: -5019.2                     Violations: 36.360952854156494                    Mean Train Rewards: -5082.8\n",
            "Episode: 980 |                     Train Rewards: -5248.6                     Violations: 0                    Mean Train Rewards: -5099.2\n",
            "Episode: 990 |                     Train Rewards: -5073.3                     Violations: 7.821264266967773                    Mean Train Rewards: -5092.9\n",
            "Episode: 1000 |                     Train Rewards: -5040.9                     Violations: 25.249216556549072                    Mean Train Rewards: -5107.0\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 22 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 22 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-70/metadata\n",
            "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-71\n",
            "\n",
            "==================================================\n",
            "Starting run 16/16, seed 7\n",
            "Parameters: {'optimizer_name': 'Adam', 'MAX_EPISODES': 1000, 'PRINT_INTERVAL': 10, 'N_TRIALS': 100, 'DROPOUT': 0, 'LEARNING_RATE': 0.0001, 'EPSILON': 0.1, 'ENTROPY_COEFFICIENT': 0.01, 'HIDDEN_DIMENSIONS': 64, 'PPO_STEPS': 16, 'BATCH_SIZE': 256, 'DISCOUNT_FACTOR': 0.99, 'constraint_penalty_factor': 0, 'episode_length': 2, 'SEED': 7}\n",
            "==================================================\n",
            "\n",
            "Initialized Beta parameters to produce uniform-like distribution\n",
            "Episode:  10 |                     Train Rewards: -4736.1                     Violations: 70.57235836982728                    Mean Train Rewards: -4789.5\n",
            "Episode:  20 |                     Train Rewards: -4700.8                     Violations: 79.69679355621338                    Mean Train Rewards: -4756.4\n",
            "Episode:  30 |                     Train Rewards: -4673.4                     Violations: 90.6486701965332                    Mean Train Rewards: -4725.8\n",
            "Episode:  40 |                     Train Rewards: -4766.2                     Violations: 53.500337600707994                    Mean Train Rewards: -4730.5\n",
            "Episode:  50 |                     Train Rewards: -4717.8                     Violations: 72.89018154144287                    Mean Train Rewards: -4748.6\n",
            "Episode:  60 |                     Train Rewards: -4960.7                     Violations: 14.311411380767822                    Mean Train Rewards: -4772.0\n",
            "Episode:  70 |                     Train Rewards: -4658.7                     Violations: 96.52316093444824                    Mean Train Rewards: -4767.7\n",
            "Episode:  80 |                     Train Rewards: -4602.2                     Violations: 119.10668134689332                    Mean Train Rewards: -4751.4\n",
            "Episode:  90 |                     Train Rewards: -4636.8                     Violations: 105.29204130172732                    Mean Train Rewards: -4742.0\n",
            "Episode: 100 |                     Train Rewards: -4794.2                     Violations: 55.734848976135254                    Mean Train Rewards: -4739.1\n",
            "Episode: 110 |                     Train Rewards: -4628.3                     Violations: 108.68116140365599                    Mean Train Rewards: -4725.2\n",
            "Episode: 120 |                     Train Rewards: -4625.0                     Violations: 110.01508951187134                    Mean Train Rewards: -4717.0\n",
            "Episode: 130 |                     Train Rewards: -4703.7                     Violations: 78.7666141986847                    Mean Train Rewards: -4716.2\n",
            "Episode: 140 |                     Train Rewards: -4656.7                     Violations: 97.31820344924927                    Mean Train Rewards: -4710.0\n",
            "Episode: 150 |                     Train Rewards: -4610.5                     Violations: 115.79125642776489                    Mean Train Rewards: -4705.7\n",
            "Episode: 160 |                     Train Rewards: -4828.5                     Violations: 37.61382699012756                    Mean Train Rewards: -4689.2\n",
            "Episode: 170 |                     Train Rewards: -5016.6                     Violations: 15.038659572601318                    Mean Train Rewards: -4713.3\n",
            "Episode: 180 |                     Train Rewards: -5324.6                     Violations: 0                    Mean Train Rewards: -4760.4\n",
            "Episode: 190 |                     Train Rewards: -5018.8                     Violations: 16.11035704612732                    Mean Train Rewards: -4796.3\n",
            "Episode: 200 |                     Train Rewards: -5118.5                     Violations: 0                    Mean Train Rewards: -4827.2\n",
            "Episode: 210 |                     Train Rewards: -5210.2                     Violations: 15.250357389450073                    Mean Train Rewards: -4876.7\n",
            "Episode: 220 |                     Train Rewards: -5029.9                     Violations: 11.641093492507935                    Mean Train Rewards: -4920.7\n",
            "Episode: 230 |                     Train Rewards: -5035.9                     Violations: 41.90182447433472                    Mean Train Rewards: -4959.7\n",
            "Episode: 240 |                     Train Rewards: -4690.2                     Violations: 83.91851902008057                    Mean Train Rewards: -4995.6\n",
            "Episode: 250 |                     Train Rewards: -5447.0                     Violations: 0                    Mean Train Rewards: -5026.0\n",
            "Episode: 260 |                     Train Rewards: -5543.7                     Violations: 0                    Mean Train Rewards: -5062.5\n",
            "Episode: 270 |                     Train Rewards: -4929.7                     Violations: 15.594639778137207                    Mean Train Rewards: -5069.7\n",
            "Episode: 280 |                     Train Rewards: -5378.4                     Violations: 0                    Mean Train Rewards: -5064.8\n",
            "Episode: 290 |                     Train Rewards: -4797.0                     Violations: 54.37930226325989                    Mean Train Rewards: -5077.0\n",
            "Episode: 300 |                     Train Rewards: -5132.2                     Violations: 14.0245521068573                    Mean Train Rewards: -5091.1\n",
            "Episode: 310 |                     Train Rewards: -5409.5                     Violations: 0                    Mean Train Rewards: -5090.1\n",
            "Episode: 320 |                     Train Rewards: -5526.2                     Violations: 0                    Mean Train Rewards: -5103.2\n",
            "Episode: 330 |                     Train Rewards: -4851.2                     Violations: 49.22570943832399                    Mean Train Rewards: -5117.6\n",
            "Episode: 340 |                     Train Rewards: -5126.5                     Violations: 0                    Mean Train Rewards: -5139.5\n",
            "Episode: 350 |                     Train Rewards: -5246.6                     Violations: 9.109654426574707                    Mean Train Rewards: -5140.1\n",
            "Episode: 360 |                     Train Rewards: -4916.8                     Violations: 59.528288841247544                    Mean Train Rewards: -5137.4\n",
            "Episode: 370 |                     Train Rewards: -5077.0                     Violations: 46.33016347885132                    Mean Train Rewards: -5148.2\n",
            "Episode: 380 |                     Train Rewards: -4782.7                     Violations: 57.08435773849487                    Mean Train Rewards: -5147.0\n",
            "Episode: 390 |                     Train Rewards: -5519.5                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 400 |                     Train Rewards: -5418.0                     Violations: 0                    Mean Train Rewards: -5145.5\n",
            "Episode: 410 |                     Train Rewards: -4776.9                     Violations: 58.96626114845276                    Mean Train Rewards: -5141.4\n",
            "Episode: 420 |                     Train Rewards: -5040.3                     Violations: 16.395481824874878                    Mean Train Rewards: -5140.2\n",
            "Episode: 430 |                     Train Rewards: -4685.5                     Violations: 85.81982374191284                    Mean Train Rewards: -5098.0\n",
            "Episode: 440 |                     Train Rewards: -4616.0                     Violations: 113.58714818954469                    Mean Train Rewards: -5041.7\n",
            "Episode: 450 |                     Train Rewards: -4636.5                     Violations: 105.40186882019044                    Mean Train Rewards: -4997.4\n",
            "Episode: 460 |                     Train Rewards: -4669.4                     Violations: 92.2599983215332                    Mean Train Rewards: -4957.2\n",
            "Episode: 470 |                     Train Rewards: -4703.4                     Violations: 78.62668752670288                    Mean Train Rewards: -4912.7\n",
            "Episode: 480 |                     Train Rewards: -4691.6                     Violations: 83.36882114410399                    Mean Train Rewards: -4877.6\n",
            "Episode: 490 |                     Train Rewards: -4737.6                     Violations: 64.9736714363098                    Mean Train Rewards: -4837.2\n",
            "Episode: 500 |                     Train Rewards: -4846.2                     Violations: 30.760644674301147                    Mean Train Rewards: -4800.0\n",
            "Episode: 510 |                     Train Rewards: -4878.6                     Violations: 58.28530550003052                    Mean Train Rewards: -4771.4\n",
            "Episode: 520 |                     Train Rewards: -4914.5                     Violations: 38.99128198623657                    Mean Train Rewards: -4740.2\n",
            "Episode: 530 |                     Train Rewards: -4847.2                     Violations: 34.017336368560805                    Mean Train Rewards: -4755.9\n",
            "Episode: 540 |                     Train Rewards: -5046.1                     Violations: 38.36244106292723                    Mean Train Rewards: -4780.5\n",
            "Episode: 550 |                     Train Rewards: -4862.0                     Violations: 55.49348354339598                    Mean Train Rewards: -4803.7\n",
            "Episode: 560 |                     Train Rewards: -5094.2                     Violations: 0                    Mean Train Rewards: -4837.8\n",
            "Episode: 570 |                     Train Rewards: -4765.9                     Violations: 66.43972992897035                    Mean Train Rewards: -4861.8\n",
            "Episode: 580 |                     Train Rewards: -4651.8                     Violations: 99.2690873146057                    Mean Train Rewards: -4868.0\n",
            "Episode: 590 |                     Train Rewards: -4776.8                     Violations: 59.12743806838989                    Mean Train Rewards: -4871.2\n",
            "Episode: 600 |                     Train Rewards: -4757.3                     Violations: 57.090396881103516                    Mean Train Rewards: -4872.7\n",
            "Episode: 610 |                     Train Rewards: -4693.4                     Violations: 82.6213550567627                    Mean Train Rewards: -4871.3\n",
            "Episode: 620 |                     Train Rewards: -4759.0                     Violations: 64.68918919563293                    Mean Train Rewards: -4864.7\n",
            "Episode: 630 |                     Train Rewards: -4784.9                     Violations: 60.62675714492798                    Mean Train Rewards: -4849.2\n",
            "Episode: 640 |                     Train Rewards: -4968.2                     Violations: 11.152561902999878                    Mean Train Rewards: -4841.2\n",
            "Episode: 650 |                     Train Rewards: -5287.8                     Violations: 0                    Mean Train Rewards: -4855.1\n",
            "Episode: 660 |                     Train Rewards: -4656.0                     Violations: 97.58322954177855                    Mean Train Rewards: -4866.4\n",
            "Episode: 670 |                     Train Rewards: -4916.8                     Violations: 33.18828105926514                    Mean Train Rewards: -4873.5\n",
            "Episode: 680 |                     Train Rewards: -5168.1                     Violations: 0                    Mean Train Rewards: -4904.9\n",
            "Episode: 690 |                     Train Rewards: -4956.9                     Violations: 10.634698867797852                    Mean Train Rewards: -4938.0\n",
            "Episode: 700 |                     Train Rewards: -5160.2                     Violations: 0                    Mean Train Rewards: -4985.1\n",
            "Episode: 710 |                     Train Rewards: -5285.8                     Violations: 0                    Mean Train Rewards: -5017.0\n",
            "Episode: 720 |                     Train Rewards: -4943.9                     Violations: 11.228935718536377                    Mean Train Rewards: -5044.8\n",
            "Episode: 730 |                     Train Rewards: -4956.0                     Violations: 14.285036325454712                    Mean Train Rewards: -5059.0\n",
            "Episode: 740 |                     Train Rewards: -4729.5                     Violations: 68.19272756576537                    Mean Train Rewards: -5087.5\n",
            "Episode: 750 |                     Train Rewards: -5302.3                     Violations: 0                    Mean Train Rewards: -5093.9\n",
            "Episode: 760 |                     Train Rewards: -4879.6                     Violations: 25.190228223800645                    Mean Train Rewards: -5086.9\n",
            "Episode: 770 |                     Train Rewards: -5067.4                     Violations: 34.49713945388794                    Mean Train Rewards: -5096.5\n",
            "Episode: 780 |                     Train Rewards: -5215.3                     Violations: 0                    Mean Train Rewards: -5104.1\n",
            "Episode: 790 |                     Train Rewards: -5396.2                     Violations: 0                    Mean Train Rewards: -5114.5\n",
            "Episode: 800 |                     Train Rewards: -5111.9                     Violations: 5.124744176864624                    Mean Train Rewards: -5097.4\n",
            "Episode: 810 |                     Train Rewards: -4673.8                     Violations: 90.48516273498535                    Mean Train Rewards: -5083.6\n",
            "Episode: 820 |                     Train Rewards: -5027.3                     Violations: 8.884021043777466                    Mean Train Rewards: -5084.4\n",
            "Episode: 830 |                     Train Rewards: -4992.1                     Violations: 13.484432697296143                    Mean Train Rewards: -5107.7\n",
            "Episode: 840 |                     Train Rewards: -5060.7                     Violations: 28.209457397460938                    Mean Train Rewards: -5099.5\n",
            "Episode: 850 |                     Train Rewards: -5077.5                     Violations: 10.43190598487854                    Mean Train Rewards: -5094.4\n",
            "Episode: 860 |                     Train Rewards: -5110.7                     Violations: 43.15834999084473                    Mean Train Rewards: -5107.7\n",
            "Episode: 870 |                     Train Rewards: -5360.6                     Violations: 0                    Mean Train Rewards: -5102.4\n",
            "Episode: 880 |                     Train Rewards: -4930.8                     Violations: 13.848464488983154                    Mean Train Rewards: -5090.4\n",
            "Episode: 890 |                     Train Rewards: -5239.8                     Violations: 10.418298244476318                    Mean Train Rewards: -5086.4\n",
            "Episode: 900 |                     Train Rewards: -4644.6                     Violations: 102.1556210517883                    Mean Train Rewards: -5073.6\n",
            "Episode: 910 |                     Train Rewards: -5075.5                     Violations: 0.9277546405792236                    Mean Train Rewards: -5087.9\n",
            "Episode: 920 |                     Train Rewards: -5095.6                     Violations: 1.4103615283965993                    Mean Train Rewards: -5089.6\n",
            "Episode: 930 |                     Train Rewards: -5152.4                     Violations: 37.0959734916687                    Mean Train Rewards: -5089.6\n",
            "Episode: 940 |                     Train Rewards: -5226.8                     Violations: 3.022887706756592                    Mean Train Rewards: -5089.8\n",
            "Episode: 950 |                     Train Rewards: -4760.2                     Violations: 55.92338562011717                    Mean Train Rewards: -5084.2\n",
            "Episode: 960 |                     Train Rewards: -5167.0                     Violations: 19.515361785888672                    Mean Train Rewards: -5086.7\n",
            "Episode: 970 |                     Train Rewards: -5019.2                     Violations: 36.360952854156494                    Mean Train Rewards: -5082.8\n",
            "Episode: 980 |                     Train Rewards: -5248.6                     Violations: 0                    Mean Train Rewards: -5099.2\n",
            "Episode: 990 |                     Train Rewards: -5073.3                     Violations: 7.821264266967773                    Mean Train Rewards: -5092.9\n",
            "Episode: 1000 |                     Train Rewards: -5040.9                     Violations: 25.249216556549072                    Mean Train Rewards: -5107.0\n",
            "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
            "[neptune] [info   ] Done!\n",
            "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
            "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
            "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/EnergyGridRL/PPO-2snapshots-replacement/e/PPOS1-71/metadata\n"
          ]
        }
      ],
      "source": [
        "run_sweep_replacement(\"replacement\")\n",
        "run_sweep_replacement(\"summation\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pypsa-za",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
